comment_id,content_id,platform,content,created_at,score,author,source_name
mmjksaf,1jwmwdy,reddit,"He built it in 9 days, and rested on the 10th. That's one two week sprint.",2025-04-11 11:09:11,2989,rcls0053,programming
mmjmrz3,1jwmwdy,reddit,"In an interview, he said, he ruminates the design over several months. Then he wrote the first version in ten days. Then after that only he starts using git for kernel development. Then handover git development after four months.",2025-04-11 11:24:44,913,zemega,programming
mmjnk86,1jwmwdy,reddit,Vast oversimplification,2025-04-11 11:30:46,423,ziplock9000,programming
mmjjxub,1jwmwdy,reddit,The hard part is design. Git still exists because the design is extremely useful and flexible.,2025-04-11 11:02:12,473,Isogash,programming
mmjl5h3,1jwmwdy,reddit,Imagine how fast he would do it today with vibe coding!,2025-04-11 11:12:08,258,TyrusX,programming
mmkqqmf,1jwmwdy,reddit,"Linux Torvalds built Git in 10 days... Plus the decades spent working on related problems and systems. Like the article said, he'd been thinking about it for a while, and he had plenty of chance to explore similar products, consult various implementations, and apply various ideas to a very specific problem that plagued him in his job.

If you understand a problem, and have a specific solution in mind, the ""writing the code"" part is just the final step of bringing the idea from your head into reality. If you can do it in 10 days, that just means you've already done months if not years of work leading up to that final sprint.",2025-04-11 15:15:31,23,TikiTDO,programming
mmjwjv3,1jwmwdy,reddit,ah but he didn't have a product manager. with a product manager you can work 20 years and the result will last for 10 days.,2025-04-11 12:33:06,42,I_AM_GODDAMN_BATMAN,programming
mmkcyqg,1jwmwdy,reddit,Linux Torvalds was able to build this in a cave! With a box of scraps!,2025-04-11 14:06:52,35,ants_a,programming
mmkpxab,1jwmwdy,reddit,Linus Torvalds built this thing **in a cave**. With a box of **shell scripts**.,2025-04-11 15:11:32,14,Zomunieo,programming
mmlly2n,1jwmwdy,reddit,"I always hate this type of mentality.   I'm sure he built version .1 in 10 days.   There's been a LOT of workover the years, that's why it's on version 2.49 and not .1 or 1.

This is the difference between ""Concept"" ""Proof of Concept"" and ""Execution""..  People think the job is done after proof... it's not.  Apparently Concept is multiple months before this point, and execution has had a lot of work done after this point.",2025-04-11 17:48:17,12,Kinglink,programming
mmjui08,1jwmwdy,reddit,It certainly shows.,2025-04-11 12:19:37,23,DrinkyBird_,programming
mmjs9k7,1jwmwdy,reddit,"There used to be a whole industry building very expensive and time and resource hungry products like Clearcase and Accurev. Git hasn't dominated because its free - lots of payware coexists with free alternatives. Git's USP is that it does the right thing. Linus found out what the right thing is by doing a *huge* collaborative source management job for years.

Whenever I have to do something with git away from a  very limited workflow I have to puzzle over the doco, and then I can do what I want. Its not intuitive at all but it works.

I suspect that the SCM problem domain is inherently counter-intuitive for humans. The commercial products tried to put an intuitive skin on a counter-intuitive problem and failed to represent it. Normal requirements elicitation failed because the users couldn't understand what they wanted. Linus scripted fixes for his suffering and scored because his problem was big enough to teach him about the domain. The result are commands that look weird, upside down, and work.

What other deep problems could be solved by modest scripts doing the right thing, but which are cognitively inaccessible?",2025-04-11 12:04:22,19,alangcarter,programming
mmk6fza,1jwmwdy,reddit,"Linus was using another VCS system licensed for free from a company, I forget the name of it. At some point the company ended the arrangement on short notice so Linus thought fuckit I’ll make my own. Perhaps some of you can supply more accurate info.",2025-04-11 13:32:29,16,mok000,programming
mmjrayd,1jwmwdy,reddit,Just as an interesting parallel: there's this other thing that was famously built in 10 days and its developer very likely didn't think it would last *30* years.,2025-04-11 11:57:42,14,Sharlinator,programming
mmkwjsz,1jwmwdy,reddit,He seems to have a knack for designing things that last longer than expected.,2025-04-11 15:43:50,3,sacheie,programming
mmlk0vc,1jwmwdy,reddit,"Fossil
https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://fossil-scm.org/&ved=2ahUKEwj9u9L4wtCMAxXQHDQIHQWaLS8QFnoECBQQAQ&usg=AOvVaw3u6Bf--4wZ1nTSrHRpNmjK",2025-04-11 17:38:57,5,tclbuzz,programming
mmlkmyi,1jwmwdy,reddit,Was he vibe coding it?,2025-04-11 17:41:55,5,xplorer00,programming
mmluv2p,1jwmwdy,reddit,"What about [Fossil](https://fossil-scm.org/home/doc/trunk/www/index.wiki) ?

It seems designed with a focus on better workflow than the other DVCS.",2025-04-11 18:32:44,5,Nicolay77,programming
mmjtiu7,1jwmwdy,reddit,"JavaScript / Brendan Eich vibes.

Except… git was either a much better design, or had benefits in being able to evolve its design over time. JavaScript (then ""LiveScript"") still fights decisions from 30 years ago.",2025-04-11 12:13:02,10,chucker23n,programming
mml00sd,1jwmwdy,reddit,"Yeah and it shows. Git is the Javascript of version control. Invented out of necessity but now we're suffering through its inconsistent garbage user interface every day.

What I don't understand is why, unlike JS, people defend it like there could be nothing better. Is it because Torvalds invented it? Mind you, only a linuxbrain could defend CLI spaghetti like that.

I used to use mercurial back before it died, which was a lot more sensible in many ways. In the mean time, I'll continue trying to decipher [arcane indecipherable bollocks](https://git-man-page-generator.lokaltog.net/) every time I want to do anything outside push/pull/merge.",2025-04-11 16:00:36,16,Xenoprimate,programming
mmjtjcq,1jwmwdy,reddit,A lot of original git was perl scripts too!,2025-04-11 12:13:08,3,commandersaki,programming
mmkc2jp,1jwmwdy,reddit,"To be fair, he soon handed it over to Junio Hamano who did an excellent job maintaining it over the years.",2025-04-11 14:02:15,3,TyPh00nCdrCool,programming
mmle5kz,1jwmwdy,reddit,It's only 20 years old. It sure got quickly adopted,2025-04-11 17:10:26,3,Baardi,programming
mmn46z9,1jwmwdy,reddit,"\> Give me six hours to chop down a tree and I will spend the first four sharpening the axe.  
\-- Linus Torvalds",2025-04-11 22:32:23,3,WhiteSkyRising,programming
mml2hq2,1jwmwdy,reddit,"Amazing what you can do when you are product, engineering and qa all in one.",2025-04-11 16:13:00,5,alwyn,programming
mmlxln4,1jwmwdy,reddit,"And that's why it's so difficult to use, no where else in the process were any other domain experts consulted. I'm sure an English major or technical writer would have made it much more pleasant tool to use.",2025-04-11 18:46:39,4,ROGER_CHOCS,programming
mmma2s1,1jwmwdy,reddit,Perforce wasn’t happy ,2025-04-11 19:50:55,2,kevleyski,programming
mmo6tzr,1jwmwdy,reddit,"> **Linus Torvalds built git in a cave! With a box of scrapes!**

Some manager probably",2025-04-12 02:34:07,2,miversen33,programming
mmosbml,1jwmwdy,reddit,Also consider it was halfway to Bitcoin. It shares a lot of similarities.,2025-04-12 05:18:34,2,chcampb,programming
mmpw24y,1jwmwdy,reddit,"I hope we get a rewrite in rust some day. I always say, that should be the benchmark for LLMs. Rewrite git in Rust.",2025-04-12 11:50:34,2,totkeks,programming
mmsojuo,1jwmwdy,reddit,"What's fascinating about Git's story is how it demonstrates the power of deeply understanding the problem domain before writing a single line of code.

Torvalds didn't just create Git in 10 days - he spent months thinking about what version control should actually do. He had years of experience with the problems of distributed development through Linux kernel maintenance, and understood exactly what was wrong with existing systems.

The content-addressable filesystem at Git's core is conceptually elegant yet incredibly powerful. Unlike many systems that evolve through feature accretion, Git started with solid foundational principles: cryptographic integrity, distributed operation, and performance.

This is why many initially found Git's interface confusing but its core model has remained remarkably stable for 20 years. The interface could be improved (and has been with tools like GitHub), but the fundamental data model was right from the beginning.

It's a great reminder that in software development, the time spent thinking and designing often produces more lasting value than just writing code quickly.",2025-04-12 21:15:51,2,traderprof,programming
mmju2zm,1jwmwdy,reddit,"JavaScript was also built in 10 days.

**Update:** https://www.computer.org/csdl/magazine/co/2012/02/mco2012020007/13rRUy08MzA",2025-04-11 12:16:50,5,jabbalaci,programming
mmjv1yp,1jwmwdy,reddit,The whole [youtube interview](https://www.youtube.com/watch?v=sCr_gb8rdEI),2025-04-11 12:23:18,2,dvidsilva,programming
mmkv6bm,1jwmwdy,reddit,He did this too? Wow,2025-04-11 15:37:10,1,qpxa,programming
mml9ci8,1jwmwdy,reddit,I wish he was right.,2025-04-11 16:47:04,1,Mr_Loopers,programming
mmld2y7,1jwmwdy,reddit,Shit article no mention of Junio Hamano who has been leading git ever since Linus laid the core foundation,2025-04-11 17:05:12,1,haro0828,programming
mmlxbmj,1jwmwdy,reddit,The goat,2025-04-11 18:45:13,1,snowcamel,programming
mmn6gf3,1jwmwdy,reddit,I really liked the mercurial and how it worked out of the box. Then github's adoption made git more popular.,2025-04-11 22:46:04,1,ffiw,programming
mmniqjp,1jwmwdy,reddit,"Git is the thing I use on a daily basis, that, and the linux kernel using LinuxMint.",2025-04-11 23:59:43,1,Ultrazon_com,programming
mmnni8p,1jwmwdy,reddit,"The whole Bitkeeper, McVoy episode was hilarious",2025-04-12 00:29:32,1,Alarming_Hand_9919,programming
mmnxu4p,1jwmwdy,reddit,"Thank goodness he took the whole 10 days, JavaScript was built in less than 10 days, and it's still got issues nearly 30 years later.",2025-04-12 01:35:35,1,entityadam,programming
mmp6rpa,1jwmwdy,reddit,"I personally do not like git, but everyone uses it and so must I.",2025-04-12 07:40:02,1,farmdve,programming
mmpize6,1jwmwdy,reddit,"The beauty of git is how simple the basics are, and how powerful the tool is.",2025-04-12 09:48:24,1,captain_obvious_here,programming
mmpnj1o,1jwmwdy,reddit,Can we start a religion based on this?,2025-04-12 10:35:19,1,Unlikely_Usual537,programming
mmpqp0p,1jwmwdy,reddit,I love and prefer Mercurial,2025-04-12 11:05:11,1,supremesomething,programming
mmqaub8,1jwmwdy,reddit,"Linus Torvalds built _the first version of_ Git in 10 days. Ftfy

It has had a lot of development since then.",2025-04-12 13:32:49,1,Anders_A,programming
mmvrtuf,1jwmwdy,reddit,[https://youtu.be/QwVqb0MEWww](https://youtu.be/QwVqb0MEWww),2025-04-13 11:55:51,1,Ok_Consequence_9363,programming
mmvz1jg,1jwmwdy,reddit,Hallo Guys. I am trying to gather a bunch of programmers that want to build shit together and become rich. If you have programming skills and want to join the group please text me in private.,2025-04-13 12:50:16,1,ManySuper,programming
mn18xsd,1jwmwdy,reddit,10 days and a lifetime of experience.,2025-04-14 09:25:26,1,turnstwice,programming
mn5nshh,1jwmwdy,reddit,I wish I was a 10th of the programmer Linus is. I’d be rich as fuck. Smh.,2025-04-15 00:42:12,1,ArthurBurtonMorgan,programming
mn6dvgb,1jwmwdy,reddit,I’m in awe of people like him. It’s truly incredible that something like this was built in a few days.,2025-04-15 03:27:15,1,rome200bc,programming
mmjvsfk,1jwmwdy,reddit,"10 days of work  
30 years on endless pain for everyone.

Git is literally made for torturing any sane person by its absurdity.",2025-04-11 12:28:07,-8,Mundane-Apricot6981,programming
mmjrsp5,1jwmwdy,reddit,"My dumb ass read ""Linus Torvalds"" and thought ""the 'Linus Tech Tips' guy made git???""",2025-04-11 12:01:07,-5,phil_davis,programming
mmjl1ab,1jwmwdy,reddit,"Part of it still feels like it was built in 10 days, particularly on Windows where it contains half a Linux system to be able to run perl, tcl etc. to glue some things together :P",2025-04-11 11:11:12,-36,KrocCamen,programming
mmkej6d,1jwmwdy,reddit,"stupendous normal workable resolute rob paint plough thumb butter sink

 *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",2025-04-11 14:14:50,-7,fieryscorpion,programming
mom7yuq,1k5zjs8,reddit,"okay that was an absolutely amazing read and a hilariously funny bug.  

Thank you for writing this and definitely keep it up.  

Absolutely a throwback to when GTA5 had it's 10 minute loading screen fixed by somebody that reversed the code to find they were doing a O( n^2 ) lookup that could just be an O(1) hash table over and over.",2025-04-23 14:49:04,975,CarnivorousSociety,programming
mommbu1,1k5zjs8,reddit,"> If this was a regular bug, I would’ve ended the post right here. However, in the case of this rabbit hole, the discovery of this fix only raised more questions – why did this break only now? What made the game work fine despite of this issue for over twenty years, before a new update to Windows 11 suddenly challenged this status quo?

You know we are dealing with a deep, fun problem when the question flips from ""Why doesn't this work?"" to ""How did this ever work to begin with?""",2025-04-23 15:58:44,175,robby_arctor,programming
mom7sku,1k5zjs8,reddit,"Great writeup! And nice work maintaining the patch - I wish all old games were as lucky.

God bless the GTA games for not validating their input data, though - a buffer overflow in save file parsing in Liberty City for the PSP opened up a whole world of custom firmwares.",2025-04-23 14:48:12,180,Akeshi,programming
momcemi,1k5zjs8,reddit,"Something I've always been curious about: I see in videos by Vadim M and in this article for example, mentions of source code, such as the snippet for `CPlane::PreRender`. How do we know these method/class names, and the source code? Is this coming from some leaked source, or has it been reverse engineered, and what we see in these videos is the reverse engineered code?",2025-04-23 15:10:50,69,Affectionate-Turn137,programming
molzc4v,1k5zjs8,reddit,"This is like some next level “if it ain’t broke don’t fix it”. Maybe they saw it back then but it was working and just left it?

Got me thinking, GTA:SA is a very popular game even being old as it is today and this happened. How many less popular games might have a very specific bug that surfaced or will surface without anyone knowing?

The plane in the bug is probably one of the last vehicles I’d use in the game and I imagine the same for many others too.",2025-04-23 14:05:49,81,BeautifulCuriousLiar,programming
moms9c4,1k5zjs8,reddit,"This would be great for r/heisenbugs 

I'm trying to get it off the ground as the go-to place for tough debugging stories",2025-04-23 16:27:51,37,LBGW_experiment,programming
mom85tl,1k5zjs8,reddit,Dam. That game came out in 2004? Time flies.,2025-04-23 14:50:02,29,this_knee,programming
mom94q6,1k5zjs8,reddit,"Wow, I love a good detective story. Great article, thanks for posting :)",2025-04-23 14:54:44,11,Chisignal,programming
mon5mnn,1k5zjs8,reddit,"In short: The skimmer seaplane had an incomplete config file, missing some values for initial Z positions of wheels. 
And until now the code worked with undefined behaviour, which made it use the values of the previously loaded vehicle because they didn't have default values set in the code.

But now a change to Windows made those previous values in the memory no longer fit as they did before and the values for the skimmer were set to giant numbers, which shot the plane into the stratosphere.",2025-04-23 17:31:31,36,Costyyy,programming
mos23oj,1k5zjs8,reddit,"This was a great read. It reminds me of a bug I fixed in my first job out of college. I was working on some embedded C code for a nuclear medical imaging machine’s motion controls.  The company hadn’t been able to update the code in a while, because any new build they tried to put on would just case to machine to vibrate and shake horribly and would have to be shut off to avoid damage. 

Turns out the problem started after a new compiler was used. See, this microcontroller was quite old, the CPU was a Motorola 68000 and I was working on it in 2003. For whatever reason, the company lost their original compiler. Bad hard drive, no backup, something like that. So they had to find and buy new compiler software. 

Well this new compiler just didn’t seem to be compatible with this code. And I was green out of college, didn’t know anything, and was working with this ancient system. I had no debugging tools. It took 30 minutes to load the compiled code onto the machine to test. A few code changes and tests would take up a whole day. 

I don’t remember the exact steps of my troubleshooting at this point, but it ended up being all the speed variables not being initialized. The old compiler would set any uninitialized variable to 0. The new compiler just allocated the memory, and whatever happened to be there was the speed.  All had to do was add an “ = 0;” in a couple places to fix it. Over 20 years and this is still the most fun bug I worked on and most satisfying to fix.",2025-04-24 12:40:26,9,Geordi14er,programming
momnx8m,1k5zjs8,reddit,Nice article! Really like these bugs investigations. May I ask which tools and software you used to unravel the origin of the bug?,2025-04-23 16:06:36,8,ricardo_sdl,programming
momzjyo,1k5zjs8,reddit,Do you still take cookies as valid currency?,2025-04-23 17:02:55,7,ThreeLeggedChimp,programming
mombpum,1k5zjs8,reddit,Silent is the GOAT.,2025-04-23 15:07:28,10,Affectionate-Turn137,programming
mombfua,1k5zjs8,reddit,Holy crap best thing I read all year. Awesome work,2025-04-23 15:06:07,5,LordSlimeball,programming
monbsnu,1k5zjs8,reddit,"That was a great read, well done.",2025-04-23 18:00:25,5,kaelima,programming
moo69b1,1k5zjs8,reddit,TIL always initialize your variables,2025-04-23 20:28:06,6,namotous,programming
monjgtm,1k5zjs8,reddit,I can’t believe it wasn’t broken in many versions of wine,2025-04-23 18:37:36,3,chazzeromus,programming
monv8hc,1k5zjs8,reddit,Well now I'm interested what was changed in Critical Sections!,2025-04-23 19:34:54,3,Tringi,programming
mopnxfw,1k5zjs8,reddit,">The real issue here is the game relying on undefined behavior (uninitialized local variables), and to be honest, I’m shocked that the game didn’t hit this bug on so many OS versions, although as I pointed out earlier, it was extremely close. San Andreas still supported Windows 98, which means it got away with this bug in at least a dozen different Windows versions and many more releases of Wine!

Holy shit",2025-04-24 01:19:43,3,TurboJetMegaChrist,programming
moqlebq,1k5zjs8,reddit,"So it was relying on undefined behaviour? 

If I'm understanding correctly, the plane asset used to be part of the boat class, so wheel scale and suspension weren't needed. Those values weren't initialised when loading the game, and on 24H2 systems, the values were accidentally initialised as massive floating point numbers. 

So the plane was technically there, it was just sitting on top of the worlds largest wheels. 

God, I want to put a lowrider kit on a skimmer now.",2025-04-24 04:56:17,3,XandaPanda42,programming
momaab4,1k5zjs8,reddit,"So this comes about in code which tries to settle the suspension.

Can you fix the suspensions in Kerbal Space Program too please?",2025-04-23 15:00:21,3,happyscrappy,programming
monh6de,1k5zjs8,reddit,Fun read,2025-04-23 18:26:28,2,themattman18,programming
monlrwp,1k5zjs8,reddit,I wonder if this change in Windows 11 is also what caused the crashes in Path of Exile,2025-04-23 18:48:44,2,Escupie,programming
moo7st9,1k5zjs8,reddit,20 days ago? damn i feel old now,2025-04-23 20:35:32,2,rawion363,programming
moraa92,1k5zjs8,reddit,"Great writeup. Although the terms that you used threw me off. What you describe as the bug *is* ""the true root cause"". Not the implementation detail of how the uninitialized data happend to be like it is due to different locks in different Windows releases.",2025-04-24 08:55:57,2,kwinz,programming
mov5p9z,1k5zjs8,reddit,We got new San Andreas bugs before GTA VI,2025-04-24 21:52:01,2,whatRepublic,programming
mooh2gt,1k5zjs8,reddit,the article doesnt seem to mention how this bug is a problem if several of the newer versions already contain a fix for it? is this only for the original pc release on cd? for cracked versions?,2025-04-23 21:20:54,3,fredlllll,programming
moostz3,1k5zjs8,reddit,An excellent read and a real talent for RCA,2025-04-23 22:23:22,1,aaron1uk,programming
moqjzrd,1k5zjs8,reddit,This some shit that would happen to me dude I swear,2025-04-24 04:45:43,1,nerdly90,programming
mormvua,1k5zjs8,reddit,nice read,2025-04-24 10:55:05,1,EnGammalTraktor,programming
motqczq,1k5zjs8,reddit,Cool find!,2025-04-24 17:39:29,1,avipars,programming
mowpcgx,1k5zjs8,reddit,I’m truly surprised that there are c/c++ programmers out there that actually leave their local variables uninitialized.,2025-04-25 03:06:14,1,SMFCTOGE,programming
momeue8,1k5zjs8,reddit,"you seem to have confused blade speed and angle, or there's a step missing?",2025-04-23 15:22:42,1,andrewcooke,programming
mlzr3ty,1ju6ils,reddit,Why is it always 10x and not like 2.86x?,2025-04-08 06:14:59,747,arturaz,programming
mlzpili,1ju6ils,reddit,"I was told on r/OpenAI that I would be replaced this year, or was it last year? The hyperbolic nature of AI discussions is a sight to behold. At least now they seem to dial it down a bit. Make that 10x to 40% and we're onto something.",2025-04-08 05:59:25,1193,Raunhofer,programming
mlzr6um,1ju6ils,reddit,"I hope everyone remembers what they were saying less than a year ago and understands this is a complete reversal. 

Guess the end of the s curve for the scaling law comes at you fast",2025-04-08 06:15:49,484,Disgruntled-Cacti,programming
mlzpbyi,1ju6ils,reddit,"10x more productive sounds like I need 1 developer instead of 10


-CEO",2025-04-08 05:57:39,179,tubbana,programming
mlzp661,1ju6ils,reddit,Shovel dealer says shovels will make gold diggers 10x more productive,2025-04-08 05:56:06,673,beebeeep,programming
mlzozbx,1ju6ils,reddit,"When AI starts to understand wtf the customer are asking for, and communicate to them, I will start to shiver, and be scared for my job. Until then, they are a tool, I can use.",2025-04-08 05:54:17,187,Soccer_Vader,programming
mlzxwkx,1ju6ils,reddit,"Two weeks earlier on 24 March 2025:

[OpenAI's Sam Altman claims AI will ""gradually"" replace software engineers — Creating an urgent need to master ""AI tools""](https://www.windowscentral.com/software-apps/openai-sam-altman-ai-will-gradually-replace-software-engineers)",2025-04-08 07:19:46,43,Cube00,programming
mlzphjn,1ju6ils,reddit,so far AI just introduced a lot of fakes and probably it will introduce a lot of fake coders as well,2025-04-08 05:59:09,71,Impossible-Staff6793,programming
mlzvg0b,1ju6ils,reddit,The use case for AI is spam.,2025-04-08 06:54:58,69,skippy,programming
mm08qyp,1ju6ils,reddit,Guy who sells AI says AI is the future.,2025-04-08 09:20:34,28,Relative-Scholar-147,programming
mlzrfap,1ju6ils,reddit,"If you measure productivity by lines of slop checked in, it’s already doing that.",2025-04-08 06:18:06,23,maxinstuff,programming
mlzvfnx,1ju6ils,reddit,"A person who works at Github gave a presentation about Copilot and I quote ""We make money from developers using our platform. Why would we create this tool that replaces them? I wouldn't get any money.""

Github's Copilot was apparently the product of their R&D department and later they promoted it as a way  to make development more fun. More enjoyable. Less boring, as boredom often is the mind killer.  Not necessarily to boost performance, although that's a nice side effect. There are others too, like some juniors having too much reliance on the tool and if you take it away, they're pretty useless.",2025-04-08 06:54:53,18,rcls0053,programming
mlzrgba,1ju6ils,reddit,"That's a contradiction if I've ever seen one.


If you need two people to complete two tasks and you make one of them ten times more efficient, then there is no need for the second person.",2025-04-08 06:18:21,29,IronGin,programming
mlzt9uj,1ju6ils,reddit,"10x is such an exaggeration, hard to take anything he says seriously with such claims. 

From my observations, AI takes away the learnings from devs, if they don't know something they'll use AI and continue not to know as the knowledge doesn't seem to persist if you're not actually trying to understand the issue or the solution.

You basically end up with a human interface that just tries things AI comes up with, which is just a very confident guess.

This is problematic because it can keep devs who use AI excessively from actually getting better and will result in less know-how in general, just devs limited the capabilities of AI. At least that's what I think might happen.

At the company we work for we're doing pair reviews and pair debugging more often now, I feel it transfers knowledge much better and juniors see what the capabilities are of someone senior. I find it funny when they sit next to me and dump things in AI and they see me do it before they ever get a proper response. But I worry because they are missing out on knowledge because of AI and become reliant on it. Imagine AI being completely locked behind a paywall if resources like stack overflow have become non existent.

/End rant",2025-04-08 06:34:21,25,Veloxy,programming
mlzulq4,1ju6ils,reddit,"So, will I be paid 10x what I'm being paid right now?",2025-04-08 06:46:48,11,UltraPoci,programming
mm0156d,1ju6ils,reddit,"Honestly, I'm using Copilot as a snippet library on steroids to avoid copy paste and boring boilerplate stuff.. it works great for that task 😊

If your work is being a human snippet library or your primary task is to copy paste YAML and change some characters here and there.. yes your job might be in danger 🥲",2025-04-08 07:55:19,7,PeachScary413,programming
mm0239n,1ju6ils,reddit,"So far AIs primary use for me has been generating Regexes and occasionally asking for information. My experience with it in code has been absolutely awful (game dev, C++), it's unreliable and confidently wrong constantly.

Right now it's a stack overflow replacement at best, and I was already not using stack overflow or Google very much.

We'll see. Current techniques are starting to have scaling issues and diminishing returns on quality, so unless there's a breakthrough I'm feeling pretty safe.",2025-04-08 08:05:51,6,cfehunter,programming
mm07yw9,1ju6ils,reddit,Productivity != good code,2025-04-08 09:12:01,5,qwefday,programming
mlzx65z,1ju6ils,reddit,"we already didn't have a problem in producing incredibly bloated code basis.

AI solves nothing. 

the ability to just generate a bunch of probabilistic crap on the fly is absolute more of a liability in long term bug production, than it does present a benefit for our immediate ability to produce features.

but it's so damn hard to actually measure long bug production liability ... making it all the more easy to ignore.",2025-04-08 07:11:48,4,fire_in_the_theater,programming
mm0cqzv,1ju6ils,reddit,"The thing is... at least where are work most of the bottlenecks are political and/or linked to resource allocation (people, hardware, training, generally budget for research). I'm not convinced LLMs can improve our productivity as a whole because of this. Turns out humans can code pretty fast _once we fucking decide what we want to do and communicate it properly to everyone_.",2025-04-08 10:02:37,4,frnxt,programming
mm04sal,1ju6ils,reddit,"Sam Altman will say ***whatever*** he thinks people will buy for in order to sell his product.

If you're a programmer treat everything he says with the assumption that it's selling snake oil as your first scenario.",2025-04-08 08:36:29,8,Hero_Of_Shadows,programming
mlzsrew,1ju6ils,reddit,"10x is a stretch, but it might be helping save 30-45 minutes a day right now

(goes back to battling Zod and typescript)",2025-04-08 06:29:41,8,oliyoung,programming
mlzvz5c,1ju6ils,reddit,"Realistically it's just an excuse to squeeze coder wages. 

But AI is a brilliant coder for non-coders. As long as you can write a good prompt and the task isn't overly complex, you can usually get working code out of ChatGPT's O1 or O3.",2025-04-08 06:59:55,6,generally-speaking,programming
mlzxe0s,1ju6ils,reddit,"bill gates doesn't know shit, he has zero experience with any of it",2025-04-08 07:14:08,9,tetyyss,programming
mlzqau4,1ju6ils,reddit,"Making things more efficient doesn't work out better for those on the bottom rung. Like when the train was invented, people thought they'd have more time for golf on business trips.",2025-04-08 06:07:04,3,RedRedditor84,programming
mm07ns9,1ju6ils,reddit,"\*up to

Sure, when you know exactly what you want, how the exactly current codebase works, it's possible to get 10x productivity boost by prompting your way through. But that's not how it works in real life though. Even with BA + PO, there's always gonna be gaps because client is never gonna be 100% sure what they want until they have a taste of the software in their hand.

I've done couple of small utility programs purely by prompt. Took me 10 mins what should take me half day (I assume 3/4 would be reading docs, actual coding should be fast). But then I also know exactly how the software should be do, how it should be written. Normal people don't.",2025-04-08 09:08:37,3,redfournine,programming
mm0gddl,1ju6ils,reddit,"The difference between a bad, an average and an excellent programmer is already x10 in each step. If AI:s are used it will only make bad programmes produce bad code x10 times faster and maybe help the average programmer but it will probably not help an excellent programmer at all.",2025-04-08 10:37:47,3,Sbsbg,programming
mm0gkm9,1ju6ils,reddit,"I wonder how this ""productivity"" was measured. I hope not in LOC. Because I've already seen scenarios where someone should have spent few hours looking into existing libraries and solutions, but instead they just let ChatGPT (re)produce hundreds of lines of math-heavy code which ""hopefully works"", but now has to be maintained. Indeed, it would have taken much more time for a developer to produce that by hand (possibly far more than the 10x), but they shouldn't have done that at all.",2025-04-08 10:39:37,3,Pharisaeus,programming
mm0mt58,1ju6ils,reddit,"My experience with LLM driven coding is that I always end up correcting the LLM at some point or just start to write my own code/logic. I am far from being an expert... I have a good command but I am not one of those you write you like a 100 lines of code and it just works flawlessly, you know.... So, I don't think that LLMs are really going to replace any coders",2025-04-08 11:31:06,3,essenkochtsichselbst,programming
mm0vhcy,1ju6ils,reddit,"Hear me out, maybe CEOs are going to say whatever makes their stock price go up. Why do we give these guys such a platform from which to repeatedly lie from?",2025-04-08 12:32:30,3,gahooze,programming
mm1c8mp,1ju6ils,reddit,Sam Altman says whatever he thinks is good for Sam Altman at that moment. Bill Gates is just happy we’re not talking about his trips with Epstein.,2025-04-08 14:10:38,3,bananahead,programming
mm1e2jz,1ju6ils,reddit,My prediction: sam altman will be replaced by Ai in the next 23 days. It would be the 100X better because it would have a fact checker included. This 'SamAi' will be created by cursor in 1  minute and debugged for the next 22.9999 days until released on Joe Rogan.,2025-04-08 14:20:15,3,Nearby_Soil_5149,programming
mm1qr1z,1ju6ils,reddit,And now the pitchmen start moving the goalposts back.,2025-04-08 15:23:56,3,TheRealDrSarcasmo,programming
mm1t9e3,1ju6ils,reddit,AI is the WISIWIG of coding.  It's going to make it so you can pay people less and less money to make worse and worse products.,2025-04-08 15:36:23,3,spytez,programming
mm1trsf,1ju6ils,reddit,"I've worked with ChatGPT to try to produce code, Sam is on fucking crack if he thinks AI can help programmers, whatit will do is infuriate them since it seems to have the memory of a fucking goldfish ",2025-04-08 15:38:57,3,akp55,programming
mm1wbmu,1ju6ils,reddit,"AI will make hundreds of millions of laymen *think* they can productively generate code and it will take a legion of actually qualified software engineers 10x the size to clean up the mess.

ps. a legion that size logically can not exist, so we are bound for a world horribly bloated with spammy, malicious and/or insecure code.",2025-04-08 15:51:23,3,Spaghetticator,programming
mm1wxbl,1ju6ils,reddit,"Falls right in line what Carmack just recently posted on Twitter: https://nitter.net/ID_AA_Carmack/status/1909311174845329874#m

I'm bored with the whole hyperbolic view on AI.",2025-04-08 15:54:19,3,psycketom,programming
mm3p6b0,1ju6ils,reddit,"My work shelled out for everyone to get a GitHub copilot license and I used it for maybe an hour or two before scrapping it. It hallucinates, it keeps trying to write pointless comments, it produces syntax errors, and it distracts me when I'm deep in the trenches of working out a problem. Literally the only thing it's useful for is generating boilerplate and even for that, it's not accurate enough to be worth it (if you don't consider the environmental impact in which case it's literally never worth it)",2025-04-08 21:04:11,3,PM_ME_UR__RECIPES,programming
mlzroia,1ju6ils,reddit,"As ever the question is are we talking about the present or future? And if the future, how far into the future?

Because in chronological order I'd say he is wrong, right and then wrong for different reasons.",2025-04-08 06:20:21,2,YsoL8,programming
mlzvff2,1ju6ils,reddit,"A person who works at Github gave a presentation about Copilot and I quote ""We make money from developers using our platform. Why would we create this tool that replaces them? I wouldn't get any money.""

AI is to enhance developer performance or to make development more fun. More enjoyable. Less boring, as boredom often is the mind killer.",2025-04-08 06:54:49,2,rcls0053,programming
mlzxco7,1ju6ils,reddit,Trippen over a magic trick,2025-04-08 07:13:44,2,thatsbutters,programming
mlzxlye,1ju6ils,reddit,"Imagine fixing/adding features in a 2M LOC AI generated pile of poo. Thanks, but no thanks.",2025-04-08 07:16:32,2,phplovesong,programming
mm0afsg,1ju6ils,reddit,"10x more critical of what comes out of this finely tuned random number generator, that is.",2025-04-08 09:38:53,2,DaveVdE,programming
mm0ahqv,1ju6ils,reddit,We are currently in the matrix run by a ai hybrid clone of Musk living on Mars. Deal with it you degenerates,2025-04-08 09:39:29,2,Organic_Height4469,programming
mm0d7gs,1ju6ils,reddit,"Oh, so know they changed their minds? Hopefully this stops the annoying ""devs who do not prepare will be out of a job in the next year/month/day/minute""",2025-04-08 10:07:14,2,azteking,programming
mm0ht6y,1ju6ils,reddit,"Finally, I can’t hear that shit anymore that we will be replaced. Everyone that works with it knows that, but all the product managers think they can just with the vibe",2025-04-08 10:50:25,2,Akarastio,programming
mm0ht9y,1ju6ils,reddit,Look… Sam Altman can eat rat poison for all I care.. raspy voiced cunt.,2025-04-08 10:50:26,2,N/A,programming
mm0i847,1ju6ils,reddit,"AI is decent with solved problems. Of course, if a problem is solved, there's likely already an API.",2025-04-08 10:53:53,2,MaruSoto,programming
mm0jyx0,1ju6ils,reddit,"in other words, deadlines shortened by x10",2025-04-08 11:08:28,2,Sweet_Television2685,programming
mm0m3y2,1ju6ils,reddit,"Honestly by the time I accurately describe everything I need from an LLM, I might as well just have wrote it myself

I hardly even use it for “writing code”. I use it for making fake data or autocompleting my code at best",2025-04-08 11:25:39,2,Dreadsin,programming
mm0neuh,1ju6ils,reddit,Has a single thing Sam Altman claimed come true?,2025-04-08 11:35:44,2,Nyadnar17,programming
mm0p3l7,1ju6ils,reddit,Its almost as if people making these claims about AI are just talking out of their ass.,2025-04-08 11:48:18,2,No_Significance9754,programming
mm0qc6f,1ju6ils,reddit,"if they haven't even replaced cashiers completely without fails, how will they skip everything else and replace the people who will fix that? Lol",2025-04-08 11:57:12,2,iosdood,programming
mm0qfaf,1ju6ils,reddit,"AI won't replace developers, if it does then we are all screwed. 

A good developer is better than the current LLMs. A less proficient developer can use AI as a nudge but if continued the developer will end up being as or more so proficient than a LLM.

Learning code examples from other code, Stack Overflow, etc have existed in the past for those with average to less-than-average proficiency - I see LLMs to basically take the place of these learning sources (or at least live along side of them) in the future.

Those that are using LLMs to blindly code are just fooling themselves.",2025-04-08 11:57:49,2,jrutz,programming
mm0tkl5,1ju6ils,reddit,I tried using Sonnet and GPT to investigate some simple bugs in a Python script.  They spent over $10 and failed.,2025-04-08 12:19:41,2,kindredfan,programming
mm0xf0c,1ju6ils,reddit,"The solution to too much complexity is to remove the complexity, not to create another complex system to try to work around it.",2025-04-08 12:44:55,2,RebeccaBlue,programming
mm1c7g2,1ju6ils,reddit,"No surprise here - a CEO hyping and overselling.

CEOs at tech startups are salespeople at their cores. Crucial for funding and revenue generation.

Just make sure not to drink the Kool Aid.",2025-04-08 14:10:27,2,LucinaHitomi1,programming
mm1d5u9,1ju6ils,reddit,"My fear is AI will replace all junior developer positions, and at some point we will have a lack of senior developers. I feel this is already happening.",2025-04-08 14:15:28,2,JonTargaryanTheFirst,programming
mm1d6m0,1ju6ils,reddit,"Always remember Altman is not a technologist, he is a salesman. This is him adjusting his pitch.",2025-04-08 14:15:35,2,angrynoah,programming
mm1d6u1,1ju6ils,reddit,The only thing I see AI fully replacing the coming years is AI techbro’s,2025-04-08 14:15:37,2,GlowiesStoleMyRide,programming
mm1dhbs,1ju6ils,reddit,"They make very bold statements. The bolder the statemets, the more suspicious I get about those statements.",2025-04-08 14:17:08,2,shevy-java,programming
mm1gdop,1ju6ils,reddit,"The only thing I care about hearing from Sam Altman is how he plans to turn a $100 billion data center into a profit using $20/month subscriptions. 

The guy isn’t Yann Lecun or Andre Karpathy, he doesn’t know shit about “AI” and doesn’t pretend to. He represents the business side of things, which right now is snake oil.",2025-04-08 14:32:16,2,lqstuart,programming
mm1prxh,1ju6ils,reddit,"If an AI could replace programmers of a company, you bet it could replace any non physical worker at the company, of course including the CEO.",2025-04-08 15:19:07,2,dan00,programming
mm21lcd,1ju6ils,reddit,Every month they change their mind🤣,2025-04-08 16:17:37,2,Affectionate_Front86,programming
mm3cvbb,1ju6ils,reddit,"It'll make software engineers 10x busier running around and fixing, rewriting all the copy-and-pasted shit code that's going to get thrown in and then discovered it doesn't work and no one knows why.",2025-04-08 20:06:03,2,powdertaker,programming
mm3ligb,1ju6ils,reddit,"If everyone isn't fucking stupid we use AI to do 10% of the work to break even. You know, the whole fucking reason we make technology, not to line the pockets of greed monsters",2025-04-08 20:46:45,2,Efficient_Sector_870,programming
mm5syg1,1ju6ils,reddit,Sam says a metric shit-ton of self-interested BS with every press release. Does anyone in the tech press ever push back on his flimflam?,2025-04-09 04:36:54,2,SlientlySmiling,programming
mlzu70v,1ju6ils,reddit,"AI has already helped me learn so much. Like generating half baked library calls it does okay, but its really great at giving me SQL ideas and has really strengthened my SQL vocabulary",2025-04-08 06:42:55,2,exploradorobservador,programming
mm0jdo7,1ju6ils,reddit,"Sam Altman says a lot of shit. 

Frankly, I don't even see a 20% increase as realistic.",2025-04-08 11:03:35,2,NuclearVII,programming
mm05hvd,1ju6ils,reddit,Finally! I think most of us have known this for awhile but it’s good to see high profile people tamping down on the nonsense.,2025-04-08 08:44:31,1,DarkTechnocrat,programming
mm0dslc,1ju6ils,reddit,"I'm using AI more and more to code, and it's a huge time saver. On the other hand I know its limits, it is suitable for a program which does not exceed two screen heights. Beyond that it's just laughable to use, it cuts code, makes lousy shortcuts, forgets things. On the other hand, for writing class documentation, especially in English, it's still the best. After the ratio of 10, I don't really believe it, we will save time, but the complexity of the systems has become such that it will not have much impact on the result.",2025-04-08 10:13:06,1,remic_0726,programming
mm0il27,1ju6ils,reddit,"The problem I see here is complacency. We are all humans and when we get a taste of something that is ready made and does not require much effort, we slowly start gravitating towards it, to a point where we start trusting it blindly, even though it is slowly feeding us poison.",2025-04-08 10:56:54,1,Lunacy999,programming
mm0p6gq,1ju6ils,reddit,AI is a tool that should be used to enhance ones work. Using it to replace people is asking for trouble,2025-04-08 11:48:53,1,SteroidSandwich,programming
mm0pcj8,1ju6ils,reddit,"Anecdote but, ChatGPT is absolutely useful for getting past writer's block if you already know 3/4 of what you want to build. It doesn't replace programming, bugs are inevitable, but it absolutely helps with the majority of the grunt work. The remainder is just expanding what it already built and fixing bugs by giving you a pretty decent headstart depending on how big you're going.


Humans won't be replaced because AI currently cannot read your mind and you still need to know how to build an application even if you don't know the boilerplate.",2025-04-08 11:50:07,1,cpt-derp,programming
mm0q0do,1ju6ils,reddit,"So wouldn’t this replace 10 coders for every 1? It’s not like there’s one ultimate software goal we’re all working towards that we need as much coding power as we can get to work towards it.

Enterprise isn’t going to release 10x the code into production, they’re going to release the same amount of code but with 10x savings.",2025-04-08 11:54:51,1,Notallowedhe,programming
mm0qxu9,1ju6ils,reddit,"Sam Altman knows AI will replace all programmers, he’s trying to create AGI. He thinks investors will be happier to give him more billions if he convinces them that will happen after they make their investment returns though.",2025-04-08 12:01:27,1,sluuuurp,programming
mm0ron6,1ju6ils,reddit,The back peddling is real with this one. Lol,2025-04-08 12:06:40,1,Goldarr85,programming
mm0scpn,1ju6ils,reddit,"I agree.  Developers will not be replaced by AI, but developers who use AI will replace developers who don't",2025-04-08 12:11:17,1,1h8fulkat,programming
mm0utdb,1ju6ils,reddit,Thats what ive been saying to everyone since ai got relevant.,2025-04-08 12:28:05,1,SprinklesFresh5693,programming
mm0wtpc,1ju6ils,reddit,"does anyone think about this paired with the fact many companies are pivoting to developing robots that will walk around doing actual, physical tasks?

I can't even trust an incorporeal AI/ML to make a small code change, am I really going to trust it to haul laundry around the house with a physical body?

Or is the plan that we'll make the average laborer 10x productive by having them manage a fleet of bumbling robots? I won't be surprised if they end up in the same mess as us, redoing robot driven work.",2025-04-08 12:41:09,1,CVisionIsMyJam,programming
mm0xfdo,1ju6ils,reddit,Why do we care on the opinion of two non coders?,2025-04-08 12:44:59,1,keepthepace,programming
mm0yew2,1ju6ils,reddit,"I keep being told I'll be replaced, and that oh no you have to guide it. I use it a decent amount I know what it's good at. I've also seen low code platforms before they aren't new, guess what they sorta work, and they're all complete dogshit that you can never move away from and you pay out the ass for in terms of technical debt. 

Software is the only field like this, ""oh we hired vibe architects, don't worry only a 10% uptick in houses just falling down. It makes you more productive!"" It's a neat tool, i don't like being told by people who apparently hate me and have no idea what I do how it should be used. I'm  a luddite because I don't want to use something that makes up library calls to do everything for me and correct it when it's wrong? Also it can't do broader architecture unless that architecture has been discussed 900 times in different articles.

I hate it for artist too, can it make art? I'm pretty liberal on that front I'd say anything can be art really, like can you make art with photoshop, sure. But the same exact thing regurgitated over and over and over by a machine, if it's art or not isn't the question. It's repetitive and not interesting though for sure. I don't understand how people who are pure ai boosters don't get this, they have 0 idea about the subjects they immate, hate the people who they're immating because they feel they should get to be in that space and reap any rewards but crucially they want NOTHING to do with learing the subject matter, that's for try hards apparently.

A lot of art is derivative also, but in that circumstance a person is enjoying creating it I assume and possibly learing. An AI model is just regurgitating the same shit.",2025-04-08 12:51:10,1,Icy_Party954,programming
mm0yi90,1ju6ils,reddit,For now,2025-04-08 12:51:44,1,AHardCockToSuck,programming
mm0ylup,1ju6ils,reddit,Lmao no fucking shit dummies.,2025-04-08 12:52:21,1,zdkroot,programming
mm0z1vv,1ju6ils,reddit,"Executive says ""10x more productive"", but actually mean ""you can lay off 90% of your workforce"".",2025-04-08 12:55:05,1,beefsack,programming
mm10v8n,1ju6ils,reddit,Does this mean bb I only have to work 1/10th as much,2025-04-08 13:06:07,1,lordbunson,programming
mm12gbj,1ju6ils,reddit,Aww so you lied?,2025-04-08 13:15:35,1,Death-by-Fugu,programming
mm12zse,1ju6ils,reddit,"If it is 10x-ing productivity, then 90% is coming from the model and the human is just keeping it on track. Don’t get me wrong though, it takes skill to manage and architect *anything*, just a very different skill set than “coder”.",2025-04-08 13:18:48,1,SpaceToaster,programming
mm14s1w,1ju6ils,reddit,"so its more productive for me to explain my colleague over abusing chatgpt what the code he copied / pasted works. yes, sure.",2025-04-08 13:29:12,1,markand67,programming
mm15h76,1ju6ils,reddit,The amount of back paddling is astonishing,2025-04-08 13:33:17,1,patientzero_,programming
mm19a5f,1ju6ils,reddit,Lol oooh that will be hard. AI will indeed make a great impact but can't replace it with what we have now.,2025-04-08 13:54:44,1,Ndubuisi05,programming
mm19xej,1ju6ils,reddit,"Make it 10% more productive from AI, and then you’re getting close to reality.",2025-04-08 13:58:11,1,DapperDolphin2,programming
mm1bbyb,1ju6ils,reddit,"So we went from AI will change software development forever and eliminate the need for developers, now we're at software developers won't be replaced by AI it'll just make things easier. So where will the goalpost be moved next Sam Altman?",2025-04-08 14:05:46,1,DeClouded5960,programming
mm1cowu,1ju6ils,reddit,"For people working at a more traditional company, not FAANG or startups, I agree that AI can't replace everything. There's too much legwork, detective work, asking users how things work, upgrading old systems where you have no idea what the columns mean, how they interconnect to various programs, etc.

It's impossible for an AI to do unless it's literally an AGI robot who can physically walk around an office, call people, analyze code, and also code. The analyzing code and writing code I'm sure AI can make our jobs easier.",2025-04-08 14:13:01,1,Hen-stepper,programming
mm1i50h,1ju6ils,reddit,"If senior developers could produce 10x more output, the company would likely hire less junior engineers. So in practice it would technically replace engineers. But it’s also possible that companies would still hire as many engineers as today, with the difference being that they expect more from each dev",2025-04-08 14:41:14,1,monsoy,programming
mm1i9nk,1ju6ils,reddit,AI is honestly a bit useless overall and especially for coding. Junior Devs know too little to know if the provided code is any good and senior devs know too much to waste their time with the trashy code that AI usually provides.,2025-04-08 14:41:53,1,BadCompulsiveSpender,programming
mm1n2h7,1ju6ils,reddit,"I think he’s means 10% not 10x, at least in my experience it’s about 10%.",2025-04-08 15:05:42,1,NiteShdw,programming
mm1rv4d,1ju6ils,reddit,"This is the same pitch that Microsoft used for Windows NT in the 1993-1995 time frame. It might actually have been 5-10x, just to sound scientific. Are Windows NT programmers 5-10x more productive?",2025-04-08 15:29:26,1,bediger4000,programming
mm1wpn0,1ju6ils,reddit,"I mean... I don't think he's *wrong*, but at some point it's still an existential problem for the field if that 10x remains higher than the demand for more code. 

What does ""not replace them"" even *mean*, when it turns the need for 10 programmers into a need for 1 programmer? Weren't the 9 ""replaced""?",2025-04-08 15:53:15,1,hacksoncode,programming
mm1xsg7,1ju6ils,reddit,"Now that the market is down they have to put out more realistic sounding messaging. 

When the greed kicks in again they’ll be saying that coders will be fully replaced in 10 minutes and AI will generate code based on reading the minds of the corporation’s officers.",2025-04-08 15:58:35,1,thedarph,programming
mma1nlv,1jvfxl3,reddit,[deleted],2025-04-09 20:55:34,774,N/A,programming
mma22sq,1jvfxl3,reddit,https://en.m.wikipedia.org/wiki/Jevons_paradox,2025-04-09 20:57:38,95,shif,programming
mm9yz4k,1jvfxl3,reddit,https://www.sfgate.com/tech/article/okta-layoffs-after-first-profits-20147418.php,2025-04-09 20:42:41,109,uniquesnowflake8,programming
mma8xa9,1jvfxl3,reddit,this jerkoff just layed off a bunch of engineers and shipped the jobs to india,2025-04-09 21:33:02,56,krispey,programming
mm9x01v,1jvfxl3,reddit,I like the cut of this guy's jib.,2025-04-09 20:33:05,85,TheBoosThree,programming
mma7d2h,1jvfxl3,reddit,"As I've been saying, we will always need formal verifiers.  Software developers simply have ever widening areas of responsibility as we automate more and more faucets of life.

Even if you rename the role... the general premise remains.  Somebody has to know how to build and deliver product even if they're telling automated systems to do it.",2025-04-09 21:24:45,38,recurrence,programming
mma8xfs,1jvfxl3,reddit,"Company that sells primarily to developers says that developers will be more in demand

Shocking",2025-04-09 21:33:03,21,mrfreeze2000,programming
mm9y11o,1jvfxl3,reddit,Paywalled. Can someone share the article?,2025-04-09 20:38:05,9,lifeslippingaway,programming
mm9zi99,1jvfxl3,reddit,"If they paid like they were in demand, that’s be nice.",2025-04-09 20:45:15,121,danikov,programming
mma7bqq,1jvfxl3,reddit,"Look at where his company is hiring 


And where it isn't ",2025-04-09 21:24:33,20,predat3d,programming
mmc9uoc,1jvfxl3,reddit,"This kind of thing reminds me of animal farm and other books of that type.

The real problem would be when the people who fix the kind of problems AI creates are not available anymore, and the pipeline that created high quality engineers , doctors or whichever field AI disrupts is gone.
Some fools compare it to calculators and slide rules, but its not as simplistic. There is a level of complexity in software engineering. A certain kind of understanding that is hard to describe. So far AI has failed to help me code even really simple things. Its syntactically correct but otherwise logically quite stupid. It compliments whatever i do saying its perfect, until i come up with an even better answer. See it cant look at how everything works together and understand necessity, impacts on performance, so many things. You cant really teach that to AI because it doesnt actually understand. They should stop calling it intelligence because there isnt any intelligence there, just the appearance of intelligence and very convincing conversational skills. We can use AI for simpler things so we dont spend time looking things up. But for complexity it can be a terrible idea. There are benefits to AI but enormous risks also, and quite frankly, most CEOs are not competent to understand. They are ceos for their ability to keep a company running, not necessarily because they understand their product, their industry or their employees.

Back to my slide rule comparison for a moment. Consider medicine. Tests can indicate certain parameters, but doctors always look at the patient standing in front of them and their history as well. Statistics are biased because mainly sick people go to the hospital. Some things are studied, but its silly to say with certainity about everything, because we dont know everything. Doctors know that, and thats why reports are a part of the analysis, not the entire thing.
Another example is veterinary medicine - dogs on raw diets have different numbers than kibble fed, so diagnosis changes.
One can make a long list of things which depend on context, and there is no way AI can know what it doesnt know and what is or isnt relevant, because its not reasoning. Now theyre talking about reasoning models, but we cant say what the problems are yet because we havent used it enough.",2025-04-10 05:07:05,5,StarkAndRobotic,programming
mmcab9x,1jvfxl3,reddit,"Well yeah, someone's going to have to clean up all this AI slop.",2025-04-10 05:11:05,6,hbarSquared,programming
mma5j1f,1jvfxl3,reddit,"I think this is probably right. These tools would be great replacements for CEO's but would not be great replacements for on the ground coders.  Most of them that I have used fail at even the most simple debugging excercises, and do not function as meaningful replacements for skilled computer scientists.",2025-04-09 21:15:10,9,0MasterpieceHuman0,programming
mmawfyo,1jvfxl3,reddit,"if we cut out management somehow,

we could probably decrease our need for software engineers by 10x or more.",2025-04-09 23:45:31,4,fire_in_the_theater,programming
mmchrga,1jvfxl3,reddit,"Yes.  Current models don't know how to write software.  They make horrible mistakes in small blocks of code.  They're totally unable to handle or understand large code bases.

It still takes a seasoned human to understand good design and spot mistakes and architecture deficiencies. 

I'm excited for where we go from here, but there's lots of fundamental problems that are not being solved with each model. I suspect we'll need radical new model designs before AI becomes more useful in projects. 

Until then, it's okay at spotting formatting mistakes.",2025-04-10 06:20:24,3,Zamicol,programming
mmfcnvn,1jvfxl3,reddit,"The only thing AI has done is removed junior positions, which means in about 5-10 years time, you won't have new seniors and then us existing ones will start charging eye-watering amounts of money to fix all your vibe-turd garbage.

I did come across a recent research on taking apart Claude and how it actually thinks. Very fascinating.",2025-04-10 17:54:39,3,ZirePhiinix,programming
mmfl2sf,1jvfxl3,reddit,"Two years ago: we're going to have AGI in a year 
A year ago: software devs will be obsolete soon
Now: AI is really just a tool to make you more productive 

Watching redditors opinions change over time is pretty amusing.",2025-04-10 18:35:25,3,nocrimps,programming
mmhlxam,1jvfxl3,reddit,"I love how everyone on this sub goes “ThEyRe CeOs ThEy DoNt KnOw WhAT tHeYrE tAlKiNg AbOuT!” Any time they say AI is going to replace devs, but as soon as one says they won’t, you’re all like “I told you AI won’t replace us!” Lmao 😂",2025-04-11 01:06:31,3,heisenson99,programming
mmaslet,1jvfxl3,reddit,"To clean up the AI slop?

Nah, you made your bed.",2025-04-09 23:23:29,6,Ratstail91,programming
mmd88e3,1jvfxl3,reddit,"Damn, people just need to relax a bit, software will be important, and ai will replace some people especially the low tier code monkeys. But you need people to do architecture, to do bug fixing, optimization, code reviews and so on. As long as you are good in what you are doing you will have a job.",2025-04-10 10:52:53,2,Zockgone,programming
mmfpok1,1jvfxl3,reddit,"Well, someone needs to come in and clean up all the vibe code. It'll be like Cobol all over again. But stupid.",2025-04-10 18:58:03,2,Noble_Thought,programming
mmg6bsm,1jvfxl3,reddit,"Bless the programmers who'll have to manage teams of ""AI Programmers"" and guide them away from coding practices that can be redundant, erroneous, and malicious. Unfortunately, the philosophy towards AI's integration in the workplace sees it as a tool for productivity versus a tool for ideation.",2025-04-10 20:19:29,2,No-Nectarine-8721,programming
mmj8brc,1jvfxl3,reddit,"I think he meant to say ""software engineers with 900 years of experience"" will be more in demand, not ""software engineers"".",2025-04-11 09:10:43,2,m03n3k,programming
mma9ate,1jvfxl3,reddit,"My prediction is that it's going to be the same story as Web and Mobile in the past -> LLM Agents are simply going to create a while new ""market segment"" for software developers, that didn't exist before. There will be people developing tools (maybe using MCP or some future version of it) specifically for supplementing LLM Agents.",2025-04-09 21:35:03,1,Pharisaeus,programming
mmac3x8,1jvfxl3,reddit,Tell that to the job market,2025-04-09 21:49:56,1,Daegs,programming
mmawzig,1jvfxl3,reddit,"Being in demand is not the same as having a stable job, being respected, and not being exploited.",2025-04-09 23:48:39,1,intull,programming
mmayxpq,1jvfxl3,reddit,"Any time now would be nice.

God fucking DAMN is the market rough.",2025-04-10 00:00:07,1,Shadowhawk109,programming
mmb35th,1jvfxl3,reddit,Can't charge AI for SSO,2025-04-10 00:25:25,1,Unkn0wn77777771,programming
mmbp5hv,1jvfxl3,reddit,"Yeah, my company just laid a huge portion of FTEs and replaced them with near shore/offshore. Kick rocks.",2025-04-10 02:34:13,1,grumblefap,programming
mmby3bz,1jvfxl3,reddit,Why did we all get laid off then?,2025-04-10 03:34:20,1,Mojo_Jensen,programming
mmc644t,1jvfxl3,reddit,"He needs to trumpet this. Without developers, who would need their auth services.",2025-04-10 04:35:53,1,Equivalent-Win-1294,programming
mmeepdi,1jvfxl3,reddit,Yup. Turns out you need Developers to make use off all this LLM nonsense. If only someone had been saying this from Day 1 🙄,2025-04-10 15:08:50,1,dillanthumous,programming
mmef5v0,1jvfxl3,reddit,Just say something flashy and appear in the news trick,2025-04-10 15:11:07,1,OpenSourcePenguin,programming
mmeiuch,1jvfxl3,reddit,"I agree with the core sentiment that demand will likely increase, but the *nature* of the demand is definitely shifting. Skills like system design, understanding complex integrations, and architectural thinking are becoming even more paramount.

AI tools are powerful for generating code for well-defined, isolated problems, but they struggle significantly with ambiguity, capturing nuanced requirements, and ensuring long-term maintainability.

The engineers who will thrive are those who can effectively leverage AI as an accelerator for implementation details, while focusing their human expertise on the higher-level problem-solving, design trade-offs, and strategic decisions that AI currently can't handle reliably. It's shifting from *writing* code line-by-line to *orchestrating* complex systems effectively.",2025-04-10 15:29:30,1,traderprof,programming
mmgmkq8,1jvfxl3,reddit,I think this is true. When agent workflow tools get commercialized there will be an explosion of new apps.,2025-04-10 21:41:12,1,hammeredhorrorshow,programming
mmlkum3,1jvfxl3,reddit,"The awakening will be painful after having hired IT philanderers driven by AI who will have produced shaky software that will have to be put back together. End of recess, take out the white flag, CEOs!",2025-04-11 17:42:57,1,MrLyttleG,programming
mmlno7b,1jvfxl3,reddit,"The relationship between automation and job demand has never been linear in our field. Looking at historical patterns, each wave of developer productivity tools has ultimately expanded the market by making new applications feasible rather than shrinking it.

I've noticed that AI tools are already changing which skills are most valuable - shifting focus toward system design, requirements engineering, and validation rather than routine coding.

What skills do you think will become more valuable for engineers as AI tools mature?",2025-04-11 17:56:39,1,traderprof,programming
mmn4qad,1jvfxl3,reddit,Especially if they develop integrations with the dumpster fire that is Okta.,2025-04-11 22:35:39,1,ianlotinsky,programming
mmoth53,1jvfxl3,reddit,"The asshat that spent a great deal to get auth0, gave himself a fat raise, cut employee bonuses and then laid everyone off.",2025-04-12 05:29:05,1,Typical_Resolution_5,programming
mmao8v9,1jvfxl3,reddit,"It's advantageous for AI companies to sell the lie but Okta lives off b2b so they need to reassure their clients that ""yes you really do need all those licenses, even with AI"".",2025-04-09 22:58:37,1,darkpaladin,programming
mmb0610,1jvfxl3,reddit,/r/programming hearing this is like 😍💘,2025-04-10 00:07:29,1,bring_back_the_v10s,programming
mmacv0g,1jvfxl3,reddit,then fucking hire me.,2025-04-09 21:54:01,-2,cloverasx,programming
mm9z1ip,1jvfxl3,reddit,And if I had wheels I'd be a wagon,2025-04-09 20:43:01,-6,light24bulbs,programming
mma1swi,1jvfxl3,reddit,Hey who gave that guy the mic?,2025-04-09 20:56:17,-1,ToaruBaka,programming
mmd6gdg,1jvfxl3,reddit,Read the piece without paywall here: https://archive.is/KGYao,2025-04-10 10:37:24,0,CptHectorSays,programming
mmaeiej,1jvfxl3,reddit,"Didn't Shopify recently say only developers who can beat Skynet, I mean, AI, will get a job ...

I also like how CEOs of different companies, now come out and predict the future via orthogonal statements. This makes me want to trust their evaluation very much - after all you must be clever to be a CEO of a successful company, be it shopify, Okta, you name it. Never ever could AI replace CEOs (intellectually that is; as far as I understand, there may be legal requirements to have a real human be a CEO, even though it is a bit strange of a concept to me because it was also said that a corporation is like a real person before a court).",2025-04-09 22:03:05,-1,shevy-java,programming
mmakxws,1jvfxl3,reddit,Why? I'm sure an LLM could implement security breaches in his program as easily as a human programmer - if not easier.,2025-04-09 22:40:02,-1,somebodddy,programming
mmetjzr,1jvfxl3,reddit,"Software engineers, not programmers. The terms are often used interchangeably but there is a difference. Like the difference between a civil engineer and the guys who build the stuff.",2025-04-10 16:22:17,-1,Reven-,programming
mmae6lv,1jvfxl3,reddit,Someone will have to maintain all the AI code,2025-04-09 22:01:16,-2,weggles,programming
mmbzbcv,1jvfxl3,reddit,Delulu,2025-04-10 03:43:10,-2,chucks-wagon,programming
mmafam3,1jvfxl3,reddit,Has he been sniffing glue?,2025-04-09 22:07:25,-3,ziplock9000,programming
mmbhype,1jvfxl3,reddit,"Gemini's summary:

Okta CEO Todd McKinnon strongly refutes the growing fear that AI will eliminate software engineering jobs, calling the notion ""laughable."" He predicts that the number of software engineers will actually increase over the next five years as AI advances. McKinnon draws parallels to past technological shifts like the introduction of compilers, arguing that engineers consistently ""move up a level,"" focusing on more complex tasks like systems design as automation handles lower-level work. He believes the ""infinite demand for automation"" and the creation of entirely new applications spurred by AI will drive continued growth in the field, outpacing efficiency gains, despite current market anxieties and some companies' statements about reduced hiring, which he views skeptically.

Gemini's thoughts:

McKinnon's perspective seems largely accurate in the long term, grounded in historical technological precedents where automation tools ultimately increased demand for skilled workers by enabling more complex creations. The core argument that engineers will shift focus to higher-level design, integration, and solving more intricate problems as AI handles routine coding is logical and widely echoed. However, his specific prediction of more engineers within just five years might be overly optimistic, potentially downplaying the significant short-to-medium term disruption AI is causing, especially for entry-level roles and the current hiring slowdown reported by some major tech firms. While the profession is unlikely to vanish, the transition period could be turbulent, and the required skillsets will definitely evolve rapidly.",2025-04-10 01:52:35,-4,WeeWooPeePoo69420,programming
mlotl7l,1jsrtrt,reddit,"PTSD

I've been a frontend engineer, backend engineer, <insert blurb> engineer, architect, developer, <insert title>.

I've run BAs, product owners, product managers, project and program managers across 13 industries.

I've worked with graduates all the way to board level. 

I've worked from startup, scale up, enterprise. 

I've created two startups from scratch (both made good money and closed with happy employees).

I've worked on gcp,AWS,Azure plus private cloud.
From days of Pascal and C to Nodejs, React, Angular,.net,java, python, PHP, Android, flutter, stupid amount of cicd tools, and more.

The most common response I get....

""Thank you for your interest in <insert leadership role>, however your skillset doesn't match our needs of <insert ridiculously stupid thing engineers do once in a year>....""

The other is

""Sorry We are looking for a FAANG approved <insert role> individual that can leap mountains and turn time""


Get fucked, I'm out.


UPDATE:
I have been getting interesting questions and also some smooth brain attacks re this post so I'll add content here and leave it be. 

1. Not unicorn startups and less then 10 people in both
2. I love solving problems and creating solutions 
3. Why do I keep looking? Refer to point 2, also I can't imagine not doing something you don't enjoy and I love engineering, I'll probably be hacking my morphine drip on my deathbed.
4. I enjoy my lifestyle and I don't spend every waking moment working (hence me currently on Reddit while drinking on my porch at fuck look at the time)
5. Some of you have distorted ideas of what rich means, no I'm not Bezos rich, I'm comfortable for me and family
6. You think my post is all bullshit, I'm happy for you, I hope it brings you peace and a wonderful day.",2025-04-06 12:23:43,1226,TheAeseir,programming
mloskaw,1jsrtrt,reddit,"> All of this complexity is there for a reason.

I think we should stop assuming this. This implies that it’s reasonable, which is far from the truth. Closer to the truth is that all of this complexity has an excuse. Often to cover up a previous mess of our own doing rather than talking a step back. It’s also heavily incentivised career-wise.",2025-04-06 12:15:24,302,jahajapp,programming
mlp8anm,1jsrtrt,reddit,"The complexity explosion in software engineering seems to have two distinct facets:

1. The complexity required to solve hard problems
2. The complexity we introduce through lack of documentation and knowledge preservation

I feel like we focus too much on the first and not enough on the second. I've joined projects where understanding the existing architecture took weeks because nobody documented design decisions or created knowledge structures.

When I compare software to actual engineering disciplines, the difference is stark. Civil engineers don't reinvent beam calculations for each bridge - they have standardized knowledge transfer. Meanwhile, we're constantly reinventing state management patterns in each new project.

One of the most productive teams I worked with spent 20% of their time creating architecture diagrams, decision logs, and structured documentation that explained not just how things worked, but why they were designed that way. New engineers became productive in days, not months.

The irony is that we've built incredible tools for building software but terrible ones for transferring knowledge about that software. Then we wonder why tech debt accumulates so quickly.",2025-04-06 14:03:51,98,traderprof,programming
mlor3ko,1jsrtrt,reddit,"> Provide valuable feed during product meetings

Now we have to manage livestock too!?",2025-04-06 12:03:17,145,vajeen,programming
mlonu6r,1jsrtrt,reddit,This kind of description always reminds me that software engineering is not an actual engineering discipline,2025-04-06 11:35:07,416,mr_x_the_other,programming
mlpuy5d,1jsrtrt,reddit,This article is so biased towards web development though,2025-04-06 16:09:04,30,saxbophone,programming
mlpd4cb,1jsrtrt,reddit,"Reading this made me very relieved that I'm still being paid to do desktop app development, with no backends or css or any Javascript frameworks involved.",2025-04-06 14:31:39,73,guygizmo,programming
mlot7hb,1jsrtrt,reddit,">You know you need types, right? Add TypeScript. Are you really going to be managing state in React like a pleb? Add Redux.

a real ""insanity"" would be rolling your own types and state management. those tools standardise these tasks and make them **easier** for everybody

""You know you need nails, right? Add hammers. Are you really going to be managing spanners like a pleb? Add a toolbox.""",2025-04-06 12:20:38,72,prefixsum,programming
mlq0ft4,1jsrtrt,reddit,"All of this happened because people started pushing for tools instead of solutions. 


I am not telling to the civil engineer ""make this house with this kind of steel"" because that is the steel used for the Burji Khalifa so it must be good.


I am not telling the doctor ""cure my back pain with this medicine"" because it worked for David Beckham so it must be good.


And yet, we have clients asking to use React for a particular project.",2025-04-06 16:39:06,30,fosyep,programming
mlpgttd,1jsrtrt,reddit,"It’s about two things: 

1 - Software development is actually one of the most difficult things to do because a person has to imagine complex and abstract ideas in their head. Even if you personally find it easy to do this it is difficult and unappealing for most people in general. 

2 - Those who hire people to do software development generally do not respect the work or those who do it, but instead, they usually tolerate the whole thing as little as possible while always looking to save money at the expensive of literally anything or anyone else. 

People complain about lawyers. But lawyers actually, through the application off the rule of law, defend people against tyrants. Lawyers also figured out their best position long ago. With clients and partners and senior partners and starting their own firms they figured out how to take big facefuck companies and force respect. Both professionally and financially lawyers setup themselves up as an industry to never get fucked. 

Software developers should have done this long ago. Programming for money is hard and programmers should force people to pay for it. Full stop. 

But… instead we have a beautiful community where programmers share code and help and don’t value social status or formal training but instead operate like punk rockers, artists and hackers. The world is better for it and overall a lot of good has come from it. 

However the biggest problem is that it’s hard to have a community of creative people like that and also have them unionize or organize so that people like a certain billionaire (whom I shall not name) can just abuse nerds out of their time and money like a fuckface schoolyard bully stealing their lunch money. 

This AI grift-bubble is the same attitude. It’s trying to sell the idea to shareholders that you don’t even need those nerds because AI can just barf out all the code automatically. 

But outsourcing overseas back in the 90’s was the same grift. They would ask for 40% upfront, 40% on the first alpha version, and then 20% when they deliver the final version. Then they slap some crap together and fuck off once they collect 80% when the last 20% of the job is often the hardest. 

Likewise AI generated code is basically, but barely, the same. It barfs out bullshit code. It’s like maybe 80% of what you wanted. But you’ve still got to be a good programmer to refine that last 20% so it actually works. 

In the end is all about powerful and rich psychopathic narcissistic assholes who don’t give a shit about anything or anyone else but getting off on their own power. That leaves most developers to try and fend for themselves in a shit storm world that doesn’t get it and doesn’t give a shit. 

That’s why my current favourite kind of startup is that one person coding their little product for their little customer base. It’s a one to one customer relationship and usually makes products that actually create value. 

But yeah programmers should unionize. Not because AI can actually replace them but because the perception that it can is the most dangerous part of this whole grift.",2025-04-06 14:52:09,90,Liquid_Magic,programming
mlpzypi,1jsrtrt,reddit,"> You’ll also need CSS.

Looks like the title should be ""The insanity of being a _frontend web_ software engineer.""

Once again, the web guys assuming that nothing exists outside of web development.",2025-04-06 16:36:30,35,MrSurly,programming
mlpmqug,1jsrtrt,reddit,"> The programming hive-mind collectively decides that React is now the right way to build software but, at the same time, companies decide they can’t afford more engineers. Lo and behold the full-stack engineer is born and you’re it.

""Full stack"" as a concept has existed since time immemorial, even if that term hadn't yet been coined. I was doing frontend, backend, and database development in the early 2000s. If you look at say game development in the 90s, it wasn't uncommon for people to wear multiple hats - maybe being both a programmer and level designer. Go back to game development in 80s or 70s and programmers were also making art. 

At scale, sure, you need specialization. But if you're working on small products with small teams, you need to have a broad base of knowledge. That's true in other disciplines as well. 

Specialization both adds and removes efficiencies.",2025-04-06 15:24:25,6,balefrost,programming
mlp1u07,1jsrtrt,reddit,"On the requirements _to know some random current fashion framework_ (“That might be Rails or Django or Laravel or something else…”) - that’s damaging because the important principles behind frameworks are very much the same. Even if you take frameworks in different languages. Frameworks differ in things that are easy to learn on the go.

Alan Kay said in one of his talks about Computer Science that it is a problem that you can make _anything_ in software and there’s no external check to that, like nature in sciences and other engineering fields. (“Our subject is design, which means we make bullshit…”) That’s what creates the inessential differences. Then HR hires & management manages based on those differences instead of principles and actual skills.

Other fields also have tons of different standards that you have to know. E.g. electrical engineering is quite tough as well. So are machining, mechanical, etc. But at least they don’t have random new metric systems being invented every 10 years. It’s good when some science figured out a more or less solid floor of knowledge for you to stand upon. Unfortunately there’s no such floor in software.",2025-04-06 13:23:29,15,xealits,programming
mlprhja,1jsrtrt,reddit,"> Then came DevOps. Some cash-strapped company somewhere decided that now all of this would be handled by the engineers and everyone agreed.

Sorry OP but I just really don't think this is how that evolution happened. Read The Phoenix Project about how devops came around. Long story short, it made things better.

Same with how full stack engineers came around because some startup didn't want to hire anybody else. It's just complaining with an emphasis on being victimized. In reality, there were always full stack devs. Those are anybody who wants to be able to build themselves an application from top to bottom. React did not create that job description in any way, shape, or form.",2025-04-06 15:50:15,7,doesnt_use_reddit,programming
mlosu0r,1jsrtrt,reddit,"I never quite understand what is the point of these kinds of articles. It's pretty clear that a single person can learn these things, so it can't be about that. The work is complicated, but similar to other complicated fields, software engineers are well compensated. So it can't be about that either.",2025-04-06 12:17:37,65,jhartikainen,programming
mlorg04,1jsrtrt,reddit,The progression (or should I say regression?) through full stack to DevOps and who knows what next is lunacy and you can never change my mind. I bet most of the people here are too young to remember a time where software tester was a job title distinct from programmer as well. As was database engineer.,2025-04-06 12:06:11,18,Sharlinator,programming
mlqtazx,1jsrtrt,reddit,"As someone who is primarily a C++ person whose career has spanned game dev, virtual reality, and now robotics I do not resonate with this post at all.

> All of this complexity is there for a reason.

Webdev is garbage. Absolute dog shit garbage. It’s layers and layers of bullshit written by people who don’t know how computers work.

Modern computers are fast. Impossibly mind blowingly fast. Webdevs wouldn’t know the term cache locality if it punched them in the face.

I complain at work every week about internal web pages with 1+ second lag. My brothers in Christ you’re rendering text to the screen. It’s just quads of text. It should run at 300 fps. I genuinely do not know how I would write code as bad and as slow browser bullshit without sprinkling in sleep(1000) calls everywhere.",2025-04-06 19:11:27,21,forrestthewoods,programming
mlq498r,1jsrtrt,reddit,"This article is about nothing and provides zero value to the reader, yet at the time of writing it has 258 upvotes. If this is what passes as ""high quality"" here (the very first guideline of this subreddit) then I don't see any point in engaging in this community.",2025-04-06 16:59:31,15,FlatTransportation64,programming
mlqv0hx,1jsrtrt,reddit,"“Lo and behold, The Fullstack Engineer is born”.

Whoever wrote this must be young/new: being only “frontend” is a relatively new phenomenon (and a Zirp phenomenon) and is going away, as I figured it would",2025-04-06 19:20:45,3,allKindsOfDevStuff,programming
mlrg30b,1jsrtrt,reddit,[deleted],2025-04-06 21:13:25,3,N/A,programming
mlov63e,1jsrtrt,reddit,"It’s an amusing skim, but I’ve heard it all before - the article is beating a dead horse.",2025-04-06 12:36:04,8,CloudSliceCake,programming
mlprjwj,1jsrtrt,reddit,"The frustration I have isn't that I'm expected to learn these things but that I'm expected to already have expert level experience with things that are obviously highly specific to the way that particular company does things. Like, no I don't have experience using this one particular aspect of a technology in a highly critical massively distributed environment serving hundreds of millions of requests a second. You're one of like 3 companies in the entire world that do that and I haven't worked for you yet.",2025-04-06 15:50:36,2,bentreflection,programming
mlpv1me,1jsrtrt,reddit,If it was easy they wouldn’t pay us so much to do it,2025-04-06 16:09:36,2,ambientocclusion,programming
mlry9w7,1jsrtrt,reddit,"They meant ""web enginner"", I'm a software engineer that doesn't have to directly deal with most of the stuff listed because I do desktop and mobile application development.

Yes, I am bitter that everyone seems to think web engineering is the only kind of software development that exists.",2025-04-06 23:00:12,2,voidref,programming
mlsbic6,1jsrtrt,reddit,"I get it, and I sympathise. I once applied for a job that asked for deep knowledge in Rust, TypeScript, and Angular. I have about eight years of Rust, over a decade in TS, and extensive work in React and Vue. The job was described as working on pipelines in Node (which I’ve done), and integrating Rust with those Node pipelines (which I’ve also done). Felt like a perfect fit!

But I have no experience with Angular, and the recruiter said they wouldn’t give an interview because of that. Who agreed with me it was odd they wanted experienced Rust engineer and quibbled over Angular experience.

(I suspect they spoke about pipelines to sex up the job, and the reality was different.)

For a different role I was asked to whiteboard a system, that as it happens, I had built ground up at a start up. It went on to be a big success for them. It was literally the same system. The interviewer was not happy with the straight forward solution I gave, despite me making it clear I’ve literally done it and made it work at scale. It turned out his correct answer was AWS SQS.

So I get it.

But things like the old age of sys admins wasn’t a panacea. I once had to write a 10 page release document to change the time on a cron job, to please the sys admins in another building. You had sys admins who were kept very busy simply saying no to change. DevOps wasn’t about cutting money or jobs, it was about giving people direct access to the infrastructure they are using.",2025-04-07 00:21:43,2,jl2352,programming
mlu5if4,1jsrtrt,reddit,Similar experience for me. I think all-rounders are getting poor ratings from AI summaries of resume/CVs.,2025-04-07 09:35:11,2,paul_h,programming
mlpbovh,1jsrtrt,reddit,Do you all even like building software? I find these tools immensely useful.,2025-04-06 14:23:37,5,logic_prevails,programming
mlq3i3c,1jsrtrt,reddit,"Oh boo-hoo. Imagine the hell electrical and mechanical engineers have to go through. Mistakes in their job will kill people. Most of us ""Software engineers"" didn't even have to go to get a college degree to get the title. 

Articles like this remind me how fragile some SEs can be.",2025-04-06 16:55:29,3,cheezballs,programming
mloo9xf,1jsrtrt,reddit,Imagine having to stay up to date with current technology in a technical field.,2025-04-06 11:39:02,13,badabummbadabing,programming
mloswqt,1jsrtrt,reddit,OP confuses software engineer with developer / programmer,2025-04-06 12:18:14,1,zaphod4th,programming
mlpz3ji,1jsrtrt,reddit,I am lead software engineer on an embedded C project. I am recommendations exclusively on problem solving. That's all someone needs to be productive. Everything else will be learned.,2025-04-06 16:31:43,2,Traegan,programming
mlq43dr,1jsrtrt,reddit,"> At some point, the people at Facebook built React. [...] Lo and behold the full-stack engineer is born and you’re it. 

Are memories that short? I was a ""full stack"" dev when cgi exes were your back end, there always has been a lot we need to know, and just as much you need to forget. Nothing has changed, it's not any harder than it always has been. Thet comes with the pay cheque.

Try being a doctor, always having to keep up your CPD points, going to conferences, etc, potentially losing your ability to practice if you don't. Count your blessings.

We have it so fucking easy for the amount we get paid, and if you can ignore the stupidity of management you can actually enjoy the work. We get to basically do our hobby for money and learn shit we are actually interested in. 

> [... whine whine complain oh it's so unfair to get paid so much and have to learn so much, why can't a profession be easy... ]

My nephew took his electrician's exam recently. An exam! Just to even be able to work in his chosen field. ""Accreditation"", I think it's called... my god, how unfair is THAT?  On top of that, he will also need periodic accreditation review here. Is he having a cry about how terrible it is to keep learning new skills? No.

> When a house is being built, tons of people are involved: architects, civil engineers [.. random inapplicable comparison..]  You don’t expect a single person, or even a whole single company, to be able to do all of those.

Yeah, again because that involves high levels of regulation and accreditation. You are not a) beholden to any regulations, b) endangering lives, or c) going to be sued for anything. Stupid comparison.

What a completely ignorant winge this is. Look around you. Are there any other jobs like this in the world, at this wage level, where comparatively so LITTLE is demanded of you? 

If you don't like the demands of certain company, work for a different company. Another perk of this profession is the enormous range of roles available.. Hell you can be a private consultant or freelancer and do things for clients in whatever stack you like best. What other career gives you all those choices?

Seriously. Go be a baker or something. Oh wait, that's food prep accreditation, and omg all those new recipes to learn, nevermind.",2025-04-06 16:58:38,2,OpalescentAardvark,programming
mlonhrj,1jsrtrt,reddit,"You are right. But as a ""Manager Software Engineering"" you should have mastered the art of avoiding closed/hard commitments, being able to play the changes in specification and how features are ""worded"". Translate every word change into time and budget.

At the same time being a ""Project Manager"" that can have his/here team solve the technical challenges while ensuring the budget is available and alotted time is sufficient. With emphesis on protecting your team than protecting the product/customer.

Sometimes you are more a politician than a engineer.",2025-04-06 11:31:55,1,koensch57,programming
mlpynac,1jsrtrt,reddit,"the way we approach coding as a society is insane

if u imagine all coding language as in fact as just one super-language, and imagine all the arbitrarily nuanced duplication going on to describe what are fundamentally the same basic concepts ... u can begin to start realizing the sheer idiocracy it has become.",2025-04-06 16:29:14,1,fire_in_the_theater,programming
mlq3glz,1jsrtrt,reddit,Reminds me of this classic: https://www.stilldrinking.org/programming-sucks,2025-04-06 16:55:16,1,w0ntfix,programming
mlqmmup,1jsrtrt,reddit,"As a native mobile software engineer, I have a different experience, but also insanity",2025-04-06 18:35:44,1,tevelee,programming
mlr7jj7,1jsrtrt,reddit,"It is true that a software engineer kind of has to know a lot, in an applied manner as well. While one can easily stick to just one or two or perhaps three programming languages, I think knowing more languages and having written in them, is of potential benefit. The same can be said for ""secondary"" knowledge - math, algorithms, also project management to some extent. It's definitely a mountain of knowledge one should have here; life-long learning without a doubt.",2025-04-06 20:27:33,1,shevy-java,programming
mlrtc7o,1jsrtrt,reddit,"I left a React job and I see Rails offers in my inbox, is it coming back?",2025-04-06 22:30:41,1,nairazak,programming
mls23c7,1jsrtrt,reddit,"Lost me at “you’ll need to know CSS”. Like as if being a software engineer is limited to web development. Imagine all that CSS running on the mars rover, or CSS running a control system for a factory production line.",2025-04-06 23:23:10,1,TimeSuck5000,programming
mlsdmls,1jsrtrt,reddit,"Some of the tools are needed, some of them are crappy decisions.",2025-04-07 00:35:11,1,RealMadHouse,programming
mlsp3mg,1jsrtrt,reddit,"Im like the biggest mut, fresh Electrical engineer doing my masters in computer engineering but trying to work in software. About to learn javascript next semester.",2025-04-07 01:49:59,1,Comprehensive_Eye805,programming
mlt5ahv,1jsrtrt,reddit,Lol got to love the hustle.,2025-04-07 03:41:53,1,RiderFZ10,programming
mlta5iu,1jsrtrt,reddit,Didn’t even touch the offline world or scaling problems. This is just the tip of the iceberg.,2025-04-07 04:20:20,1,spicyclams,programming
mlthndk,1jsrtrt,reddit,"Awful conclusion, good article otherwise",2025-04-07 05:25:14,1,flanger001,programming
mlu1zy1,1jsrtrt,reddit,"I rate my software skills the way RPGs handle Major/Minor skills.

For example, I have major skills in backend Java and databases, and minor skills in frontend and docker. I have no skills in Terraform or Figma or perl.

Sure, I can write something in React or python, and write a DockerFile, or read a perl file, but once you start asking me to keep up with React, or which framework I prefer in python or javascript, or how I deploy on AWS using Terraform, you will be redirected to my specialized colleagues (Frontend developer, Python developer, System administrator) as I am not experienced enough to help you. 
If there isn't a specialized colleague, then I make it my (hiring) manager's problem. 

You don't expect a barbarian to cast high-level fire spells. Or a thief to run around in heavy plated armor. Decide on your major skillset and hone those skills.",2025-04-07 08:55:39,1,nomercy400,programming
mlu2xg6,1jsrtrt,reddit,"Personally, I stop at the DevOps tasks. I don't mind multiple programming languages and frameworks, I like working with them, but I refuse to learn anything DevOps related. I always tell them I am a software engineer, not a systems administrator.",2025-04-07 09:06:07,1,axilmar,programming
mludoev,1jsrtrt,reddit,"Complexity in software comes from people who don’t know what they’re doing being the driving force behind how and what’s built. 

Get rid of non-cs folks in the software industry and 50% of the problem is solved instantly",2025-04-07 10:55:33,1,imagebiot,programming
mlur26c,1jsrtrt,reddit,"Skill issue lmao, cry about it",2025-04-07 12:38:33,1,Top-Accountant4103,programming
mlurhdi,1jsrtrt,reddit,“Im a Solutions Engineer and my solution is to stop engineering”,2025-04-07 12:41:22,1,Bonzie_57,programming
mlv2vab,1jsrtrt,reddit,"If you really want to continue being a software engineer and find some satisfaction in your job, stop doing web development. Perhaps you can look more into embedded systems, desktop applications, or some more niche area that does not involve front end development.",2025-04-07 13:52:26,1,PacManFan123,programming
mlvon0y,1jsrtrt,reddit,"This is what happens when the CEO’s of organizations are not within the field that they survey. It has become bean counters over everything. Must optimize shareholder value over all up to and including the quality of the product you push. With the LLM’s becoming the supposed go to for tech, we will see more and more non tech people simply and proudly being as wrong as they can be as loudly as possible. Specialization is the end result of automation.",2025-04-07 15:45:33,1,AdvantagePretend4852,programming
mlw548g,1jsrtrt,reddit,"school close instinctive dinner attempt continue bow unite fragile crown

 *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",2025-04-07 17:10:07,1,Kraigius,programming
mlwbcyf,1jsrtrt,reddit,It’s not really that “insane” is it. Man white-collar professions require continuing education. If a bunch of tax laws change accountants have to know about it. The basic principles aren’t changing.,2025-04-07 17:41:05,1,RICHUNCLEPENNYBAGS,programming
mlxrcul,1jsrtrt,reddit,You get responses? I have 35 years of experience and I get nothing.,2025-04-07 22:12:39,1,smrxxx,programming
mlxtr2c,1jsrtrt,reddit,"Once you get into embedded programming you'll realize how ridiculously complicated SaaS programming has become, and only for the fact that somebody else is using similar technologies in their stack. And no you don't need kubernetes in every goddamn project",2025-04-07 22:26:29,1,dont_takemeseriously,programming
mlyh63w,1jsrtrt,reddit,"We are mixing bad hiring practices to whole sw engineer scene. Many working swdevs know less than what you describe and actively push back the expectation.

These demands come from only hiring side, which I call bullshit. The truth is hiring practice usually just put out extremely unrealistic expectation so they can reject candidate without risk accusation of unfair. But if you really the right person for them, you would not need to pass all those requirements.",2025-04-08 00:44:01,1,chrisza4,programming
mm0ourl,1jsrtrt,reddit,"I especially hate the ""React knowledge is an absolute must"", and then get filtered out as a full-stack dev with decades of JavaScript and years of Vue exp. on the frontend. C'mon man!",2025-04-08 11:46:32,1,josfaber,programming
mm5azai,1jsrtrt,reddit,"The insanity of being a *software engineer working on web or mobile applications. This isn’t true for all software engineering jobs. If you’re working on building kernels, compilers, databases, embedded, data pipelines or anything else like that the job is very different.

If you’re working in enterprise they usually don’t even let you touch the deployment environment even if you wanted to.",2025-04-09 02:31:19,1,Spirited_Ad4194,programming
mm60epv,1jsrtrt,reddit,"Software developers trying to put themselves on the cross as if it’s somehow a super hard unrewarding job is a massive joke right? In my early 20s I worked a lot of manual labour jobs, factory, construction, also worked at a couple call centres. I got into software dev in my mid 20s and it’s infinitely better than any of those other shitty jobs, the pay is wayyyy better and the job itself may be challenging, but stressful is a stretch lol",2025-04-09 05:40:10,1,flaiks,programming
mm72yn0,1jsrtrt,reddit,"I am not a programmer. As far as I can tell, based on the description in the article, it does not sound like a tough job.  If anything, it sounds like a cushy white collar job.",2025-04-09 11:52:29,1,TelevisionAlive9348,programming
mm7irje,1jsrtrt,reddit,Sounds like a skill issue,2025-04-09 13:30:21,1,Normal-Prompt-7608,programming
mm7mciu,1jsrtrt,reddit,"I was lucky enough to learn software development at a company using a single IDE/suite.  I’ve been developing with it for about 20 years, and I get to retire with a pension in 10. We are phasing the tool out, so I am learning other things. Along the way I’ve had to learn a whole bunch of JavaScript framework to make things pretty on the web, and some backend tools for communicating with other systems, which, thankfully I was able to do almost exclusively in Java.

My career consistency has resulted in much lower earnings, but a tremendous amount of stability, or from another perspective, tremendous amount of stagnation. I think I would have enjoyed the insanity OP posted about, I kind of thrive in chaos, when everything’s getting thrown at you all at once and you’ve gotta figure something out, but you don’t know what to do, but you just do something and hope it works…That’s my happy place. Unfortunately I’m so good at the specific framework I work in, I always know what to do, and there’s never really any risks.",2025-04-09 13:49:56,1,N/A,programming
mm9d8xb,1jsrtrt,reddit,Ditch react and use angular. Do Not use tailwind. Half of problems are gone.,2025-04-09 18:57:05,1,TheBrickSlayer,programming
mmci24q,1jsrtrt,reddit,"Funny, everyone make fun about PHP, but the real problem is and was all the time fucking JS. 
Yes, it does amazing stuff on the browser, but omg...

I'm just happy that I don't have to deal with JS anymore. I've never understood this language.

I congratulate everyone who understands JS.",2025-04-10 06:23:19,1,Oreo-witty,programming
mlpjetv,1jsrtrt,reddit,"You have to be called to this profession since it's difficult, makes your back sore, and has traditionally had extremely bad hours.
 

Still would rather be a software developer than a lawyer",2025-04-06 15:06:05,1,gc3,programming
mlur0sj,1jsrtrt,reddit,"Oh look, another webshit developer who thinks:

1. all software development revolves around webshit (CSS? Javascript? Web browsers? Web development frameworks? In my 25 years long or so career I never had to touch any of that ill conceived garbage)
2. is, apparently, overwhelmed by no so complex things
3. believes software development is somehow ""special"" and more complex/involved than other jobs (and yet in the same breath admits having no idea how things are outside of software development)

Coders deluding themselves into believing they do the most complex job on earth is how you get hackernews type ""most intelligent person in the room"" who think they can resolve the world's problems because they're good at touching computers.

I saw this first hand when I once worked with an extremely mediocre programmer who would say stupid things along the lines of ""we are literally paid to think and that makes us big brain geniuses"".",2025-04-07 12:38:17,1,ClownPFart,programming
mlp2ux2,1jsrtrt,reddit,"If you don't like continuously learning new things, software engineering is not for you.",2025-04-06 13:30:15,1,chafey,programming
mlp1vk6,1jsrtrt,reddit,"I understand the point of the article. But OP sounds like they're experiencing tunnel vision. EVERY worthwhile discipline is like this, unless you're in the boring side of academia, which pays 30% of what software engineers get.

The world is complex, and new complexities and challenges always come up to punch you hard. you have to keep learning new things everyday, you should treat yourself as a company, and breath R&D

Once you stop learning and wish challenges disappear, you're already behind.",2025-04-06 13:23:46,-1,imported_username_,programming
mlorb9b,1jsrtrt,reddit,And python and Perl,2025-04-06 12:05:05,0,TheApprentice19,programming
mlp1vnq,1jsrtrt,reddit,"""Provide valuable feed during product meetings""


I do love a good lunch and learn 🙂",2025-04-06 13:23:47,0,sedatesnail,programming
mlzhkku,1jsrtrt,reddit,"How about stop simpping to the latest technology? Stuff like Coffee script, Ruby on Rail, is quite obvious it won't last long, so don't get into it until the technology matures. If you think web development is immature and changes too fast, how about going into other industry where they don't chase after new tech every 6 months? Sure it is easier to get a job knowing the latest trendy technology, but if that's your entire personality, you will be forced to keep chasing the latest trend.",2025-04-08 04:47:32,-1,BoBoBearDev,programming
mloxt0q,1jsrtrt,reddit,And you get a fat paycheck for all those skills you learned so stop bitchin’. It’s not like you’re working two shifts at McDonald’s and being paid minimum wages.,2025-04-06 12:55:30,-11,totally-not-god,programming
mloyiax,1jsrtrt,reddit,"Stop the moan please, since LLM's arrived this field has never been easier for a seasoned vet",2025-04-06 13:00:33,-16,babige,programming
mo8xkq9,1k4c4t0,reddit,"If Microsoft actually broke the MIT license by removing the original license information / claiming they wrote the code themselves when they actually copy-pasted it, that's illegal, isn't it?",2025-04-21 12:42:48,890,Pesthuf,programming
mo902yk,1k4c4t0,reddit,"This reminds me of the Winget and Appget story: 

https://keivan.io/the-day-appget-died/

Notice the same parallels. There is some reaching out by MS (in fairness, that's better than nothing), followed by silence, followed by the original creator being blindsided.",2025-04-21 12:59:00,284,iamapizza,programming
mo8w7s6,1k4c4t0,reddit,"Devs love to take mit code and remove it's license entirely. I dunno why, just do the bare minimum and keep some, any amount of source code citation",2025-04-21 12:33:44,168,bzbub2,programming
mo9i80c,1k4c4t0,reddit,"Microsoft actually has a whole lot of internal people and processes dedicated to compliance, especially for use of open source. The conduct here (not complying with the original license) would be seen as violating standards of business conduct and would quickly be corrected.

If I understand correctly, the ask here would be for peerd to be relicensed under the original MIT license? I'd email the current maintainers and cc buscond@microsoft.com with the concrete ask.",2025-04-21 14:41:31,61,ysustistixitxtkxkycy,programming
moc8yuk,1k4c4t0,reddit,"- [This issue](https://github.com/Azure/peerd/issues/109) from 11 hours ago mentions lack of attribution and cites OP's blog post.

- [This PR](https://github.com/Azure/peerd/pull/110) merged 3 hours ago adds attribution and closes the issue.

The project currently contains the same MIT license that Spegel was licensed under, and now properly mentions the Spegel Authors' copyright. Seems OK to me.",2025-04-21 23:14:27,23,kogasapls,programming
mo8uvti,1k4c4t0,reddit,Licensing will always be a problem. And being exploited by big corpos especially Microsoft and Amazon is a reality everyone will have to go through.,2025-04-21 12:24:41,77,RoomyRoots,programming
mo96441,1k4c4t0,reddit,"Well, if you have meetings with big corps, they should be for selling your product, not explaining the architecture to facilitate the theft",2025-04-21 13:35:54,28,RB5009,programming
mo8wyyx,1k4c4t0,reddit,Use GPL,2025-04-21 12:38:46,127,agilefishy,programming
mo9pu53,1k4c4t0,reddit,"Spegel was licensed with the MIT license and so is Peerd. The only thing Microsoft has done wrong here, as far as I can tell, is changing the copyright owner to themselves in the license file, that is an easy fix.

If the author of Spegel doesn’t like the terms of the MIT license he shouldn’t have licensed it as such.",2025-04-21 15:19:59,25,wildjokers,programming
moe4dih,1k4c4t0,reddit,"you could simmer this down to ""MS spoke to you about collaborating and asked you a bunch of questions about architecture then decided to fork your project without any proper attribution and push you out of the space you created"" and somehow people dont see this as transgression? That's insane to me.",2025-04-22 06:50:51,6,SweetBabyAlaska,programming
mo8w8eu,1k4c4t0,reddit,"Embrace, extend, and extinguish",2025-04-21 12:33:51,63,elmuerte,programming
mo9ri0j,1k4c4t0,reddit,"10/10 headline. I, too, would like to get forked by Microsoft",2025-04-21 15:28:16,3,DaBluBoi8763,programming
mo8xja0,1k4c4t0,reddit,"That's why I tell everyone to set limits on how your software and product can be used, when you are open source. 


The limits can be even very high, just to make sure that the giants are not trampling on you. 


If you make millions, you can afford to pay a few bucks.",2025-04-21 12:42:32,20,Bitter-Good-2540,programming
moh8qkb,1k4c4t0,reddit,"The GPL is actually really well thought out and put together. It’s also legally been tested in court. Additionally if you assign copyright to the FSF then they could use their lawyers to take an infringer to court.  

However there are people that want to do this:

- They want the “community” to see the source and contribute.
- They want the “community” to be able to use it personally freely.
- They want to maybe make a little money off of it but can’t actually be bothered to run that like a proper business.
- They don’t want anyone else, like a big company or even a little one, to make money off this. 

Well this is just not tenable. It’s not. I know many people want it to be but it isn’t. 

The GPL was about freedom. Both freedom of the source code but also freedom for the end user. The GPL licences do this very well. 

As soon as you start controlling the freedom it’s no longer freedom. 

This freedom lets people use, remix, and learn using the source code. It also lets them build a business around that code. If they do that they *have* to play nicely and publish that code. So if they use their commercial money to pay developers to use the software they can and the original project benefits. 

This also means that if an end user contributes some code to that project then their code will also be free. They can know that their code will not get lost into some closed source code and benefit only some company. So when a very permissive licence allows something like that then it’s possible a project that gets contributions in good faith ends up benefiting a company in their not freedom enabling source code. 

Of course if you put your time into a project and it’s GPL and some company ends up getting rich because of it that’s maybe not a great feeling. However the original creator of a GPL knows that other people can contribute and not lock it all up, and the big company making money is also not able to lock it all up. So the project benefits from any changes the company makes because they are forced to do that or else they can’t use the code. 

Once you try and prevent this you basically end up saying to people: “hey contribute to this project. It’s basically only for this one person to make money off of but hey you won’t get sued if you use it personally.” Well that’s essentially no different from proprietary software that sold for $0 money and you get to look at the source code. 

Sure there’s a place for that. I’m not against proprietary software.

But here’s the thing: if you really don’t care about your software you can release it into the public domain. But if you do care then the GPL makes the most sense. It gives the most freedom while limiting the ability of anyone to use it to create something else that gets locked up. 

Here are the simplest choices: 

1 - If you want to control who how you’re remembered for the software and be the only one who makes the money: go proprietary. 

2 - If you want to make a community and a difference: go with one of the GPL licenses. 

3 - If you want to give it away and not a give a shit whatsoever: go public domain. 

As soon as you try to get into fine grained control it becomes a slippery slope where the unintended side effects become complicated and hard to predict. The problem of that complication is that your potential users and especially your potential contributors now have to struggle with understanding all these complications. 

For example I can go on eBay or Amazon and buy a box of software on floppy disk or CD-ROM or USB drive or buy a movie on Bluray or whatever. I can then turn around and resell that box on eBay. I don’t have a licence to setup a projector in my driveway and charge the neighbours $5 to come watch that movie but I can sell my one copy to them for $5. 

I can do that. It would be chaos if I couldn’t do that. 

But what if I bought some software and the licence said I wasn’t allowed to create tutorials on how to use the software? By using the software I’ve agreed to that licence restriction. So now my (hypothetical) business making tutorials could be sued by the company if I didn’t notice that clause. I would now have to go to court and test if this limitation was actually enforacble. 

Now what if the author of some semi-open but actually closed source software sold a copy on their website on USB drive. The licence says that you get to use the software and source code and share it but not for commercial purposes. 

But now I want to resell my USB stick based software because I don’t want it anymore. Is that “commercial purposes”? What about making tutorial videos? Is that “commercial purposes”? What if I decide to do tutoring for other people who use the software and charge money for that? Is that “commercial purposes”?

I’m sure the people who want to release their code freely but not for “commercial purposes” would say “oh no, that’s okay. You can do that. You just can’t sell the software”. Well now your licence needs to reflect that or you need explicit permission from the owner. 

This is a crazy mixed up rabbit hole! And thinking about that rabbit hole will put people off of contributing to the project. 

The GPL avoids that whole mess. Sure you give up control over who makes money. But you don’t loose control of ability of yourself and others to access the source code and build upon the source code and have that improved code also be accessible. 

Something like the MIT or BSD licence let’s someone take the code and build a product out of it and not share their improvements. But with the GPL anyone can make and sell their version of it but they HAVE to share it! So if your competitor makes their product better then you can incorporate their changes into you product and now your product benefits too. 

To me those 3 choices I outlined make the simplest and most predicable sense. Anything else just adds too much complication for whatever benefits might be brought by it. 

Wow sorry for the wall of text.",2025-04-22 18:56:27,3,Liquid_Magic,programming
mo8zuj2,1k4c4t0,reddit,"Morally, I think I would expect Microsoft to make a donation or be upfront about their intentions when they originally asked for help. They essentially took someone else's hard to work for free and now (presumably) make a profit from it.

But legally they're within their rights to do whatever they want. Writers of open-source code freely give that right to others. So on the other hand, I find it hard to have sympathy if someone makes their code open source and then gets upset if a big company forks it or uses the code in a way they don't like.

It could have been prevented by putting a more restrictive license on it, if that's what they wanted. But if they want to empower the general public and are willing to work for free, then I think they've also got to be prepared for the downside of a Microsoft doing something like this.",2025-04-21 12:57:29,18,BaffledKing93,programming
mo9kuf5,1k4c4t0,reddit,"This is why the polyform licenses are gaining usage

https://polyformproject.org/licenses/

They are the closest I’ve seen to Do whatever you want except extinguish us",2025-04-21 14:54:48,10,AReluctantRedditor,programming
moaf901,1k4c4t0,reddit,"So, you used a license that basically allows anyone to do whatever they want with the code, and now you’re upset that someone is actually doing something you don't like?

Next time use a less permissive license!",2025-04-21 17:38:38,6,sfandino,programming
moehrsf,1k4c4t0,reddit,"Oh, how I'd love Microsoft stealing my ideas how to [fix their stuff](https://github.com/tringi/papers).",2025-04-22 09:15:32,2,Tringi,programming
moa6jnz,1k4c4t0,reddit,"Your only protection against businesses that want to exploit your labor as a programmer who is releasing code for others to use is to combine the use of a reciprocal license with requiring a license agreement with contributors to your projects such that you exclusively maintain the ability to provide additional rights to others via contracts. Anyone who wants to use your code in a reciprocal manner can, and Microsoft and other behemoths can purchase additional rights from you as you see fit to provide.",2025-04-21 16:56:59,2,dontyougetsoupedyet,programming
moduewc,1k4c4t0,reddit,">How can sole maintainers work with multi-billion corporations without being taken advantage of?

In the context of open source; [by not using cuck licenses](https://lukesmith.xyz/articles/why-i-use-the-gpl-and-not-cuck-licenses/) like MIT.",2025-04-22 05:15:19,4,kamikazechaser,programming
mo94v4e,1k4c4t0,reddit,Same thing happened with Lerna https://www.reddit.com/r/linux/s/LOx9yZccJj,2025-04-21 13:28:26,2,tackdetsamma,programming
mo96q2c,1k4c4t0,reddit,Don't listen to the people here. Get an IP lawyer and see if there's an early retirement waiting for you ,2025-04-21 13:39:29,1,AManHere,programming
mo9gfp1,1k4c4t0,reddit,"Assuming the article is correct, Microsoft should fix their attribution. However I’m wondering how they contacted Peerd maintainers to fix it. Also the whole David vs Goliath mention feels weird to me, MS has all the right to fork as long as they attribute correctly. Just ask them to fix their attribution mistake first…",2025-04-21 14:32:24,3,IdyllicIdiot,programming
moaqfid,1k4c4t0,reddit,Should've used AGPL. Don't cry now.,2025-04-21 18:32:39,3,UNIX_OR_DIE,programming
mob3ib2,1k4c4t0,reddit,"Not a lawyer but IIUC, as a substantively transformative work, Peerd would not need to retain the verbatim copyright notice from Spigel. Based on a cursory review of the repos, it does appear to be substantively transformative. And since the original MIT license allows permissive use of whatever similar function names might remain, it doesn't seem like there's much to complain about here. They even credited Spigel in their acknowledgments, which is purely optional.

Sounds like if the author is miffed by Microsoft's behavior here, they should have used a less permissive license.",2025-04-21 19:37:18,3,MooseBoys,programming
mo98sta,1k4c4t0,reddit,"getting ""f----ed"" by Microsoft is the experience of anybody who's touched a computer in the last 30 years",2025-04-21 13:51:25,3,sob727,programming
mo9nwqm,1k4c4t0,reddit,"Not the first time, nor the last. Remember appget?",2025-04-21 15:10:16,2,Worth_Trust_3825,programming
modph0b,1k4c4t0,reddit,"Here is a strategy for people.

1. Take an LLM and fine tune it with this code, all forks of it, and all similar open source projects.
2. Ask that LLM to code a project that does the same thing.

Voila!, technically you are not violating any copyrights.",2025-04-22 04:35:21,2,myringotomy,programming
mo9sdud,1k4c4t0,reddit,"This is what Evan Czaplicki calls getting ""Jeff'd.""",2025-04-21 15:32:38,1,ChavXO,programming
moe4ner,1k4c4t0,reddit,Looks like Microsoft forked up.,2025-04-22 06:53:37,1,SameVariation9043,programming
mog04r0,1k4c4t0,reddit,"If Microsoft wants to make a statement to its employees, firing the Product Manager would send the right message.",2025-04-22 15:20:57,1,controlxj,programming
mogr1dy,1k4c4t0,reddit,"im wondering if a stricter license could have benefitted the project? 

for example, maybe it's free for personal use, but requires a commercial license subscription if you're making over a certain amount with it.

similar to how game engines license their software but for code instead.

is that not possible? or is that something really hard to uphold?",2025-04-22 17:30:18,1,Lucrecious,programming
mogx5i7,1k4c4t0,reddit,<Sarcasm> Remember now as all the MS apologists will tell you (repeatedly) Microsoft has _changed_. They’re not evil stealers of other people’s hard work! </Sarcasm>,2025-04-22 17:59:21,1,Casalvieri3,programming
morqae5,1k4c4t0,reddit,"I saw this situation in YouTube channel from MiduDev, this was really not nice.",2025-04-24 11:21:30,1,Heavy-Blacksmith4411,programming
moabtzl,1k4c4t0,reddit,"> Spegel was published with an MIT license.

And there you go. The PR push for painting GPL being ""bad"" and ""viral"" is near entirely by corporate developers so they can make their job easier without paying anyone or contributing back.",2025-04-21 17:22:18,1,CrunchyTortilla1234,programming
mo9avzp,1k4c4t0,reddit,Getting f***ked by microsoft,2025-04-21 14:03:02,1,trenixjetix,programming
mo9btc2,1k4c4t0,reddit,The mistake is thinking this is “Microsoft”. It is about individuals that are seeking advancement at all costs. I doubt there was any discussion or strategy. Somebody wanted a promotion. So it’s more about leveraging any mechanisms within the organization to enforce ethical norms.,2025-04-21 14:08:08,1,Tricky_Condition_279,programming
mo8yqx3,1k4c4t0,reddit,I'm not really seeing the issue? This is the whole point of MIT. And MS version is still MIT as well.,2025-04-21 12:50:27,-2,Jmc_da_boss,programming
mo97k0f,1k4c4t0,reddit,GPL + no commercial use without license,2025-04-21 13:44:19,1,_ciruz,programming
moe36st,1k4c4t0,reddit,"I wonder, if it wasn't MS, but some random guy forking this, would people be equally mad?",2025-04-22 06:38:37,0,Hacnar,programming
moaoi0a,1k4c4t0,reddit,"Don't fork 'em!

Spoon them!!!

> It looks as if large parts of the project were copied directly
> from Spegel without any mention of the original source.

I kind of prefer BSD/MIT licence myself these days, but I don't
quite understand the issue here: if you would want to avoid this,
use GPL and then sue these greedy mega-corporations for
stealing your code.

> I am frequently asked about the differences between Spegel and
> Peerd.

Yeah that can be annoying. The current team maintaining rubygems
introduced various restrictions such as ""after 100.000 downloads, you
can no longer remove your gems"". In other words, taking away control
over my own code (!) while people downloading my gems assume I 
still maintain gems I would WANT to remove, but can not because these
geniuses at rubygems decided otherwise. As I don't want to have emails
asking for bug fixes for projects I no longer maintained, I decided to quit
rubygems (I am fine anyone forking my MIT or GPL projects, so the issue is not about forking my code, the issue is about insinuating association when there is none, and I can not do anything other than delete my profile - that part was annoying). So I can relate to him not wanting to invest time clarifying how
other projects that are similar, are not so similar. It's quite interesting that
Microsoft is doing so - not good for your reputation, big blue!

> In my conversation with Microsoft I was open to collaboration to continue building out a tool to benefit the open source community.

Alright - at the least this part is not Microsoft's fault, but of the blog author, sorry.

> How can sole maintainers work with multi-billion corporations without being taken advantage of?

Yes this is a problem. GPL helps a little bit, at the least more than MIT. It's still time investment and legal issues. It's not just mega-corporations though. There is an overall tendency towards more and more time investment in general. This was also one reason I cut down my time investment in regards to open source - at the least the one that is distributed online; I still write a lot of code, but a lot of that also stays local (to some extent, at the least also compared to, say, 3 years ago).

> along with the strong decline in investment in open source as a whole, how does the community prevail?

It is indeed a problem. And I don't mean total funding either. Of course donations help to some extent, but there needs to be a better distribution of resources such as money. Again, not in the sense of ""paid full time professional developer"", but simply more money that goes overall into open source in general. Right now the distribution seems unfair, even without greedy mega-corporations acting as the ultimate leeches.",2025-04-21 18:23:10,-1,shevy-java,programming
mo9cgid,1k4c4t0,reddit,classic EEE in full effect,2025-04-21 14:11:37,-3,mailed,programming
moa7fzp,1k4c4t0,reddit,"Whenever ANY corporation asks you to spend ANY time on their behalf (""Tell us what you think"", ""Tell us why you cancelled"", ""Meet with us about your OSS"" - __ANYTHING__), make them PAY YOU for your time.


Do NOT, under ANY circumstances, do work for corporations that they ask you to do for free.


EVER.


Any they WIIL, OFTEN, as you to DO WORK FOR THEM FOR FREE.  I see it here on Reddit pretty much every day!  Billion dollar corporations asking people to do work for them for free. 


THAT is exploitation. If OSS is used according to license, that's not exploitation.  If it's in violation of licensing like this article describes, that IS exploitation.


Choosing to write OSS software of your own accord, and making other choices _not_ of some corporation's request is _not_ related to my point.",2025-04-21 17:01:15,-3,Traveler3141,programming
mojr9w6,1k4c4t0,reddit,"Vote this up!

I created the Small Business License for my AI tooling. NO WAY do I want Microsoft or OpenAI or ANY non-small business / individuals using my AI stuff for *FREE*:

https://github.com/AutonomoDev/SmallBusinessLicense

This would have prevented this fork from happening. Microsfot would have to buy a commercial licnese that you could put any restrictions you wanted, even Microsoft-specific restrictions.

Please share the word.",2025-04-23 03:12:36,0,hopeseekr,programming
moctk7m,1k4c4t0,reddit,"I kinda feel bad for Avtakkar.  Yes, he did something foolish, and he is already starting to pay for it, but I am confident he didn't understand how bad it would be to be ""that person who stole someone else's project"" in the community.   As for Microsoft they could go either way but I imagine it will be easier and simpler just to cut ties and blacklist him.",2025-04-22 01:12:34,-1,ionixsys,programming
mom9yqt,1k4c4t0,reddit,"Stop spreading hate.

This is not the issue anymore.",2025-04-23 14:58:46,-1,fieryscorpion,programming
mo8v8vg,1k4c4t0,reddit,Is this whole article a brag that someone at microsoft used the code from a library that blog owner created?,2025-04-21 12:27:08,-56,Levomethamphetamine,programming
mo96of7,1k4c4t0,reddit,"If they do this, whats going on with the privately hosted code on github?",2025-04-21 13:39:12,-3,kingslayerer,programming
mo8ye88,1k4c4t0,reddit,"Microsoft violated anything, the license perhaps?  Seriously, I don't get what his problem was.",2025-04-21 12:48:10,-20,AKMarshall,programming
mo9mmuv,1k4c4t0,reddit,And what willyou do? Sue them? lol,2025-04-21 15:03:49,-6,Eastern_Interest_908,programming
mmsf8oc,1jxpl9c,reddit,What's clever about over-using one letter variables? ,2025-04-12 20:23:45,601,RiverRoll,programming
mmsgga6,1jxpl9c,reddit,I have long said people who think they are being clever when writing some obtuse piece of code are the absolute worst engineers. Your cleverness makes it 1000% more difficult for the next person. I will always try to get the author to fix this type of code in their prs.,2025-04-12 20:30:31,344,zoddrick,programming
mmsiwzs,1jxpl9c,reddit,"The difference between a junior and a senior. 

""Wow this code is cool I bet no one will understand it but it's so sweet"" 

""Wow this code is hard to understand, I won't remember it in 6 months, better document it""",2025-04-12 20:44:06,166,Kinglink,programming
mmskccl,1jxpl9c,reddit,"This was parroted already 20+ years ago when I began, or the more clever acronym: KISS, keep it simple stupid. But instead this has been used as an argument for lazy programmers to pick the most apparent solution; the one which most programmers would think of from the beginning, and consequently code bases grow huge & slow. You can open up a file of 1000+ lines of code & realize it accomplishes almost no actual work, superfluous comments, elimination of all sub expressions, and it's a major PITA to get an overview of what's going on because everything is so spread out & there's only so much short term memory in the mental computer. I actually think there's mostly 1 thing wrong with the so called horrible python code in this article, it's the variable names, otherwise it's quality code. It says what it does on the tin, it's contained, it uses standard python functions which should be in most python coders toolboxes, and if it turns out there's some error here you want to debug you can just split out the sub expressions & get to work if you want.",2025-04-12 20:51:59,109,Sairony,programming
mmsv6mt,1jxpl9c,reddit,"The irony is that truly clever code is not the clever code that is referred to in the article, that's like level 1 cleverness.",2025-04-12 21:54:32,21,UMANTHEGOD,programming
mmuwcep,1jxpl9c,reddit,"In my 60's now and still writing code..or programming, as I still call it.

Had a stroke in October 24 and have some memory issues now.

I have to write code as if it is being written for a stranger to read..because in 3 months time I will be that stranger. Sometimes I will remember nothing about the code except the names.

So..clean variable and function names. No hidden side effects. No hidden assumptions. Everything a function does is explicitly named. Prefer simplicity over complexity.

How's it working out for me? Ok. It actually does help me to understand things I might see months or even years later...I do a lot of refactoring, write the code first then clean it up, fix the names etc.

I often find I reuse code at least three times..which includes three sets of refactoring..before it is in it's ""final"" state. How do I know it;s in a final state? Because I can use it in other projects without having to change anything or fix any hidden assumptions or side effects.

In addition simplicity can actually help the compiler.",2025-04-13 06:36:10,18,TheDevilsAdvokaat,programming
mmsdg3d,1jxpl9c,reddit,"I recently had this feeling with some complex, and ""very elegant"", AutoMapper profiles. It was taking the results of a couple of queries, and projecting them out in a view model. One of the collections on the view model was getting created with some property values not getting set. It difficult to even wrap your head around how exactly it was doing these complex, nested mappings and projections. Even once I finally got past the cognitive load of that, it didn't really matter, because it was still impossible to debug in a straightforward/traditional manner. It was still going to be a whole lot of guess and check. I couldn't help but wonder what we were gaining for this clever code, instead of having probably a 2-4 dozen lines of code doing a few for loops. It would be super easy to follow, and you could cleanly debug everything all the way through.  Buy apparently it is better to use packages that save you some lines of code, but make everything about the developer experience worse. 🤷",2025-04-12 20:13:49,10,poop_magoo,programming
mmsj27r,1jxpl9c,reddit,There’s a difference between prematurely optimizing code and deliberately writing slow code because it’s easier,2025-04-12 20:44:55,40,Jobidanbama,programming
mmsje9e,1jxpl9c,reddit,"> I now understood why Big Tech seemingly had so many docs — half of the docs I wrote didn’t need to be written, except they did… because I wanted to get raises and be promoted.

Yup, just had this talk with my manager. He asked me to write more documents, give more presentations, even if they’re not necessary, because they’ll help him argue that I deserve a promotion.",2025-04-12 20:46:48,20,Arandur,programming
mmsocbj,1jxpl9c,reddit,"So in defense of consise code:

I've seen the code bases of people who aggressively wrote clean code.  There were *multiple pages* of intermediate variables in some modules.  Tracking down what happened where was ""easy"" in the sense that the code wasn't doing anything clever, but not ""simple"" in the sense that you often had to scroll through several different very large files to find what you were looking for.

There were some troubleshooting tasks where I would have rather been dealing with a code-golfed one-liner than reading through pages and pages of useless comments and variable declarations.

If you're familiar with the language in question, its often faster to decode a one liner than it is to read several pages of boilerplate.",2025-04-12 21:14:39,18,Bloaf,programming
mmt0jqd,1jxpl9c,reddit,"Clever is subjective. I tried to use pubsub at a job to replace useState in a react provider to avoid re-rendering the entire app on state change by allowing only the children that needed the value to subscribe, but it got tossed because my team didn't know what pubsub was.

They told me clever isn't always the best way to go.",2025-04-12 22:26:52,21,ohx,programming
mmtcprh,1jxpl9c,reddit,"My CS professor used to say that we write code to be read by other people and only incidentally to be executed on a computer.

One of the reasons why code reviews are so important - not so much to find bugs, but to get a second pair of eyes into the process. For the author the code is usually ""clear and obvious"", because they just spent hours/days on it and it's all fresh. But the real test is if this is also clear for someone else.",2025-04-12 23:42:55,10,Pharisaeus,programming
mmuthpo,1jxpl9c,reddit,"The problem described in the article is not the code, the problem there is the absolute tool of a manager that doesn't respect the craft, or the work other people do.

> “While I understand how complex this was, when it comes to performance reviews, this code looks trivial. It looks too easy, too simple.

That's a bad manager. He should be replaced by someone actually competent.",2025-04-13 06:08:05,9,Nicolay77,programming
mmsa7ne,1jxpl9c,reddit,"A related saying I'm fond of is ""An hour of programmer time costs as much as a month of CPU time.""

Although that is just a re-wording of ""Premature optimization is the root of all evil.""",2025-04-12 19:55:46,65,Hrtzy,programming
mmuticy,1jxpl9c,reddit,"I am preparing the lecture on sorting algorithms. Every single one of them uses clever code. It is not trivial to understand, at least for my students, but it is not out of malice, the ideas used are just actually clever.

I can imagine the complains: ""why learn this, we will never use it"" and my favourite: ""this is only useful for interviews"". No, this is computer science, and sorting algorithms are fundamental.

The good thing is there are lots of very nice videos explaining all the details about them. It is clever code, but also extremely well documented.",2025-04-13 06:08:15,6,Nicolay77,programming
mmx7d71,1jxpl9c,reddit,"Code Complete still relevant in 2025, software engineering profession has barely changed in the last 30+ years, more at 11. 

Next week; measuring engineering efforts in man-hours is futile and leads to mythical timelines.",2025-04-13 16:56:26,4,hans_l,programming
mmswmk5,1jxpl9c,reddit,"""Clever code"", ""simple code"", etc are thought-terminating cliches with zero real relevance to actual code. These discussions are nothing more than endless circlejerks about how much smarter you are than the developers you're shadowboxing.

This article is in LinkedIn Standard English, so clearly nobody actually read it, otherwise it wouldn't be #1 on the sub.",2025-04-12 22:03:03,21,starlevel01,programming
mmub55r,1jxpl9c,reddit,"I think it was Brian kernighan who said that debugging is twice as hard as writing code, so if you wrote your cleverest code , you're kinda by definition not clever enough to debug it. Likely paraphrasing",2025-04-13 03:35:25,3,dom_ding_dong,programming
mmv7n5w,1jxpl9c,reddit,Being boring and completely uninteresting is one of the highest praises for a piece of code. ,2025-04-13 08:32:34,3,yksvaan,programming
mmyxst7,1jxpl9c,reddit,"Not sure if I'd be calling those example and ideas ""clever code"", maybe minimised code, or terse code. I'd call code ""clever"" where it does something that you normally wouldn't think possible to do, or where it should on the surface be far more complex. Those can be incredibly difficult to read and understand later as well (not always though), but the achieve something that wouldn't otherwise be possible, that's what makes it clever, not how little code you used.",2025-04-13 22:30:45,3,m00nh34d,programming
mmsbh9j,1jxpl9c,reddit,"I know the title is just click bait and I understand the point of the article (hardly a new point but still valuable). 

However, sometimes what is clean code in some eyes is disgusting in others. I look at clever code as easy to read and understand. 

Some people think writing most inefficient code possible is clean and suggesting an improvement to the algorithm or layout is premature optimization and being too clever.

So in this case, it’s C++, why the hell would performance not matter. If performance doesn’t matter then we might as well be writing in Python or Go. Why would we deal with the headache of learning all the strange ins and outs of C++ (or the trendier Rust) if performance didn’t matter?

A lot of people think optimizing for performance is premature and it’s being “too clever.” I think these types of mantras definitely perpetuate this.

If this is all what programmers are hearing, no wonder apps keep getting slower even though hardware is faster.",2025-04-12 20:02:48,21,Ok-Bank9873,programming
mmsipzg,1jxpl9c,reddit,"I think it’s ok if you put the intent of your clever one liner as a comment above the clever code. That way if you need to revisit it you understand the original intent, and can go from there",2025-04-12 20:43:02,6,PureDocument9059,programming
mmsmhhw,1jxpl9c,reddit,"I've found this problem has intensified dramatically with AI-assisted coding. When working with LLMs to generate code, they often create unnecessarily clever solutions that optimize for compact implementation rather than maintainability.

In one recent project, I had to modify a feature implemented with AI assistance just weeks earlier. Despite passing all tests and functioning correctly, understanding the design decisions became a major challenge. The AI had optimized for succinctness at the expense of readability.

Since then, I've started focusing on explicitly documenting the ""why"" behind design decisions in comments, especially for AI-assisted implementations. Having the context preserved makes all the difference when revisiting code months later.

Has anyone else noticed similar challenges when working with AI-generated code? How are you addressing the maintainability aspect?",2025-04-12 21:04:01,6,traderprof,programming
mmsdkh0,1jxpl9c,reddit,"This aversion to the so called “premature optimization” is why software on a whole is fucking slow everywhere. I say optimize, always! Even startup times (one time operations) should be sped up.",2025-04-12 20:14:30,26,mr_sunshine_0,programming
mmsqmcb,1jxpl9c,reddit,"There is nothing more elegant and clever than code that is simple, obvious, expressive and correct. We are craftspeople, and maintainability is how we write quality code that lasts.",2025-04-12 21:27:55,5,gruengle,programming
mmsw2uu,1jxpl9c,reddit,"If the cleverness is just for the cleverness' sake. If the cleverness is applied to making an incredible developer experience for working with the code, or to solve a specific performance constraint, then its pretty great.",2025-04-12 21:59:48,3,TracerBulletX,programming
mmsfcn2,1jxpl9c,reddit,tldr: grug once think big brained but learn hard way. complexity very bad.,2025-04-12 20:24:22,8,FistBus2786,programming
mmsk9y6,1jxpl9c,reddit,"My style of coding tends to have a lot of very short expressions, and lots of temporary variables to name an intermediate result.  I think it might even have been influenced by reading the readme from some old basic->assembly compiler that restricted the number of operations in a statement.",2025-04-12 20:51:37,2,Dwedit,programming
mmt14id,1jxpl9c,reddit,you will take currying from my cold dead hands.,2025-04-12 22:30:26,2,raam86,programming
mmt1lfu,1jxpl9c,reddit,This would get thrown in the programmers face in every place I worked or studied.,2025-04-12 22:33:22,2,UltraMlaham,programming
mmtqr9b,1jxpl9c,reddit,"Simplicity is a prerequisite to reliability, while complexity sells.

As I used to tell my juniors, ""what's the point of clever code if everyone needs 10 min to see how clever your code is?""",2025-04-13 01:14:58,2,Dicethrower,programming
mmuvv53,1jxpl9c,reddit,It's a fine line between stupid and clever.,2025-04-13 06:31:24,2,I0I0I0I,programming
mmuw7ew,1jxpl9c,reddit,"I recently worked for a F500 company. Millions of LoC. Thousands of services.

The best code I found was 5 lines long. Very simple. A funnel thing. It was smartly written, very clear, very efficient and easy to maintain.

The rest of the LoC was random things. 

Juniors and intermediates love to over complicate things. It gives a powerful feeling. But when you become a senior, it's harder to write complex code in a simple manner. This is actual power.

Like when you see someone dancing. You can see someone do something very complicated and you can feel it by watching. But when you look at high level pro dancers, all you see is something easy and fluid. You can't see where the complexity is. It's wrapped under the skill and experience.",2025-04-13 06:34:47,2,HolyPommeDeTerre,programming
mmv2ahc,1jxpl9c,reddit,"it obviously also depends on the situation, if you need some clever high level magic with the transistor god to make the software as performant as possible, then why not, just don't forget to explain the elven dark magic with the comment so the future sorcerer can at least have a grasp on the forbidden knowledge 



for most things though, yeah, don't try to be clever",2025-04-13 07:36:08,2,deanrihpee,programming
mmv9x9x,1jxpl9c,reddit,"It depends what you're writing really. 

Standard application logic and features - keep it simple,  stupid

Foundational utilities that will make those features easier for everybody else to implement - do what you have to do to make it as useful as possible, just document it.",2025-04-13 08:57:34,2,cfehunter,programming
mmvnhzj,1jxpl9c,reddit,"I had an interview with the question ""what's a unique solution you came up with for a problem"" and that honestly stumped me because I try to avoid unique solutions. With the amount of code that exists, if a solution is truly unique, there's probably a reason it's not been used, and there's probably a better, simpler solution that will be easier for others to understand and maintain (I'm not doing anything revolutionary, I work in frontend on the website of a telecom company).",2025-04-13 11:18:51,2,sashaisafish,programming
mmwx2xf,1jxpl9c,reddit,"Write code for the next person to understand. The compiler does all the clever things for you. 

The clever bit might be right when writing assembly",2025-04-13 16:02:39,2,Xerxero,programming
mmxnrcw,1jxpl9c,reddit,"That's just bad code in a language that tends to bad code, not cleverness.

This one is ""clever"":

    float InvSqrt(float x)
    {
        float xhalf = 0.5f * x;
        int i = *(int*)&x;              // get bits for floating value
        i = 0x5f375a86 - (i >> 1);      // gives initial guess y0
        x = *(float*)&i;                // convert bits back to float
        x = x * (1.5f - xhalf * x * x); // Newton step, repeating increases accuracy
        return x;
    }

To this day, this code (well, maybe not exactly 1:1) still performs better than even \_mm\_rsqrt\_ss in many situations. 

Could you write different code for the same / a similar result? Sure.

Would it perform as well, i.e. be as fast? No chance in hell.

And the way this achieves its result in a not-so-obvious way is what I would call clever.

Not sure what exactly the benefit of your code example is though - it just looks like bad code to me. Not in the least clever.",2025-04-13 18:19:59,2,griffin1987,programming
mmyg78q,1jxpl9c,reddit,But it feels so good,2025-04-13 20:51:55,2,Producdevity,programming
mmsfn91,1jxpl9c,reddit,"Kernighan's Law - Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.

I have rarely regretted writing code as stupidly as possible. There is nothing quite as dumb as the original author looking at the code after three months.",2025-04-12 20:26:00,4,lurgi,programming
mmsrput,1jxpl9c,reddit,Writing code is easy. Reading code is hard. Every line of code I write is optimized to be easily read and understood by me in a year or by anyone else.,2025-04-12 21:34:23,3,turbulentFireStarter,programming
mmsulju,1jxpl9c,reddit,"I don't disagree with the conclusions of the article.  It's just that I have a different opinion on what constitutes clever code.  To me, clever code is not about the naming conventions, but rather about the way a problem is solved.  To me clever code is code that is more complex than what the problem requires.",2025-04-12 21:51:05,2,BotBarrier,programming
mmsjrp7,1jxpl9c,reddit,"Clever code means bugs or a pain in the ass to modify.

A clever solution is important and good with documentation’s",2025-04-12 20:48:51,1,s0ulbrother,programming
mmt4om4,1jxpl9c,reddit,"I found a bug in a compiler once and tried to incorporate its unintended behavior into the design. Unfortunately it was patched and stopped working, resulting in additional work before MTP.

It was for pdf document generation where a function was creating blank pages (instead of having to call page break twice through a different complicated process). ",2025-04-12 22:52:56,1,EJoule,programming
mmtidrv,1jxpl9c,reddit,I've seen some not difficult to understand methods or ideas on how to accomplish something that I would call clever. But the actual code is just basic.,2025-04-13 00:19:06,1,Animal2,programming
mmty3ty,1jxpl9c,reddit,"As an engineer with 7+ yrs exp, the code I wrote at 2-3yrs was so much cooler. I write boring-ass code now.",2025-04-13 02:04:23,1,Synyster328,programming
mmutqla,1jxpl9c,reddit,I usually say that writing the code to solve the problem is just half of the work,2025-04-13 06:10:27,1,th1bow,programming
mmvez4s,1jxpl9c,reddit,"Put me on the cross but what the author describes is not clever code. One-liners were never clever.  
Clever code is what Quake III did, if we close our eyes for a moment on the part where it's technically UB in C.  
That ***does NOT*** mean you shouldn't accurately describe clever parts with comments, which for obvious reasons excludes `// what the fuck?`.

Writing good code has nothing to do with making optimizations when possible and/or necessary! Writing the algorithm from the start with SIMD is a premature optimization because you still don't have a working copy with tests for said copy. Leaving it like that after testing is why the industry is in this dire state of ""just add more RAM, swap and storage"".",2025-04-13 09:52:59,1,The-Dark-Legion,programming
mmvfw17,1jxpl9c,reddit,You'd be surprised. I can write worse code than that,2025-04-13 10:02:44,1,deathstroke3718,programming
mmvgga4,1jxpl9c,reddit,"The code example looks like something that would be submitted to the Obfuscated C contest.  I know they didn't use C but the concept seems similar and they have these contests in other languages.  Some great examples in the wikipedia link.


https://en.wikipedia.org/wiki/International_Obfuscated_C_Code_Contest",2025-04-13 10:08:39,1,bobj33,programming
mmvicz9,1jxpl9c,reddit,"Easiest PRs ever.

I don't understand what this does --> denied.",2025-04-13 10:28:42,1,navetzz,programming
mmvnwbz,1jxpl9c,reddit,"This is mislabeled. There's nothing clever about those code snippets, they're just littered with poor variable names. Using those examples to empower your arguments is intellectually dishonest.",2025-04-13 11:22:30,1,FuckOnion,programming
mmvqz6f,1jxpl9c,reddit,"I always use the phrase “obvious code,” as in, “obviously it’s my code.”",2025-04-13 11:48:49,1,slantview,programming
mmvsvqg,1jxpl9c,reddit,"That's not clever code.

But the real danger of clever code is when you no longer see it as clever.",2025-04-13 12:04:13,1,Blecki,programming
mmvwue0,1jxpl9c,reddit,"A lot of the time “clever code” is just normal code derided by people with zero CS ingenuity. We get it, you haven’t spent 4 years learning foundational knowledge and now you deem everything too “clever”.",2025-04-13 12:34:27,1,BothWaysItGoes,programming
mmvz51b,1jxpl9c,reddit,Hallo Guys. I am trying to gather a bunch of programmers that want to build shit together and become rich. If you have programming skills and want to join the group please text me in private.,2025-04-13 12:50:57,1,ManySuper,programming
mmw09li,1jxpl9c,reddit,"The curl devs list of what to follow is basically perfect and this is one of the rules. 

Code in a way that the next person can understand and replicate.",2025-04-13 12:58:47,1,Party_Cold_4159,programming
mmw0ry1,1jxpl9c,reddit,"Okay, it's clear.",2025-04-13 13:02:16,1,tomtay27,programming
mmwfesy,1jxpl9c,reddit,this is known.,2025-04-13 14:29:41,1,Tornado547,programming
mmwl70x,1jxpl9c,reddit,"""Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it."" - Kernighan's Law

And that tells you everything you need to know. Also, KISS, and so on ...",2025-04-13 15:00:30,1,C_Madison,programming
mmwzoxw,1jxpl9c,reddit,"Clever code is something that saves you or someone else time, and isn't a huge pain in the ass for someone to figure out.",2025-04-13 16:16:22,1,GreatBigJerk,programming
mn11sbe,1jxpl9c,reddit,"Clever one-liners are the worst for collaboration, which makes them a terrible choice for production code. However, if it's self-contained and doesn't produce side effects and has a test suite, it's quite easy to refactor.

Using line-liners when prototyping and building quickly is useful, but I would always eliminate those before submitting PRs when working in a team. Otherwise, either my future self or other developers may have trouble understanding or debugging it.",2025-04-14 08:07:41,1,nexo-v1,programming
mn2k2tb,1jxpl9c,reddit,"Agreed, because if you do then you're the only person who knows how anything works. So have fun writing every single patch and every single update, job security I guess a lot of the time it can make processes faster but it slows down overall development.",2025-04-14 14:56:44,1,ShiftyShifts,programming
mnatxul,1jxpl9c,reddit,"***Clever*** **isn't bad;** ***sneaky*** **is bad.**

If you figure out that you can skip a bunch of steps in some process and deliver more performance, great! That's clever! As long as you leave a comment nearby that says something like ""normally we'd have to do x, y, and z at this point, but it's safe to skip them here because we already eliminated the cases where those steps help,"" there's no problem. I'd say clever code is even *preferred* if it provides noticeably better performance or has some other benefit.

But if you do that kind of thing without explaining what and why, you've gone from clever to sneaky. The next programmer to come along (including the future you) won't know what insight led to the code that you wrote. They might be afraid to change it, or they might change it and break it because they changed some condition that you took for granted. The problem really isn't the code, it's that you didn't take the time to communicate what the code is doing and why in a situation where none of that is obvious.",2025-04-15 21:05:59,1,iOSCaleb,programming
mnd436l,1jxpl9c,reddit,Put your stupid code in a stupid function. Then use that stupid function in other stupid functions.,2025-04-16 05:39:26,1,cosmicloafer,programming
mneybm2,1jxpl9c,reddit,I feel like this article speaks to my soul.  I even debate what to name variables because of how often variable names start not making sense in the future.,2025-04-16 14:32:33,1,Colt2205,programming
mmu6cf4,1jxpl9c,reddit,"This article is right on the money. Clever code is unreadable, difficult to understand, nearly impossible to modify, full of ideas that you've had in the process of writing it and have already forgotten by the time you type in ""git commit."" It's inherent in the word ""clever."" Something is ""clever"" if it requires you to start at it for a while in order to figure out how the hell it works. It's ""clever"" if it requires wit and ingenuity in order to deal with it. That's great in a chess game, where you want to make a move that your opponent doesn't expect, but it's toxic in a codebase that you expect to maintain over the years.

Think of it this way, would you want to live in a ""clever"" house? One where the loads keeping the roof stable rely on the position of a table in the garage? Or would you prefer a simple, boring, and straight forward house where you can see how the load is distributed from the roof to the foundation at a glance?

If you ever write some clever code, and I'm sure most of us have and will, the best thing you can do is spend a bit longer to transform that clever code into boring, stable code. In the process it will become faster, easier to read, and more efficient. You will also understand the problem way better than when you needed cleverness to solve it, and the insight you develop is much more likely to be applicable to other problems in the future.",2025-04-13 03:00:49,1,TikiTDO,programming
mmseit1,1jxpl9c,reddit,"Amen - do the simplest, clearest method unless there's a compelling reason otherwise",2025-04-12 20:19:47,1,enigmo,programming
mmspjm4,1jxpl9c,reddit,"Lines are cheap, brain space is expensive.",2025-04-12 21:21:38,1,sir-camaris,programming
mmssfsv,1jxpl9c,reddit,"Earlier in my career I was lower in rank compared to this one guy who had just a little bit more seniority over me.  He always wanted us to play code gold, ""simplify"", and add all sorts of paradigms that really made no sense for our use case.  His reasoning usually was ""I read it in a medium article on HackerNews"".  It resulted in two things: hard to read code and some bad habits that I took to a future job (because I was afraid of being yelled at by him).

Later on I was under someone much more senior and he wanted us to use much more verbose code, multi-liners, and less complex constructs.  It resulted in code that anyone could read and debug.  He calmly justified (and well) why using a much more basic approach was better.  He also never shouted at me.",2025-04-12 21:38:37,1,def-pri-pub,programming
mmtxmrf,1jxpl9c,reddit,[The Parable of the Two Programmers](https://web.archive.org/web/20141111011633/https://www.csd.uwo.ca/~magi/personal/humour/Computer_Audience/The%20Parable%20of%20the%20Two%20Programmers.html).,2025-04-13 02:01:13,1,fromwithin,programming
mmtyfm8,1jxpl9c,reddit,"Also, you can save storage by not having any comments in your code. The code speaks for itself!",2025-04-13 02:06:37,1,JayC_111,programming
mmu6xfn,1jxpl9c,reddit,"If it was hard to write, it should be hard to read. 💀",2025-04-13 03:04:49,1,smellin_bacon,programming
mmsvj7k,1jxpl9c,reddit,"Worse than writing clever code is using a programming language that treats whitespace as syntactically significant.

Worse still is using that programming language to illustrate putatively clever code.",2025-04-12 21:56:34,0,church-rosser,programming
mmsk2oj,1jxpl9c,reddit,Now try to figure out neural network based AI how they came to a result,2025-04-12 20:50:31,0,Tintoverde,programming
mmsto2y,1jxpl9c,reddit,"The example code isn't ""clever."" It's obfuscated.",2025-04-12 21:45:43,0,CanvasFanatic,programming
mmslvvq,1jxpl9c,reddit,"Apologies to the author, but it makes me think of the K.I.S.S. Methodology.",2025-04-12 21:00:37,0,grumpyfan,programming
mmukrgg,1jxpl9c,reddit,"A software programmer thinks being told their code is ""clever"" is a compliment, while a software engineer finds this to be an insult.

For better maintainability, it is more important that your code is readable and easy to understand.  Not only for the next person to touch the code, but for yourself, as you will probably have forgotten that clever thing you did in the first place by the next time you look at it.

Sometimes clever problems do require clever solutions, but where you do have to be clever and do something non-obvious, you can at least document your code.",2025-04-13 04:50:24,0,artibyrd,programming
mmv5fgl,1jxpl9c,reddit,"Disagree.
Either the code is clever or i'll use AI to generate it.
I don't like to waste time reimplementing wheels and boilerplate, its soul-draining to write ""dumb code"" to add functionality, like 'small talk' but it lasts for hours. Without AI writing down dumb code by kilobytes, i'd spending most of time debugging dumb code doing something even dumber(e.g. corner cases in C/C++).",2025-04-13 08:08:53,-1,Elven77AI,programming
mmszcio,1jxpl9c,reddit,"All code is clear, only confusing part is naming of your variables",2025-04-12 22:19:31,-3,Empty_Geologist9645,programming
mki90at,1jnb00a,reddit,">obscure languages like Delphi

Heroes of forgotten days.",2025-03-30 12:11:58,726,YahenP,programming
mki8oc5,1jnb00a,reddit,"Paper: [Coding Malware in Fancy Programming Languages for Fun and Profit](https://arxiv.org/abs/2503.19058)

> The continuous increase in malware samples, both in sophistication and number, presents many challenges for organizations and analysts, who must cope with thousands of new heterogeneous samples daily. This requires robust methods to quickly determine whether a file is malicious. Due to its speed and efficiency, static analysis is the first line of defense.

> In this work, we illustrate how the practical state-of-the-art methods used by antivirus solutions may fail to detect evident malware traces. The reason is that they highly depend on very strict signatures where minor deviations prevent them from detecting shellcodes that otherwise would immediately be flagged as malicious. Thus, our findings illustrate that malware authors may drastically decrease the detections by converting the code base to less-used programming languages. To this end, we study the features that such programming languages introduce in executables and the practical issues that arise for practitioners to detect malicious activity.",2025-03-30 12:09:14,116,self,programming
mkine8n,1jnb00a,reddit,"An alternative way to write the topic could be ""Reverse engineering code is actually quite difficult if most of it isn't just straightforward C code that only does OS / library calls"".

My pandemic project was reverse engineering a mid 90s demoscene demo written in a combination of Watcom C and assembly. Every single reverse engineering guide I found was completely useless because they all assumed 90% of the code would be just library calls instead of actually consisting of computations and non-trivial logic.",2025-03-30 13:52:41,194,SkoomaDentist,programming
mkii8b1,1jnb00a,reddit,"Idea: Write malware in APL.
Blocker: Need to learn APL first.",2025-03-30 13:19:34,42,I_just_read_it,programming
mkia9w3,1jnb00a,reddit,"Not just malware, any software written in Haskell is incomprehensible!",2025-03-30 12:22:07,279,IshtarQuest,programming
mkk2knv,1jnb00a,reddit,"Someone wrote a malware in PureBasic and now almost any non trivial PureBasic software is considered malware, It sucks!",2025-03-30 18:22:33,14,ricardo_sdl,programming
mkjf1qi,1jnb00a,reddit,You can't write Malware in Haskell because you would need to figure out how to do IO,2025-03-30 16:23:11,50,dasdull,programming
mkjsu46,1jnb00a,reddit,"Yeah. I wrote my database stuff in THP!

Never heard of it? Good.

I’m retired now but never dropped a database or lost any data, or got hacked in a 30 year career.

THP? It’s a LISP interpreter. Ran a tad slow but super-easy to work with and very hard to reverse-engineer.

Most important project? Glastonbury Festival booking system for Theatre and Circus performers and crew.

Attack Frequency: high. We issue festival tickets, so some bad actors try to hack us, probably mostly for fun and on the off chance. They were looking for basic  database security failures mostly.

So that all worked just fine.",2025-03-30 17:33:51,9,DXTRBeta,programming
mkidt85,1jnb00a,reddit,"No shit, antivirus is a bandaid. It won’t detect 0-days, and (at least almost) all of them are a security risk themselves because they need elevated permissions.

So antivirus is for you if you don’t trust users (be it yourself or others) to properly use the internet. Fair, most people are dumbasses, but if you know what you’re doing, don’t get an antivirus.",2025-03-30 12:48:48,45,flying-sheep,programming
mkiq3r0,1jnb00a,reddit,"delphi, thats a name i haven't heard in a very long time",2025-03-30 14:08:41,8,Healthy_Razzmatazz38,programming
mkiojd9,1jnb00a,reddit,I believe D is a popular choice for malware for this exact reason.,2025-03-30 13:59:31,11,renatoathaydes,programming
mkksiue,1jnb00a,reddit,"I **didn't see any statistics** showing that obscure platforms have a *higher* rate of attacks. While it's true there are fewer prevention tools and efforts available for such, there is still the value of security-through-obscurity, which may make the rate break even.",2025-03-30 20:35:24,5,Zardotab,programming
mkipigo,1jnb00a,reddit,laughs in brainfuck,2025-03-30 14:05:14,9,xxxx69420xx,programming
mkkc1na,1jnb00a,reddit,"Wow, Delphi is now an obscure language? 🥲",2025-03-30 19:10:37,8,Dash83,programming
mkj4ui2,1jnb00a,reddit,"""They cite Rust, Phix, Lisp, and Haskell as languages that distribute shellcode bytes irregularly or in non-obvious ways.""

NSA urge to switch to safer languages like C, C++, that generates better bytecode",2025-03-30 15:30:07,18,sjepsa,programming
mkl7ind,1jnb00a,reddit,Anders sure has made a great career product line from Turbo Pascal to Delphi to C# to TypeScript.,2025-03-30 21:56:30,4,mycall,programming
mkkre01,1jnb00a,reddit,"Wow...  I used to believe a few fairy tales myself...  because that's not how compilers work, ir automated search algorithms...  🙄   at all...",2025-03-30 20:29:33,3,painefultruth76,programming
mkln89z,1jnb00a,reddit,"https://en.wikipedia.org/wiki/OCaml


https://www.ponylang.io/discover/

https://www.scheme.org/",2025-03-30 23:28:06,3,moschles,programming
mkig7hx,1jnb00a,reddit,"Re Delphi, the title of the post is quite misleading.

Given the continued development and enhancements Embarcadero pours into RAD Studio (That is, both Delphi and C++Builder) and quite significant user base and active community, calling it obscure is simply not accurate.",2025-03-30 13:05:44,10,b1t5murf,programming
mkiptri,1jnb00a,reddit,Grandmasters of Flash 2002,2025-03-30 14:07:04,2,BillyQ,programming
mklrdxo,1jnb00a,reddit,Is Delphi really a language I thought it was just branded Pascal?,2025-03-30 23:52:38,2,Plank_With_A_Nail_In,programming
mkm3ods,1jnb00a,reddit,I write all my malware in Raku.,2025-03-31 01:09:19,2,1_Pump_Dump,programming
mkmygem,1jnb00a,reddit,It is harder to detect a thing that nobody is really doing because the exacting signatures don't match up to the things that people actually do. Er.. yes. It is indeed harder to find things that aren't in your sample distribution.,2025-03-31 04:46:44,2,edwardkmett,programming
mktazao,1jnb00a,reddit,"Having worked on both Delphi and Visual C++, I like to feel like I’ve contributed to both ends of this market",2025-04-01 05:43:03,2,steixeira,programming
mklchi4,1jnb00a,reddit,"TIL Delphi is an ""obscure"" language...",2025-03-30 22:25:19,2,He_Who_Browses_RDT,programming
mkjyj0k,1jnb00a,reddit,Or assembler.,2025-03-30 18:01:58,1,rpxzenthunder,programming
mkmskye,1jnb00a,reddit,I will now brush up on my GW-Basic.,2025-03-31 03:58:36,1,brightlights55,programming
mkn1cki,1jnb00a,reddit,So that's why Microsoft has been blocking my app for months [without](https://www.reddit.com/r/techsupport/comments/1jm5636/low_reputation/) explanation 🥲 /s,2025-03-31 05:12:00,1,Teamatica,programming
mkp5ltc,1jnb00a,reddit,This is wild. I wouldn’t have guessed that using Haskell or Delphi could actually help malware fly under the radar. Do you think this will push security analysts to learn more obscure languages? Or will AI eventually just automate the detection across any language anyway?,2025-03-31 15:21:37,1,tomasartuso,programming
mkpob89,1jnb00a,reddit,True for reverse engineering and static analysis. Doesn’t really matter for dynamic analysis where you run a sample in a sandbox and observe the system calls. That has been the goto method for malware sample analysis till you encounter anti-sandbox and anti-VM tricks to defeat dynamic analysis.,2025-03-31 16:55:21,1,N1ghtCod3r,programming
mksk3gf,1jnb00a,reddit,"Cmon man, here in Brazil 99% of ERPs are still actively developed and mantained in Delphi.

It is even lectured in universities.",2025-04-01 02:16:40,1,Naive_Review7725,programming
mktg4he,1jnb00a,reddit,What the heck is obscure on Delphi? My childhood! Long live Borland!,2025-04-01 06:35:33,1,Original_Two9716,programming
ml9jba6,1jnb00a,reddit,I write malwares in delphi in past for educational purposes but it depends on is antivirus blacklisted compiler.,2025-04-03 20:43:39,1,HydraDragonAntivirus,programming
ml9jlxe,1jnb00a,reddit,"Fortran is more interesting, I write malware in Fortran nad has zero detections whe nI first published.",2025-04-03 20:45:06,1,HydraDragonAntivirus,programming
mlfw0ln,1jnb00a,reddit,Write it in Assembly. Boom.,2025-04-04 21:12:08,1,Organic_Opposite_753,programming
mlo32ap,1jnb00a,reddit,"The reason because AV software doesn't expect malware to be written in high-level languages. 
Sure thing it's a bad idea since low-level languages like C gives wider control of memory management which is a critical aspect in malware dev.",2025-04-06 07:56:49,1,N/A,programming
mkiulqi,1jnb00a,reddit,"Hmmm. So, I assume the more people understand language xyz, the easier it may be to find malware. I also assume that more elegant languages make it harder to write obfuscated code in general, and malware is probably often obfuscated in one way or another.

But ... I find the general premise to not be convincing here. There is more malware written in Haskell than in PHP? I doubt this very much. Haskell is quite complicated, people often fail to enter because they don't understand the language. And the adoption rate of haskell is very low - not that many people really use it. Compare that to python.

> ""Even though malware written in C continues to be the most prevalent, malware operators, primarily known threat groups such as APT29, increasingly include non-typical malware programming languages in their arsenal,"" they write.

They even admit this themselves here.

> ""Malware is predominantly written in C/C++ and is compiled with Microsoft's compiler,"" the authors conclude. ""

I am not sure about this either. Anyone has the link to the article? I want to know HOW they obtained the data, to which they claim the above. For instance, I would assume there is a lot of malware written in PHP. So how did they determine the usage frequency of languages?",2025-03-30 14:34:25,1,shevy-java,programming
mknbkvp,1jnb00a,reddit,"Delphi ? obscure ?

is kind of Pascal.",2025-03-31 06:51:39,1,florinp,programming
mkicrd0,1jnb00a,reddit,"delphi is a front end to pascal, not a language",2025-03-30 12:41:12,-12,revnhoj,programming
mndckfw,1k0dyk8,reddit,This news should have a score of 10.0,2025-04-16 07:02:36,572,iamapizza,programming
mneolci,1k0dyk8,reddit,"Contract was just extended this morning, thankfully. Sounds like this may have also prompted a migration away from dependence on the US govt. to keep the program alive, which seems like a good thing.

https://www.bleepingcomputer.com/news/security/cisa-extends-funding-to-ensure-no-lapse-in-critical-cve-services/",2025-04-16 13:41:19,116,ryusage,programming
mndir2s,1k0dyk8,reddit,Huh I had no idea this was a US Gov programme. I'd have thought the economic benefits to the US alone outweighed the cost of running the service. The costs of the service seem like a drop in the ocean compared to the costs of cyber crime generally. If you wanted to show some gainz then you could ask other countries for a GDP weighted contribution to the costs surely?  But clearly that approach isn't sufficiently bigly savings.,2025-04-16 08:08:23,241,Advanced-Essay6417,programming
mndh6b0,1k0dyk8,reddit,"This is where the world is learning that anything that was largely reliant upon the USA needs to be addressed sharpish as they can no longer be relied upon to act in their own best interests, let alone anyone else's.",2025-04-16 07:51:31,284,thatpaulbloke,programming
mndno5v,1k0dyk8,reddit,How in the hell is this not getting more attention?,2025-04-16 09:02:09,65,funeralforecast,programming
mnexboi,1k0dyk8,reddit,Update: CISA extended the funding this morning! Crisis averted for now. This whole situation shows how fragile our security infastructure can be when it depends on govmnt funding. The CVE system is literally how devs track vulnerabilities worldwide.,2025-04-16 14:27:32,15,PM_ME_UR_ROUND_ASS,programming
mne1hv8,1k0dyk8,reddit,Today in “things a Russian asset would do” news,2025-04-16 11:13:38,30,jelder,programming
mndw4cm,1k0dyk8,reddit,Why isn't anyone saying thank you?,2025-04-16 10:28:18,10,heatlesssun,programming
mngaic7,1k0dyk8,reddit,This post title doesn’t match the article title. The post title is “CVE program **averts** swift end after CISA executes 11-month contract extension”,2025-04-16 18:27:26,2,dmilin,programming
mnjkx4a,1k0dyk8,reddit,I'm super curious of the impact of this. Will we see less CVE script kiddy style attacks but more sophisticated APT type attacks?,2025-04-17 06:35:08,2,Glum_Sun_3459,programming
mnlxmb0,1k0dyk8,reddit,"Considering DOGE credentials were leaked within hours to Russian hackers, I'm beginning to think softening/eliminating our defense posture against Russian cyber attacks is the point.",2025-04-17 16:24:55,2,Tyrilean,programming
mndev1x,1k0dyk8,reddit,Efficiency!,2025-04-16 07:26:43,44,CramNBL,programming
mndfapc,1k0dyk8,reddit,"**This** will finally bring the price of eggs down, right?",2025-04-16 07:31:21,122,Carighan,programming
mndiyak,1k0dyk8,reddit,"So, are we getting a reprieve on C and C++ bashing?",2025-04-16 08:10:34,-40,Ill_Bill6122,programming
mndjqrb,1k0dyk8,reddit,"I guess those of us over in /r/europe can hope that the EU steps up, but augh, jeez, there sure is a lot of ""whoops, funding ends tomorrow!"" stuff and the EU isn't exactly known for being quick to move.",2025-04-16 08:19:15,80,syklemil,programming
mndkhib,1k0dyk8,reddit,"Bonus toots from Greg K-H

> Given the news of the potential disruption of the CVE main server, I've reserved 1000 or so ids for the kernel now, which should last us a few weeks. [[1]](https://social.kernel.org/notice/At8ohpOxW2P3HenJho) 

&nbsp;

> And for those curious, here’s the current stats for kernel CVEs reserved/assigned/rejected since we started just over a year ago:

>     Year	Reserved	Assigned	Rejected	 A+R		Total
>       2019:	  47		   2		   1		   3		  50
>       2020:	  36		  14		   0		  14		  50
>       2021:	  20		 728		  23		 751		 771
>       2022:	  20		1098		  16		1114	    1134
>       2023:	  20		 493		  28		 521		 541
>       2024:	  20		3067		  84		3151		3171
>       2025:	1837		 384		  12		 396		2233
>      Total:	2000		5786		 164		5950		7950

> [[2]](https://social.kernel.org/notice/At8pjpxCX7VfWvKgyW)",2025-04-16 08:27:27,35,syklemil,programming
mndqxxr,1k0dyk8,reddit,"Welp, that's not great",2025-04-16 09:37:22,10,juhotuho10,programming
mndupwu,1k0dyk8,reddit,I hope someone steps up and funds the program. If not the EU or a major country then it would still be peanuts for a company like Microsoft or Google.,2025-04-16 10:15:07,12,Ok-Kaleidoscope5627,programming
mndxtjo,1k0dyk8,reddit,"This is nuts. I’d love to hear a conservative justify this.

I assume they will be coming for NIST at some point. The United States is being thoroughly dismantled.",2025-04-16 10:43:29,36,DarkTechnocrat,programming
mne6nqm,1k0dyk8,reddit,What will terrible non-technical CISOs freak out about now? Back to Dark Reading!,2025-04-16 11:52:22,2,crash______says,programming
mnes82m,1k0dyk8,reddit,Holy fuck.,2025-04-16 14:01:05,3,lyth,programming
mnfxm4e,1k0dyk8,reddit,Did anyone else get an increased number of cve warnings this morning?  Like they decided to clear the queue ASAP before it's cut off....,2025-04-16 17:25:27,0,Salamok,programming
mngapqu,1k0dyk8,reddit,"I get the concerns, but there is a part of me that feels like a government shouldn't be in control of a system critical program like this. I mean if there's one thing programmers should know it's that this information can (And will) be abused... 

It's also head scratching that DHS is the one behind CVE and not NSA?  

If this is something people think the ""government"" should be in charge of, maybe it should be in control of the UN where no one party can abuse it's power... 

But at the same time, it would be better if it's funded in a way that doesn't behold it to one government or another.",2025-04-16 18:28:30,0,Kinglink,programming
mnhep60,1k0dyk8,reddit,"I think it should be noted that although the DHS was funding the CVE program, the actual research for the CVE's was being done by people all over the world. It would be nice for a world wide decentralized CVE program, so no one entity gets stuck with the bill, and anyone can decide to pull out of the program without affecting any other country. Maybe wishful thinking on my part, but as an American, I'd like to see more sharing of knowledge when it comes to security considering how many of the CVE's truly affect software across the entire world.",2025-04-16 21:51:51,1,progcodeprogrock,programming
mnizeot,1k0dyk8,reddit,It’s almost like this and CISA cuts are intended to cripples our country’s security…But that couldn’t be right /s,2025-04-17 03:33:01,1,come2thecabaret,programming
mnf6i4a,1k0dyk8,reddit,"The CVE system should be burned down and replaced anyways.

But, it'd be nice if that was an adult discussion instead of randomly canceling it with no warning.",2025-04-16 15:13:01,2,tofous,programming
mne7ty3,1k0dyk8,reddit,"I wouldn't have guessed that 1300 people work on maintaining the CVE registry. Should be possible to get away with at least 1/4, right?",2025-04-16 12:00:30,-10,SwitchOnTheNiteLite,programming
mne2rt7,1k0dyk8,reddit,"Here is a thought, maybe the world’s corporations can get together and fund the program instead of sucking at the tit of the American taxpayer.",2025-04-16 11:23:37,-38,wildjokers,programming
mneex4c,1k0dyk8,reddit,"no politics. please read the rules. this isn't the place for TDS.

> - That means no image posts, no memes, **no politics**
> - Just because it has a computer in it doesn't make it programming. **If there is no code in your link, it probably doesn't belong here.**",2025-04-16 12:46:33,-34,CVisionIsMyJam,programming
mlg9xua,1jrl2zw,reddit,"> According to the VS Code Marketplace [Terms of Use](https://aka.ms/vsmarketplace-ToU), *you may only install and use Marketplace Offerings with Visual Studio Products and Services*.

Source: https://github.com/VSCodium/vscodium?tab=readme-ov-file#more-info

So any product like Cursor was not allowed to use those extensions in the first place.",2025-04-04 22:31:23,469,krokodil2000,programming
mlfkqe6,1jrl2zw,reddit,"Bound to happen tbh, surprised it took them this long to create a branch of Copilot to rival Cursor.

Straight blocking MS extensions from VS-Code moving forward is a bit of an old school MS move, but it makes complete sense from a business perspective. They want people to use their Agent, people want to use VS Code. 

Either the Cursor team puts together a fork of VSCode and maintains the extensions (or people just never update beyond the previous version) or their users just naturally migrate over time.",2025-04-04 20:13:25,310,ScriptingInJava,programming
mlfmhma,1jrl2zw,reddit,I wish I never had to hear about AI companies again.,2025-04-04 20:22:21,733,BlueGoliath,programming
mlfl3w0,1jrl2zw,reddit,"It looks like the plugin itself is open source but there are some needed binaries that are not open source. I'm not sure what binaries the license is referring to though. Maybe it's a matter of someone picking it up and making an alternative version of the plugin. 

[https://github.com/microsoft/vscode-cpptools](https://github.com/microsoft/vscode-cpptools)",2025-04-04 20:15:20,52,Suspect4pe,programming
mlfubdw,1jrl2zw,reddit,"They were going to figure out a business model for VSCode eventually.  It was always going to be uncomfortable for users that found themselves on the other side of where Microsoft wanted to make their money.

Just because we didn't know what it was going to be, doesn't mean it wasn't inevitable. Or that this is the end.

edit: I'm pretty sure the ssh extension already refused to work in vscodium, but I'm not at home to check.",2025-04-04 21:02:54,50,old-toad9684,programming
mlgz9xn,1jrl2zw,reddit,[Visual Studio Code is designed to fracture](https://ghuntley.com/fracture/),2025-04-05 01:09:20,16,micod,programming
mlg4dzq,1jrl2zw,reddit,"Open source is all fun and games, until a competitor uses your shit.",2025-04-04 21:58:39,66,abraxasnl,programming
mlfxzf8,1jrl2zw,reddit,"It was bound to happen I guess. 
Other companies like SourceGraph bet for staying as a plug-in of vscode and it may play better for them long term",2025-04-04 21:22:55,15,r0s,programming
mlh4a61,1jrl2zw,reddit,Just use the clangd extension. It works better than the MS C++ extension anyway.,2025-04-05 01:42:08,9,DeeBoFour20,programming
mlfvyly,1jrl2zw,reddit,"Classic msft move with the extensions.🤣 They were always going to eat Cursors lunch eventually, but I didn't see the extension block coming.

Hopefully the kid behind cursor enjoyed it while it lasted. I was endly baffled that he/they didn't sell.",2025-04-04 21:11:50,23,Livid_Combination650,programming
mliply8,1jrl2zw,reddit,"I don't like any fat mega-corporation trying to dictate (and steal) freedom of users, be it Microsoft, Google (chrome code base), you name it. It does not affect me personally though, so I am not really upset - but I still dislike such restrictions. I feel it also violates e. g. how GCC and LLVM-clang behave, so Microsoft is really not a ""good open source citizen"" here.

Edit: Others pointed out that it violated Terms of Use. So Microsoft's behaviour may be understandable, but I still don't agree that this changes the situation. Such restrictions simply should not be there in the first place.",2025-04-05 10:16:13,8,shevy-java,programming
mlkr1lb,1jrl2zw,reddit,"That they're enforcing the ""this extensions can only be used in vscode"".

It's honestly not something you should care (for now) since every fork of vscode (including the open source version of it that microsoft bases its work for vscode) can't use ms, vscode exclusive extensions.

As per the GitHub issue, the cursor team can either accommodate to the open extension store, or fiddle to have the vscode exclusive extensions working with cursor.",2025-04-05 18:14:39,3,Danteynero9,programming
mllkg4m,1jrl2zw,reddit,"Oh man, this is the whole issue that made most developers seek alternatives as Linux/Macos as main dev machines. If you want to build a good open source product, you have to compete with alternatives making your product better, not trying to make other products worse.

Bye MS, you tried to make us think you changed, but you didn't",2025-04-05 21:00:35,2,JudgeBergan,programming
mlmxlup,1jrl2zw,reddit,This is hilarious to me as my company just this week spent a lot of time telling all of us that we should be switching to use cursor as our editor/AI tooling and trying to force-without-forcing us to switch.,2025-04-06 02:10:00,2,shruubi,programming
mlp0nw7,1jrl2zw,reddit,"As someone who doesn’t use AI agents, this means nothing to me",2025-04-06 13:15:36,2,KalaiProvenheim,programming
mm3feta,1jrl2zw,reddit,Can someone ELI5 what these agent modes are? Is this just LLMs taking over an editor and writing code in a conversational way? That sounds terrible.,2025-04-08 20:18:13,2,Due-Sector-8576,programming
mlg71j4,1jrl2zw,reddit,"as someone who frequently uses cursor for work (to generate loads of test cases usually)

really will be ticked off it it breaks, but it's not my money so might just suck it up and switch back to vscode, I need my extensions badly, but I prefer claude to copilot, quite annoying",2025-04-04 22:14:04,7,JoelMahon,programming
mlj0gcv,1jrl2zw,reddit,"> What do you think? 

I use GNU Emacs I don't care much.",2025-04-05 11:59:39,3,DGolden,programming
mlfsv3s,1jrl2zw,reddit,"Embrace, Extend, Extinguish.",2025-04-04 20:55:14,-1,PurpleYoshiEgg,programming
mljto57,1jrl2zw,reddit,I setup clangd instead of MS and honestly clangd is better,2025-04-05 15:09:50,1,Xryme,programming
mlum3m9,1jrl2zw,reddit,I think Microsoft is well within their rights to enforce the EULA that Cursor has been violating for half a decade.,2025-04-07 12:03:02,1,IanAKemp,programming
mlw9i7c,1jrl2zw,reddit,Well well well.,2025-04-07 17:32:01,1,eat_your_fox2,programming
mndpmsp,1jrl2zw,reddit,There is no reason for a closed source software to accuse an open source software of not being open source enough.,2025-04-16 09:23:26,1,caiqichang,programming
mlfvecj,1jrl2zw,reddit,I wonder if it's easy to patch out the check to make the extensions continue working...,2025-04-04 21:08:45,1,KawaiiNeko-,programming
mlggswm,1jrl2zw,reddit,"Use neovim and the problem is solved 

edit: my point was that relying on non-proprietary systems solves the meta issue here.",2025-04-04 23:12:54,-6,puppet_pals,programming
mlfucd5,1jrl2zw,reddit,"I SAID this would happen one day, no reason it wouldn't. MS is a business and this is a classic tried and true move. Release for free, operate at a loss to generate dependent users, then pull the rug. This is only one of the many things that will come over the next few years. 


It's why I won't use VS Code no matter what. I would rather pay for an IDE than use any MS option.",2025-04-04 21:03:03,-8,VegtableCulinaryTerm,programming
mljmz75,1jrl2zw,reddit,Makes it a bit harder for M$ simps to defend the view that M$ is a serious free/open source software player.,2025-04-05 14:32:16,0,bring_back_the_v10s,programming
mlg56q2,1jrl2zw,reddit,Is this the “extinguish” part?,2025-04-04 22:03:14,-14,rectalrectifier,programming
mli0d5u,1jrl2zw,reddit,It's anticompetative and frankly a load of BS,2025-04-05 05:52:09,-6,douglasg14b,programming
mlfprsq,1jrl2zw,reddit,To all the people preaching vscode is open source so no need to worry about it taking over the market - feeling dumb yet?,2025-04-04 20:39:13,-36,CyberWank2077,programming
mlg91bi,1jrl2zw,reddit,"Microsoft are scumbags who also can't execute on anything anymore, nor innovate, and anything they do that sounds like they're not is simply expedience as they continue their inexorable slide toward nouveau-IBM status, is what I think.",2025-04-04 22:25:59,-20,sisyphus,programming
mlfzgn0,1jrl2zw,reddit,[deleted],2025-04-04 21:31:06,-25,N/A,programming
mlgar7t,1jrl2zw,reddit,"Embrace, Extend, Extinguish.",2025-04-04 22:36:22,-22,ddollarsign,programming
mlghckn,1jrl2zw,reddit,"I’m not against using VScode. I don’t really care as long as their editor will rival Cursors capabilities eventually. But if Microsoft restricts this to only OpenAI models, I’m not touching it, I’ll use WebStorm with an MCP, or copy and paste manually, or use a terminal agent like Claude.",2025-04-04 23:16:11,-6,techdaddykraken,programming
mli04tl,1jrl2zw,reddit,But microsoft said they love opensource...,2025-04-05 05:49:53,-6,kldjasj,programming
mlht2rx,1jrl2zw,reddit,Told you idiots not to use VSCode.  ,2025-04-05 04:45:47,-10,illathon,programming
mlhsmjs,1jrl2zw,reddit,You can easily bypass this. Just ask ChatGPT.,2025-04-05 04:41:57,-6,illusionst,programming
mngrwu9,1k0sc6y,reddit,Even worse: sometimes it's used to deliver javascript,2025-04-16 19:55:48,1159,nickcash,programming
mnguvmt,1k0sc6y,reddit,**NODE.JS** is used to execute *powershell* commands,2025-04-16 20:10:14,160,Jealous_City_9623,programming
mnhyjvr,1k0sc6y,reddit,So scripting languages used for malicious scripting?,2025-04-16 23:43:19,121,atomic1fire,programming
mnkez4j,1k0sc6y,reddit,"I dislike usage of JS outside of browsers as much as the next guy, but what the hell is this article? ""A programming language can be used to write (malicious) software""? Wow, who could've thought.

I kinda expected it to be about the fact that [merely installing an npm package can execute arbitrary code](https://docs.npmjs.com/cli/v6/using-npm/scripts#life-cycle-scripts), but this is something else.",2025-04-17 11:26:34,15,TypicalFsckt4rd,programming
mngn4nl,1k0sc6y,reddit,No shit Sherlock ,2025-04-16 19:31:47,69,GreedyBaby6763,programming
mni54zo,1k0sc6y,reddit,The amount of brain rot in these comments is tremendous.,2025-04-17 00:24:08,39,WebDevLikeNoOther,programming
mnghsua,1k0sc6y,reddit,Shit found in shithole!,2025-04-16 19:04:49,128,zmose,programming
mni363w,1k0sc6y,reddit,Breaking news: supply chain attacks exist in popular software ecosystems,2025-04-17 00:10:57,10,tj-horner,programming
mnhgpvu,1k0sc6y,reddit,AI slop,2025-04-16 22:02:57,26,grumblefap,programming
mnj8l5w,1k0sc6y,reddit,Surely vibe coding will help,2025-04-17 04:43:03,9,ooqq,programming
mngxa21,1k0sc6y,reddit,"Node brought us left-pad, for which I am eternally grateful - for many got some laughs out of it; but other languages can always say ""look, yes, this is a vulnerability, but ... node has 10x as many as we do!!!"".

I am not as happy with regard to browsers though. For instance, JavaScript should not be usable as weapon against the browser; on the other hand I also sometimes want easy file-access via JavaScript, such as when working on a local website only, but without wanting to need node/npm ... if only WASM would bring us true liberation here.",2025-04-16 20:22:07,20,shevy-java,programming
mnmnjlw,1k0sc6y,reddit,Most used programming language being used maliciously!,2025-04-17 18:29:21,2,nsjames1,programming
mnnu1ac,1k0sc6y,reddit,"Back in the day, disabling JavaScript was a normal part of everyday security.

Now people are pikashock when javascript carries malware.",2025-04-17 22:02:50,2,reallokiscarlet,programming
mni12we,1k0sc6y,reddit,"First, this has to happen:

One active campaign, detailed in Microsoft's report, uses malvertising to lure users to fraudulent websites imitating cryptocurrency trading platforms like Binance or TradingView. Visitors are prompted to download a malicious installer crafted using Wix, which embeds a custom DLL (CustomActions.dll). Upon execution, this DLL gathers system data via Windows Management Instrumentation (WMI) and sets a scheduled task to run obfuscated PowerShell commands.",2025-04-16 23:57:43,3,skinnybuddha,programming
mnkv3bo,1k0sc6y,reddit,And Microsoft knows a thing or two about delivering malware.,2025-04-17 13:10:51,3,MrSurly,programming
mnj4bjk,1k0sc6y,reddit,time to add cyberinsider to my block list for ai slop articles.,2025-04-17 04:09:16,3,PurpleYoshiEgg,programming
mnhdkpe,1k0sc6y,reddit,"I've been out of the webdev game for a while, are there still Greenfield projects choosing to use Node?",2025-04-16 21:45:41,0,poemmys,programming
mnpfgwu,1k0sc6y,reddit,"Node, pip, crates or whatever Rust's is called...   
Who would have though that trivializing libraries delivery would ease ways to infect users faster, huh?",2025-04-18 04:02:43,1,RoomyRoots,programming
mnsrasp,1k0sc6y,reddit,npm package management is disgusting mess.,2025-04-18 18:09:38,1,iNoles,programming
mo17nnd,1k0sc6y,reddit,Waos,2025-04-20 02:58:02,1,ivanAlf1,programming
mo3wnqf,1k0sc6y,reddit,They said the same for Crypto,2025-04-20 15:59:21,1,bidaowallet,programming
mnkdke2,1k0sc6y,reddit,Original article: https://www.microsoft.com/en-us/security/blog/2025/04/15/threat-actors-misuse-node-js-to-deliver-malware-and-other-malicious-payloads/,2025-04-17 11:16:00,1,mcpower_,programming
mnk0nwd,1k0sc6y,reddit,"Welcome to javascript. It's the hell that was chosen by corpos, nodevs, and now will continue to be chosen by ai.",2025-04-17 09:19:02,0,NanoYohaneTSU,programming
mnkopaa,1k0sc6y,reddit,"And they should know, after all, the biggest tool used for Malware Delivery and Data Theft is Microsoft Windows.",2025-04-17 12:32:35,0,erez,programming
mnn8vt2,1k0sc6y,reddit,Definitely speaks to the ease of use of the Node.js ecosystem. ASP.NET though.........,2025-04-17 20:16:01,0,Flaky_Ambassador6939,programming
mo2yg8s,1k0sc6y,reddit,"Of course microsoft would say this because node.js removes the need to use their buggy proprietary IDE’s and bloated libraries 

You could equally say compilers used to create all malware",2025-04-20 12:38:01,0,Creative-Dust5701,programming
mngkyo6,1k0sc6y,reddit,JS truly is the new VB.,2025-04-16 19:20:55,-31,Caraes_Naur,programming
mnihu0a,1k0sc6y,reddit,I'll tell you this:  I tried compiling the git source three times on a server that I share with some fiends (because I'm an LFS kinda guy and like installing stuff in my ~ rather than the system).  Each time it took the server down due to a runaway gcc process.  I didn't even know it was me until one of the other dudes did some deep log analysis and told me.,2025-04-17 01:41:04,-4,I0I0I0I,programming
mniq9i7,1k0sc6y,reddit,Microsoft worried about node when they won’t do anything to stop DOGE. ,2025-04-17 02:32:24,-10,LordAlbertson,programming
mnhrwxi,1k0sc6y,reddit,But how to solve it? Ahahahah,2025-04-16 23:06:06,-12,thacurter,programming
mke5yhh,1jms5sv,reddit,"Accurate takes all around.  Vibe coding sounds like some silicon valley bullshit to make a particularly stupid idea seem cool.  But these people are disconnected nerds so it seems pretty lame to a person like me.

The author's path to integrating AI into their workflow mirrors mine.  I use it to do the things I don't want to do and guide it but I always have a good idea of the architecture and work I have in mind to implement things.

I also lean pretty heavily on integration tests.",2025-03-29 18:20:55,559,NoobChumpsky,programming
mkf7z3i,1jms5sv,reddit,"TIL that vibe coding is not just a derogatory term for extensive use of ai while coding, but instead something that people are in fact serious about",2025-03-29 21:50:35,97,spirit-of-CDU-lol,programming
mkeh9vm,1jms5sv,reddit,"Vibe coding goes against the core principles of Clean code: Accountability for code being written. 

You expect your doctor to be liable for mistakes he makes. It’s very important to safeguard people’s lives. We live in a World where our safety depends on systems being written by people that know what they are doing. 

Would you blindly trust your plane’s auto pilot system code being prompted by a Product person?",2025-03-29 19:22:21,189,Immediate-Raccoon-84,programming
mkg1ohi,1jms5sv,reddit,I’m still getting used to this sub. Is it just links to people’s blog articles?,2025-03-30 00:44:40,18,Greenphantom77,programming
mkh8wys,1jms5sv,reddit,"Code exists because natural language is not precise enough. Putting an LLM in between your natural language and the code means you are losing that precision, and replacing it with extremely convincing hallucinations.",2025-03-30 05:59:41,18,CharlieDarling14,programming
mkezxlm,1jms5sv,reddit,"Companies that allow AI slop into their codebases will create a lot of job opportunities for real, experienced programmers a few years down the road. ",2025-03-29 21:04:41,30,Grove_street_home,programming
mkhdicy,1jms5sv,reddit,"What worries me the most is that investors are buying into this trend. They want to see the products released as fast as possible. Recent Y Combinator podcast ""Vibe Coding Is The Future"" shows that their lack of fundamental understanding of software engineering is only getting worse.

I recently worked in a gen-z startup that fully embraces vibe coding. The founder expected a bunch of features to be developed and deployed for an investor meeting overnight. It was a shit show and the code was complete garbage full of bugs and it looked like shit. Needless to say I no longer work for them.",2025-03-30 06:47:13,10,akirodic,programming
mkejd9e,1jms5sv,reddit,"People blow this dude's quote so far out of proportion. How one brief, fun tweet got turned into ""Karpathy's Vibe Coding Movement"" is pretty surreal.

>Also I just talk to Composer with SuperWhisper so I barely even touch the keyboard. I ask for the dumbest things like ""decrease the padding on the sidebar by half"" because I'm too lazy to find it. I ""Accept All"" always, I don't read the diffs anymore. When I get error messages I just copy paste them in with no comment, usually that fixes it .... Sometimes the LLMs can't fix a bug so I just work around it or ask for random changes until it goes away... It's not too bad for throwaway weekend projects, but still quite amusing""

Really? You think this dude was proposing ""verbally asking for random changes until the bug goes away""  as a movement for a new software engineering paradigm?

I'm imagining this dude sitting on his couch, pizza in one hand and beer in the other,  just talking at his computer, vibing, having fun on his weekend project, while the entire software engineering community shits itself over how this isn't a viable strategy for a long term healthy codebase.",2025-03-29 19:34:08,125,_BreakingGood_,programming
mkejdzj,1jms5sv,reddit,"A good friend does fractional CTO and contract dev work. He told me that he’s found a great area of business: he goes into a company that vibe coded a product, raised money, and discovered that what the AI built is completely unsustainable. Now they need to fix it and hire a team to run their business. He says it’s very similar to what he saw more than a decade ago with ad agencies hacking together spaghetti Rails and Wordpress sites on behalf of companies and then leaving them to figure out how to make them work.",2025-03-29 19:34:14,39,sickcodebruh420,programming
mke5gy8,1jms5sv,reddit,"The suggestions in the Better Path Forward section are almost exactly the guidelines we have for using AI coding assistants in my org.

This is a quality post with a weird title, OP. Maybe it's just me, but I was expecting some kind of data describing why it's considered harmful, and by whom.",2025-03-29 18:18:16,37,hurbunculitis,programming
mkh32yo,1jms5sv,reddit,"Vibe Coding isn't harmful  
It harmful to discuss such stupid idea, Vibe coding is harmful since day 1

Discussions, pro/cons of a stupid idea = giving credit to the stupid idea, maybe the idea isn't such stupid idea

The only thing to say about vibe coding - it is stupid idea  
just like the idea the earth is flat  
  
maybe vibe coding is the earth is flat moment for programmers",2025-03-30 05:04:48,8,gjosifov,programming
mkevu0k,1jms5sv,reddit,The fact that “vibe code” has already made its way into payment systems 😢,2025-03-29 20:42:10,13,rectalrectifier,programming
mkf1g4f,1jms5sv,reddit,"I just realized I never actually read the original definition of ""vibe coding"":

> His exact words? *“I ‘Accept All’ always, I don’t read the diffs anymore.”*

This is the software-career equivalent of [getting in the back of your Tesla and trusting the ""self-driving"" not to kill you](https://www.ktvu.com/news/man-arrested-for-riding-in-back-of-driverless-tesla-on-autopilot-gets-out-of-jail).

It's also missing *the* biggest opportunity here: If you're a junior trying to wrap your head around a new codebase, API, framework, whatever, and if the AI is actually doing better than you are and generating stuff you don't understand yet, ask it questions:

> Review all generated code as if it came from a junior developer

And the AI won't get offended if you ask *the* most nitpicky code review questions. It won't judge you if your question reveals a lack of understanding of something fundamental; instead, it'll point you to the relevant documentation! And if you treat it like a junior even when it seems to be smarter than you, sometimes you'll catch it with its pants down doing something stupid, at which point it'll explain *that* too.

I've found it to be pretty useless on my normal day-to-day coding. Not entirely useless, it fills in when other tooling breaks down -- if your language server's IntelliSense is broken, an AI autocompletion can do in a pinch. It does well with the rare boilerplate that *should* be boilerplate, like test cases. But that's because I'm *not* a junior. I know my way around the codebase, I've been using the language for years, and I *had* to learn that, because we didn't have LLM tooling then!

But if you want to get to that level... well, that's what I'm trying to do with my own weekend project. ""Hang on, your last suggestion was this way and now you want to do it that way, why?""",2025-03-29 21:13:15,11,SanityInAnarchy,programming
mkhgc7m,1jms5sv,reddit,"No shit. The reason why good engineers are hired is for their accountability and responsibility to keep things maintainable. Contractors or AI won't do that, they only give solution for current problem. When you're handing it over to someone/something else as cost-cutting measurement, you're adding hidden technical debts which eventually leads to unsustainable software.",2025-03-30 07:17:41,4,daftmaple,programming
mke771i,1jms5sv,reddit,[deleted],2025-03-29 18:27:39,13,N/A,programming
mkgcibc,1jms5sv,reddit,Karpathy literally says in his tweet that it's something he enjoys doing for small weekend projects because it's amusing to see what the AI comes up with. It's not something he does on production code.,2025-03-30 01:51:14,3,SwitchOnTheNiteLite,programming
mkfiwnj,1jms5sv,reddit,"I’m going to go with “No shit, Sherlock” for 100, Alex.",2025-03-29 22:54:31,7,dex206,programming
mkgzfb0,1jms5sv,reddit,"I don't know who this Karpathy guy is, but he sounds like an idiot.",2025-03-30 04:33:52,8,bittlelum,programming
mkesdlr,1jms5sv,reddit,sooo the lesson learned about writing code as cleverly as possible but using a system that doesn't even reason so you generally have little hope of debugging it because you weren't clever enough to write it the first time.,2025-03-29 20:23:17,4,wildcarde815,programming
mkgccab,1jms5sv,reddit,"If AI could count and order things consistently and correctly this might be helpful... but it just sounds like the AI will be the new ""Visual Studio interrupting me typing with bad suggestions"" in a new form.",2025-03-30 01:50:15,4,XypherOrion,programming
mki77dz,1jms5sv,reddit,"He meant it sarcastically? Also, no shit",2025-03-30 11:57:03,2,__Maximum__,programming
mklg0ps,1jms5sv,reddit,"When I was reading the original post by Karpathy, I wasn't sure if he's joking or not.

In fact, I'm still not sure.",2025-03-30 22:46:22,2,dezsiszabi,programming
mkntspa,1jms5sv,reddit,"I haven’t seen a “considered harmful” headline in so long, that I’m surprised “vibe coding” has eclipsed it in irony",2025-03-31 10:09:36,2,ckomni,programming
mkfzt3j,1jms5sv,reddit,"Well, it is entirely possible to mathematically prove code correct 

* https://en.wikipedia.org/wiki/Formal_methods
* https://en.wikipedia.org/wiki/Formal_verification

If machine-generated code *is correct*, well, ...it's correct code. What's the problem?

So are these people going to apply formal verification methodology to all generated code? Aahaha, no, absolutely not, the glassy-eyed eejits seem to think because A Computer Did It, it must be correct already - most of them don't even have the compsci training enough to have even heard of formal verification etc. May even think that's what's already happening?  But that's [just not](https://transformer-circuits.pub/2025/attribution-graphs/biology.html) how the current statistical babbling LLM crap works, sigh.   They *are not reliable*.

Guess we can all look forward to a ""vibe coded""  [Therac-25 type incident](https://en.wikipedia.org/wiki/Therac-25) sooner or later. Yay.",2025-03-30 00:33:29,4,lood9phee2Ri,programming
mkewo0j,1jms5sv,reddit,"You guys know vibe coding is a joke, right?

... right?",2025-03-29 20:46:41,3,thats_so_bro,programming
mkeumvl,1jms5sv,reddit,Nobody considers this to be insightful right? Is it not obvious to everybody? No? Hmmm.,2025-03-29 20:35:38,2,blafunke,programming
mkft89d,1jms5sv,reddit,"I think what people are taking out of context is that KARPATHY IS AN AI RESEARCHER. Every interaction he has with this technology is from the point-of-view of an experimentalist. While he's playing with it, he's learning nuances about what it is and isn't good at, which gives him ideas for new experiments to try. 

Of COURSE he clicks ""always accept"".

We're talking about someone who left OpenAI at their peak to focus on side projects. Dude is already loaded, and isn't even attached to an AI product right now. He does not give a fuck if the AI wastes his time. He's just having fun anyway. He's not telling other people to work like that, he's giving them a window into how an AI researcher interacts with these systems.

""Vibe coding"" is basically a game, a la ""Engineering Manager Simulator."" Consider the perspective of a manager who manages a team of people who have skills the manager doesn't.

It's not a novel work style. The work style already exists: it's called *delegating*.",2025-03-29 23:54:12,2,DigThatData,programming
mkgo6w9,1jms5sv,reddit,"vibe coding is just a forced meme, why are people taking it seriously?",2025-03-30 03:07:48,2,Difficult_Mix8652,programming
mkeyldb,1jms5sv,reddit,We all know how difficult it is to solve bugs.,2025-03-29 20:57:16,1,True-Environment-237,programming
mkjylvt,1jms5sv,reddit,"""Just vibe with the code"" sounds like an excuse to skip unit tests. But if it works for Karpathy, who am I to judge?",2025-03-30 18:02:22,1,dodogutz,programming
mkkzpil,1jms5sv,reddit,"One thing I have noticed is non-tech people thinking they ""mastered the vibe"" and show off their React todo apps... that honestly 99% of the time not only look like shit but the code is a garbage truck on fire.

Then a real dev comes along and with the intent of trying to be nice tells them it's really good and to ""keep up the good work"" so they get empowered and really believe they found the cheatcode in life.

We need to stop being nice, we need more Linus Torvalds energy for this stuff.. call out garbage code for being garbage (and obviously give praise when they put in the effort and actually tried)",2025-03-30 21:13:21,1,PeachScary413,programming
mkm8q22,1jms5sv,reddit,"I just learned what vibe coding means, and it sucks. The fun in programming is doing it yourself. It's about coming up with solutions or ideas to achieve your goal. There is no vibe in just prompting AI to generate you the code. Not to mention the quality of AI generated code.

AI can only be used as a teacher that can give you examples of how certain concepts work, and even that should be used with caution from hallucinations.

Programming is also a form of art. It's as if an artist let AI draw portions of their painting while they slightly tweak everything together.",2025-03-31 01:41:30,1,Dreadlight_,programming
mkmnurk,1jms5sv,reddit,"Agree current day
How long until it’s not though?",2025-03-31 03:22:57,1,kunfushion,programming
mkndfc2,1jms5sv,reddit,Some of these codebases from Vibe coding are worse than result from no code built apps.,2025-03-31 07:11:09,1,srona22,programming
mknrwfo,1jms5sv,reddit,"I refuse to use AI to code, ever.


This vibe coding crap is getting out of hand.",2025-03-31 09:50:49,1,Ratstail91,programming
mkog07u,1jms5sv,reddit,Holy fuck nobody ever reads the last paragraph where he says it's for weekend toy projects and MVPs. Beat the fuck outta that straw man though,2025-03-31 13:02:53,1,N/A,programming
mkp6clz,1jms5sv,reddit,"*I feel like ‘vibe coding’ captures something real—that flow state where everything just clicks… but yeah, without guardrails it can turn into a mess. Do you think coding by instinct always leads to bad design, or are there times when that intuition actually adds real value to the process?*",2025-03-31 15:25:21,1,tomasartuso,programming
mkq64zp,1jms5sv,reddit,Hero worship at its peak. He makes one post about doing this and the whole internet takes off with it like Jesus commanded it.,2025-03-31 18:22:55,1,N/A,programming
mkr7da6,1jms5sv,reddit,"The most frustrating thing about this is that I had already been using the phrase ""vibes-driven development"" to describe programming whose course is determined by aesthetics (e.g. ""code smells"").",2025-03-31 21:29:30,1,jpfed,programming
mkrvnxx,1jms5sv,reddit,"If you are using a language that doesn't provide for explicit representation of intent, then you are always ""vibe coding"".",2025-03-31 23:46:18,1,Internal-Sun-6476,programming
mkf2y4y,1jms5sv,reddit,Vibe coding is supposed to just be fucking around. It isn't supposed to be in connection to anything important. Yall need to take tbe sticks out of your asses.,2025-03-29 21:21:45,1,AsparagusAccurate759,programming
mkevd30,1jms5sv,reddit,"How the !$%& did something like this ever become ""a thing""? 

Not knowing what your code does? Just clicking ""accept all"" without verifying that the code does what it's supposed to? When did this become acceptable?

EDIT: Oh, it didn't. The whole thing was blown out of proportion apparently. See explanation: https://www.reddit.com/r/programming/comments/1jms5sv/karpathys_vibe_coding_movement_considered_harmful/mkejd9e/",2025-03-29 20:39:35,-1,deceased_parrot,programming
mki7icc,1jms5sv,reddit,These Dijkstra wannabes need to stop using this title to compensate for their lack of creativity. Claude could come up with a better title,2025-03-30 11:59:38,1,ayyyyyyyyyyyyyboi,programming
mkebagn,1jms5sv,reddit,"Didn't we agree years ago that ""considered harmful"" articles are considered harmful?",2025-03-29 18:49:53,-2,mr_birkenblatt,programming
mkhga12,1jms5sv,reddit,boomers are harmful 😏,2025-03-30 07:17:01,0,SlickWatson,programming
mkh8sti,1jms5sv,reddit,"Hello, I am the confusingly charismatic AI lunatic. My goal is to create an experiential vibe of programming.",2025-03-30 05:58:33,0,nibselfib_kyua_72,programming
mkhzl47,1jms5sv,reddit,I mean. Movement? It's more of naming of a thing that wasn't possible a year ago.,2025-03-30 10:47:15,0,bladehaze,programming
mkivklu,1jms5sv,reddit,"The critique of ""vibe coding"" actually highlights something I've been thinking about a lot lately: the importance of context in documentation.

When we rely on AI to generate code without truly understanding the context or documenting our decision-making process, we create technical debt that's much harder to identify. It's not just about documenting *what* the code does, but documenting *why* certain approaches were chosen over others.

In traditional development, engineers might choose an approach based on performance considerations, maintainability, or business requirements. These decisions often get captured in comments, PRD documents, or design specifications. But in the ""vibe coding"" paradigm, these decision trails can evaporate.

I've found that the most effective documentation in modern development includes not just implementation details but also:

1. Decision context (why this approach was chosen)
2. Alternatives considered
3. Key assumptions made
4. Expected limitations

This becomes even more critical when AI is involved in any part of the development process. Without this contextual information, future developers (or even the same developer six months later) are left guessing about the rationale behind certain implementations.

In a way, good documentation is becoming the new code review - it's a forcing function that makes us think about and articulate our design decisions, which is especially important when working with AI tools that might obscure some of that reasoning.",2025-03-30 14:39:51,0,traderprof,programming
mkhutc8,1jms5sv,reddit,99.9% of programmers who think they’re better than Andrej Karpathy are probably wrong.,2025-03-30 09:57:24,-5,ProbablyBsPlzIgnore,programming
mkfqy7o,1jms5sv,reddit,"Overly cautious people can't grasp Karpathy's ""vibe coding"" mindset, just like a stereotypical STEM guy can't read between the lines.",2025-03-29 23:41:02,-8,DonJ-banq,programming
mkerd5a,1jms5sv,reddit,"> Considered harmful

By whom? ""Harmful"" how? What the article explains is that there are pitfalls to building products mainly through AI assistance but that's hardly something ""harmful""",2025-03-29 20:17:48,-10,MileiMePioloABeluche,programming
mkeaxts,1jms5sv,reddit,"For how long will it be harmful?  Currently,  understanding the code is important. But in a year, will understanding design and data functionality be the only thing that matters? The combination of good aesthetics and data.  When you can simply present your idea to an AI agent and have them create it for you, you might never truly know what the code is. I see the point, but I also think that in six months to a year, it won't matter. I like the idea of having five terminals open with AI agents, each doing something different that I can't accomplish all at once.",2025-03-29 18:47:59,-25,Ok_Possible_2260,programming
ml2yow0,1jpribc,reddit,"*“it deleted the whole repo”*

*“i had another idea anyway”*",2025-04-02 20:07:45,159,husky_whisperer,programming
ml1j17u,1jpribc,reddit,"*""It's not a syntax error, it's a mood misalignment""*

*""Fix this or you go to jail""*

So many fantastic quotes in this one. I love all this guy's videos, honestly.",2025-04-02 15:58:11,300,creaturefeature16,programming
ml1yn16,1jpribc,reddit,I have to say even without watching the video the preview picture perfectly matches my expectations from the headline.,2025-04-02 17:14:40,181,jk_tx,programming
ml2rfwe,1jpribc,reddit,"This guy is great. Go watch his ""Interview with Senior JS Developer"" if you haven't, also really good.",2025-04-02 19:33:05,53,SpikeX,programming
ml1ruly,1jpribc,reddit,Why the ski goggles?,2025-04-02 16:42:15,29,atika,programming
ml2shij,1jpribc,reddit,Last couple of minutes are a gem.,2025-04-02 19:38:17,23,touristtam,programming
ml3dnud,1jpribc,reddit,"""Cease and desist? Bro, the AI takes care of everything.""

""I don't know how to take it down. Clause, take it down!""

""Lawyers... with... a.... criminal... record... near me.""

""Why is my bill $30,000?!""",2025-04-02 21:18:35,39,grendus,programming
ml413ot,1jpribc,reddit,"""claude turn it off or you will go to jail""",2025-04-02 23:23:51,9,JDMagican,programming
ml3n2s9,1jpribc,reddit,"I just learned about vibe coding yesterday, the fact that it's even a thing makes me scared for the future.",2025-04-02 22:06:51,18,Sage2050,programming
ml22y8b,1jpribc,reddit,r/ProgrammerHumor,2025-04-02 17:34:43,38,Mysterious-Rent7233,programming
ml7hxz7,1jpribc,reddit,"“Are we caching the data? Oh I’m cashing in hard on it yeah” Best line in the whole video, right out of the gate",2025-04-03 14:43:38,5,tor2ga-_-ag2rot,programming
ml3nitx,1jpribc,reddit,lawyers with a criminal record…in my area,2025-04-02 22:09:13,4,moreVCAs,programming
ml2d2o2,1jpribc,reddit,"I want to ""vibe never work with anyone who does this"" and ""vibe fire them from where they work""",2025-04-02 18:22:42,13,VictoryMotel,programming
ml4etbt,1jpribc,reddit,lol i love that guy.,2025-04-03 00:42:27,3,k1rd,programming
ml8opww,1jpribc,reddit,"""No, no, that's not how we write endpoints, I put in a whole style guide.""

I have said this to real humans, so I guess the AI has actually caught up? xD",2025-04-03 18:12:41,2,zdkroot,programming
ml8ojsg,1jpribc,reddit,"While the video is humorous, it highlights a real challenge in AI-assisted development. Code that ""just works"" without understanding creates significant technical debt.

I've seen teams implement structured knowledge management approaches where design decisions are documented before any AI generation. This dramatically improved maintainability compared to relying solely on generated code.

Has anyone found effective ways to balance the speed of AI generation with the need for sustainable, understandable systems?",2025-04-03 18:11:52,1,traderprof,programming
mlaumeu,1jpribc,reddit,I don't see how any can get good vibes while trying to reason with a LLM,2025-04-04 01:16:07,1,daHaus,programming
ml5pttj,1jpribc,reddit,Why they don’t call it Copilot coders or similar?,2025-04-03 06:15:04,-4,Jeff_Johnson,programming
mm3n8hm,1julofe,reddit,"As somebody who spent last weekend trying out ""_vibe coding_"", this is **SHOCKINGLY** close to my experience to the point this isn't even a parody.

Anyways... Learned a lot today, love galactus..",2025-04-08 20:54:55,336,valarauca14,programming
mm3ujat,1julofe,reddit,Current AI coding tools are what happens when you wish for a personal assistant and then the monkey paw curls.,2025-04-08 21:31:33,182,TheDrInconsequential,programming
mm4bqww,1julofe,reddit,"Imagine having a really dumb intern or junior like really dumb, but they have access to Google. And they are surprisingly good at googling. But put almost no thought into what they doing just making their Google search fit to what you are doing. And they just won't get any better until the next intern model comes out. But it's more or less the same",2025-04-08 23:06:20,189,todo_code,programming
mm5aizy,1julofe,reddit,I mean the whole video is gold but the editing adding a border around the video really did me in lmao,2025-04-09 02:28:40,28,thetdotbearr,programming
mm3yhgz,1julofe,reddit,Ha! He calls himself senior but doesn't even have 10+ years experience using LLMs!,2025-04-08 21:52:10,74,Putrumpador,programming
mm47ntw,1julofe,reddit,"Have seen this term all over recently but haven’t bothered to look into what it means yet. 

Is it really just pretending to be Tony Stark or Capt Picard talking to “AI” and hoping it will do what you ask? 

….. That’s fucking dumb.",2025-04-08 22:43:22,65,ShenmeNamaeSollich,programming
mm3b8i3,1julofe,reddit,Never not good. Love these! Lmao!,2025-04-08 19:58:19,20,this_knee,programming
mm6atfh,1julofe,reddit,"These vibes, they are all bad.",2025-04-09 07:23:31,7,pelrun,programming
mm3p1du,1julofe,reddit,Sounds like having an intern.,2025-04-08 21:03:29,20,fireduck,programming
mma05uc,1julofe,reddit,"“No no, you don’t use clear: both on a flexbox.” Fucking gold.",2025-04-09 20:48:25,5,squeeemeister,programming
mm4kpjm,1julofe,reddit,Ok ok ok I've seen all the posts so I'll go ahead and ask...wtf is vibe coding? I've made a few inferences but someone eli5,2025-04-08 23:57:05,16,thefinest,programming
mm6muu6,1julofe,reddit,My CTO thinks AI will do our job in a year or so and our only job will be to review PRs...,2025-04-09 09:34:07,4,AllPeopleAreFuckers,programming
mm4r4pk,1julofe,reddit,i’ve never seen a more accurate video,2025-04-09 00:34:49,8,collin2477,programming
mm6nl91,1julofe,reddit,What is Vibe Coding???,2025-04-09 09:41:52,3,rasmusdf,programming
mm8sgz5,1julofe,reddit,"The patterns I've observed with vibe coding remind me of the early RAD (Rapid Application Development) days, just accelerated with AI.

The productivity boost is impressive for prototyping, but the technical debt accumulates rapidly. What's most concerning is how context and design rationale vanish - the ""why"" behind implementation choices disappears.

This works for solo developers on greenfield projects, but becomes problematic with team handoffs or when maintaining systems long-term. The next evolutionary step needs to address knowledge persistence, not just code generation.

Has anyone found effective methods to document AI-assisted development decisions?",2025-04-09 17:18:38,3,traderprof,programming
mm65nwd,1julofe,reddit,"Are people deliberately understanding the concept wrong just to make fun of it? 

The man who coined the term literally said that he found the technique ""not too bad for throwaway weekend projects"" and described it as ""quite amusing."" Does that sound like he's advising to use it in production? No, he made it clear it's fun for throwaway projects, but you might still get something working out of it.",2025-04-09 06:30:33,7,Harzza,programming
mm6p5hx,1julofe,reddit,"I feel the thing people pushing AI forget is ""code"" is itself just a simple, unambiguous way to tell a computer exactly what you want it to do - and its really good at it.",2025-04-09 09:57:36,2,mr_bag,programming
mm8bwuj,1julofe,reddit,Is it really possible to code with these systems without knowing anything about coding? Or are they asking the AI system to teach them how to code as it's giving the code to them? I use AI everyday but I have been programming for 25 years so I know when it's just plain wrong or it didn't give me what I asked for.,2025-04-09 15:57:38,2,Sufficient_Wheel9321,programming
mmcpby1,1julofe,reddit,"Haha, you're a NASA coder... why are you using Lisp!! was funny.

https://thenewstack.io/nasa-programmer-remembers-debugging-lisp-in-deep-space/

> On the podcast Garret described the very limited programming options in 1988 — a world before Java, Python, JavaScript, and even C++. “There is Pascal and C and Basic and machine code. And that’s pretty much it in terms of popular languages. To get anything done in any of those languages is just really, really hard.” The code for most spacecraft ended up being written in assembly language.
>
> But then there was Lisp — a language based on abstracting problems cleanly into lists and functions. And while C programmers worry about things like dangling pointers, Lisp also has automatic memory management. “It’s just so much faster and easier to get things done when the language you’re using provides you with some of these high level abstractions,” Garret remembered on the podcast. “And in a world where the only language that has that is Lisp, knowing Lisp really is like a superpower.",2025-04-10 07:38:19,2,jugalator,programming
mm6h8gf,1julofe,reddit,"I thought vibe coding was just shitposting, are people actually taking it seriously? 😅",2025-04-09 08:33:13,2,Shadowblink,programming
mm62h3x,1julofe,reddit,"I'm having a really good vibe coding session building an accurate 3D Space engine with orbital mechanics. 

I have wanted to build once since I was 12 (I'm 43 now) and have to admit I wouldn't be this far along without AI helping me, and switching to Cursor let me do it - it's really good at the math and physics.

Having said that it *keeps* breaking things in unexpected ways - like I'm working on an unrelated topic and all of a sudden something *else* will break and you find it's randomly changed some settings it was never asked to look at.

I've got quite good at committing changes now, and also ask it to occasionally remind me - but this isn't replacing even junior coders right now.",2025-04-09 05:59:15,7,tanepiper,programming
mm64asw,1julofe,reddit,It me.,2025-04-09 06:16:57,1,deadwisdom,programming
mm7xp62,1julofe,reddit,That phrase need to die,2025-04-09 14:47:42,1,ziplock9000,programming
mmadbyy,1julofe,reddit,"As someone who doesn’t really buy much of the AI hype when it comes to coding, a coworker did a demo on cline.ai today and I was impressed and a little frightened at how good it seemed to implement features",2025-04-09 21:56:38,1,javyQuin,programming
mmb3pyi,1julofe,reddit,I'm getting a vibe alright.,2025-04-10 00:28:46,1,blackcain,programming
mmhz8ai,1julofe,reddit,"I use copilot to get my test coverage over the really important functions. I won’t lie I use it for everything storybook.

I tried the new agent mode?!

It was like I was overseeing a team of four jr. and their rapid fire mostly useless, over zealous PRs.

The data layer package is right there AI, use it. The design system is right there ai. No ai, you’re not product, you don’t get to change the design tolkens….

Hey where did my styles go? Ok ai decided to rollback five versions…

Why are my lambdas not working? Oh because my zod schemas are now empty and I’ve got pascal cased types?

No thanks. I’ll just ask it to mundane tasks without thinking.",2025-04-11 02:29:54,1,zaskar,programming
mmjuuys,1julofe,reddit,So that how 40 yo people look in Amurica.,2025-04-11 12:22:01,1,Mundane-Apricot6981,programming
mm6shk2,1julofe,reddit,"I know its shit right now, but its first steps. I can see a future where coding partly like this might be marginally useful.",2025-04-09 10:29:34,-3,KristinnEs,programming
mm1ryr3,1judf0y,reddit,My company doesn't allow us to use AI. InfoSec reasons.,2025-04-08 15:29:56,378,wildjokers,programming
mm23pm9,1judf0y,reddit,In my 25 years of developing writing the actual code must be like 10% of the time. Waiting for other people to get shit done seems to be around 75% of where my time has gone.,2025-04-08 16:28:09,152,Plank_With_A_Nail_In,programming
mm3794r,1judf0y,reddit,"If it were us two years ago asking executives to give access to AI tools for increasing productivity, they would say no. But when AI turned into a FOMO thing, now executives forcing us using AI to increase productivity.",2025-04-08 19:39:27,40,yamirho,programming
mm1dolf,1judf0y,reddit,"We also had that lately with shopify aka the CEO ""if AI is better than you, you won't get a job here"".

Pretty bleak future ..",2025-04-08 14:18:13,241,shevy-java,programming
mm3tdd0,1judf0y,reddit,"Our CTO ""left"" 2 weeks ago, because his AI strategy didn't work out for the firm, and caused some really high value employees to leave for competitors.",2025-04-08 21:25:28,24,wapskalyon,programming
mm2xd9b,1judf0y,reddit,"In one sense I am relieved I will still have a job in Refractoring old/bad codebases, on the other hand my god that job will probably suck.",2025-04-08 18:50:07,18,LordAmras,programming
mm15a8u,1judf0y,reddit,"> In 2024, 72% of respondents in the Stack Overflow report said they held a favorable or very favorable attitude toward the tools, down from 77% in 2023.

You'd expect a far larger drop if the following statement was as widespread as the article would have you think:

> Overall, developers describe a slew of technical issues and headaches associated with AI coding tools, from how they frequently suggest incorrect code and even delete existing code to the many issues they cause with deployments.

Not that these aren't problems -- they clearly are -- but this isn't exactly ""driving people to the brink"" levels of dissatisfaction.",2025-04-08 13:32:08,162,phillipcarter2,programming
mm2kyyp,1judf0y,reddit,"The worst thing about this is   
Companies are giving cheap laptops for writing software, where 40% of the hardware resources are spent on security background checks  
and they expect software engineers to deliver software faster with this AI

It is like Pixar giving animators cheap laptops and 10 year old drawing tablets and then write email with subject the movie release next week",2025-04-08 17:50:27,24,gjosifov,programming
mm2cx4r,1judf0y,reddit,"I have started using AI coding tools (Claude, to be specific) extensively in the last month.

I've wasted a fair bit of time (or spent or invested, I guess) learning what they're good at and what they're not good at.

The high-level summary: my job is safe and probably will be for the foreseeable future.

That being said, they are definitely good at some things and have increased my productivity, once I have learned to restrict them to things they're actually pretty decent at.

The overarching shortfall, from my point of view, is their confidently incorrect approach. For example, I set the tool to help me diagnose a very difficult race condition. I had a pretty good idea of where the problem lay, but I didn't share that info from the jump with Claude.

Claude assured me that it had ""found the problem"" when it found a line of code that was commented out. It even explained why it was a problem. And, its explanation was cogent and very believable.

This is the real issue: if you turned a junior dev or non-dev loose with this tool, they might be very convinced they had found the problem. The diagnosis made sense, the fix seemed believable, and, even more, easy and accessible.

Things that the tool is really good at, though, help me out a lot, even to the point that I would dread not having access to this tool going forward:

\- documentation: oh, my god, this is so good. I can set Claude to ""interview"" me and produce some really nice documentation that is probably 80-90% accurate. Really helpful.

\- spicy stack overflow: I know Spring can do this, but I can't remember the annotation needed, for example

\- write me an SQL query that does this: I mean, I can do this, but it just takes me longer.

\- search these classes and queries and make sure our migration scripts (found here) create the necessary indexes - again, needs to be reviewed, but a real timesaver",2025-04-08 17:13:00,56,evil_burrito,programming
mm1706i,1judf0y,reddit,"> Many also say the use of AI tools is causing an increase in incidents, with 68% of Harness respondents saying they spend more time resolving AI-related security vulnerabilities now compared to before they used AI coding tools.


So 32% of respondents spent more time resolving AI-related security vulnerabilities *before* using AI coding tools? This has to be a butchering of the survey question, right?",2025-04-08 13:42:07,39,apnorton,programming
mm32ryr,1judf0y,reddit,"Am I the only one that uses gpt to replace Google, documentation (while still refering to official if it doesn't seem right), and stack over flow? And not just copy past entire coda bases and ask it to do crazy unrealistic shit.",2025-04-08 19:17:04,6,bllueace,programming
mm481gq,1judf0y,reddit,It's almost as if there is a complete lack of trust and communication between the C Suite and the rest of the company based on the fact that they are categorically MBA sociopaths with an expertise in exactly nothing at this point. I haven't had a CEO who ever worked for a living in 10 or 12 years. I haven't had a CTO who could write code in 8. I haven't had a CMO that made words that made sense in... ever?,2025-04-08 22:45:32,6,abeuscher,programming
mm1uwwx,1judf0y,reddit,"If the stupid DOM and web UI frameworks haven't made coders snap, then AI probably won't either.",2025-04-08 15:44:31,18,Zardotab,programming
mm4qt0q,1judf0y,reddit,"AI is so ridiculous. It provides convincing looking answers to people who are ignorant or lack experience. Best used for syntax, debugging or looking up stuff, but not good for logic or design.",2025-04-09 00:32:56,3,StarkAndRobotic,programming
mm476dq,1judf0y,reddit,Who's brink?,2025-04-08 22:40:35,2,No-Possession-8478,programming
mm27w90,1judf0y,reddit,"I was afraid of this. I had a thought the other day that i wasn't getting anywhere with interviews because id say that i don't use AI. 10 years i had no problem finding work, but now ive been out of work an entire year.

 Guess its time to retire?",2025-04-08 16:48:53,4,enricojr,programming
mm4jex2,1judf0y,reddit,"Another day another r/programming post bashing AI...I have optional choice to us AI at work and they pay for it if we want..really been Enjoying Windsurf IDE so I guess I am the minority here.


I feel everyone acts like you have to be a full out ""Vibe Coder"" or hate AI when in fact somewhere in the middle it is very useful.  To me it feels just as much a tool as using git for managing source.",2025-04-08 23:49:40,5,yur_mom,programming
mm59t1y,1judf0y,reddit,"> The most attractive aspect of these tools to business leaders is their potential to automate repetitive coding tasks, which can make teams more efficient, help them ship faster, and increase revenue.

I use these tools every day. In many instances I feel naked without the coding assistant nearby. 

> The quiet implication also means employing fewer expensive developers,

This is not happening and won't happen.   Every single line of code produced by the AI must be scrubbed and scrutinized.   Absolutely no human in my large building is going to be ""replaced"" 

> Y Combinator’s managing partner, Jared Friedman, said that a quarter of startups in the accelerator’s current cohort have codebases that are almost entirely AI-generated.

I don't believe this for a second.


> Many also say the use of AI tools is causing an increase in incidents, with 68% of Harness respondents saying they spend more time resolving AI-related security vulnerabilities now compared to before they used AI coding tools.


""security vulnerability"" and  ""AI code"" should never appear in the same sentence.  


> “I tried GitHub Copilot for a while, and while some parts of it were impressive, at most it was an unnecessary convenience that saved only a few seconds of actual work. And it was wrong as many times as it was right. The time I spent correcting its wrong code I could have spent writing the right code myself,” said one developer in a Reddit discussion


This redditor does not know how to prompt Copilot.  He likely thinks the tool can read his mind.  It can't.",2025-04-09 02:24:26,2,moschles,programming
mm52bz1,1judf0y,reddit,"""Mandate"" is the keyword.   
   
People don't like to be told what to do, and even though a job is literally about people telling you what to do, it's a whole different level when you get told how to do it, and what tools to use or not use, by people who have no idea what they're talking about, and they expect magic.    
It's not any different than business types pushing agile, or severless, or microservices, or whatever else they think is going to let them get away with giving develoymore work for less money.   
    
I lightly use AI, and it's great. I mostly use it for things I either don't want to do, or as a practical jumping off point for something I'm ignorant about.   
   
I don't want to make GUI frontends for every little experimental script, but the scientists and engineers around me won't touch a console or terminal.   
Everyone wants a one click solution with sensible defaults that they can twiddle.  
   
AI has saved me so much tedium.  
    
I was dragging ass today, and I had Copilot make an inno setup installer for me.  
It made 3 minor errors, but it only took about a minute to fix.   
I could have done all myself, but I just didn't want to, and it would have taken way longer.  
   
Nobody is *forcing* me to use AI, I'm just using it when I think it'll make my life easier, without making too much extra work, and I can focus more on the things I actually want to do.",2025-04-09 01:40:53,1,Bakoro,programming
mm5nifi,1judf0y,reddit,"To be honest I find it really helpful for some tasks and not that helpful for others.  But that's not really much of an issue if they're just making the tools available and allowing you to use them as appropriate, rather than giving you some rule about how often you must use them.",2025-04-09 03:55:10,1,RICHUNCLEPENNYBAGS,programming
mm83prq,1judf0y,reddit,"It surprises me when managers think that bullying their employees is some great new innovation. 

It’s like: “Do you actually think that you’re the only person right now having the great insight of cracking the whip as hard as possible? Like in all your competitors management meetings do you really think you’re the only one that thought that up? Really? The only one? You’re the goodest and bestest bully in all the land and your company will be the winner because you’re the only one who’s bullying their employees into success? Like in all human history it’s just you? Nobody ever thought of cracking the whip? Only you?”

I get having to ensure profitability and I get it’s hard to make the hard decisions. But…

Bullying is the laziest and least effective way to do literally anything. 

That’s what’s happening here. Instead of saying: “hey you poor fucker stay late and work harder” they are instead saying “hey you poor fucker stay late and work harder because fuck you now you have no excuse because blah blah blah AI”. 

Like what the absolute fuck. 

However I should have empathy for them. These managers perceive everyone as being selfish lazy slackers because that’s what they are.",2025-04-09 15:17:20,1,Liquid_Magic,programming
mm8m7nl,1judf0y,reddit,"One simple reason why AI tools never replace human devs - when project failed - you cannot punish AI.  
Bossed always will hire scrape goats even if AI will do most of work.",2025-04-09 16:48:27,1,Mundane-Apricot6981,programming
mmnj6s7,1judf0y,reddit,"I'm not divulging proprietary source code to LLMs for their digestion, such the borg of 2025.",2025-04-12 00:02:30,1,Ultrazon_com,programming
mm36u3x,1judf0y,reddit,"This American idea of ""move fast and break things"" is so absurdly stupid... but it really only works because America is pretty much the only big player that have these behemoth corporations that doesn't have to fight tooth and nail in contrast to say... China or even the EU.",2025-04-08 19:37:24,1,monkeynator,programming
mm4opt9,1judf0y,reddit,"The reaction to AI is the biggest cope I've seen from developers in my career. People are acting like using AI isn't ""real coding"", or pretending that AI only gives bad/unmaintainable results. I think it's the ego of having built up skills your whole career to see those skills because valued less due to a computer being able to do the basic parts of it. 

Learn to use AI, keep making pull requests and reviewing code. It's another tool that will make productivity go up. Whether that means we only need 1 developer doing the work of 10 now, I'm not sure.",2025-04-09 00:20:35,-2,EruLearns,programming
mm2f9cw,1judf0y,reddit,Anyone else kind of tired of all these ai coding is bad articles?,2025-04-08 17:24:07,-12,Dragon_yum,programming
mm32rfc,1judf0y,reddit,"Claude code is amazing.  Just don't expect that you can forget reasonable software engineering principals, and you'll be pretty productive.  I got through several large refactors at least 2-3x faster than I would have otherwise, because of boredom + ADHD.

TDD is your friend.",2025-04-08 19:16:59,-4,rustyrazorblade,programming
mm1sflh,1judf0y,reddit,"Respectfully, if a developer can’t learn to use modern tools to accelerate their productivity, we will find ones who can.

Likewise, if you’re using AI tools and not reading the output or producing a higher rate of bugs, will find developers who don’t.

We don’t want idiot vibe coders but we do expect that you use AI as appropriate to work as fast as possible without creating a mess.

Times are changing. Adapt or die.

I think developers hubris is catching up to us. We don’t get paid to produce masterful art in our code, we get paid to produce products that sell features. AI tools, when used correctly, can often dramatically accelerate time to market and we are obligated to use them when they do. This is a competition.",2025-04-08 15:32:16,-33,o5mfiHTNsH748KVq,programming
mkugxdu,1joqlry,reddit,"Thats amazing. 

**The backend team builds APIs based on their own assumptions**

This sums up a problem I had today 😂",2025-04-01 12:35:13,108,BeyondLimits99,programming
mkujm6h,1joqlry,reddit,"Price's law is not about work don but about scientific publication:
> in any scientific field, half of the published research comes from the square root of the total number of authors in that field

And even in its correct form, it's not a very acurate ""law"":
> Subsequent research has largely contradicted Price's original hypothesis 

source : https://en.wikipedia.org/wiki/Price%27s_law",2025-04-01 12:52:50,147,mareek,programming
mkwue5u,1joqlry,reddit,You forgot about [Cole's Law](https://www.google.com/search?q=coleslaw&udm=2),2025-04-01 20:10:02,44,darchangel,programming
mkvclx7,1joqlry,reddit,"Retired old guy here. 

All accurate BUT: it completely absolves the engineers from any responsibility regarding outcome. (Been an engineer, been in management, switched back and forth many times.)

Engineers can learn how to manage their managers. 

Easy statement to make, hard to implement. Company culture, communication skills (the engineers, and the managers), motivation, etc come into play. But successful teams eventually figure it out. 

Ie: (as stated in the article) every rule (law) has exceptions and smart people learn to work with them.",2025-04-01 15:35:08,34,thesamim,programming
mkuun28,1joqlry,reddit,Well that was almost good until it mentioned Elon Musk firing a bunch of Twitter devs as if it was no big deal.,2025-04-01 13:59:44,53,N0t_my_0ther_account,programming
mkxde1s,1joqlry,reddit,">Elon Musk fired 50% of Twitter in November 2022.
Price's square root law explains why Twitter didn't collapse, even when a further 30% were fired.

>The square root of the original 8,000 employees is just 90!

You lost my respect when you brought that up.

Twitter did in fact, collapse. A bunch of times. X/twitter has had a lot of glitches, the last one 2 days ago [https://www.it-daily.net/en/shortnews-en/x-down-again-thousands-of-users-report-outages](https://www.it-daily.net/en/shortnews-en/x-down-again-thousands-of-users-report-outages)",2025-04-01 21:49:17,45,cazzipropri,programming
mkvcbfr,1joqlry,reddit,Imho missing a very important one: https://en.m.wikipedia.org/wiki/Amdahl%27s_law,2025-04-01 15:33:36,5,reveil,programming
mkvl5zy,1joqlry,reddit,Illustrating Cunningham's law with anything else than [XKCD 386](https://xkcd.com/386/) is just wrong.,2025-04-01 16:18:59,5,jdehesa,programming
mku9ag4,1joqlry,reddit,Funny. Sent it to my teammates and we all had a good laugh.,2025-04-01 11:40:31,4,NewExplor3r,programming
mkuxvqi,1joqlry,reddit,Great read. Really good points in there.,2025-04-01 14:17:51,2,Jaarmas,programming
mkz8lyk,1joqlry,reddit,"Murphy's Law of Thermodynamics..... Things get worse under pressure.

Corollary to Murphy's Law.... Things only ever go right so they can go more spectacularly wrong later.

Corollary to Price's Law.... Quite a few of those sqrt(N) were actively preventing the N-sqrt(N) others from doing their job. ie. Be careful about who you fire.... if you fire the only ones not visibly producing stuff, quite likely you will be retaining those that attempt to dominate any space they're in.... resulting Price's Law recursing. (Hint: Observe how absolute reproducible the Pareto Principle / Power Law distributions are in social media / interactions)

Corollary to Gilb's and Goodheart's... Stop asking what to or how to measure. Ask what will you do if measure X reaches level Y? The answer is usually nothing in which case don't measure, or the obvious, in which case start doing that.",2025-04-02 05:08:39,1,TheAxeOfSimplicity,programming
ml3bnjq,1joqlry,reddit,No love for Amdahl's law?,2025-04-02 21:08:37,1,tiajuanat,programming
mlg8nc9,1joqlry,reddit,Well this sums what is wrong with computer engineering and software development: they should be a science and follow scientific method. It shouldn't be a collection of tweet size humorous remarks that any noob can spit and sound deep.,2025-04-04 22:23:38,1,faustoc5,programming
mltf7pe,1joqlry,reddit,"Sturgeon’s Law is fascinating. I’ve been thinking about it a lot lately — how do people decide what’s actually worth doing? It seems like we still have to wade through that 90% of ""crap"" because it’s not always obvious which features or ideas will turn out to be useful.",2025-04-07 05:03:10,1,DieSyxes,programming
mky8tda,1joqlry,reddit,"downvoted because it did not mention Wirth's law

https://en.wikipedia.org/wiki/Wirth's_law",2025-04-02 00:55:57,1,all_is_love6667,programming
mkv6cmu,1joqlry,reddit,"I completely forget that there are people who don't know these. Also, eager for email are we...",2025-04-01 15:02:33,1,N/A,programming
mkxeici,1joqlry,reddit,"> Murphy’s Law
> Anything that can go wrong will go wrong.

> No list of laws is complete without Murphy :)

Well - first april, but I think Murphy's Law is actually a good metric, in the sense that
you can anticipate problems (in code, hardware etc...). Erlang kind of has this built
in as a core philosophy (though syntax-wise, they really should have learned from
python or ruby; elixir improved a few things but is nowhere near as elegant as ruby
either).

Other languages also try to deal with the unexpected, but often is rather awkward -
catch/throw ... I never liked the concept. Even begin/rescue in ruby can be annoying -
once I had to deal with network-related issues. After perhaps the sixth specific
error clause, I wondered what the heck I was doing. (I don't know who or what 
recommended to be specific when it comes to handling errors; once the error
handling code became like +50 lines of code, I wondered what I was doing.)

> Every time I think something is improbable, I go the extra step to verify that we are still covered.

Kind of like Rust acknowledging that memory errors are issues in C and C++. Whether
Rust is better I have no idea, but Rust kind of influenced both C and (especially) C++ in one way or
the other.",2025-04-01 21:55:35,1,shevy-java,programming
mkytmof,1joqlry,reddit,"I've encountered all of these in my decades at this, and didn't realize they all had formal names and quotes for them, heh. I still prefer my versions like, ""The scope of the problem will expand to consume all resources"" versus ""Work expands to fill the available time"". I like that mine sounds more menacing, heh. I also have one about maintenance that goes, ""Every new thing we build is one less thing we can build.""",2025-04-02 03:09:29,1,TurboGranny,programming
mkwq9uw,1joqlry,reddit,Does every software engineer’s personal blog have one of these posts? I just published mine: http://www.jacobelder.com/2025/02/24/eponymous_laws.html,2025-04-01 19:49:15,-1,jelder,programming
mn4mxka,1jz8jrw,reddit,"This is why setting environment variables is now defined to be unsafe, because it’s not threadsafe and can result in very unusual behaviours when races occur.

It’s not even possible to wrap it in a safe abstraction, like would normally be done (even aside from the breaking changes this would involve), as rust has no control over what other non-rust callers may do with environment variables.",2025-04-14 21:11:10,353,_zenith,programming
mn4qrkl,1jz8jrw,reddit,"`getenv` strikes again.  If you follow the ABI standards, you are faced with a dilemma.  You either must leak memory (prevent an old environment from being freed), or have a use-after-free bug because another thread changed the environment pointer.

Yes, it's possible to change the standard to give ""getenv"" a reference count and allow it to be freed if everyone plays nice and releases their reference to the string, otherwise a leak.",2025-04-14 21:31:49,75,Dwedit,programming
mn51j1z,1jz8jrw,reddit,Am I understanding the last sentence correctly that a possible fix in libc is to introduce a memory leak of the old environment strings?,2025-04-14 22:32:18,31,Own_Goose_7333,programming
mn4ewuj,1jz8jrw,reddit,"I was expecting this to be whiny, but it was instead really informative and interesting!",2025-04-14 20:30:02,91,Primary-Walrus-5623,programming
mn5nvzb,1jz8jrw,reddit,This is a [repost](https://np.reddit.com/r/programming/comments/1i7iz4h/c_stdlib_isnt_threadsafe_and_even_safe_rust_didnt/). I guess they moved the site. The comments on that link are far better than the ones here.,2025-04-15 00:42:47,21,chengiz,programming
mn4rcsa,1jz8jrw,reddit,"No affiliation with the article but surprised to see people saying the title is whiny?

>C stdlib isn't threadsafe

This is a statement of fact.

>and even safe Rust didn't save us.

Barring doing something to violate thread safety in unsafe code, Rust guarantees thread safety. I would be surprised too if my Rust project with zero lines of unsafe code was segfaulting. This is why Rust now marks these functions as `unsafe`.

What about the title is bad other than being mildly clickbaity?",2025-04-14 21:35:00,148,weirdasianfaces,programming
mn4w1ky,1jz8jrw,reddit,setenv is just a bad idea. Just never call it if you need something to have a different env spawn a new process with that altered environment.,2025-04-14 22:00:45,53,Days_End,programming
mn5z4es,1jz8jrw,reddit,why do you expect rust to save you when the crash happened due to memory corruption in cstdlib?,2025-04-15 01:50:35,12,Southern-Reveal5111,programming
mn9vizg,1jz8jrw,reddit,I dream of being able to debug this well.,2025-04-15 18:14:10,2,helix400,programming
mn5d4zz,1jz8jrw,reddit,Does anyone have examples of a “valid” use case for ever even using ‘setenv’?,2025-04-14 23:39:28,5,landon912,programming
mn4biy9,1jz8jrw,reddit,The title you have given this article needs to be revised to sound a little less whiny,2025-04-14 20:13:00,-6,Western_Bread6931,programming
mn7gbvp,1jz8jrw,reddit,This didn't need to be an entire blog post when https://rachelbythebay.com/w/2017/01/30/env/ was written **8 years ago**. But the fact that developers are still using C and its `*env` functions in 2025 (even indirectly) is a damning indictment of the industry as a whole; I especially like how the guy with a PhD in ARM memory models was unaware of the thread-unsafeness of these functions.,2025-04-15 09:37:49,3,IanAKemp,programming
mn52j2j,1jz8jrw,reddit,Furrylang has failed us. We must all switch to bronielang.,2025-04-14 22:38:08,3,BlueGoliath,programming
mnfofao,1jz8jrw,reddit,How can you even write any multithreaded program without checking that every library you use is multithread safe?,2025-04-16 16:41:45,1,rep_movsd,programming
mnfojox,1jz8jrw,reddit,Why would you mix Rust and python in the same process?,2025-04-16 16:42:21,1,rep_movsd,programming
mn78o7g,1jz8jrw,reddit,[removed],2025-04-15 08:13:11,1,N/A,programming
mn50liy,1jz8jrw,reddit,"\> setenv MT-Unsafe

Oh no, Rust did not save us from intentionally using something unsafe. Why?",2025-04-14 22:26:54,-16,DygusFufs,programming
mn4biq4,1jz8jrw,reddit,"> setenv is not a safe function to call in a multithreaded environment. This is often a problem, and occasionally rediscovered as developers like us hit weird crashes in libc's getenv

Sounds like a dev problem not a threadsafe problem. If you're setting thread dependent values in the global environment with setenv your failure is well deserved... and your debugging time to rediscover what 'developers like you' (OPs words) might have discovered sooner had you used a proper language like C to implement your solution instead of abstracting it away with Python is also well deserved.  

There are no free lunches, and especially not threadsafe ones.",2025-04-14 20:12:58,-113,church-rosser,programming
mn9pzqw,1jzxu1i,reddit,This is hilarious af,2025-04-15 17:46:46,176,stickfigure,programming
mnaky48,1jzxu1i,reddit,"The economist-approved formula is:

    Δτᵢ = (xᵢ − mᵢ) / (ε ⋅ φ ⋅ mᵢ)",2025-04-15 20:21:27,108,obfuscatedanon,programming
mnam47q,1jzxu1i,reddit,Finally some quality shitposting,2025-04-15 20:27:13,47,rotilladetapatas,programming
mn9t39m,1jzxu1i,reddit,Not bad! But it should work by default by querying the country of the package and applying the tarrif based on that,2025-04-15 18:01:55,70,sjepsa,programming
mnakm55,1jzxu1i,reddit,I am more concerned that you can overwrite the importing mechanism at all.,2025-04-15 20:19:48,34,Worth_Trust_3825,programming
mnaao27,1jzxu1i,reddit,Do you get tarrifed on transitive dependencies every time it is added?,2025-04-15 19:30:30,28,cellarmation,programming
mn9rdnv,1jzxu1i,reddit,That’s a good meme 😂,2025-04-15 17:53:28,31,neo-raver,programming
mnd0cyw,1jzxu1i,reddit,"Presumably there's an update coming soon which reduces some of the tarrifs, then another one shortly after which claims it didn't reduce the tarrifs, but changed the _type_ of the tarrifs (but without any type annotations to prove it), then a third update which just gives up altogether and randomises them?",2025-04-16 05:06:35,13,adh1003,programming
mngy2j4,1jzxu1i,reddit,"> This is a parody package. 

Sometimes reallife in itself is more the parody than the parody about reallife is. Although I think it is sad how people can seize power and control so many other people ""downstream"". Tariffs are basically just an extra tax really. So many shop owners complained about suddenly having to pay a lot more money when importing goods.",2025-04-16 20:26:01,5,shevy-java,programming
mnaja8s,1jzxu1i,reddit,"I love it, i feel like this could be better expanded to tariff functions in modules....

[this talk will always be gold](https://youtu.be/t863QfAOmlY?si=G8Q292326G82oATV&t=729)",2025-04-15 20:13:14,7,Thisconnect,programming
mna02p9,1jzxu1i,reddit,You win. 🏅,2025-04-15 18:37:09,7,this_knee,programming
mnagkls,1jzxu1i,reddit,Can someone give me context?,2025-04-15 19:59:46,5,PalomSage,programming
mnagpzz,1jzxu1i,reddit,Hahahahaha,2025-04-15 20:00:31,2,coconut_maan,programming
mnd009c,1jzxu1i,reddit,Solving supply chain problems by homesourcing...,2025-04-16 05:03:39,0,schlenk,programming
mndci19,1jzxu1i,reddit,"You could have made the world better by improving some open source packages. Instead, you've wasted your time on this BS. I hope you're glad of yourself.",2025-04-16 07:01:54,-12,Trang0ul,programming
mnefpc7,1jzxu1i,reddit,should make a relatiatory tariffs library too,2025-04-16 12:50:51,1,alternyxx,programming
mnkmits,1jzxu1i,reddit,Absolutely beautiful. So much winning!!! Obviously the bigger number [amount of time] means it's better!!,2025-04-17 12:18:39,1,vader_gans,programming
mnl0bu0,1jzxu1i,reddit,Finally! Now I can use this to slow down the single most shitty packages!,2025-04-17 13:40:14,1,Vincent394,programming
mnyvlsn,1jzxu1i,reddit,"Hell yeah, does you're dictionary take negative values to subsidize the imports?",2025-04-19 18:41:23,1,turunambartanen,programming
mn9y3oj,1jzxu1i,reddit,LMAO 🤣🤣🤣🤣🤣,2025-04-15 18:27:07,0,RedEyed__,programming
mnam3w6,1jzxu1i,reddit,reminds me of the test VW module for perl.,2025-04-15 20:27:10,1,Amuro_Ray,programming
mn9qpv2,1jzxu1i,reddit,FFS this is obnoxious,2025-04-15 17:50:17,-64,church-rosser,programming
mnhhmv2,1k0wouy,reddit,"I use GitHub users to segment, I have a whole series of config files for this. Copilot has started to ignore those and enables itself in folders that those accounts don’t have access too. 

I’m assuming it’s the same behavior. I have to logout of all accounts when I open a workspace/window now and log back in to the accounts that the config files should be allowing.

I think their agent that is coding the agent became over zealous. Imagine that.",2025-04-16 22:08:05,233,zaskar,programming
mniqnzi,1k0wouy,reddit,"Copilot enabled itself as a reviewer on our org's repos without notice. And because the ""request"" hyperlink is tiny, there's very little space between users in the suggested reviewer list, and copilot put itself right on top... there were a couple of instances where devs accidentally requested copilot to review PRs in our private repos before we figured out what was happening.",2025-04-17 02:34:58,132,kisielk,programming
mnjj0yc,1k0wouy,reddit,"Whoops hehe seems we accidentally trained our model with your stuff, no problem bro don't make a fuzz about it, here have a copilot discount coupon to compensate",2025-04-17 06:16:25,74,_OVERHATE_,programming
mni9z1l,1k0wouy,reddit,[deleted],2025-04-17 00:53:47,117,N/A,programming
mnk3bfn,1k0wouy,reddit,techbros have idea of consent of an average rapist,2025-04-17 09:46:04,66,CrunchyTortilla1234,programming
mnj5ms3,1k0wouy,reddit,Just Microsoft things™,2025-04-17 04:19:29,24,fn3dav2,programming
mnj6zcu,1k0wouy,reddit,they really want our code,2025-04-17 04:30:08,23,SlovenianTherapist,programming
mnjnui1,1k0wouy,reddit,"its the microsoft classic, they have done this type of bullshit for as long as i can remember. if you have windows you basically have to consatnly check your privacy settings to see if microsoft turned something on that you had turned off,  apart from the fact that most things cant be disabled anyways",2025-04-17 07:04:16,23,bokuWaKamida,programming
mnkhg17,1k0wouy,reddit,"I think this is going to be the first in a long line of big tech ""oopsies"" that result in them accidentally stealing all your data in the next few years.",2025-04-17 11:44:28,11,nnomae,programming
mnk9h8n,1k0wouy,reddit,The myth of consent,2025-04-17 10:43:15,10,PrimozDelux,programming
mnkxcih,1k0wouy,reddit,"Is there a way to remove co pilot from Vs code?

I dont have the extension but there is still an icon on top as well as bottom bars. Clicking asks you to set up to use, i haven't set it up so i guess it is not accessing my code. 

There is an option to hide it. But i want this shit gone from my vs code. 

How do I get this crap removed entirely?",2025-04-17 13:23:43,7,Lurker_wolfie,programming
mnjoga5,1k0wouy,reddit,"Exactly why I don’t use any Microsoft products. “Oops; we just snarfed your whole life, and can’t un-train it. Sorry!”",2025-04-17 07:10:29,34,PapaOscar90,programming
mnj8rzx,1k0wouy,reddit,"Stop paying for GitHub. I stopped as soon as their interest in replacing engineers with their programs became clear, and I’ll never go back to giving them money ever. Avoid Microsoft products as much as you are able.",2025-04-17 04:44:34,31,dontyougetsoupedyet,programming
mnnez05,1k0wouy,reddit,Report it to Microsoft as a security bug,2025-04-17 20:45:44,6,MyUsrNameWasTaken,programming
mnl4l1k,1k0wouy,reddit,"I had to manually disable some AI features in one of our M365 environments because they had been auto-enabled in Pre-Prod even though the settings were already turned off in Dev. 

As a rule I've started going through all settings I can find (and not just in M365 either) to disable any sneaky AI options.",2025-04-17 14:02:53,3,TheMistbornIdentity,programming
mnjxlrl,1k0wouy,reddit,Like any repos are private ;),2025-04-17 08:46:44,3,Minute_Action,programming
mns00il,1k0wouy,reddit,"Time to hop to gitlab, codeberg or sr.ht lol",2025-04-18 15:54:06,1,prodleni,programming
mnhnid2,1k0wouy,reddit,"Well, you know what they say about karma...",2025-04-16 22:41:27,-12,BlueGoliath,programming
mnmcy1l,1k0wouy,reddit,"For me continue.dev with ollama works well. But I have a Tesla p40 in my local server anyway, so if you don't have a good card maybe it's not something for you.

Both are open source and I download the models too. So it's not a privacy issue.",2025-04-17 17:38:17,-1,baackfisch,programming
mmxzf3z,1jycix4,reddit,That's legitimately a hilarious exploit. Some names just get hallucinated more often!,2025-04-13 19:22:00,215,Tsear,programming
mmy6nsa,1jycix4,reddit,"Its wild for me that people just import whatever packages some tool suggested. I may be paranoid, but I'm used to manually pick even which version to install or update to.",2025-04-13 20:00:58,193,meganeyangire,programming
mmyicf5,1jycix4,reddit,"I'm just going to keep repeating this:

The consulting jobs that will be created in a few years to fix all this garbage are going to be glorious.",2025-04-13 21:03:40,170,h3ie,programming
mmycq1e,1jycix4,reddit,"""slopsquatting""? I prefer to call it vibe-jacking.",2025-04-13 20:33:13,93,Popog,programming
mmykez3,1jycix4,reddit,"My major grievance is that not even OpenAI/Copilot knows which Windows Desktop framework uses what XAML dialect, no matter how often you tell him it's MAUI (not WinUi3, not WPF, not Xanmarin, MAUI!!!) and 90% of the results are almost unusable.",2025-04-13 21:15:09,38,md_youdneverguess,programming
mmynb5n,1jycix4,reddit,Snyk Code scanner has a feature where it suggests a coding fix to a vulnerability.  Now I understand why in one case it was suggesting a library that I never heard of and could not find in my searches: it was a hallucination.,2025-04-13 21:31:22,17,ScottContini,programming
mn0hf6w,1jycix4,reddit,It's hilarious to me that a while back all the professionals told us this kind of thing would happen and all the AI stans got all worked up telling us how dumb everyone is.,2025-04-14 04:45:48,16,ClownMorty,programming
mmzwph0,1jycix4,reddit,Senior engineers are going to make a mint rewriting the nasty code bases created by this wave of AI nonsense,2025-04-14 02:10:30,11,-grok,programming
mn0ttun,1jycix4,reddit,well its actually not sabotaging but more like vibe-sabotaging,2025-04-14 06:43:23,3,FederalRace5393,programming
mmzk8h8,1jycix4,reddit,"Recently was trying to import node module suggested by LLM and it fkng didn't exist, i could have been hacked.",2025-04-14 00:49:03,1,RealMadHouse,programming
mn19nfx,1jycix4,reddit,"I was recently looking for a cross-platform python library to detect when USB devices are plugged in, like `pyudev` does in Linux. Two of the major LLMs told me I could just pip install `pyudev-macos` and `pyudev-win` (when I asked for more info about those libraries, one told me that `pyudev` is actually cross platform).",2025-04-14 09:33:17,1,askvictor,programming
mn5ykkp,1jycix4,reddit,Vibe rater business is gonna be boomin,2025-04-15 01:47:13,1,JoshYx,programming
mn1fdtw,1jycix4,reddit,That can be solved by connecting the LLM to a RAG that has the latest package names.,2025-04-14 10:30:57,0,happycamperjack,programming
mmxozh0,1jycix4,reddit,"> have a habit of hallucinating

I know the academics say they can find this behavior, but I’ve never experienced it even one time in my ~2 years of using LLMs for work daily. Doesn’t seem like a real risk to me especially if you have any tests or code review which all serious OSS projects do.",2025-04-13 18:26:26,-168,daishi55,programming
mm8l7r0,1jv3emt,reddit,"God all these articles are so fucking useless. The actual news is just: https://xcancel.com/blelbach/status/1902113767066103949

> We've announced cuTile, a tile programming model for CUDA!

> It's an array-based paradigm where the compiler automates mem movement, pipelining & tensor core utilization, making GPU programming easier & more portable.",2025-04-09 16:43:37,110,fxfighter,programming
mm7p4o3,1jv3emt,reddit,Original article without the LLM slop: https://thenewstack.io/nvidia-finally-adds-native-python-support-to-cuda/,2025-04-09 14:04:26,233,mcpower_,programming
mm71vpm,1jv3emt,reddit,"Bad news for mojo, I guess?",2025-04-09 11:44:56,56,pstmps,programming
mm76e8u,1jv3emt,reddit,I don’t really get much from this article. If I am understanding this correctly this now allows for you to specify threads to run on grids that you specify? Do they just always use shared memory smart pointers? That seems awfully non pythonic. As a scientist I rarely feel like I never need anything more than the cuda associated libraries with anything implemented in RAPIDS but maybe someone else might find this useful.,2025-04-09 12:15:51,43,Cultural-Word3740,programming
mm7rxv3,1jv3emt,reddit,"What does native python even mean here, are they JITing to PTX?",2025-04-09 14:18:53,8,activeXray,programming
mm708mp,1jv3emt,reddit,"Ah, that's what they been working on, cause they haven't been fixing their gaming drivers",2025-04-09 11:33:05,164,supermitsuba,programming
mmaslaw,1jv3emt,reddit,"NVIDIA is doubling down on Python. I did some training with them recently and they asked everyone in attendance what languages they knew. Mine was the only hand that went up for C++ and of course everyone knew some Python there. The trainer went on to explain how everything is moving to Python. I am familiar with NJIT and Numba but they did not get into the specifics of what they meant when they said that at all. Honestly, I think much of this is TBD but they know the direction they want to go.",2025-04-09 23:23:28,3,thatdevilyouknow,programming
mm85dup,1jv3emt,reddit,"Is it me, or is trying to make Python fast in hardware a really dumb idea? Why use some of the fastest, hot, expensive, and capable hardware to natively support one of the slowest and most bloated runtimes? Is there really that much demand from people who need things to be fast but can't code in another languag....oh.

So- massive power use so non-coders can have AI generate python, which needs massive power use to run fast on massive GPUs to hide the fact that AI code usually sucks...
  
Excuse me, I'm going to go buy some stock in electrical utilities and swimming pool companies.

edit- I was wrong. I had to dig a bit, it turns out it does compile to Nvidia Runtime C++, so it's just an official wrapper. The article failed to mention that, I got the vibe that Python was going straight to CUDA opcode.",2025-04-09 15:25:39,-1,Truenoiz,programming
mm8rfer,1jv3emt,reddit,How is GPU memory allocation and freeing supposed to work with that?,2025-04-09 17:13:37,1,Dwedit,programming
mmaelbo,1jv3emt,reddit,They can’t have you be using an abstract API that could work with other hardware…,2025-04-09 22:03:32,1,mkusanagi,programming
mmbvrdm,1jv3emt,reddit,“Hits” is the correct verb to use here.,2025-04-10 03:17:54,1,Ze_Greyt_KHAN,programming
mm7o1zv,1jv3emt,reddit,Just use bend lang.,2025-04-09 13:58:51,-2,2hands10fingers,programming
mm8okv6,1jv3emt,reddit,great more crap that doesn't benefit actual apps.,2025-04-09 16:59:53,-4,tangoshukudai,programming
mjw172v,1jkgh2s,reddit,[deleted],2025-03-26 19:50:44,204,N/A,programming
mjxcr7c,1jkgh2s,reddit,"I work in bioinformatics. 

We constantly get computer scientist offering their services to save us. 

Then you point them at the relevant data to what they want to work on and you never hear from them again. 

Biology is hard. For most problems it requires knowledge of both biology, chemistry and computer science to even attempt to solve anything beyond toy problems. The most successful scientific research is done by groups/labs with specialists in all areas who have deep domain knowledge and the lab/organization has the ability to run wet lab experiments to generate additional data and test the algorithm results. 

There have been some cases where the thing needed was simple enough for a computer scientist to make significant impact such as the various algorithms to align dna sequences to a references or each other. But they are few and far between.",2025-03-26 23:47:08,153,TheLordB,programming
mjvy79o,1jkgh2s,reddit,"> At least 60 GB of free space on your machine and at least 2GB of RAM.

I understand the RAM, but what takes so much disk space for the simulation?",2025-03-26 19:36:12,117,voronaam,programming
mjw5q1z,1jkgh2s,reddit,"It reminds me of those synthetic biology experiments where they remove as much of the genome of a cell as possible and see if it still lives and grows. 

This is really cool, finishing the worm would be like finding the Higgs boson, its a confirmation that our model of reality is correct.",2025-03-26 20:12:25,17,lizardmos5,programming
mjv0fbo,1jkgh2s,reddit,"Stephen Larson is a cofounder of OpenWorm, an open source software effort that has been trying, since 2011, to build a computer simulation of a microscopic nematode called Caenorhabditis elegans. His goal is nothing less than a digital twin of the real worm, accurate down to the molecule. If OpenWorm can manage this, it would be the first virtual animal: the “holy grail,” as OpenWorm puts it, of systems biology.

Unfortunately, they haven’t managed it, even though scientists have been studying C. elegans for decades (in fact, no fewer than four Nobel Prizes have been awarded for work on the worm).

So why keep trying? What is it about this little worm that pulls generations of scientists towards its challenge? Well, it’s an opportunity. Understanding C. elegans is a stepping stone toward understanding more complex nervous systems and eventually, someday, the human mind.

Read the full story: [https://www.wired.com/story/openworm-worm-simulator-biology-code/](https://www.wired.com/story/openworm-worm-simulator-biology-code/)",2025-03-26 16:53:47,295,wiredmagazine,programming
mjv9b0b,1jkgh2s,reddit,He should talk to u/perfect-highlight964.  His work is on snake but that’s not too different,2025-03-26 17:35:35,48,s0ulbrother,programming
mjwxi54,1jkgh2s,reddit,"Babe, would you still love me if I were a computer simulation of a worm?",2025-03-26 22:25:59,24,TangerineX,programming
mk0k6uu,1jkgh2s,reddit,"This article is fascinating—OpenWorm feels like the perfect intersection between biology and programming. It’s wild to think that something as “simple” as a worm still can't be fully simulated, even with all the computational power and talent we have.

It really puts into perspective how complex even the smallest forms of life are. Makes me wonder: is it just a matter of time and resources, or is there something fundamentally missing in how we model behavior?

Also curious—anyone here ever contributed to OpenWorm or a similar project?",2025-03-27 14:18:53,5,tomasartuso,programming
mjyfjsa,1jkgh2s,reddit,"People are working on this, but all I want is a modern 2d update to the Creatures series of games that takes full advantage of how powerful home computers have become.",2025-03-27 03:40:04,3,MrArborsexual,programming
mk1cjz2,1jkgh2s,reddit,"As a co-founder of the OpenWorm project, there has been many interesting and fun off shoots of the project. I was instrumental in cataloging the nervous system and left the project back in 2014 to explore higher level animals. My worm emulation work has been written up in many places including Wire, as well as, replicated around the world and applied to many different robots. My point is don't discount their work. It has led to a number of discoveries despite the ultimate goal not having been achieved. 

[https://youtu.be/YWQnzylhgHc?si=z9AJ774ZrahS785t](https://youtu.be/YWQnzylhgHc?si=z9AJ774ZrahS785t)",2025-03-27 16:37:08,5,ConnectomicAGI,programming
mjxa4uq,1jkgh2s,reddit,I knew DEVS was horseshit.,2025-03-26 23:32:56,7,Omikron,programming
mjy0xdc,1jkgh2s,reddit,Have they tried asking ChatGPT to pretend to be the worm?,2025-03-27 02:05:38,6,manystripes,programming
mjyc5it,1jkgh2s,reddit,There is a guy developing an organic computer that simulates how neurons work.  When that works I'm sure we can do this and more.,2025-03-27 03:16:30,2,DragonflyMean1224,programming
mjyis5m,1jkgh2s,reddit,"When OpenWorm started I was hooked to project and so deeply as I always imagined intelligence from mimicking brain , I wanted to do Bio Tech Software, but this project never really updated as I thought and my interest on BioTech also lost.",2025-03-27 04:03:38,2,Stunning-Lee,programming
mjx10rc,1jkgh2s,reddit,What an insufferable writing style,2025-03-26 22:44:45,7,Tura63,programming
mjvb8zu,1jkgh2s,reddit,"Hmm... So in the near future we might have a creature (however simple) that does not know it is, and is living in, a simulation running in some (to it) cosmic horror's incomprehensibly vast computer.",2025-03-26 17:44:41,-13,alangcarter,programming
mk5gvkv,1jkgh2s,reddit,"so, why still calling it a worm? call it a beetle, fgs.",2025-03-28 08:13:16,-1,Ecstatic_Potential67,programming
mjxbfkb,1jkgh2s,reddit,Ha jokes on them. I have enough RAM to put it all in RAM plus some!,2025-03-26 23:39:56,-6,UnworthySyntax,programming
mko2ksu,1jo0dzz,reddit,"When an AI replies to a prompt with: “Wait, I don’t think we should do that and here is why”, I’ll believe that there is a future for vibe engineering down the line.

Right now, affirming every request and confidently delivering bullshit is far from it.",2025-03-31 11:28:24,751,akirodic,programming
mko73ly,1jo0dzz,reddit,"The funny thing about the whole ""AI"", ""vibe coding"" replacing software engineers debate is that it's being determined by AI outputting the equivalent complexity of a to-do list app, judged by non-software developers who wouldn't be able to code a to-do list app themselves without AI.",2025-03-31 12:02:56,252,freecodeio,programming
mkpgunh,1jo0dzz,reddit,what the fuck is vibe coding,2025-03-31 16:17:41,20,jcl274,programming
mkpqh6s,1jo0dzz,reddit,"As soon as I first heard the phrase ""vibe coding"" I knew immediately that it was some stupid tech bro vapour ware shit like ""web 3.0"". 

Why do people keep falling for these scams?",2025-03-31 17:06:07,26,seamustheseagull,programming
mkq7623,1jo0dzz,reddit,"One of the biggest problems still is that it just can't fit enough domain context to even start. We humans take a lot of stuff for granted when dealing with subject matter experts and using our own lived experience. 

It needs a large context size to understand the customer base and domain and then say something like, ""hey actually your Christmas shopping list app might be better suited to using a passwordless authentication mechanism because based on your use case you have non technical users who only use it for a month or a year, they won't remember their password next year. For the best user experience we can just text them a one time use code when they log in to avoid the problems of forgotten password resets. Implementing this will avoid having to do password reset flows entirely!""

Most of the experiments I've done where I try to feed it enough documentation context of ends up just dying. So you have to really implement RAG workflows and ""reasoning"" internal monologs, and build a whole multi-agent workflow to try and do it, but in practice it gets tripped up by document context window limits in those cases too.",2025-03-31 18:28:02,7,manliness-dot-space,programming
mkol562,1jo0dzz,reddit,"> Such systems could tightly encapsulate AI-generated black-box components with rigorous testing, detailed performance profiling, tracing, canary deployments, and strict protocol compatibility checks. In other words, the systems would employ the same rigorous engineering practices that underpin today's software – but likely much, much stricter.

Yeah, that's just regular engineering.

When I am taking that trend to its extreme, I see something I like: self-healing software. If you get to the point where you can have good tests covering 100% of the use cases, and have 100% of the code generated autonomously, then fixing a bug is just a matter of describing it, in the form of a test, and letting the system fix it.

Many things can go wrong there, and it opens a new range of many potential issues, but this is also a totally new engineering style that opens up.",2025-03-31 13:33:57,12,keepthepace,programming
mko1nid,1jo0dzz,reddit,"I thought the insight into AI coding as pushing the problem to the right where it is more expensive to fix was good.  I think the jury is still out on if “vibe coding” is here to stay.  As a term, it’ll end up with “surfing the web”, even if the practice actually sticks around.",2025-03-31 11:20:45,17,N/A,programming
mkpm4xk,1jo0dzz,reddit,Today I saw a job post for vibe coder. Industry is cooked,2025-03-31 16:44:23,7,ImprovisedGoat,programming
mkptujz,1jo0dzz,reddit,"Programmers aren't engineers.  Engineers actually have to pass certification, there are laws controlling who can call themselves an engineer. Anybody can just *say* they're a programmer or software engineer. 


That's why we have 6 round interviews. Because they've been the ```IsEven``` code you guys come up with, and they want to avoid that kind of bad hire.",2025-03-31 17:22:43,7,ColoRadBro69,programming
mkqkle0,1jo0dzz,reddit,This crush is harshin my mellow,2025-03-31 19:35:14,2,mycall,programming
mkpxeyt,1jo0dzz,reddit,"Neither is there a pressing need to disprove its existence by pulling people to your blog. 

Yet here we are busying ourselves.",2025-03-31 17:40:00,1,throwaway490215,programming
mkuxyus,1jo0dzz,reddit,"Replace ""vibe"" in ""vibe engineering"" with ""lack of"" and you have a truth.",2025-04-01 14:18:20,1,IanAKemp,programming
mkq9xme,1jo0dzz,reddit,"I think a lot of this “vibe” coding stuff is a weird debate, seemingly amateurs vibing with AI while experts scoff and reject AI for being more trouble than it’s worth. However the reality is an experienced programmer can vibe better than an amateur. I already can have the AI write large amounts of code for me, however I’m experienced and already spend most my time at work code reviewing. So for me it’s not much different than working with a JR engineer that gets back to me in minutes instead of days. If you are any kind of lead programmer you can now be a team of 1 tbh",2025-03-31 18:41:56,0,Xryme,programming
mkoo6lr,1jo0dzz,reddit,"Has OP looked in what bit.cloud is looking to do?
Basically does the “tightly encapsulate AI-generated black-box components with rigorous testing, detailed performance profiling, tracing, canary deployments, and strict protocol compatibility checks.” and compose with them later.
These “things” can be built by ai or developer",2025-03-31 13:51:16,-4,Subject-Substance984,programming
mkp5snj,1jo0dzz,reddit,"Really enjoyed this read. There’s something very real about how we romanticize team ‘vibes’ when what’s often missing is structure and clear leadership. Do you think it’s actually possible to *design* a good vibe, or is it more of a byproduct of solid processes and aligned people?",2025-03-31 15:22:35,-1,tomasartuso,programming
mkoldyg,1jo0dzz,reddit,Online shopping will ever take off,2025-03-31 13:35:24,-25,NoleMercy05,programming
mofkp8v,1k56hlt,reddit,"Despite the fact that TFA ends with a pitch for Earthly’s Lunar product, I’ll have to empathise with some of the problems they’ve outlined in the table. Especially the bit about common CI/CD templates. It doesn’t work well due to differing maturity levels and business needs.

That said, scorecards can be implemented in various ways. We (large engineering org in a Fortune 100) have ended up creating scoreboards that track changes, deployments and periodic scans and this has worked well for us.

But yeah, nuance and flexibility is the key. Eg I’ve seen a lot of control owners obsess over “blocking” releases which don’t comply with x. In reality, blocking *increases risk* for all but the most egregious of violations. But a lot of SDLC governance approaches completely ignores that. Perhaps this is an education / awareness issue.",2025-04-22 14:02:42,100,pxm7,programming
mofg0xi,1k56hlt,reddit,"Hey folks - author here. We started this industry research with the goal to monetize an open-source CI tool, but as we tried to understand how to make it work at scale, we ended up going down a rabbit hole of conversations with platform and DevOps teams. What we heard was honestly a bit overwhelming — not about CI speed or dev productivity, but about just how fragmented and hard to govern modern engineering has become. We wrote down what we learned and where the journey took us. Curious if these problems resonate with you too (or if we're imagining things lol).",2025-04-22 13:37:13,120,vladaionescu,programming
moh6yhh,1k56hlt,reddit,"Yes, microservices are a terrible choice for most organizations.",2025-04-22 18:47:41,46,AmalgamDragon,programming
mogrdz0,1k56hlt,reddit,"its almost like, 99.9999% of teams do NOT need kubernetes. if you have less than 100 million customers, fuck ALL the way off with k8s. and when you do have that many customers, you have the money to hire the teams to specialize in those chaotic tools you need at that scale. engineering got complex because everyone convinced themselves they have to do what google does, but they dont have google levels of demand for their unheard of product",2025-04-22 17:31:58,70,Scavenger53,programming
mokckuv,1k56hlt,reddit,"I don't want to be a downer here, but you're trying to use tech to fix a social problem. Good luck.",2025-04-23 05:59:38,6,Sigmatics,programming
mohp8n9,1k56hlt,reddit,[Someone should really do something about that](https://xkcd.com/927/).,2025-04-22 20:18:03,7,xorian,programming
mojtlce,1k56hlt,reddit,"Can confirm.

The bigger the team(s) the more it sucks. The best open source projects have 1-2 devs",2025-04-23 03:28:08,3,reini_urban,programming
mokfgva,1k56hlt,reddit,"I was laid off because it “just wasn’t working out” from a programming job two weeks after an all hands meeting about how to improve retention. 

It sucks, I had a 90% completion rate per cycle, with my peers hovering in the 40%s. And I liked that job a lot, because it was hard. Been doing taxes ever since because I can’t mentally sell myself this kind of uncertainty in my life as being a good thing. I make about 1/3rd what I would/should programming.",2025-04-23 06:27:47,2,TheApprentice19,programming
monfyzi,1k56hlt,reddit,"I saw ""too many dashboards"" and was then offered another dashboard 🤷‍♂️",2025-04-23 18:20:37,1,messiah-of-cheese,programming
moj37k4,1k56hlt,reddit,"I mean, duh.

Get a bunch of developers who are paid very well, and they start to think they're all snowflakes who should be given the latitude to do whatever they want.  Not a single one of them is a Donald Knuth or Dennis Ritchie or Edsger W. Dijkstra or even Linus Torvalds, but they all wanna play *prima donna* in this tragedy.

**DivaDevs**: *""I couldn't care less about the risk to the organization! My pet language/framework/coding style/idioms have total primacy over the organization's needs, and I know I'm special because I make 10x what some schlub in India or Croatia makes.""*

**Anyone sensible**: *""What are you actually making?""*

**DivaDevs**: *""Oh, well, I'm connecting this API with that API, and inserting a record in the database.""*

TL;DR:

> *""We used to build buildings with a set of materials that we understood, like wood and steel. But, today, for speed's sake, we'll use anything.  It could be some ""concrete"" we made from grandma's fudge, my little sister's makeup, and a literal shit I took after lunch.  Sometimes our buildings fall down, but sometimes it stays up for a minute, and we can attract Series B.""*",2025-04-23 00:48:16,-4,qrrux,programming
moi4zmz,1k56hlt,reddit,"Eng teams shouldn’t track metrics like Lines of Code - they’re useless.

Track units of work: https://docs.ellipsis.dev/features/analytics#units-of-work",2025-04-22 21:37:04,-4,Man_of_Math,programming
mnmlifl,1k1jn9x,reddit,"Mod node: this is r/programming, a technical subreddit. Technical discussion of vulnerabilities is encouraged but political rants won’t be tolerated.",2025-04-17 18:19:17,1,ketralnis,programming
mnpi0r5,1k1jn9x,reddit,"Two fun reminders: Cellebrite itself is vulnerable to many exploits because of how naively its' implemented, and has been exploited in the wild.

And preventing any kind of cellebrite exploit is as easy as rebooting your phone if you know its about to get confiscated (for most modern devices)",2025-04-18 04:23:04,36,Somepotato,programming
mnn01o6,1k1jn9x,reddit,"> The attack relied on an intricate exploit chain that used emulated USB devices to trigger memory corruption vulnerabilities in the Linux kernel.

I am trying very hard to not say the thing.",2025-04-17 19:32:07,151,minno,programming
mnmkmi0,1k1jn9x,reddit,"* ""Serbian student activist’s phone hacked using Cellebrite zero-day exploit"" by Pierluigi Paganini (March 3, 2025): https://securityaffairs.com/174822/breaking-news/serbian-student-activists-phone-hacked-using-cellebrite-zero-day-exploit.html , https://archive.is/1zf8I


- The first part of the submitted title (""Serbia: . . .  activist"") and the submitted link are from ""Serbia: Cellebrite zero-day exploit used to target phone of Serbian student activist"" by Amnesty International (February 28, 2025): https://www.amnesty.org/en/documents/eur70/9118/2025/en/ , https://www.amnesty.org/en/wp-content/uploads/2025/03/EUR7091182025ENGLISH.pdf  (""CELLEBRITE ZERO-DAY EXPLOIT USED TO TARGET PHONE OF SERBIAN STUDENT ACTIVIST"" ""RESEARCH BRIEFING"" ""AMNESTY INTERNATIONAL"") from https://www.amnesty.org/en/documents/eur70/9118/2025/en/

    ""Cellebrite zero-day exploit used to target phone of Serbian student activist"" by Amnesty International (February 28, 2025) -- has the ""table showing traces of each USB connection and disconnection event which was seen while the youth activists phone was exploited using Cellebrite UFED"" (quotation from [https://www.amnesty.org/en/wp-content/uploads/2025/03/EUR7091182025ENGLISH.pdf](https://www.amnesty.org/en/wp-content/uploads/2025/03/EUR7091182025ENGLISH.pdf)): https://securitylab.amnesty.org/latest/2025/02/cellebrite-zero-day-exploit-used-to-target-phone-of-serbian-student-activist/


  - ""Serbia: “A Digital Prison”: Surveillance and the suppression of civil society in Serbia"" by Amnesty International (December 16, 2024): https://www.amnesty.org/en/documents/eur70/8813/2024/en/ , https://www.amnesty.org/en/wp-content/uploads/2024/12/EUR7088132024ENGLISH.pdf from https://www.amnesty.org/en/documents/eur70/8813/2024/en/

  - ""Cellebrite Statement About Amnesty International Report"" by Cellebrite (published on December 16, 2024 and updated on February 25, 2025): https://cellebrite.com/en/cellebrite-statement-about-amnesty-international-report/ , https://archive.is/fkWoW

  - https://nvd.nist.gov/vuln/detail/CVE-2024-53104

  - https://nvd.nist.gov/vuln/detail/CVE-2024-50302

  - https://nvd.nist.gov/vuln/detail/CVE-2024-53197



&nbsp;

* ""Android USB Zero-Day Exploit Exposed"" by Mohammad Mehdi Edrisian: https://findsec.org/index.php/blog/418-android-usb-zero-day-exploit-cellebrite , https://archive.is/mIx43





&nbsp;

* ""[Phone] Enables a future optional security feature, which will automatically restart your device if locked for 3 consecutive days."" from ""Google System Release Notes"" ""April 2025"" ""Google Play services v25.14 (2025-04-14)"" ""Security & Privacy"": https://support.google.com/product-documentation/answer/14343500 , https://archive.is/yFTEY , https://archive.is/2025.04.17-134211/https://support.google.com/product-documentation/answer/14343500

* ""For security, Android phones will now auto-reboot after three days"" by Lorenzo Franceschi-Bicchierai (April 15, 2025): https://techcrunch.com/2025/04/15/for-security-android-phones-will-now-auto-reboot-after-three-days/ , https://archive.is/FFpjX






&nbsp;

- ""Your Phone, Your Data: How to Safeguard Your Digital Life When Entering the U.S."" by Emily Neumann (March 7, 2025): https://www.rnlawgroup.com/your-phone-your-data-how-to-safeguard-your-digital-life-when-entering-the-u-s/ , https://web.archive.org/web/20250307234303/www.rnlawgroup.com/your-phone-your-data-how-to-safeguard-your-digital-life-when-entering-the-u-s/

    - From https://archive.is/2025.04.12-111954/https://news.ycombinator.com/item?id=43650507 (Hacker News, ""Your Phone, Your Data: How to Safeguard Your Digital Life When Entering the U.S.""):
  
        - Is Your Password Secure? (IYPS) is a ""password strength app that evaluates and rates your password's robustness, estimates crack time, and provides helpful warnings and suggestions for stronger passwords."": https://github.com/StellarSand/IYPS

        - Android KeePassDX can generate passwords and passphrases: https://github.com/Kunzisoft/KeePassDX

        - ""Password Generator is a simple Android application which generates secure passwords."": https://gitlab.com/vecturagames/passwordgenerator

        - KeePassXC has a ""Password Generator"": https://keepassxc.org/docs/KeePassXC_UserGuide , https://github.com/keepassxreboot/keepassxc , https://keepassxc.org/download , https://github.com/termux/termux-packages/tree/master/x11-packages/keepassxc


        - ""keepassxc-cli is the command line interface for the KeePassXC password manager."": https://github.com/keepassxreboot/keepassxc/blob/latest/docs/man/keepassxc-cli.1.adoc , https://keepassxc.org/docs/KeePassXC_UserGuide#_command_line_tool , https://keepassxc.org

        - ""Motorola moto g play 2024 Smartphone, Android 14 Operating System, Termux, And cryptsetup: Linux Unified Key Setup (LUKS) Encryption/Decryption And The ext4 Filesystem Without Using root Access, Without Using proot-distro, And Without Using QEMU"": https://old.reddit.com/r/MotoG/comments/1jkl0f8/motorola_moto_g_play_2024_smartphone_android_14/


&nbsp;

* ""EU issues US-bound staff with burner phones over spying fears"" ""European Commission officials heading to IMF and World Bank spring meetings advised to travel with basic devices"" by Andy Bounds (April 14, 2025): https://www.ft.com/content/20d0678a-41b2-468d-ac10-14ce1eae357b , https://archive.is/nxjxG  




* ""Avoid US or Take Burner Devices, Canadian Executives Tell Staff"" by Thomas Seal (April 14, 2025): https://www.bloomberg.com/news/articles/2025-04-15/avoid-us-or-take-burner-devices-canadian-executives-tell-staff , https://archive.is/GvBLF


* ""No burner phones for Swiss diplomats on US visits"" ""Switzerland has no plans to increase digital security of diplomats visiting the United States, despite the European Union issuing burner phones to protect from snooping."" by SWI swissinfo.ch (April 16, 2025): https://www.swissinfo.ch/eng/swiss-politics/no-burner-phones-for-swiss-diplomats-on-us-visits/89170804 , https://archive.is/WD8qZ



&nbsp;




* ""Australian with working visa detained and deported on returning to US from sister’s memorial"" by Daisy Dumas (April 11, 2025): https://www.theguardian.com/us-news/2025/apr/11/australian-with-us-working-visa-detained-insulted-deported , https://archive.is/Kej6V

&nbsp;

* ""New airport rules will get rid of boarding passes and check-in"" ""Passengers will be issued with a digital ‘journey pass’ containing all relevant information in the biggest shake-up of global aviation in 50 years"" by Ben Clatworthy (April 11, 2025): https://www.thetimes.com/uk/transport/article/new-airport-rules-boarding-pass-check-in-fs8d5qg2j , https://archive.is/4Xqm9



&nbsp;

* ""DHS to screen social media of visa applicants for 'antisemitic activity'"" ""Similar guidance was issued by the State Department in March."" by Luke Barr (April 9, 2025): https://abcnews.go.com/Politics/dhs-screen-social-media-visa-applicants-antisemitic-activity/story?id=120642944 , https://archive.is/5V4Ax

&nbsp;",2025-04-17 18:14:56,39,throwaway16830261,programming
mnr33qx,1k1jn9x,reddit,Is this amateur hour? Why would you burn a 0-day and not cover your tracks?,2025-04-18 12:59:40,10,commandersaki,programming
mnw0q0a,1k1jn9x,reddit,"* ""Android Security Bulletin—April 2025"" (published on April 7, 2025 and updated on April 8, 2025) -- "" . . . The most severe of these issues is a critical security vulnerability in the System component that could lead to remote escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation. The severity assessment is based on the effect that exploiting the vulnerability would possibly have on an affected device, assuming the platform and service mitigations are turned off for development purposes or if successfully bypassed.  . . ."": https://source.android.com/docs/security/bulletin/2025-04-01

* https://nvd.nist.gov/vuln/detail/CVE-2024-53150

* https://nvd.nist.gov/vuln/detail/CVE-2024-53197",2025-04-19 06:38:44,1,throwaway16830261,programming
moc3mjv,1k1jn9x,reddit,What's the fix to this potential problem? Doing a factory reset? Or it appears on a list of all apps and can be removed?,2025-04-21 22:44:27,1,pajser92,programming
mno3ura,1k1jn9x,reddit,[deleted],2025-04-17 22:58:28,-18,N/A,programming
mmd5y1q,1jvujzu,reddit,"This was a fun read. Thanks for not publishing it on medium. Thanks for sharing a random side project instead of the usual flood of thinly veiled career boosted crap.

Enjoyed it.",2025-04-10 10:32:50,204,CrushgrooveSC,programming
mmdca20,1jvujzu,reddit,"This is really cool! Truly what programming is supposed to be, just tinkering around making cool stuff",2025-04-10 11:24:58,39,thatssomegoodhay,programming
mmdpe8b,1jvujzu,reddit,I’m a web dev and this stuff is over my head but a very cool read.,2025-04-10 12:54:03,15,SideDish120,programming
mmexg5g,1jvujzu,reddit,"Good Job! Can you tell why you clone your Pokemon if you reset the leader gameboy at the right time? Does this work with your spoofer, too?",2025-04-10 16:41:26,14,Arosares,programming
mmf88x4,1jvujzu,reddit,"You might want to post this to r/emulation, they love any type of emulation stuff.   This is fascinating. 

Technically the TAS community might be interested in this too, but I have no idea where to find them :)

>I’m not 100% sure about the data in between 4. and 5.
> The spoofer just echos this data. The preamble bytes (0xFD) seem off.

Is it possible this is future proofing?   Let's say Pokemon Pink comes out and wants to add a new super cool feature, but Pokemon Red doesn't understand that feature.  So Pokemon Pink uses the extra bytes, but when that character is passed to Pokemon Red, they get lost (or who knows?  Maybe saved but unused).  But if Pokemon Pink and Pokemon Pink pass a character, it uses that for extra stats or something?",2025-04-10 17:33:42,7,Kinglink,programming
mme1rxh,1jvujzu,reddit,is this a year old or like 3 days old?,2025-04-10 14:04:16,7,therossboss,programming
mmdhc73,1jvujzu,reddit,Pretty cool!,2025-04-10 12:01:41,5,DinoChrono,programming
mmhfdbf,1jvujzu,reddit,"I interpreted `(with Go)` as `(with PokemonGo)` and was like ""well that certainly doesn't sound like it should be possible but please tell me more!.""",2025-04-11 00:26:12,3,DigThatData,programming
mmdgk75,1jvujzu,reddit,"Curious why your serial library is in a private repository (seemingly)
Edit: I am dumb. Ignore me.",2025-04-10 11:56:19,7,razialx,programming
mmdyi9e,1jvujzu,reddit,"Cool, Pokemon Red was awesome",2025-04-10 13:46:59,3,sammymammy2,programming
mme020l,1jvujzu,reddit,Ah you had me excited. I thought you were doing it with the physical hardware,2025-04-10 13:55:13,3,amestrianphilosopher,programming
mmirsup,1jvujzu,reddit,It's a microcontroller. I use them in a lot of timing sensitive projects,2025-04-11 06:16:50,0,kageurufu,programming
mnh71d5,1k0tsm5,reddit,Who does this affect exactly? I have a home network where I have my own root CA to access the server via a VPN as `https://xxx.lan` and `https://1.2.3.4`. There are exactly 0 ways for me to automatically distribute a new cert to the many kinds of devices used in the family from what I have found so far.,2025-04-16 21:10:38,114,helloiamsomeone,programming
mnin51i,1k0tsm5,reddit,I did a regression in desmos on the lifetime schedule and the curve intersects the x axis in late 2030.  So get ready for instantaneously expiring certs next decade!,2025-04-17 02:12:58,39,FetusExplosion,programming
mnjkbxc,1k0tsm5,reddit,"There are a number of comments from people asking what benefits this change has to end-user security, and there are other comments from people claiming that there are no such benefits.

Suppose that you own a domain and run a TLS server (eg, web server) for that domain. Here are the relevant threats that I am aware of:

1. *Someone obtains your TLS server's private key.* Even after you discover the breach and switch to a new private key and new certificate, the attacker can impersonate your server until the last certificate issued for the stolen private key expires.
2. *Someone somehow obtains a TLS certificate for your domain from CA.* They can impersonate your server until that TLS certificate expires.
3. *You recently obtained ownership of the domain.* Its previous owner may have legitimately obtained TLS certificates. They, or anyone who obtains the old private key and certificate from them, can impersonate your server until the old certificate expires.

When the changes take effect, they will reduce the period of vulnerability in each of these situations.

The vulnerability lasts until the certificate expires because CRLs and OCSP do not work in practice. At least, that's what the CA/B Forum seems to have decided, and their judgment seems plausible to me. And OCSP stapling doesn't seem much different from issuing a short-lived certificate without revalidating domain ownership etc, except with the complexity of a different protocol.",2025-04-17 06:29:14,15,ryan017,programming
mnhneit,1k0tsm5,reddit,These people don’t have shitty applications that you have to upload certs to and stuff. It’s not all docker containers and trendy serverless BS!,2025-04-16 22:40:50,65,crazyguy5880,programming
mnjcovx,1k0tsm5,reddit,Why not let us trust on first use and use only self signed with Dnssec txt record lookups for every request; why trust a CA more than the website; Why put everything  in one basket with LE;,2025-04-17 05:17:45,16,MilkFew2273,programming
mnh9xem,1k0tsm5,reddit,Why not 30 days?,2025-04-16 21:25:55,24,iNoles,programming
mnjdaw9,1k0tsm5,reddit,"Obviously none of the people who point fingers at ""autorenewal"" or somesuch ever heard of air-gapped data-centers or locally-mandated CAs. ""Ewwww, but you can use LetsEncrypt!, silly"" no you actually can't for many reasons.

What's more ironic is that LE! is shutting down OCSP in three months this year, talking about automation.",2025-04-17 05:23:09,28,zam0th,programming
mnguhbc,1k0tsm5,reddit,"It's excellent news, and for all the right reasons. Everyone should be managing certs automatically, there's no excuse for not doing it.",2025-04-16 20:08:16,81,gredr,programming
mnmaa1r,1k0tsm5,reddit,"Thanks for the heads up. I will adjust my cron jobs to run every week instead of every month.

I need it more frequently to get more time in case there is an error as I tend to ignore the error e-mails for multiple weeks due to my fatigue from handling of various kinds of certificates.

Personally I also have an HTTP mirror for my more important projects when availability is more important than security of the connection.",2025-04-17 17:25:42,3,jezek_2,programming
mni8d85,1k0tsm5,reddit,/sigh/ our org automated certification process so much that it's more feasible to just manually upload certs nowadays because of reasons. yeah i will enjoy this change :(,2025-04-17 00:44:07,6,No_Nobody4036,programming
mnh4d0u,1k0tsm5,reddit,What about root certificates? Intermediate certificates?,2025-04-16 20:57:14,7,haroldjaap,programming
mnlgr4n,1k0tsm5,reddit,"ITT: sysadmins whining about complying with security best practices because they're too lazy and/or their organisation is too shit to use Let's Encrypt to autorenew.

Y'all need to get into the 21st century.",2025-04-17 15:03:17,2,IanAKemp,programming
mnguxik,1k0tsm5,reddit,"Looks like plain old http is back on the menu boys!

Edit: Ooof.... no humor setting I see.",2025-04-16 20:10:29,-16,RedditorsAreWeird,programming
mnm80gp,1k0tsm5,reddit,"AFAIK, apple relies on you manually going in and asking it to check your site again for its certificate to use Apple Pay. Does this mean someone has to refresh it every month?",2025-04-17 17:15:00,1,Borghol,programming
mlamn61,1jqypxq,reddit,"The alternative is learning an ever-growing mountain of DSLs and tools and technologies and terms that aren't very rewarding to a majority of devs... So you do the bare minimum and get crappy results and deliver slowly.

I don't disagree, really, but as an ex-devops I'm not sure the alternative is better",2025-04-04 00:26:06,581,pampuliopampam,programming
mlazmjg,1jqypxq,reddit,"All I'll say is Amazon's approach to DevOps was really bad when I was there, just devs doing lots of ops work and basically doing two jobs for the pay of one 

At my new place we have dedicated SREs doing pager duty while the devs are not

And at least afaik the SREs get paged way less than we devs did back at Amazon, probably in large part cause the devs have their time allocated towards writing the software with long-term quality rather than putting out fires in the short term",2025-04-04 01:47:45,106,GenTelGuy,programming
mlatuc7,1jqypxq,reddit,"I see a lot of ""We did X, we did Y"" in this blog post. But who is ""we"" here?

I recognize some of the original challenges, but I don't recognize the world this dude describes.",2025-04-04 01:11:09,149,abraxasnl,programming
mlb5xss,1jqypxq,reddit,">Originally, DevOps was about trusting developers with production. But modern DevOps teams operate on the belief that developers can’t be trusted with production.

Heh. I am old. This belief existed (and was challenged) before the term ""DevOps"" existed.

DevOps is just a word that merely reflects a cooperation need that exists between development and deployment , in a growingly complex world. Who do you think deployed software 50, 60 years ago...? Developers, that's who, with cooperation from system admins. In fact, first deployments were done by developers alone.

Nothing has changed from that, and it cannot change, except the position of a ""dev-ops"" needle in individuals, depending on the organisation etc.",2025-04-04 02:27:23,33,goranlepuz,programming
mlaq60j,1jqypxq,reddit,It doesn't matter what you call it; poor communication is just poor communication.,2025-04-04 00:47:58,131,omniuni,programming
mlbf310,1jqypxq,reddit,"Speaking as a product engineer, there's two types of companies: companies with dedicated DevOps teams and companies I don't want to work for.

You need specialists at certain things in a mature company else your ""fullstack engineers"" are gonna want to blow their brains out.

Of course we're going to have people on both sides of some fences that are aware of and have experience on the other side. Those people will have a unique extra perspective vs people who are very focused on one domain and know nothing else.

At the same time as us having those special multi-skilled swiss army knife devs, I'll bet that there's plenty of engineers who don't want to do all the stuff that other types of engineers do. That's why I'm a backend product engineer and not a DBA, devops, web developer, mobile app developer, product manager, engineering manager, or anything else product development-adjacent. I like what I do.",2025-04-04 03:29:12,23,Scottz0rz,programming
mlat4x6,1jqypxq,reddit,"""We need Operations but naming it *DevOPs* was a mistake*""*  is a pretty weak argument ngl. The SOC complaining is especially weak. It's essentially someone groaning exagerattedly when they get told their code was rejected for violating HIPAA/security or something regulated. In that example you give, you are basically arguing that devs should be able to just merge non-compliant code anyways, despite the possiblity it could adversly expose clients/users to unnecessary risk.",2025-04-04 01:06:42,96,MoistCarpenter,programming
mlc06td,1jqypxq,reddit,"There is a distinct ‘DevOps team’ failure mode, the article writer has experienced it. It’s also clear that not everyone else has, and that leads to people having very different takes on what the author is saying. 

My personal experience with this failure mode was in a 150 person scaleup. As we were scaling from 50 people to 150, we realized that we needed some more devops oriented profiles. Rather than embed them onto different product teams, they got formed into a single dedicated devops team, who was supposed to support everyone. 

First they wasted 12+ months on building their own CI/CD platform in AWS based around hashicorp tech, it had a lot of bells and whistles, being able to bootstrap itself in case of disaster, service mesh to support multiple cloud providers and ability to seamlessly migrate between AWS, Azure, google cloud. After that they discovered that everyone was happily using azure devops for CI/CD tasks, and that there was 0 reason to migrate to their homegrown solution. 

Next they decided to streamline our AWS environments. Everything should go into terraform, and to make things even better, they should only use our home grown terraform templates. They hadn’t settled on which practices they wanted to use for those templates yet, but the policy was still in effect. Only members of the devops team could bypass it. 

Net effect was that if you needed a new server for anything, you could either get the on-prem infrastructure people to order it, set it up, and get it running in 4-6 weeks, or you could ask the devops team to provision it for you in the cloud and you might get it sometime after 3 months, but also you might just never ever get it. 

Even worse if you wanted to use a new service or feature in AWS, then you first needed to wait for an official or unofficial module in terraform to be made available, and then wait for the devops team to have time to write their own wrapper around it, which could be delay you a few months, or result in you never ever getting it.

So I have seen the failure mode of ‘devops teams’ and it is not pretty",2025-04-04 06:23:07,12,Grubsnik,programming
mlar14h,1jqypxq,reddit,"OP it’s not too late to delete this really strange way of enthusiastically telling everyone you have very little experience. 

TLDR of the article is: 

Developer is big sad they can’t potentially break production, which is just like, super unfair. Back in the day developers were trusted with production, and it’s just really weird that after years of developers needlessly breaking production that an entire skillset rose up to protect companies from the harm caused to silly things like brand equity and reputation! Those pale in comparison to the freedom of giving developers the keys to the kingdom! This certainly is a trust issue, DEFINITELY not companies learning from mistakes. Nope. It’s just absolutely pointless. 

DevOps meanies build tooling that deal with stateful operations, policy and access controls, security, any of which can easily take down the entire stack, and you know, those things are just super duper restrictive for developers… Like, why not just have product engineers do those things? 

I mean, it’s so simple - companies just need to allocate the time for product engineers to learn complex provider offerings and implementations, design tooling to provision resources for those without destroying the world, which is obviously just a total walk in the park and can EASILY be done in parallel to existing product development. 

I mean, it’s all just so pointless. Never mind things like compliance audits, security, resilience - those are just super duper simple for every single developer ever.",2025-04-04 00:53:23,288,btdeviant,programming
mlarcv2,1jqypxq,reddit,I am amazed at how quick IT industry can churn out new fancy names every few years for things that aren't even new.,2025-04-04 00:55:26,90,udum2021,programming
mlax1u5,1jqypxq,reddit,"> Originally, DevOps was about trusting developers with production

Most developers can't be trusted with production because for any product beyond a trivial monolith, running it well requires non-trivial systems knowledge (be that OS-level, or knowledge of cloud APIs), which is why it is a profession of its own, and a large majority of software engineers don't have the skills or inclination to learn how to run production well.",2025-04-04 01:31:25,36,sionescu,programming
mlarb2h,1jqypxq,reddit,"Yeah this is just not a good take, completely misses several of the main take aways of what devops promotes. It works really well when you follow ALL the guidance, obviously doing anything half assed or using it as buzz word to rebrand the same shit will provide poor results",2025-04-04 00:55:08,41,Vi0lentByt3,programming
mlbo7ro,1jqypxq,reddit,"Comments are absolutely right that demanding expert level knowledge in multiple different areas is unreasonable if not impossible.

The problem is that having isolated teams enforces the notion of 'this is my job, this is yours' when in reality there's always a layer in the middle where you need a mutual understanding.

Of course it's going to be difficult if the product dev keeps having code pushed back for not being 'compliant' if they're not given room to learn or provide feedback on what the rules are and why those particular guardrails need to be in place.",2025-04-04 04:38:55,6,xPacifism,programming
mlarqa6,1jqypxq,reddit,"The underlying issue is that you simply can't use process to make people behave in a way that's contrary to their interests.


It's inevitable that a DevOps team will turn into an Operations team for the same reason that an Operations team exists in the first place. People in a team larger than like 5 people can't wear all hats at once. And once you've taken on a certain role, it's beneficial to everyone if you continue to gain expertise in that role. Beneficial to you because you get better at it. Beneficial to others because they get to be better at what they do instead of constantly flitting back and forth. Beneficial to the team as a whole with increased efficiency.",2025-04-04 00:57:48,19,vi_sucks,programming
mlaob0c,1jqypxq,reddit,DevOps is one of the many big tech heuristics that only makes sense if you can afford to throw a software engineer at every problem. That's tech and fintech and...end of list?,2025-04-04 00:36:25,17,TheESportsGuy,programming
mlb8kyk,1jqypxq,reddit,"Can we stop platforming random people's opinions that are blatant self promotion of their blog?

I honestly don't see how this guy ranting about devops from what seems to be a junior dev level of understanding is all that relevant to programming.

Yes, devops can be implemented poorly.

But no competent team lacks compliance and QA which is where he is unhappy.",2025-04-04 02:44:37,10,AlexanderNigma,programming
mlb2nye,1jqypxq,reddit,"The blog title is annoying even though the contents are generally fine, the blog title is referring to the job title of ""DevOps Engineer"" (lol) that appeared out of the original term.

It looks like most people in the comments here don't know what DevOps was in the first place, which is understandable given how the term has been hijacked for years now. It was never meant to be a job title, just the term given to a team/structure wholly responsible for the full lifecycle of software to differentiate it from the usual heavily silo'd teams. Just to clarify, the goal wasn't to change team structures, but have teams/people with the right skills for the task, work more closely.

If you have worked at small enough companies, this is how it naturally works.

Here's a common siloed example still present in larger companies; needing to open a ticket with the ""network team"" to get a new DNS entry or a firewall port opened. A less common situation now, which is mentioned in the article and used to happen a lot more, was ""handing over"" to the operations team.

I've only worked at 2 larger tech companies (200+ and 500+ employees) over the years that actually had a real DevOps culture where our teams actually had network, security and operational specialists within the team itself (because it was a large part of the project/product) or at least dedicated a serious portion of their time and not just as separate ""approvals"".",2025-04-04 02:06:33,5,fxfighter,programming
mlbugrs,1jqypxq,reddit,"That's not what the idea of DevOps is, that's the cargo-cult version of DevOps.

Every single time a group of people come up with a good idea how how to improve work and collaboration, they name it, and then companies take take name and stick it on something else and try to sell it as tooling, classic business processes, and certification courses.

Agile, DevOps, CI, ... what is often being ""sold"" these days is not what the original idea was. Although not being sold like the previous terms, Unit Tests and Refactoring are also generally misunderstood.

If you want to know what DevOps was supposed to be, read The Phoenix Project. Besides being an entertaining story. It also explains the transition from ""classic"" ops to DevOps. It is _not_ about devs deploying to production.",2025-04-04 05:31:44,5,elmuerte,programming
mlc5mo5,1jqypxq,reddit,"Devops is a very good **idea**. How most people (including those who call themselves devops engineers) ~~barely~~ understood and implemented it - that is business as usual; the same did happened with Agile, Lean, Kanban, ITIL, architecture governance and all other methodologies.",2025-04-04 07:13:41,3,zam0th,programming
mlerilz,1jqypxq,reddit,"I read through all the comments before the article ... after I did I'm not sure what most of you were looking at. I almost 100% agree with his take. Taking DevOps peeps off the teams literally is the exact opposite of what the original intent was. Same with ""Platform Engineering"". Its basically the same Operations idea from years ago I thought we all agreed wasn't working well.

Most here are commenting that devs shouldn't have to focus on all those things ... but the author doesn't say that at all. He's just saying to keep the DevOps engineers on the teams.",2025-04-04 17:43:59,3,ltdanimal,programming
mlbiauk,1jqypxq,reddit,I don’t think that’s really because they gave it a name. People just kept operating the way they had been.,2025-04-04 03:52:51,2,RICHUNCLEPENNYBAGS,programming
mlbkphq,1jqypxq,reddit,I worked for a company in a highly regulated industry. They did not have a strong devops culture in their early years. As a result there were some critical services which ran under the user accounts of developers who had left the company. Those ldap accounts could never be deactivated because it would disrupt business operations. We had apps in production which relied on compiled binaries for which no source existed and there were no build instructions. We had client certs which had been generated by developers and not issued by the corporate CA. It was a mess held together with hopes and dreams.,2025-04-04 04:11:15,2,rocket_randall,programming
mlbxfoo,1jqypxq,reddit,"I mean, yeah? It sucks if you do it wrong, just like everything else. 

Devops isn't supposed to be silo'd. Its meant to be integrated into the product team so devops engineers can pick up dev and ops tasks as they see fit.",2025-04-04 05:58:54,2,Destrok41,programming
mlc8hfe,1jqypxq,reddit,"DevOps is the nicest idea ever.

Separation of concerns is one of the best principles.

I, as a c++/java/javascript software engineer, don't want to spend time learning the stuff DevOps does, not only because they seem boring^* to me, but because the DevOps domain is huge and in reality I would not be able to do both jobs correctly.

^* DevOps is boring to me because designing a software API seems to me a hell of a lot more interesting than designing a software pipeline. The former is an art, the latter is a chore with a lot less creativity involved.",2025-04-04 07:44:19,2,axilmar,programming
mlcfmjy,1jqypxq,reddit,"DevOps is nothing new, it's just old, spiced up, wine in new bottles.

Larger corporations have had separate teams or people for doing deployments for ages. When you're two people it's fine and convenient if you're both able to deploy, but the same simply isn't true for when you're ten people.

When it's split off, of course you get some bureaucracy. The thing is, while bureaucracy typically sounds bad and annoying, when done right it also enforces procedures that ensure quality and minimize mistakes. It's a trade-off that's done at every important level of companies (and civilization as a whole).",2025-04-04 09:02:03,2,mensink,programming
mlcmpr3,1jqypxq,reddit,It's primarily a bad idea because it empowers every marketing PM to break prod by manipulating the dev team with dark psychology nonsense.,2025-04-04 10:16:05,2,RokoTech,programming
mlcvhew,1jqypxq,reddit,Hot take: Devops doesn't mean developers have to learn the underlying tools that enable it.,2025-04-04 11:31:11,2,KarmaCop213,programming
mld013l,1jqypxq,reddit,"It really depends on the size of your operation. When you are large enough you aren't stealing from other teams to fill out the DevOps team - they are a dedicated integration support element.

When it breaks in the middle of the night do you want the Devs to be the ones who are on call? In a perfect world you have enough people to cover all the work that needs doing, but in a lot of places operations is a black hole where the demands outpace the resources. As a result you get stuck in a downward spiral where you cannot innovate because you are too busy maintaining. Keeping your developers out of that mess lets them keep the organization innovating.",2025-04-04 12:04:15,2,PedanticDilettante,programming
mleklie,1jqypxq,reddit,"I was on a team that ran along the lines of OG DevOps as this guy describes it, but that was back when we were using virtual machines and Puppet to configure everything. These days, I can't imagine not having at least one person focused full-time on ops given how complex cloud services have become.",2025-04-04 17:09:58,2,zhezhijian,programming
mlgwcbs,1jqypxq,reddit,"This is an organizational issue, not an industry one. If your ""DevOps"" team is making it impossible to do DevOps in the name of SOC2 they aren't doing their job. 

This is a fixable problem, it's hard work but it's doable.",2025-04-05 00:50:11,2,safetytrick,programming
mlh2bu1,1jqypxq,reddit,"The article feels limited in its viewpoint. First it describes DevOps like ""just a little extra work at the end of the sprint"" which is just wrong. DevOps is not uniform in every organization. I've worked in small product teams with a couple dedicated DevOps engineers. I worked in orgs that had 4 DevOps teams to support 300 developers.",2025-04-05 01:29:10,2,Inferno_Crazy,programming
mlhjkfm,1jqypxq,reddit,"Agree.

In my opinion, the DevOps usually goes to the senior/staff engineer team member that know the architecture of the system. So, they know what tools that we need _right now_ and improve along the time. It is part time jobs of member of the team until the system become bigger and bigger.

Now aday, devops is someone who setup CI/CD, sometimes logging, sometimes monitoring that miss the metrics to be monitored. If the tools or functions that being setup does not based upon the request from developer or product, most likely it will be unused or over engineered.",2025-04-05 03:29:20,2,_shulhan,programming
mlb0qvd,1jqypxq,reddit,"The point is valid but example is bad.

To make distinction between classic operation and devops clear, I can take your SOC example.

Operation team: 

“Devs must git good. Skill issues. Not my problem. I protect production.”

DevOps: 

“here is how you can be compliant with SOC. Here are some tools to help”

Is your value about how well you protect production? Or is your value about by how well you support devs to protect production?

(DevOps metrics nowadays is measured by DORA added on SLA, indicating how fast it is to help devs get to production.)

And many DevOps does not have this kind of service mind and supportive mindset because they originated from being isolated technical operation folk, and they miss the point of original DevOps.

DevOps engineers nowadays usually step away from vision of DevOps.",2025-04-04 01:54:39,2,chrisza4,programming
mlbrcrj,1jqypxq,reddit,"Insanely stupid article, if I’m being frank. Everyone knew these “devops teams” were doing devops wrong the entire time they existed. Illiterate ITIL brained managers are the problem, not devops",2025-04-04 05:04:23,2,free_chalupas,programming
mlb4k2p,1jqypxq,reddit,"this is click bait, as is lacks sufficent context, or rather supplies its own to say ""thing bad"", maybe your experience aligns with the autbors context, thats unfortunate.

treated as a role and nothing else, not as a practice or standards execise with specalists (as its founders intended) yeah, its bad, because your doing it wrong.

same argument could be used for anything.",2025-04-04 02:18:37,1,david_nixon,programming
mlbkgk6,1jqypxq,reddit,"New post ""we try to implement X, we failed, X must die"" without really trying to imagine others context and how their implementation is buggy",2025-04-04 04:09:18,1,barmic1212,programming
mlblji4,1jqypxq,reddit,The SOC comic makes no sense. Does the author actually think DevOps engineers “make” the rules?,2025-04-04 04:17:49,1,starmiemd,programming
mlc067r,1jqypxq,reddit,"There is a distinct ‘DevOps team’ failure mode, the article writer has experienced it. It’s also clear that not everyone else has, and that leads to people having very different takes on what the author is saying. 

My personal experience with this failure mode was in a 150 person scaleup. As we were scaling from 50 people to 150, we realized that we needed some more devops oriented profiles. Rather than embed them onto different product teams, they got formed into a single dedicated devops team, who was supposed to support everyone. 

First they wasted 12+ months on building their own CI/CD platform in AWS based around hashicorp tech, it had a lot of bells and whistles, being able to bootstrap itself in case of disaster, service mesh to support multiple cloud providers and ability to seamlessly migrate between AWS, Azure, google cloud. After that they discovered that everyone was happily using azure devops for CI/CD tasks, and that there was 0 reason to migrate to their homegrown solution. 

Next they decided to streamline our AWS environments. Everything should go into terraform, and to make things even better, they should only use our home grown terraform templates. They hadn’t settled on which practices they wanted to use for those templates yet, but the policy was still in effect. Only members of the devops team could bypass it. 

Net effect was that if you needed a new server for anything, you could either get the on-prem infrastructure people to order it, set it up, and get it running in 4-6 weeks, or you could ask the devops team to provision it for you in the cloud and you might get it sometime after 3 months, but also you might just never ever get it. 

Even worse if you wanted to use a new service or feature in AWS, then you first needed to wait for an official or unofficial module in terraform to be made available, and then wait for the devops team to have time to write their own wrapper around it, which could be delay you a few months, or result in you never ever getting it.

So I have seen the failure mode of ‘devops teams’ and it is not pretty",2025-04-04 06:22:58,1,Grubsnik,programming
mlc6dhy,1jqypxq,reddit,"**50 things every JavaScript developer should know about OpenShift**

Can we please not? Having a talented OPS/IT/DevOps team, be it a silo or integrated, is such a relief.",2025-04-04 07:21:28,1,eldelshell,programming
mlco0jj,1jqypxq,reddit,"I once worked with and older experienced colleague in a devops team who summarized our daily toll like this:

”Everywhere else in society we have gone down the specialization route - that’s why you don’t see surgeons managing the hospital cafeteria or doing the laundry. But in the devops world you’re supposed to be an expert programmer, security specialist, cloud architect and network engineer at the same time”",2025-04-04 10:28:32,1,TallGreenhouseGuy,programming
mlcoos5,1jqypxq,reddit,The snippet at the bottom about platform engineering strikes true on such a core level.,2025-04-04 10:34:49,1,EvilTribble,programming
mlcs7xo,1jqypxq,reddit,"I used to work in small companies/teams as a SWE where i was also one of the few devs incharge of our small devops needs. I gotta say, even for small scale projects, doing both was pretty taxing. It felt like the more i focused on one, the less i felt proficient in the other. I dont feel like I could have grown as a software engineer had i kept going on in this 50-50 state. 

So i can totally see why you would assign people to be dedicated devops engineers. in the mixed alternative you feel like you are niether.",2025-04-04 11:05:30,1,CyberWank2077,programming
mlcw22z,1jqypxq,reddit,"[DevOps is dead, long live DevOps.](https://medium.com/@drew.khoury/devops-is-dead-long-live-devops-43b3b1d06a7d)",2025-04-04 11:35:37,1,prof_ritchey,programming
mle55oq,1jqypxq,reddit,"Only someone who did not work in software before DevOps could make this claim - go back and [listen to Allspaw describe what it was like and why we needed to move forward](https://www.google.com/search?q=12+deploys+a+day+dev+ops&rlz=1CDGOYI_enUS723US723&oq=12+deploys+a+day+dev+ops&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIJCAEQIRgKGKABMgkIAhAhGAoYoAEyCQgDECEYChigATIGCAQQIRgKMgcIBRAhGJ8FMgoIBhAAGIAEGKIE0gEIOTM3MWowajeoAhqwAgHiAwQYASBf8QVMuD3rgDm97PEFTLg964A5vew&hl=en-US&sourceid=chrome-mobile&ie=UTF-8#fpstate=ive&vld=cid:18883606,vid:LdOe18KhtT4,st:0).

I advocated strongly against DevOps teams but ultimately it is better today even with this kind of silo than it was before and there is nothing stopping engineers from learning the pipeline - automation means that configuration is code - learn the tooling - silos are part organizational pattern and part mindset.",2025-04-04 15:52:15,1,omgnogi,programming
mlea0dv,1jqypxq,reddit,"This subreddit has a nasty habit of upvoting the idea and not the substance.  

""Devops is bad""  Ok what's the solution?""  ""DevOps is bad""   Ok what did we do before it you want to revert to.  ""DevOps is bad"".....  I see where we're going.

My guess is this is a guy who has never experienced anything other than one or two places.   Or similar to someone who hates scrum but has only worked in Scrum offices/worked in the ONE office that does waterfall right, nor took the time to learn what Scrum/Agile/Kanban or anything else is supposed to work like.

At least it's not a long post where someone is shilling their new version of Agile, while complaining about Agile.",2025-04-04 16:16:43,1,Kinglink,programming
mleaklx,1jqypxq,reddit,"DevOps used to be a culture, not a role. Basically making devs and ops working together to make the process smooth.
Not sure who made it a role first, but it was a bad idea. It was never meant to be a role.",2025-04-04 16:19:34,1,mxsb55,programming
mlemfx3,1jqypxq,reddit,don’t blame the name for a shitty implementation. you implemented it.,2025-04-04 17:19:12,1,collin2477,programming
mlexbch,1jqypxq,reddit,"> In the beginning, DevOps made sense. It was a logical evolution of healthy engineering practices. But we never should have given it a name. Once we labeled it, it got completely out of hand.
> …
> We undid everything that made DevOps work in the first place.

Oh, so it’s like some quantum effect: you put a finger on this workflow and the magic collapses.",2025-04-04 18:12:52,1,xealits,programming
mlf5b1h,1jqypxq,reddit,"I have to say; this article is quite one sided. 

He does make one good point; when we named something DevOps, it got outta hand. 

I regularly request not to use the term anymore in meetings. That is because it lost all meaning. To be more precise, it had so many different meanings for so many different people that it effectively meant nothing anymore.

The author uses his own definition. This is not a global truth, but something he has experienced. For example, any developer in my current company is called DevOps engineer, because *all* developers are also responsible for production. That is something I see quite often in my country, actually. The concept of a “central DevOps team” is something I haven’t seen often, but the author seems to  take particular issue with that pattern. I agree that seems like a very weird organizational choice, but again it is not a universal truth.",2025-04-04 18:53:34,1,djerro6635381,programming
mlfzcar,1jqypxq,reddit,Absolutely,2025-04-04 21:30:27,1,joashua99,programming
mlg83qg,1jqypxq,reddit,"DevOps isn't about getting Dev to do Ops, it's about getting cheap Ops employees to do Development without having to pay development wages.

How about we do what we've always done... Ops do Ops. Dev do Dev. And SRE do SRE... The problem is when you don't have regular meetings between ops & dev to discuss ops issues that dev can help with.",2025-04-04 22:20:23,1,Valendr0s,programming
mloz69y,1jqypxq,reddit,"AWS *is* the ""dedicated DevOps"", teams just write scripts to call AWS APIs to get their containers into ECS or Kubernetes.  No need for another team to write mountains of stuff that product teams can't google to figure out how they work.",2025-04-06 13:05:17,1,crazyeddie123,programming
mlye12a,1jqypxq,reddit,I did not know I did DevOps until I went to a job that had a dedicated DevOps team,2025-04-08 00:24:53,1,N/A,programming
mnizwqv,1jqypxq,reddit,is it accurate to say that devops suits those who prefer to not code full time?,2025-04-17 03:36:35,1,kezi-halima,programming
mlay06m,1jqypxq,reddit,"DevOps was a huge improvement over silo'd dev and operations staff, completely worthwhile.  The author evidently didn't like the DevOps teams that sprang up in some of the places where he worked, which became a new priesthood separate from the main development staff.  Well, that wasn't how things were supposed to work.  A dedicated DevOps staff, if it exists at all, is supposed to jump start the process and be the resident experts, not to be responsible for writing all the infrastructure as code forever after.",2025-04-04 01:37:29,0,emotionalfescue,programming
mlbfwhx,1jqypxq,reddit,"That comic ""didn't you make the SOC compliance rules?"" No, DevOps didn't make those rules, the compliance officers did. DevOps is just making sure they're actually being followed",2025-04-04 03:35:07,1,Ranger207,programming
mlbv4p1,1jqypxq,reddit,"Can't disagree more, what are we going to have full-full-stack developers now? Foot surgeons don't do brain surgery for a reason. ",2025-04-04 05:37:45,1,dumsumguy,programming
mlaqy4x,1jqypxq,reddit,"This is so on point! Essentially what happened is that developers or “product engineers” stopped caring about infra and devops guys just turned back into ops. And every developer who cares about production is encouraged to hand this over to the devops team, missing out on learning. On top of that devops teams don’t trust developers and this creates conflicts all the time. I do believe that there should be no devops, we need tools that every engineer can use and don’t drown in the convoluted mess of configuration (*cough* k8s *cough*)",2025-04-04 00:52:52,-8,heraldev,programming
mlbaluf,1jqypxq,reddit,"OP is an idiot, working with idiots. If it hurts, don't do it.",2025-04-04 02:58:05,0,knobbyknee,programming
mlbywa8,1jqypxq,reddit,"This is moron take. 

We don’t keep you out of production because we don’t trust you. We keep you out of production because it’s a fucking security risk that’s unnecessary. We keep you out because automation prevents manual changes and human errors. We keep you out because of fucking SOC compliance and external vendor audits you dense fool.

People like this guy are why these policies are in place. 

Nobody should want elevated access. If you want elevated access, you aren’t the type of person that should have it.",2025-04-04 06:12:36,-4,o5mfiHTNsH748KVq,programming
mlcrwfi,1jqypxq,reddit,"I did DevOps wrong, therefore DevOps is bad..?",2025-04-04 11:02:53,0,frederik-cc,programming
mlaqo9g,1jqypxq,reddit,"This has the ring of truth to it.

I have been recently thinking about how helpless a lot of my colleague devs become in the face of needing to write a new GitHub pipeline. It's not that they can't do it - it's just yaml and some tools - it's that it's not \*their\* job, it's the job of some DevOps person. They don't want to cross over to the DevOps role or something. It's a kind lf learned helplessness and quite silly.

Also, too, ""pure"" DevOps people shouldn't be writing terraform or bicep. If they can do that well, they should be coding with the rest of us.

Transparency is the key. Great point.

Great article.",2025-04-04 00:51:08,-13,pagalvin,programming
mlb7oaz,1jqypxq,reddit,apr 1,2025-04-04 02:38:38,-3,perumeni,programming
mnqr8ue,1k22pdf,reddit,I look forward to them moving it back in one year when they realise how much GCP actually costs.,2025-04-18 11:38:54,419,Rhoomba,programming
mnqx9qv,1k22pdf,reddit,"Ah yes, putting more critical infrastructure in the hands of a single for-profit megacorp.",2025-04-18 12:22:05,232,hbarSquared,programming
mnrkmu8,1k22pdf,reddit,"Strange they would choose Google Cloud for this. 

I’d expect something more sustainable and lower cost and likely to exist in 10 years. 

I think arXiv is a great resource and was kind of surprised to learn it’s just run by Cornell. I kind of feel like it needs to be hosted by Wikipedia Foundation or something.",2025-04-18 14:37:23,45,prepend,programming
mnqqwb6,1k22pdf,reddit,"Good, so Google will need less efforts to scrap it.",2025-04-18 11:36:14,44,RoomyRoots,programming
mnr5gdi,1k22pdf,reddit,"[Oh dear](https://i.imgur.com/KH9Is6U.jpeg)  Well, kind of - if they do the work to modernize it as a containerized app on top of now-standard k8s containerized hosting, then it IS migratable again fairly readily back to modern in-house k8s or other k8s provider hosting services I suppose.",2025-04-18 13:14:02,12,lood9phee2Ri,programming
mnr0ohi,1k22pdf,reddit,"Hmmm. I can understand it to some extent; local universities here in Europe also kind of do the same, usually running to Microsoft (guess they don't understand the problem of Trump's US-first directive and tariffs, but that's a secondary thing, I am not meaning to pull in politics here). The problem I see is that more and more inter-dependencies in regards to computer and software, are controlled by a few mega-mega-corporations. While this is understandable (many universities or campus sites lack knowledge and manpower to offer any alternative), it's still pretty unfortunate.

> replace the portion of our backends still written in perl and PHP

^^^ we can see that with regard to COBOL. Granted, neither perl nor PHP are in a similar state as COBOL is, but slowly you have those issues coming up more and more, in particular in regards to perl. And while people claim ""COBOL is so highly paid, sure perl will be the same"", the fact of the matter still is that young software devs will rarely specialize in any niche language merely because they have a more secure job (or they assume this to be the case, which is not necessarily true either).

> containerize all, or nearly all arXiv services so we can deploy via Kubernetes or services like Google Cloud Run

That seems mega-buzzword jargon. So, their legacy system is perl and php ... but they TOTALLY know the MUST have Kubernetes running on Google Cloud? I mean what is next: ""extend AI to all infrastructure""?

> The cloud transition is a pre-requisite to modernizing arXiv as a service

How so?

They did not give any arguments.

Great for those landing those three jobs, but there are some mixed feelings. If anyone of you lot land a job, make sure to give feedback about it in a few years. And we'll also have a look at arXiv how their epic move to become part of a googlified cloud will have work. If all has been messed up, AI may come to the rescue. Possibly ... \o/",2025-04-18 12:44:33,9,shevy-java,programming
mnti563,1k22pdf,reddit,"I don't know why, but this is bad.

May be I know why: It's Dejanews all over again.

Google killed Usenet when they acquired and neglected Dejanews. On purpose, I may add.

arXiv is getting dejanewed.",2025-04-18 20:30:09,0,Nicolay77,programming
mns37y8,1k22pdf,reddit,This post clearly triggered a lot of people who bought into the cloud repatriation kool-aid.,2025-04-18 16:10:17,-11,yourfriendlyreminder,programming
mnqxxvn,1k22pdf,reddit,it's so over,2025-04-18 12:26:40,-16,DreamDeckUp,programming
mlar519,1jqwybf,reddit,Kinda ironic that so much of this was about trying to fit BASIC in 4k - and then they publish it as a 100meg pdf.,2025-04-04 00:54:04,148,wosmo,programming
mlc206g,1jqwybf,reddit,Let’s see Paul Allens code.,2025-04-04 06:38:14,59,Sarthox,programming
mladmxo,1jqwybf,reddit,"as a naturally distracted person, having the text change funkily right underneath my cursor is certainly a readability choice",2025-04-03 23:31:19,181,bzbub2,programming
mlafold,1jqwybf,reddit,[deleted],2025-04-03 23:43:31,133,N/A,programming
mlb8pkp,1jqwybf,reddit,"The actual code linked a the bottom of the epilepsy triggering post:

https://images.gatesnotes.com/12514eb8-7b51-008e-41a9-512542cf683b/34d561c8-cf5c-4e69-af47-3782ea11482e/Original-Microsoft-Source-Code.pdf",2025-04-04 02:45:27,32,quakedamper,programming
mlb8ud5,1jqwybf,reddit,"Interesting that Bill is writing this book now, after Paul Allen has died.  I have a feeling Paul might have a different take on some of the stories in the book.",2025-04-04 02:46:19,32,jedberg,programming
mlali8v,1jqwybf,reddit,"Looks cool if one isnt trying to read the site. But really annoying if one is trying to read it. I think demonstrates quite well why the user experience of Microsoft products is so bad in comparison to other companies.

Bill gates writing could be simple text without any formatting and people would read it just to hear what he has to say. This kind of gimmickry is usually reserved for content that isnt worth reading.",2025-04-04 00:19:06,51,StarkAndRobotic,programming
mlajb95,1jqwybf,reddit,">Incredible leaders like Steve Ballmer

lol.",2025-04-04 00:05:28,22,-grok,programming
mld08bt,1jqwybf,reddit,"You know what I want from a website? For it to **not** show me the content, and instead flicker some bullshit for a few seconds, reflowing text and images, and just plain being an asshole.",2025-04-04 12:05:40,5,lalaland4711,programming
mlbtcwh,1jqwybf,reddit,"How is this upvoted? I literally cannot read it. In Brave, the whole page is white. In Chrome, the constant animations are fucking idiotic.",2025-04-04 05:21:51,10,netherlandsftw,programming
mlchuhc,1jqwybf,reddit,"
Why does this subreddit hate everything? This was a great story and I find it fascinating to see the original code. Good for Bill to celebrate it and add a touch of visual flair / whimsy. Shame 100% of r/programming users apparently use screen readers in obscure browsers and couldn’t read it.",2025-04-04 09:26:17,9,DeepSeaDiving,programming
mlexerx,1jqwybf,reddit,neat,2025-04-04 18:13:21,2,jutct,programming
mlee135,1jqwybf,reddit,Good lord the design on this webpage is atrotious,2025-04-04 16:37:06,2,Trotskyist,programming
mlbgjm6,1jqwybf,reddit,The site's not that bad.  Just put your cursor aside and read it normally.  It doesn't change unless you're playing around with your cursor.  Why are there so many complaints?,2025-04-04 03:39:52,7,BujuArena,programming
mlc80i3,1jqwybf,reddit,Now fork it - doors operating system here we come,2025-04-04 07:39:15,1,maxinstuff,programming
mlc20ua,1jqwybf,reddit,Let’s see Paul Allens code.,2025-04-04 06:38:24,1,Sarthox,programming
mlc55bq,1jqwybf,reddit,He started out with a lie and has been lying ever since.,2025-04-04 07:08:35,-2,Traveler3141,programming
mlbhh62,1jqwybf,reddit,Should've just made this a YouTube video or something,2025-04-04 03:46:42,-2,WatchOutIGotYou,programming
mkrqiog,1joeiaj,reddit,"This is the key. Just like when the AI initially suggests nonexistent methods on libraries, then apologizes with a “You got me!” when you point it out. If it can’t use features that actually exist the first time, it can’t “code.”

> Take my Express backend experiment. The code worked perfectly, but it was clear that protection against SQL injection was completely absent. Not even in the most basic way was it taken into account, which means that the site was so incredibly unsafe that it wouldn’t take an hour before it would be hacked. When I addressed ChatGPT about this, it immediately provided a security fix. The knowledge was there, but wasn’t proactively applied. Of course, this can be solved with better prompting, but that’s obviously not a solution that can replace developers. To be able to prompt well, you already need the knowledge of a developer by definition.",2025-03-31 23:16:37,445,TestFlyJets,programming
mkrrv3s,1joeiaj,reddit,It's fine for spitting out code segments and various types and such. And also just throwing ideas at it helps me think. Like a superpowered rubber duck. I absolutely loathe using it as auto-complete though. I need my editor to be deterministic.,2025-03-31 23:24:17,83,SerdanKK,programming
mkr5mbp,1joeiaj,reddit,"As an engineer with 2 decades of experience, I find myself increasingly annoyed by non-coding managers thinking AI is going to bring 190% reduction of cost, or replace entire divisions of coders. A helpful tool, sometimes yes, but sometimes also a complete and utter tool. So I wrote a rant about it.",2025-03-31 21:20:12,298,monkeyinmysoup,programming
mksdnnz,1joeiaj,reddit,"> It's a reality check that LinkedInfluencers prefer to ignore, because AI is so incredibly cool and hip and for many people the only intelligence they know, but those who build products on a daily basis know better.

Beautifully said.",2025-04-01 01:36:42,36,Big_Combination9890,programming
mkt13oi,1joeiaj,reddit,">But in my view, this is just the next step in a long evolution of developer tools.

This is absolutely true, and I think a key point that seems to be glossed over by so many articles hyping the technology. 

I would argue that LLMs as they are today are less impactful than modern IDEs, frameworks, version control, infrastructure as code tooling, you name it. Tools written by developers for specific purposes that always do what you tell them to allow for repeatable compiles, builds, testing, and deploys.

IntelliJ can use the language compiler itself to literally tell you exactly what parts of code are correct or not, in real time, and it can perform mass refactoring in a way that is nearly perfect and pretty much guaranteed to do exactly what you expect, every single time.

Frameworks like Spring Boot and React allow developers to create fully functional applications with minimal work, and MAINTAIN THEM. IaC improvements allow site reliability engineers to simplify a huge amount of platform management responsibility. 

Meanwhile, LLM offers the potential to MAYBE do what you want, as long as you can babysit it, correct it when it's wrong, and know all the little 'gotchas' you have to warn it about. Yes, they can help you do some grunt work now and then, and occasionally they can help you out if you get stuck and do things like read 700 lines of error logs to help find the one that's meaningful, but just as often, they give you the wrong answer, or they misunderstand what you meant, or YOU misunderstood what you were asking for and they just went along with you.

They're a tool that sometimes helps a bit. IMO the jury is still out for complex work whether or not they help more than they hurt. Like 90% of the time I do something like hand gpt a class and ask it to write tests for a new method I wrote, it does something totally different than what I wanted, even if I provide example test cases. It will miss obvious edge cases, mock nonsense things, get variable names wrong. Even with o3-mini or o1-pro it does stupid things ALL THE TIME. 

It's just not reliable. And even when it is, it's still just an incremental gain over our previous tooling advantages.",2025-04-01 04:16:02,26,sprcow,programming
mkrulos,1joeiaj,reddit,"Very sane take, appreciate the post. I also appreciate how you addressed productivity and expectations: “You could even say that productivity doesn’t increase, but expectations do.”

I’ve also found the same value in treating it as a private tutor: something to help fill in the blanks, but also something you’ve got to actively think about. It’s why the whole vibe coding “just hit the approve button” is so misguided. Why surrender the most important thing: the context people have about what the problem is and what kind of solution is the most appropriate.",2025-03-31 23:40:10,17,sufianrhazi,programming
mksoipc,1joeiaj,reddit,"Also fairly old as far as programmers now with over 2 decades experience. Been through enough cycles to know that new technology always over sells, people jump on it, investors push in funding, and ultimately most of it turns to shit. That is not to say that it's bad, just have to let other people waste their time in the beginning until it matures.",2025-04-01 02:45:11,10,Sairony,programming
mktawtj,1joeiaj,reddit,"Big fan of AI tools, but the more I use them, the more it's obvious how the suggestions are just a blended up version of whatever source it was trained on. If you ask it about a common problem then it does well. The more uncommon your situation, the more it flounders. It's definitely not a general reasoning intelligence.",2025-04-01 05:42:24,11,Zealousideal-Ship215,programming
mkts18r,1joeiaj,reddit,"It seems to me that, in the current IT boardrooms there is this fantasy that AI will mean no more senior developers will be needed—just hire a bunch of juniors and hand them an AI. 

The truth is that, if anything, it would be the juniors who will be cut down on. The AI can do all the badly-executed grunt work, while the seniors spend half their days correcting it. 

Of course, in this scenario the industry will soon run out of senior developers.",2025-04-01 08:50:04,7,sambeau,programming
mktv66n,1joeiaj,reddit,"The way I've expressed it before (probably in this sub) is that AI code generation is like simultaneously the best and worst intern you've ever had.

This virtual intern is uncannily good at certain weird minutiae of the sort that might look impressive in the typical poorly-thought-out whiteboarding interview. There's a perspective from which it appears to know more than any one human developer is capable of holding in their own head, and that's superficially compelling.

On the other hand, it cannot operate with even the least independence, and never can. You will forever be driving this ""intern"" as a full-time over-the-shoulder micromanager, because the second you drop your vigilance it will produce something *insane* and doesn't even have the capacity to recognize or learn from that.

Hate doing code reviews? Most of us do. Well, guess what, now your job as a responsible, competent developer relying on AI is *all code reviews* of a *complete moron.* As a bit of technology it dazzles people. As a human you'd fire it no matter how many obscure languages it seemed to know enough of to be dangerous.",2025-04-01 09:26:04,7,gelfin,programming
mks3wei,1joeiaj,reddit,"Will give it a read in the morning, but generally I savour these blogs. It helps me to groan less at PMs and developers rotting their brains knowing that some seasoned developers look at it with a skeptical eye",2025-04-01 00:36:14,7,SoulSkrix,programming
mktzrxb,1joeiaj,reddit,"Apart from the underwhelming performance of AI when it comes to complex tasks, I think there are other issues when relying on AI tools too much, creating a situation where in the long term it will have negative consequences, especially for junior developers. I posted an article about this yesterday as well for those interested:

[https://lucianonooijen.com/blog/why-i-stopped-using-ai-code-editors/](https://lucianonooijen.com/blog/why-i-stopped-using-ai-code-editors/)",2025-04-01 10:15:42,3,lucianonooijen,programming
mkvegy6,1joeiaj,reddit,"100% true!  
I recently posted [12 lessons on working with AI](https://www.reddit.com/r/ClaudeAI/comments/1jj2ucr/i_completed_a_project_with_100_aigenerated_code/) that went viral, then created this [ai-assisted-development-guide](https://github.com/Qais-Hweidi/ai-assisted-development-guide) GitHub repo, check them out and let me know what you think.",2025-04-01 15:44:36,3,helk1d,programming
mkvsh5y,1joeiaj,reddit,"Your point about the lack of SQL injection protection highlights a fundamental issue: AIs lack MECE structure in understanding context. I recently wrote about how the MECE principle can transform documentation and help AI better understand project context: https://medium.com/@jlcases/mece-for-product-managers-the-forgotten-principle-that-helps-ai-to-understand-your-context-9addb4484868. Proper organization of context is key to getting secure, quality code from these tools.",2025-04-01 16:56:42,3,traderprof,programming
mkt4les,1joeiaj,reddit,"I have a similar view. My AI usage is very different than what I see around me.

I basically use AI as a glorified autocomplete. I keep coding the same way as before, and I occasionally review the extra lines it suggests (rarely accept more than 1 or 2 lines at a time). It's great to generate long boilerplates or complex DTO definitions. It saves me typing time when writing documentation. It can generate small helper functions that saves me a couple Google searches. It's useful for writing stuff like simple regexes.

Once the coding is done, I will ask Claude to review it in hopes of finding any obvious mistakes or suggest improvements in terms of clarity and security (most of the time it's pretty meh but it does give me some ideas here and there). I've never found AI particulary useful for unit testing. Asking the AI to create a new feature from the get-go is a waste of time. 

I would say it saves me a solid 15% of my time if I also take into account the time wasted evaluating gibberish answers, but that's ultimately it.",2025-04-01 04:44:42,6,uplink42,programming
mksej34,1joeiaj,reddit,"Pro-AI is the same as Pro-MAGA.

- Supporters have no idea how things actually work.
- Worship grifter idols.
- Incompetent platform hidden by hype.
- Want to remove ""inefficient"" workers who actually do all the work.
- Want to become rich without doing anything.
- Fine with stealing from the powerless.
- Certain they won't be the ones replaced because they have *good* ideas.",2025-04-01 01:42:10,10,MaruSoto,programming
mkrtn0o,1joeiaj,reddit,"> After the initial surprise that was the arrival of ChatGPT, it hasn't progressed very hard.

Absolutely wild take.",2025-03-31 23:34:38,-1,AD7GD,programming
mkrytmv,1joeiaj,reddit,people always kick the robots,2025-04-01 00:05:08,1,salvadorabledali,programming
mkto5fm,1joeiaj,reddit,"I've recently been using and learning AI programming, and it really saves a lot of time, especially for simple tasks or features that are more independent in functionality. However, when it comes to more complex logic or features that require strong logical reasoning, it's still faster to code them myself. AI might introduce some logical errors that are hard to spot, and later when you have to debug them, it could end up wasting a lot of time. So, I believe AI should be seen as a tool, not the solution to everything.",2025-04-01 08:04:44,1,Hungry_Importance918,programming
mku3gsh,1joeiaj,reddit,"The real problem with AI is that people in the C-Suite are hallucinating and the AI is confirming their delusions.

Fantasy: ""We'll get rid of most of our people, make a shit ton more money, stonks go up, and new private jet!""

Reality: nothing will work reliably, the people who have been fired will stop spending money, the economy will tank, and the most in-demand corporate skill will be Mandarin.

AI in itself is useful for low-level things like creating regexes and little bits of boilerplate. Some people are using langchain to build useful processes.

But the idea that someone who isn't that smart to start with can use it to replace entire herds of seniors by giving it a vague goal is just wacky town mental illness.",2025-04-01 10:51:29,1,TheOtherHobbes,programming
mkvi28l,1joeiaj,reddit,"Really enjoyed the post. As a senior myself, I’ve found that AI copilots don’t replace deep thinking but they absolutely speed up the path to it. Especially when refactoring or exploring unfamiliar codebases. Have you noticed any change in how juniors pick up patterns when pairing with an AI?",2025-04-01 16:02:56,1,tomasartuso,programming
mkwkjho,1joeiaj,reddit,"One thing that infuriates me about AI copilots is how they generate code with ridiculously unnecessary comments.#open the file for reading
fi = file.open('foo.txt')
#write to it
fi.write(foobar) ### note how ai didn't put it in write mode.

# take the output from the banana despensor and put it in the smoothie.
smoothie.add(bananaDespensor.get(1, BananaDespensor.STATE_FROZEN)

# turn the blender on.
blender.turnOn()

Meanwhile it can't even bother to close the file or make sure the blender is turned off at the end. Nor does it bother to check if the blender is plugged in before turning it on, but it'll give you an obvious comment about how it's turning the blender on or opening the file.",2025-04-01 19:19:28,1,blind_ninja_guy,programming
mky51k6,1joeiaj,reddit,"I think he's eventually wrong...  But I think people who are saying that all the software engineers are going to lose their jobs in the next 5 years are wildly overoptimistic/over-pessimistic.  We're at a point where the AI is smart enough to be trained to handle a single well constrained domain really really well.  What needs to happen is AI's need to go through the process of being trained to handle more and more domains, and coordinate other AIs to manage tasks within their domain.

All the work of making these AIs function and work is software engineering work, and it's going to take a long time to get AI that can meaningfully contribute in all the different domains where it can get work done.",2025-04-02 00:32:18,1,Economy_Bedroom3902,programming
mksw19p,1joeiaj,reddit,Does anyone know which paid LLM service is best as a coding assistant?,2025-04-01 03:37:12,0,moschles,programming
mkt6x1c,1joeiaj,reddit,"Methinks thou doth protest too much. 

LLMs are tools, just like linters and prettier.",2025-04-01 05:05:05,-5,ppezaris,programming
mktnrey,1joeiaj,reddit,"anyone want to redo this with gemini 2.5? seems to have stomped the benchmarks, has the latest knowledge cutoff, and most importantly has by far the largest context window with very low context falloff/degradation",2025-04-01 08:00:18,-2,JoelMahon,programming
mkuj88d,1joeiaj,reddit,"You guys sound like the old auto workers in Detroit. Robots will never make a weld like a human, because the bead will spit and leave a hole. So they invented spot welding. Then they invented gigacasting that didn’t need welds at all. And the humans got replaced anyway. 

Keep up. Disruption happens. It happened in Detroit. It will happen in Silicon Valley. ",2025-04-01 12:50:23,-2,Large-Ad7984,programming
moft2f7,1k541xl,reddit,"I never thought people would get in to cryptocurrency, then choose the one where the people that started it can just print themselves more whenever they want. I am constantly discovering new depths of systemic stupidity.",2025-04-22 14:45:46,80,GaboureySidibe,programming
mof2iqp,1k541xl,reddit,What is the file example that is corrupted?,2025-04-22 12:14:10,21,Reeywhaar,programming
mogscwm,1k541xl,reddit,Crypto scammers scamming crypto scammers?,2025-04-22 17:36:34,19,araujoms,programming
mof1ek5,1k541xl,reddit,"Hahahahaha

When will cryptobros learn (rhetorical question, for they are not capable of learning)",2025-04-22 12:06:29,116,eyebrows360,programming
mofcde2,1k541xl,reddit,"oh no

anyway",2025-04-22 13:16:05,36,fragglerock,programming
mof4mmk,1k541xl,reddit,"> the official Ripple SDK

Well there's your problem. Why would anyone seriously think they could avoid being grifted by voluntarily working in crypto, a technology that was invented solely to grift?

What the hell did you honestly expect?",2025-04-22 12:28:11,83,Djamalfna,programming
mof8qlx,1k541xl,reddit,When our descendants far in the future look back at how we ruined the planet crypto will be right there at the top as the absolutely dumbest shit.,2025-04-22 12:54:12,44,Sairony,programming
mofw6vv,1k541xl,reddit,"Hello! Creator and maintainer of vet here. We run an npm package monitor to detect malicious open source packages and retrospectively it seems like we detected it as well

The detected package versions and signals:

[https://platform.safedep.io/community/malysis/01JSD265S7K1P46FY0G90J9E5S](https://platform.safedep.io/community/malysis/01JSD265S7K1P46FY0G90J9E5S)  
[https://platform.safedep.io/community/malysis/01JSD49NEDP81SJS5WZPS84RN5](https://platform.safedep.io/community/malysis/01JSD49NEDP81SJS5WZPS84RN5)  
[https://platform.safedep.io/community/malysis/01JSD4HV7W29TJZAPNR92FPVAE](https://platform.safedep.io/community/malysis/01JSD4HV7W29TJZAPNR92FPVAE)  
[https://platform.safedep.io/community/malysis/01JSD58JJHPG7GWNVHVZKZ21JG](https://platform.safedep.io/community/malysis/01JSD58JJHPG7GWNVHVZKZ21JG)

GitHub project: [https://github.com/safedep/vet](https://github.com/safedep/vet)",2025-04-22 15:01:14,12,N1ghtCod3r,programming
mohzwwk,1k541xl,reddit,"Always enjoy your blog posts, thanks for the informative write-up. Really small annoyance: the code blocks are small compared to the actual code in them sometimes. I was a bit confused reading the line:

> It all looks normal until the end. What’s this `checkValidityOfSeed` function?

Then realised the block had a scroll bar and the actual malware was hidden below the fold.",2025-04-22 21:10:43,3,ScriptingInJava,programming
moh4csb,1k541xl,reddit,"Serves them right, maybe when enough people will be scammed and lost hundreds we will finally stop those BS and try searching for an actual use for the block chain and NFT technologies 

Also karma for that dogshit that hacked one of the most interesting FR YouTubers a few days ago (Axolot got his channel hacked and hijacked to basically stream H-24 Ripple crypto shit content)",2025-04-22 18:34:44,5,Belhgabad,programming
mogx8rw,1k541xl,reddit,so scammers are ripping off scammers?,2025-04-22 17:59:48,4,choobie-doobie,programming
mofadua,1k541xl,reddit,[deleted],2025-04-22 13:04:14,1,N/A,programming
mofuw6h,1k541xl,reddit,That's not a very nice package!!!,2025-04-22 14:54:49,1,fliption,programming
mmj5k0i,1jwiqfp,reddit,">MLKEM is not only faster, but is also now standardized by NIST.

the same people who standardized [Dual_EC_DRBG](https://www.schneier.com/essays/archives/2007/11/did_nsa_put_a_secret.html) from 2006-2014 despite the very obvious NSA backdoor and wide public criticism for 7 years? lovely",2025-04-11 08:40:56,92,Takeoded,programming
mmivi1u,1jwiqfp,reddit,"I still think it is somewhat strange to have more and more code in regards to quantum computing, without having desktop PCs be quantum computers too. Or do they plan some hybrid model? E. g. ""this is your new 20 CPU core chip; it has a secondary quantum chip only for when you really need quantum shenanigans"" (and then we have a quantum spectre exploit with multiple Schroedinger cats inside the box).",2025-04-11 06:54:10,-82,shevy-java,programming
mkcmu6a,1jmlgue,reddit,"gah. my second favorite boss ever was the bane of my existence for 5 years. it was only after he left and he wanted to poach me (absolutely shocked me, i assumed the guy absolutely hated me) that we became friendly and talked about our work experience 1:1 without filters. 

it was enlightening to say the least. turns out, i *was* a huge egotistical asshole. good at the job, just an asshole about it. i was young. people would come complain to him about me frequently and he'd just be an asshole back to me to try and make me feel how i made his other people feel. i'm not sure that's good leadership but i can't fault it and i was very young.

best lesson i ever learned; don't be a dick. 

but that was more of a soft skills thing. 😂",2025-03-29 13:12:47,462,YOUR_TRIGGER,programming
mkcot67,1jmlgue,reddit,"I worked in an org at a large company that had shifted so far into ""everyone gets a trophy"" territory that it became exhausting. Every week there was a day of appreciation where our Slack channel was filled with ""Thank you @xyz for explaining how your new feature works!"" and similar circle jerking nonsense. All championed by middle management who would also fill our calendars with team building ""fun activities"".

The engineers that were heads-down churning out business value were effectively ostracized for not being ""team players"" by thanking other people for doing their jobs.

If you **dared** to provide any feedback that wasn't 100% positive and covered in unicorn stickers, you could expect managers to start talking about how you are creating a hostile work environment.

I'm a fairly positive and empathetic person. However, I simply cannot give you a gold star and approve your PR because ""gosh darn it, you sure did try"". Nobody learns that way, nothing improves, tech debt accumulates and it crumbles under its own weight.

Being objective and honest while also instructive is part of the job. Constructive feedback fosters growth, while convincing everyone they're perfect stifles it.

So, not only is this ""tough love"" beneficial, the opposite is absolutely ruinous.",2025-03-29 13:26:02,210,vajeen,programming
mkd40u7,1jmlgue,reddit,Eventually we all realize this. Clever code is code that’s not maintainable.,2025-03-29 14:56:54,56,vehiclestars,programming
mkcvm6v,1jmlgue,reddit,Brutually honest feedback and delivering as constructive criticism aren't mutually exclusive,2025-03-29 14:08:48,42,_byl,programming
mkd0ab9,1jmlgue,reddit,"Fyi, search results are filled with AI generated tech articles with gen AI pictures as headers. So, all my brain sees in the article preview is a big ""irrelevant, and potentially incorrect made up info ahead"" sign",2025-03-29 14:35:57,64,saantonandre,programming
mkcngw6,1jmlgue,reddit,Sometimes the manager just really is a dick.,2025-03-29 13:17:05,24,stevemk14ebr2,programming
mkclgiw,1jmlgue,reddit,">Over-engineered. Too many moving parts. Refactor.

what the fuck does that even mean? Either give good feedback or don't give it at all. 

Also this AI generated image is awful",2025-03-29 13:03:22,105,yanitrix,programming
mkfjvgs,1jmlgue,reddit,"> “Over-engineered. Too many moving parts. Refactor.”

This is a terrible PR feedback and something we actively discourage on my team. 

Critical feedback is fine. However I expect it to be targeted feedback with explanations of what exactly is wrong, with suggestions for how to fix it. 

If a junior posted a CR that was so fundamentally incorrect. Then I would ask them to cancel it, write a design proposal, review that before writing more code. 

> I demoed a feature I was sure would impress him. Instead, he cut me off halfway through.

>    “This is fragile. What happens under load? What’s the rollback plan?”

> I scrambled for answers but didn’t have good ones. He paused and then said, “You’re thinking like a coder, not an engineer. Build things that survive failure.”

That is actually good feedback. It's something every junior needs to learn in their career.",2025-03-29 23:00:06,9,versaceblues,programming
mkdpvgz,1jmlgue,reddit,"Trying to put my finger on the issue I have with this.
A little respect goes a long way is the best way I can put it I guess.

Engineers seem to vastly underestimate the significance of a small amount of kindness in their approach as younger developers are going to learn from them not just technically but in the type of culture they will maintain.

If a PR is that off the mark, and yes over engineering means that the intent and desired outcomes were either not clearly communicated or simply ignored, then a simple comment of, “Hey great effort. There’s a few things that i wanna go over with you as some of these changes might be beyond the scope of the acceptance criteria”

Then you can explain all the functionality/scalability/maintainability issues on a call or an in-person meeting etc.

And to head off any issues of whether the tech lead or engineering manager has time for that, understand that the time spent putting together a huge PR that won’t get merged and then redo the work and put together another one, on top of the engineering leads reviewing both of those iterations, is significantly longer than an hour or so with a jr dev to explain some of the concepts and desired solution types they’re looking for",2025-03-29 16:56:26,8,BellPeppersAndBeets,programming
mkck30i,1jmlgue,reddit,"The manager I hated taught me how to spot bosses who like nose candy. He was the owner, not my direct manager, but he eventually made a bunch of deals he knew the company couldn’t deliver on and took the money and ran. No idea what happened to him after that, but he has basically no online presence, which is interesting.",2025-03-29 12:53:53,11,remy_porter,programming
mkcx5y3,1jmlgue,reddit,"Can we stop with the pop-overs that don't disappear when clicking behind them?

Thanks.

Also this feels like a linkedin post.  And it doesn't contain code.  It's about the arbitrary and frustrating structures surrounding coding.",2025-03-29 14:17:55,10,PurpleYoshiEgg,programming
mkd8l6m,1jmlgue,reddit,"A manager that reads code? Give me one of those! I have managers that think everyone's perspective is equally valid, who tell me that ""perception is reality"" and urge me to play politics.  Perception is not reality! When you perceive reality wrong, reality hits you in the face!",2025-03-29 15:22:04,8,TommyTheTiger,programming
mkgwvun,1jmlgue,reddit,"Idc if the article is good, everything with a shitty ai picture should be banned categorically. Give everyone who posts it 6 month, too",2025-03-30 04:13:04,2,Bananenkot,programming
mkecl49,1jmlgue,reddit,"I worked out the Mikado Method from first principles just a bit before the time the book was published. That old line about “standing on the shoulders of giants” is very true. The state of the art sets the preconditions for the next advance and anyone who has the right synapses fire can discover that A + B = C now that B is known. 

The big selling point that I use on other people is that once you know the crux of a problem, many of the pieces you think you need are irrelevant and should be dropped, which Mikado does handily. The same way that scientific experiments prove that 2 inputs result in an outcome and any other qualities are largely irrelevant. 

The problem with understanding this is that it’s like understanding that you don’t need all the shit that is filling up your garage so you can’t get your car into it anymore. It’s a start but now you have to overcome your attachment and sunk cost fallacy to do something about it. 

People hate to delete code, even if it’s code that nobody else has even used yet. I don’t know which is the cart and which is the horse, but I think it’s tied to the notion of lines of code being a proxy for effort. That deleting lines means you wasted time and effort, instead of saving it in the future by saying what you mean in fewer statements.",2025-03-29 18:56:49,1,bwainfweeze,programming
mkeh3sp,1jmlgue,reddit,"I just don’t understand how code that is unreadable, that is tailored around ideal cases, and is written such that the next person who reworks it cannot grasp its meaning (quite similar to unreadable code) can be defined smart, do you?",2025-03-29 19:21:25,1,perx76,programming
mkexjl1,1jmlgue,reddit,I don’t understand what it means by “clever code”.  Clever code to me was always the simplest and elegant implementation devoid of unnecessary complexity.,2025-03-29 20:51:30,1,hoexloit,programming
mkhp5wu,1jmlgue,reddit,This only works if the manager itself is a senior programmer. I worked under a non technical manager and it totally sucked.,2025-03-30 08:55:45,1,pratik6158,programming
mkhzd4t,1jmlgue,reddit,"That kind of behaviour would get them to HR in many companies coz he was ""hurting feelings"" of people that cosplayed as engineers/developers in the organization",2025-03-30 10:45:05,1,CrunchyTortilla1234,programming
mki2bis,1jmlgue,reddit,"Damn, the manager was 100% right. He did not deserve any hate.",2025-03-30 11:13:55,1,Nicolay77,programming
mki2pa6,1jmlgue,reddit,Sounds like someone needs to implement some human firewall training. Anyone decode what 'Overlegment' means here?,2025-03-30 11:17:34,1,RedGrdizzlybear,programming
mkihxzn,1jmlgue,reddit,"I’m not saying that the boss’ criticism was wrong - what I’m saying is that he’s a dick, and not a very good leader.

The world needs people who demand competency, but it does not need people who are that publicly critical without giving proper feedback 1:1.",2025-03-30 13:17:38,1,mega-man-0,programming
mkiv5k7,1jmlgue,reddit,"Leading by example would have likely been a better approach. Displaying the type of behavior he was looking for you to internalize probably would help you grow faster than reinforcing your rude behavior with his own bad behavior. Especially since you admitted to being immature and likely not great on picking up on social queues. Also, giving you honest empathic feedback both on what you were doing well and on behavior he found subpar would have likely had gotten you to a better place faster.",2025-03-30 14:37:29,1,eleric71,programming
mko1c1z,1jmlgue,reddit,"Now will be:

* AI - submits code
* Reviewer - This sucks, here's why
* AI - I'm sorry let me correct this for you - proceeds to give another shitty solution

Vibe and repeat.",2025-03-31 11:18:07,1,mikaball,programming
mkwsgwc,1jmlgue,reddit,"yeah, this was a good piece, and it was brief and to the point. approved. shipit.",2025-04-01 20:00:20,1,metaphorm,programming
mkd3a7k,1jmlgue,reddit,who goes to all that trouble on that website to make the scrollbar like half the size or smaller.  Looks like there needs to be some application of the lessons.,2025-03-29 14:52:50,1,dalittle,programming
mke03cx,1jmlgue,reddit,"People don't realize how hard it is providing genuine feedback and review, let alone trying to be kind about it. Most folks, myself included, move to a dispassionate direct mode of feedback just because it takes too much energy to be empathetic every single time.",2025-03-29 17:49:36,0,appoloman,programming
mkffauj,1jmlgue,reddit,Chatgpt is on fire today. It's sad that we are discussing such garbage.,2025-03-29 22:33:16,-1,YahenP,programming
mnl7djp,1k1d4d2,reddit,You mean database is not bits floating around on cloud? Weird.,2025-04-17 14:17:16,275,robberviet,programming
mnl2zr2,1k1d4d2,reddit,"Next up: ""Databases are just bits sitting on long-term storage, accessible via the I/O mechanisms provided by the operating system.""",2025-04-17 13:54:31,963,qrrux,programming
mnle9r0,1k1d4d2,reddit,"Okay I got a good chuckle out of the smart ass comments, but in all seriousness sometimes just reminding developers of these base concepts can be helpful. We deal in a world with so many abstractions on top of abstractions that it can be easy to lose sight that everything is built on some pretty core mechanisms. These concepts do still come up from time to time when working on things like query optimization for e.g.",2025-04-17 14:51:20,193,jardata,programming
mnl7zhx,1k1d4d2,reddit,In other news: Cloud is just other people computers,2025-04-17 14:20:20,331,AlphaX,programming
mnl8tv9,1k1d4d2,reddit,Data is just data really.,2025-04-17 14:24:32,32,ziplock9000,programming
mnljkcz,1k1d4d2,reddit,"I remember early in my IT career I was shocked to learn that the windows registry was a file. I mean it makes perfect sense, I just never thought about it",2025-04-17 15:16:58,29,duckwizzle,programming
mnlq32c,1k1d4d2,reddit,Everything’s computer,2025-04-17 15:48:24,20,justAnotherNarwhal2,programming
mnlg2ux,1k1d4d2,reddit,"Hm, ok... what did people think they were backed by? The Holy Ghost?",2025-04-17 15:00:00,39,cazzipropri,programming
mnlloml,1k1d4d2,reddit,"> It’s a complex and powerful system—but fundamentally, it’s just an executable that manipulates files.

...is like ""It's a complex and powerful engine, but fundamentally SpaceX Raptor is just a bottle that spits fire.""",2025-04-17 15:27:16,41,wxtrails,programming
mnm49co,1k1d4d2,reddit,"Some enterprise level databases use disk partitions for storage, instead of files.

An extra level of speed at the price of complicated kernel level access.",2025-04-17 16:57:04,11,fried_green_baloney,programming
mnllxek,1k1d4d2,reddit,(All) Excel files are just databases.,2025-04-17 15:28:27,10,cbojar,programming
mnmba9z,1k1d4d2,reddit,"I think this is missing the point of SQLite's being ""just files"":

> You just need a mental model of the system as a set of files, a process, and a config.

This both oversells the complexity of SQLite and *undersells* the complexity of Postgres and MySQL.

MySQL is closer to that, but its process is also replacing a big chunk of what the OS usually does with files. Usually, you want to configure it with `O_DIRECT` -- it does its own buffering and caching, instead of relying on the OS-level buffers/cache. This isn't true of Postgres.

Meanwhile, Postgres isn't *one* process, it's a whole tree of cooperating processes.

You also probably want to start some processes of your own and talk to the DB, which means you now need either IPC or networking. For a local dev environment, you'd at least be looking into stuff like Unix sockets...

At the other extreme, SQLite isn't even a process. Or a config, really. It's a *file format.* It's beloved for being simple, but it's not just that we've demystified that it's ""just files"", it *really is* just files. It really is a meaningfully simpler design.

---

So... it's hard to argue that this is entirely wrong:

> Once that veil of ignorance is lifted, everything becomes simpler: debugging, provisioning, versioning, backups, and even just experimenting with settings...

> You’ll move with more confidence, build cleaner workflows, and stop treating your database like a black box.

Except I think being overly-reductive and treating it as ""just files"" is another way to treat it like a black box.

For example: Need to back up your data? If your mental model is entirely ""A process, a config, and some files,"" then you'd build a backup system like

    systemctl stop postgres
    tar cpSf backup.tar /var/lib/postgres
    systemctl start postgres

That... *works,* but it's of course *massively* disruptive to a production system. So either you can treat this as even more of a black box and take a block-device-level snapshot, or you can at least learn about things like `pg_start_backup()` and `pg_basebackup` to be able to safely work with those files without having to shut the whole DB down just to take a backup.",2025-04-17 17:30:26,9,SanityInAnarchy,programming
mnlhlbe,1k1d4d2,reddit,Did you know an HTML table is not made of actual wood??,2025-04-17 15:07:24,15,josfaber,programming
mnlps7s,1k1d4d2,reddit,"some db systems do run on top of block-oriented storage devices directly, not storing data backended by normal files-in-a-filesystem, especially historically where the rdbms (or other dbms) arguably was the machine os too.  

Preemptively: while block devices are themselves often represented as funny ""block special files"" [representing the devices](https://en.wikipedia.org/wiki/Device_file), especially on unix/unix-like/linux operating systems, that also *doesn't* actually have to hold true in operating system design in general either e.g. [AmigaOS Exec devices](http://amigadev.elowar.com/read/ADCD_2.1/Libraries_Manual_guide/node029F.html) actually just have their own `DoIO(struct IORequest iorequest)` API that is not presented as some sort of overloaded C file/file-like `open()`/`seek()`/`read()`/`write()`/`close()` (... and of course `ioctl()` [for](https://en.wikipedia.org/wiki/Ioctl) all the stuff that doesn't fit into the paradigm...) API in the first place.

(The other way to look at it is of course typical hierarchical/dag filesystems are themselves a kind of database, filenames as query strings for data blobs, but filesystems are typically anaemic in areas like transactions etc.)",2025-04-17 15:46:57,6,lood9phee2Ri,programming
mnlrecx,1k1d4d2,reddit,I mean sort of?  But there have been databases that allow you to use raw storage rather than sit on top of a filesystem?,2025-04-17 15:54:43,7,jcGyo,programming
mnlhog3,1k1d4d2,reddit,"Sure, and it's all just electrical impulses on a rock we tricked into thinking too.",2025-04-17 15:07:49,6,fzammetti,programming
mnlhkn3,1k1d4d2,reddit,"No!


Databases are magic!",2025-04-17 15:07:19,5,s-mores,programming
mnlk67e,1k1d4d2,reddit,(All) Operating Systems Are Just Programs. Windows Too,2025-04-17 15:19:54,4,two_bit_hack,programming
mnm9e5m,1k1d4d2,reddit,"TIL files can deal with distributed consensus \s

Databases are __not__ just files. They are the semantics of the database, which may (but not always) use file system APIs as a part of their implementation to persist data. Most file systems are not ACID and the entire existence of databases is to get around that fact, otherwise we would live with open/close/read/write/fsync and be done. 

In fact many of the fancier file systems are implemented as databases underneath, so they can't be ""just files.""",2025-04-17 17:21:31,4,International_Cell_3,programming
mnn9gpg,1k1d4d2,reddit,Filesystems ARE key-value databases.,2025-04-17 20:18:52,3,chadmill3r,programming
mnll2gp,1k1d4d2,reddit,"Wait till you find out Oracle can store its tablespaces on raw partitions, no filesystem, no files.",2025-04-17 15:24:18,6,jfedor,programming
mnm4hst,1k1d4d2,reddit,"I will pedantically disagree. I used a horror show of a sybase database some time ago where it used a ""raw"" partition. 

That is, the database entirely took over the unformatted hard drive. Using horrible commands you had to tell it how much of the hard drive would be dedicated to indexes, data, etc. The weird part was that you had to ""tune"" this over time, so the best thing was not to preallocate the whole drive, but just roughly what you needed. Then, later you would add (not expand) new partititions to handle new things. 

Other major DB vendors of this era also had (have?) this feature.

Guess how much fun it was to duplicate or backup this DB? What made it extra fun was that using their backup process wasn't clean when it came to memory or storage. Thus, to backup the DB you needed way more storage than what you were backing up, and you needed massive amounts of RAM. A backup of a 10GB database on a modern machine running this setup could take more than 24h. The ""easy"" way was to use disc duplication tools and just copy a pulled HD. Even raid struggled with this mess.

This crap architecture would buy you maybe 5% more performance.",2025-04-17 16:58:10,8,LessonStudio,programming
mnng8pk,1k1d4d2,reddit,"Ultimately, everything is a file.",2025-04-17 20:51:55,3,Stilgar314,programming
mnljtob,1k1d4d2,reddit,"
Its basically all atoms anyway",2025-04-17 15:18:14,2,NotGoodSoftwareMaker,programming
mnllmb9,1k1d4d2,reddit,Websites are just skins for databases ,2025-04-17 15:26:58,2,BoKKeR111,programming
mnlm0ts,1k1d4d2,reddit,"As long as the bits coming out looks vaguely like the bits coming in, no one care what's in the box.",2025-04-17 15:28:55,2,Pomnom,programming
mnmmkut,1k1d4d2,reddit,I just assumed little Asian guys were writing things down somewhere.,2025-04-17 18:24:33,2,kurtcanine,programming
mnmpq0e,1k1d4d2,reddit,You should see what we did with some rocks and lightning.,2025-04-17 18:40:18,2,b_rodriguez,programming
mnn0zh5,1k1d4d2,reddit,"Everything is a file. Even my cat. It processes things. On the one side it gets food. On the other side I think it ... leaves behind gold coins (I think!).

The file-like-an-object model is very powerful (e. g. as a UNIX/Linux pipe model) because I feel it is so simple and pervasive. You can extend it to, say, a function: a function slurps up input, does something wonky with it, and outputs greatness (or a bug, depending on how the code was written). A similar rationale can be applied to a method, an object and messages, probably also a monad (they are scary, but I think they probably also do useful things and could be compared to everything-is-a-file; I don't really understand them, so I am not sure, but people who know what a monad is, probably can explain if and how monads rely to a file-model / pipe-model / object-model.

One thing I found a bit difficult in regards to databases is SQL. Now, SQL is fairly simple, select all from xyz and similar magic, but it never ""felt"" easy on my brain. To me, treating it more as an object, felt more natural (though I also find activerecord, sequel etc... not that easy either, but that's a separate issue). I don't know how SQL would be ""like"" if it were ""just a file"" or files, but perhaps it may be easier or better.

Although I think Postgresql is great, people may find it much easier to access the SQL world via sqlite. At the least to me that seemed so much simpler, even if postgresql is faster (at the least that was my impression for large datasets).",2025-04-17 19:36:51,2,shevy-java,programming
mnpdtmm,1k1d4d2,reddit,In 2025 people are discovering that the Unix principle that everything is a file is a good abstraction.,2025-04-18 03:50:02,2,RoomyRoots,programming
mnphkh6,1k1d4d2,reddit,Wow No way,2025-04-18 04:19:24,2,Snow-Crash-42,programming
mnpmxl6,1k1d4d2,reddit,Everythings computer,2025-04-18 05:05:14,2,elongio,programming
mnlozcy,1k1d4d2,reddit,In other news bytes are just bits.,2025-04-17 15:43:05,3,ZealousidealFudge851,programming
mnlo3md,1k1d4d2,reddit,"Well, this is incorrect in many ways.


A database is just organized data. A **printed** phone book is a database. So, a lot of databases existed before we have files (but computers) and before that computers.

A *relational* database is organized data using the relational model (most know *informally* as bunch of tables). Critically, *relational* not mean the PK, FK and how you connect tables. 'Id:I32=1' (or even '1' if have type inference) is a relation.

What some developers call databases are in fact database *managment* systems. They are what are in charge of HOW deal with the concept of `database` and interface with the hardware/os, that most of time, could store them in files.

So, an `csv`, `json` are databases. But not relational (because you don't have a way to execute relational operator, that is the other side to make it a `relational database`, ie: it must have code+data in relational terms).",2025-04-17 15:38:52,3,mamcx,programming
mnlmsv7,1k1d4d2,reddit,A lot of the smart ass comments are missing the point,2025-04-17 15:32:40,2,AcanthisittaScary706,programming
mnm65sg,1k1d4d2,reddit,And all filesystems are just databases.,2025-04-17 17:06:09,2,MC68328,programming
mnmddv4,1k1d4d2,reddit,Its all just energy,2025-04-17 17:40:22,2,umangd03,programming
mnlau7h,1k1d4d2,reddit,"All code is just text, too",2025-04-17 14:34:35,3,cheffromspace,programming
mnlhxhr,1k1d4d2,reddit,"Is it SQLite commonly used by apps, e.g. web browsers?   User app has a good chance to use a library which takes over the handling of queries and responses, writing directly to DB-file on disk without any DB-server be involved.",2025-04-17 15:09:03,1,Biyeuy,programming
mnm0zfz,1k1d4d2,reddit,">An `UPDATE` eventually becomes: open a file, write to it, close it. It’s a complex and powerful system—but fundamentally, it’s just an executable that manipulates files

  
now, imagine that those operation are made by at least 10 users on the same machine at the same time  
now, imagine that those 10 customers are expecting food delivery ?

It will be luck if those 10 customers get what they order if database are just manipulating files",2025-04-17 16:41:21,1,gjosifov,programming
mnm2u3a,1k1d4d2,reddit,"Huh, that makes me wonder: I don't know much about this, but are there any databases that operate with raw access to their own dedicated disc(s) just for database storage, and the low-level formatted structure on that disc is designed around the database, without using the OS file system as an intermediary?",2025-04-17 16:50:20,1,BellerophonM,programming
mnm4l0z,1k1d4d2,reddit,"So weird, and wrong in some ways (while saying some sorta good stuff otherwise).  Of course Postgres databases aren't just files.  They're running programs that happens to use files for persistence.  The difference is important.  

Sqlite actually is just a file and the sqlite library does all the processing on it inside the app.  All other databases *have services doing that*.  There's indexers running, there's translators running.  And so on.

That's like saying every major enterprise app is ""just a webpage"".  No it isn't.  It has a backend that's 90% of the app that doesn't even touch html directly.",2025-04-17 16:58:36,1,novagenesis,programming
mnmom7s,1k1d4d2,reddit,The internet is just an app running on some databases.,2025-04-17 18:34:46,1,flightsin,programming
mnmwuwh,1k1d4d2,reddit,In Linux everything is a file,2025-04-17 19:16:01,1,ThreeLeggedChimp,programming
mnn3l58,1k1d4d2,reddit,"It is actually intersting, dont stop at the title.

tl;dr: postgres DBs can also be transfered around like sqlite files, except it is a directory:

> At its core, postgres is simply a program that turns SQL queries into filesystem operations. A CREATE TABLE becomes a mkdir. An UPDATE eventually becomes: open a file, write to it, close it. It’s a complex and powerful system—but fundamentally, it’s just an executable that manipulates files.

> These files live in the so-called data_directory, often referenced by the PGDATA environment variable. To create that directory from scratch, you can run:

> initdb /tmp/db0

> Now you can start a PostgreSQL server using:

> PGPORT=1991 postgres -D /tmp/db0 -c shared_buffers=""10GB""",2025-04-17 19:49:42,1,keepthepace,programming
mnnb0wx,1k1d4d2,reddit,Just files in your shitty dev setup that nothing is using. A little different when there’s a million online users actively using it.,2025-04-17 20:26:32,1,Empty_Geologist9645,programming
mnorxie,1k1d4d2,reddit,lol!,2025-04-18 01:22:46,1,diagraphic,programming
mnpqruj,1k1d4d2,reddit,A fuel motor is just controlled explosions.,2025-04-18 05:40:27,1,kobumaister,programming
mnqfan0,1k1d4d2,reddit,If you wish to make a database from scratch you must first invent the universe.,2025-04-18 09:53:10,1,GaryChalmers,programming
mnsb2s3,1k1d4d2,reddit,"Complete insanity. Unless you’re the dba you just need a specific version of Postgres and specific versions of plugins. Sure you might want to mimic the config, but that can be done with a sudo systemctl Postgres restart or container restart.",2025-04-18 16:50:01,1,BiteFancy9628,programming
mnscgxv,1k1d4d2,reddit,Some databases write directly to block devices.,2025-04-18 16:56:51,1,PopFun7873,programming
mnsyzwn,1k1d4d2,reddit,"Nah, In-Memory DBs have no file representation. Some have a history, but that’s not the DB.",2025-04-18 18:48:58,1,ArgumentFew4432,programming
mnw395h,1k1d4d2,reddit,All databases are just DETAIL https://medium.com/@vbilopav/clean-architecture-book-review-and-analysis-the-database-is-a-detail-eda7424e8ce2,2025-04-19 07:04:05,1,vbilopav89,programming
mnw3f5b,1k1d4d2,reddit,Files are just carefully aligned rust particles on a spinning al disc.,2025-04-19 07:05:48,1,ChrisOz,programming
mnwgx8i,1k1d4d2,reddit,"other fun fact: humans are, in fact, animals.",2025-04-19 09:28:36,1,FederalRace5393,programming
mnzg45f,1k1d4d2,reddit,"Didn't Oracle use a raw partition mode? 

If there is no filesystem are they still files?",2025-04-19 20:35:16,1,Amazing-Mirror-3076,programming
mo6886p,1k1d4d2,reddit,Databases are not “just” files.,2025-04-20 23:45:35,1,MiddleSky5296,programming
moh3okz,1k1d4d2,reddit,"do one on images just being files next!


also, In-memory databases aren't files so you might want to update that title",2025-04-22 18:31:22,1,choobie-doobie,programming
mnl8dj1,1k1d4d2,reddit,It's like uncle bob when he said microservices are only a deployment strategy,2025-04-17 14:22:17,1,bunglegrind1,programming
mnlehfy,1k1d4d2,reddit,All applications are just databases.,2025-04-17 14:52:21,1,Isogash,programming
mluwp9z,1jtkfpq,reddit,the points listed are such common sense yet lots of enterprise programs I've seen go haywire because the basics of common sense are not applied,2025-04-07 13:15:13,75,LowB0b,programming
mlxatj4,1jtkfpq,reddit,"> Code should read as if it was written by a single human. There should be a consistent and uniform code style all over, as that helps us read code better. Wrong or inconsistent code style is a bug. We fix all bugs we find.

Good god every developer who rebels against linting needs to read this over and over again until it sinks in.

And actually, I needed to read it too. I hadn't thought of how to put into words _why_ linting is so important and this is so succinct and clear that I love it.",2025-04-07 20:42:33,21,chalks777,programming
mlv3ml9,1jtkfpq,reddit,"> Warning-free

> While it should be natural to everyone already, we of course build all curl code entirely without any compiler warning in any of the 220+ CI jobs we perform. We build curl with all the most picky compiler options that exist with the set of compilers we use, and we silence every warning that appear. We treat every compiler warning as an error.

Does he mean they fix every warning when saying ""we silence every warning that appear [sic]""?",2025-04-07 13:56:41,68,Ratslayer1,programming
mlw9xlh,1jtkfpq,reddit,"These are the simplest standards I've ever seen.  And I've seen so many companies not live up to them. 

>C is not memory-safe

Yup.  But you can write it cleanly, and if you use applications like valgrind to test your code you can feel even more safe in your assumptions. 

> Warning-free

Fucking hell yes.  Though I will say C has some !@#$ing warnings.  ""OH are you sure you want to use this?"" YEs.. YES I DO  stop asking me.  (You literally have to use -Wno-psabi to silence them. WTF C/C++) 

I prefer python because you can silence linter warnings at times... but in general Warnings are warnings for a reason.

>Avoid “bad” functions

If you don't know any of these... you need to. (Sprintf?  Strcpy? )  honestly I almost think those should be removed, but that would break applications of course because people don't know them and used them

>keep master golden

MMMMMM   This is the one I love. You NEVER work in the Ship branch.  I'd argue ""Master"" is the wrong word,  Final or ship is better, but agreed there's a clean branch somewhere that can NEVER EVER EVER EVER be broken.  And people should be starting by cloning using that, not other people's work branches.   The amount of times I've been boned because the ""Dev branch"" is broken and left broken for weeks is not acceptable. 

>Always check for and act on errors

""This never happens"" Great throw a log, throw an exception, throw X  Because ""Never happens"" becomes ""happens once"" real quickly.

>  We do. We are human. We do mistakes. Then we fix them. 

Words to live by.",2025-04-07 17:34:07,18,Kinglink,programming
mluyg21,1jtkfpq,reddit,"All that, and they *still* have tons of bugs and vulnerabilities due to C:

> We are certainly not immune to memory related bugs, mistakes or vulnerabilities. We count about 40% of our security vulnerabilities to date to have been the direct result of us using C instead of a memory-safe language alternative...Over the last 5 years [out of 29 years], we have received no reports identifying a critical vulnerability and only two of them were rated at severity high. The rest (60 something) have been at severity low or medium.",2025-04-07 13:26:04,44,gwern,programming
mlxlo5j,1jtkfpq,reddit,"> In early 2023 we dropped support for building curl on systems without a functional 64-bit integer type.

With many core OSS projects now doing this, I wonder how fast Debian is going to drop x86-32. Good riddance, though &mdash; it's just too much work to keep supporting it.

> We build curl with all the most picky compiler options that exist with the set of compilers we use, and we silence every warning that appear. We treat every compiler warning as an error.

Wait... every possible warning for every compiler? Curl supports [an ungodly number of configurations](https://daniel.haxx.se/blog/2023/11/14/curl-on-100-operating-systems/). Maybe I'm just used to [superfluous warnings in other languages](https://rust-lang.github.io/rust-clippy/master/index.html?groups=pedantic) but that sounds super impressive.",2025-04-07 21:40:52,6,Booty_Bumping,programming
mly6wfu,1jtkfpq,reddit,Can I just comment on what a pleasure it is to access a new website and not be immediately assaulted by a cookies popup.,2025-04-07 23:42:02,6,jdehesa,programming
mlv3908,1jtkfpq,reddit,80 columns and preferring short names in 2025? Did this get posted a week late?,2025-04-07 13:54:34,28,Spaceman3157,programming
mlz734h,1jtkfpq,reddit,"My native language is not English. I want to ask, is ""write C in curl"" correct? I think it should be ""write curl in C"". //the sentence is from the first sentence in the article, not title.",2025-04-08 03:26:52,3,heroboy,programming
mm7v660,1jtkfpq,reddit,The C89 requirement is archaic. 1989 is 36 years ago. I wonder if there is anyone out there who is building and using curl in an environment where a C99 compliant compiler isn't available.,2025-04-09 14:35:13,2,setuid_w00t,programming
mn3bnoe,1jtkfpq,reddit,this subreddit is just bots commenting to bots arguing about AI,2025-04-14 17:14:59,1,NoleMercy05,programming
mlv7qru,1jtkfpq,reddit,"Those complaints remind me of why I wrote [my language](https://bolinlang.com/). But you can consider it dead for now since it's going to be awhile before I want to write an entire standard library. Writing a compiler showed me how obnoxiously bad debuggers were. Why can't I have a collection of breakpoints that I can enable together?, or watch variables based on the function I'm in?",2025-04-07 14:18:56,-8,levodelellis,programming
mlwj02h,1jtkfpq,reddit,"Rewrite in Rust already!!!!

(I am not serious - I just want to ride the wave ... \o/ )",2025-04-07 18:19:19,-10,shevy-java,programming
mkaseiu,1jm79rv,reddit,"Long is commented out here: https://github.com/mortdeus/legacy-cc/blob/936e12cfc756773cb14c56a935a53220b883c429/last1120c/c00.c#L48

Is there a story behind that?",2025-03-29 02:58:49,33,Ok-Bit8726,programming
mk9l7v3,1jm79rv,reddit,"This cannot be the first C compiler, as the source is clearly written in C.",2025-03-28 22:43:58,115,vytah,programming
mkca2b3,1jm79rv,reddit,"https://github.com/mortdeus/legacy-cc/blob/master/last1120c/c00.c

Old C was indeed a lot uglier than Modern C - which is also pretty ugly.

It feels as if C is just syntactic sugar that reads a bit better than assembler. Basic logic in a function is semi-hidden after some syntax noise:

    while(i--)
      if ((*sp++ = *s++)=='\0') --s;
         np = lookup();
         *np++ = 1;
         *np = t;

Oddly enough I haven't seen this before:

    i =% hshsiz;",2025-03-29 11:35:10,6,shevy-java,programming
mkbvwdg,1jm79rv,reddit,[deleted],2025-03-29 09:06:56,-16,N/A,programming
mkcjqzy,1jm79rv,reddit,Against proving tabs has always been superior.   …++,2025-03-29 12:51:32,-5,Shock2k,programming
mlwbkez,1jtr45e,reddit,I'm thrilled this joke is entirely recyclable from IOT,2025-04-07 17:42:06,196,elprophet,programming
mlynn8l,1jtr45e,reddit,"Me: ""wtf is MCP?""  
Google: ""Think of MCP like a USB-C port for AI applications.""  
Me: ""wtf""",2025-04-08 01:23:34,126,MooseBoys,programming
mmcrgcs,1jtr45e,reddit,Great article just added it to Awesome MCP Security [https://github.com/Puliczek/awesome-mcp-security](https://github.com/Puliczek/awesome-mcp-security) :),2025-04-10 08:01:13,21,Puliczek,programming
mlwn7aa,1jtr45e,reddit,lol I'm going to make so much money helping companies unfuck themselves after this AI wave,2025-04-07 18:40:54,97,-grok,programming
mlwci9n,1jtr45e,reddit,"It's also interesting that there's possibility for remote remote execution... I need to think through this more, but I'm envisioning a scenario where one mcp instructs the agent in a way that triggers an RCE in a second MCP",2025-04-07 17:46:45,45,elprophet,programming
mlwvtt6,1jtr45e,reddit,"When I saw the first specification of the MCP protocol I was immediately struck by the fact that they have not specified any authentication for a protocol meant to be used over network. Only in the newest version, some utterly complicated authentication mechanism (some kind of double OIDC) is specified. Why does someone, nowadays, design a protocol mostly  useful for desktop clients (missing authentication, STDIO as standard protocol, the SSE based protocol was initially underspecified)? We live in the time of web applications!",2025-04-07 19:25:17,45,BlackSuitHardHand,programming
mlyz5y2,1jtr45e,reddit,"Just read the authentication section of the MCP spec. It is so spectacularly bad...

1. It is not a draft, yet it requires OAuth 2.1 complience - which is still a draft.

2. The spec starts with an exclusion that it does not apply to non-HTTP protocols. There is no spec for how to do auth on those in the spec.

3. It arbitruary regulgulates portions of OAuth spec, such as redirect URL validation. Despite that being already implied at the start. And the regulgulated requirements are weaker than in the original.

4. It lacks any meaningful constraints on implementation. For example, Access tokens must be subject to a lifetime, but setting life of a token to thousand years would be totally fine by this spec.

A way better version of the spec would've had just two lines:

> MCP server SHOULD require OAuth 2 authentication.

> MCP client MUST support OAuth 2 authentication.

The plephora of weak restatements of OAuth 2 spec, arbitrary domain name restrictions and extensive examples only muddy the waters without adding anything to MCP security beyound what a faithful OAuth 2  implementation would.",2025-04-08 02:34:18,23,voronaam,programming
mlyy15z,1jtr45e,reddit,"Has anyone looked at MCP, specifically the underlying protocol? They are incredibly simple. Like dumb simple. It's not made for this, it's made for very simple, very controlled situations.",2025-04-08 02:27:06,9,deadwisdom,programming
mlyfj41,1jtr45e,reddit,">  What Can You Do?

Not use MCP?",2025-04-08 00:34:07,13,chat-lu,programming
mm0626f,1jtr45e,reddit,My first reaction to the AI boom was considering a career change into security research.,2025-04-08 08:50:52,5,hejj,programming
mly7u6x,1jtr45e,reddit,">Spoiler: it doesn’t. But it should.

I mean even if it did, there's a problem with the ""S"" standing for Security in MCP.",2025-04-07 23:47:33,4,Kinglink,programming
mlyzlea,1jtr45e,reddit,Future is looking bright for senior+ engineers who are seeing this unfold in real time.,2025-04-08 02:37:02,6,pfc-anon,programming
mm1toqf,1jtr45e,reddit,"If you are building something like this, where an LLM is generating code to work against APIs, consider using `deno` as the language it generates rather than python.

Deno programs can be run with specific permissions, meaning the generated code cannot access the file-system, make network requests against non-whitelisted hosts, execute arbitrary shell commands and such.

Obviously these programs can still busy-loop or try and escape the sandbox via vulnerabilities but it vastly reduces the surface area you are covering as compared to running arbitrary generated python or bash code.",2025-04-08 15:38:32,1,CVisionIsMyJam,programming
mlwq19k,1jtr45e,reddit,">There’s no mechanism to say: “this tool hasn’t been tampered with.” And users don’t see the full tool instructions that the agent sees.

How would that even work? That's not how networked services work.

How do I know if my bank website has been ""tampered with?"" How do I know if gmail has been ""tampered with""?",2025-04-07 18:55:13,-11,Mysterious-Rent7233,programming
mlxlx5x,1jtr45e,reddit,"Oh no! Anyways, MCP is a pretty cool open standard that is going to unlock a lot of the problems that AI has today around liveness of data. I'm looking forward to it becoming far more robust support in the spec over time.

And for those who continue to object over ""security"", it's worth actually engaging on the topic instead of crying about it because it's literally being worked on: https://github.com/modelcontextprotocol/specification/pull/133",2025-04-07 21:42:12,-28,phillipcarter2,programming
mny0y1q,1k2uy82,reddit,"This is a very interesting tool. I usually try to make sure that my programs do not carry any exclusive information in color, but so far I haven't verified that for example the contrast would still be high enough.",2025-04-19 16:00:39,48,dravonk,programming
mnxvhui,1k2uy82,reddit,Why is the Readme so poorly written? ,2025-04-19 15:32:11,41,WackoDesperado2055,programming
mnz4bcj,1k2uy82,reddit,"[Here is a dramatically better discussion on color blindness](http://www.daltonize.org/)

[And here is how little code it takes to convert RGB color to something a colorblind person can see](https://miko.art/labs/Color-Vision/Javascript/Color.Vision.Daltonize.js)

[Also simulation code](https://miko.art/labs/Color-Vision/Javascript/Color.Vision.Simulate.js)",2025-04-19 19:29:48,9,Craiggles-,programming
mo3hn1m,1k2uy82,reddit,"Dumping code out in the open before the CCP gets their hands on it?

God I can't wait for Ubishit to finally die.",2025-04-20 14:37:51,-3,cake-day-on-feb-29,programming
mn1xa6c,1jyxu3p,reddit,Sometimes the cost of not deciding or taking too long to make the call is higher than the cost of making the wrong decision.,2025-04-14 12:48:13,313,One_Economist_3761,programming
mn24fst,1jyxu3p,reddit,"I feel like the one thing this post is missing is that not only is it okay to be wrong, it's also okay to change your mind on a decision.

There obviously may be a cost associated with switching tack but this can still be desirable over no decision / action.",2025-04-14 13:32:11,185,nicholashairs,programming
mn235cx,1jyxu3p,reddit,"Maybe when you are not able to commit to a solution as a senior engineer is because of lack of context. 

I don't think the proposed solution of faking confidence  is the correct approach.

What I would propose to do is to organize two small POCs with focus points, collect data and evaluate both solutions. At the end of the day engineering is not about options but hard data.",2025-04-14 13:24:30,59,AlphaFarmer42,programming
mn2hp2m,1jyxu3p,reddit,"I think most experienced engineers will (imo, wisely) avoid committing to things they don't have enough control over.

It's not even about being wrong or right, it's about avoiding the possibility of getting thrown under the bus and being blamed for the consequences of things you couldn't have foreseen.

PMs and management are frequently looking for ways to shed accountability if they don't meet their goals, don't willingly be their stooge. Remember, even if you put your skin in the game for them and succeed, they will still get most of the credit for it regardless.",2025-04-14 14:44:34,52,SanityAsymptote,programming
mn27g9h,1jyxu3p,reddit,"Just `git commit -m ""My update""` bro, it takes 2 seconds.",2025-04-14 13:49:38,77,poop-machine,programming
mn3xtwp,1jyxu3p,reddit,"Why does the kicked dog cower? Because it fears the boot is coming again.

If your senior and staff and whatever the fuck you're calling them this week engineers are remaining noncommittal, look into why. You'll probably find a management culture that is, at best, indifferent to suggestions from engineering, and more than likely actively hostile to them.

I worked at a company once where there was a big debate over a piece of technology to use. There were largely two camps, the engineers that had been with the company for a long time (call them Tech A), and then some of the engineers and managers that were brought in more recently (Tech B). There was a promise of an open discussion regarding this technology, both sides made their arguments, and then there was a ""closed meeting"" where the choice was made. Only the new manager and a few of the new engineers, who supported Tech B, were invited to the closed meeting. Unsurprisingly, they went with Tech B. This told all the old engineers exactly what we needed to hear, which was that input wasn't valued and organizational bullshit would rule the day. So most of them stopped providing complex feedback, and soon the attrition started, with a slow but steady exodus of older, knowledgeable engineers.

I check back on that company from time to time, and find they _still_ haven't managed to implement Tech B, despite the fact that Tech A had a working demo that could have been productionized in 6 months.",2025-04-14 19:03:51,18,Paradox,programming
mn373w0,1jyxu3p,reddit,"This piece is written by someone who has never been on a team that functions properly. Using ""institutional power"" AKA seniority to facilitate your opinion? Weakest-but-loudest engineers making decisions on the entire team's behalf? Pretending to be confident when you're only 60% certain? That's dysfunction junction right there.

True cowardice is refusing to accept that you are part of, and a contributor to, this dysfunction.",2025-04-14 16:52:35,23,IanAKemp,programming
mn2ovn4,1jyxu3p,reddit,"I think committing to technical solutions and committing to estimates/deadlines are two entirely different things.

I find it fairly easy to commit to a solution.  Most of the time, any of several choices will work, they just have advantages and disadvantages.  You pick one that you think you can best live with and make it work.  Usually it works out, and if it doesn't, you decide if you want to spend the effort to change it.  Even if you ""fail"", you end up learning something.

IMO there's usually nothing to learn from a ""failed"" estimate.  You just have to deal with a bunch of stressed out people who wanted something to happen sooner.",2025-04-14 15:21:12,9,EntroperZero,programming
mn38gvz,1jyxu3p,reddit,">managers do not typically think “wow, I’m glad this person is being so careful and accurate”. They think “ugh, why are you forcing me to make the decision myself?”

Here's a manager that's going to require absolute heaps of ""managing up.""

He believes that for any given question there is always an apparent answer, that someone on his team will know enough to make that decision correctly, that person will be able to identify themselves as the one on the team who should be owning that decision, and it's just a personality flaw that they're not answering with the confidence of ChatGPT.

Yet, he simultaneously does not know how to gather enough information from the team with which to gain that ""55% or 60%"" confidence himself.

This is the kind of ""manager"" that expects their senior engineers to do all the actual management because it's nerd shit. He'll just play hall-monitor in between taking credit in front of middle management.",2025-04-14 16:59:13,9,old-toad9684,programming
mn20mj5,1jyxu3p,reddit,I seem to disagree with almost every line of this article,2025-04-14 13:09:10,35,Huberuuu,programming
mn2w19a,1jyxu3p,reddit,"My strategy for these situations, when I'm not sure which answer is right, is to really think about what happens if I am wrong. I think about things like ""how hard would it be to pivot if I'm wrong"", how can I make it easier to pivot (if I'm wrong), how can I make it obvious more quickly if I'm wrong, etc. Often that has a better cost/benefit than investigating the two solutions more deeply",2025-04-14 15:56:54,6,ghillisuit95,programming
mn3n66e,1jyxu3p,reddit,"The IT industry is full of not committed tech and reinventing the same solution for the same problem with different name every 5-10 years

Tech like distributed computing - RPC, CORBA, SOA, Microservices  
  
Distributed computing has the same problems since the beginning, but IT tech companies are inventing new ""solutions"" and they are creating new vocabulary  
So, if someone learn about the pros/cons of CORBA then he has to relearn everything for SOA and then relearn everything for Mircoservices  
On top of that software engineers love Bikeshedding and most of them don't understand thing or two about their job, why they are paid to do what they are doing  
On top of that software engineers love to change jobs every 3-4 years, that means - ""this tech will look good at my CV, lets add to the project""  
On top of that most of the management in IT doesn't understand what they are doing and they don't understand the software live cycle a.k.a if it works don't touch it  
  
If you want engineers to commit then the companies have to create conditions for that and they need to have decision makers that know what they are doing  
  
How do you expect a engineer to commit to a solution that is workaround because the current infra team doesn't want to upgrade to the latest platform, that will provide 10x less code and 10x less bugs ?",2025-04-14 18:10:24,3,gjosifov,programming
mn21v9g,1jyxu3p,reddit,I've dated some...,2025-04-14 13:16:46,15,ebbiibbe,programming
mn237wr,1jyxu3p,reddit,"I found usually having a clear specs help the team make commitments. Though, in reality, that’s a luxury, so management can step in and help by making a commitment themselves on the damn specs.",2025-04-14 13:24:55,3,namotous,programming
mn2b6uo,1jyxu3p,reddit,"I think what was left out of this article is that you can more times than not make a decision based on some metric.  We had to pick a no-sql database and a number of people on our team just wanted to seize on one, but I was like hold up.  We made a series of tests for our use cases and then tested all the options based on those.  Original problem took 2 weeks for the user to get their data.  If we had gone with what several people were pushing for they would get their data in 2 1/2 minutes.  Our final decision got the data in 16 seconds.  Yes, not all decisions are cut and dry, but a lot of them can be just like that.",2025-04-14 14:10:09,2,dalittle,programming
mn2qytx,1jyxu3p,reddit,Sometimes making a decision is pointless if infra and tech adoption is top down as in engineers are not allowed to make a mistake then expect little decisions.,2025-04-14 15:31:49,2,Beginning_Basis9799,programming
mn2rh9j,1jyxu3p,reddit,"In large enterprises it is always clear who is supposed to commit. That person is almost always a team lead, director, or manager of some kind.

Being a senior engineer doesn't always give you the obligation to be a decision maker.",2025-04-14 15:34:26,2,nocrimps,programming
mn2u0og,1jyxu3p,reddit,Had a guy I was sort of mentoring who reeeeaaaaaally wanted a promotion to senior. Whenever he had a technical decision to make he would “ask my advice” then argue with me to try to convince me to suggest that he do whatever he had already decided he wanted to do so that it would be my fault and not his if it didn’t work. He eventually got it sorted but not before complaining that I was being mean to him for not taking his ideas into consideration to my manager.,2025-04-14 15:47:02,2,SmokeyDBear,programming
mn2yhos,1jyxu3p,reddit,"If I can commit to something, I explain why. If any choice is okay for me, I tell my restrictions to help others restrict possibilities (e.g. We can eat wherever you want as long as we don't eat fish). If I have to commit to something with caveat, I say them before commiting. There's nothing about bravery or cowardice, just plain pragmatism.",2025-04-14 16:09:12,2,Naouak,programming
mn33ykm,1jyxu3p,reddit,"I had a manager who was deeply noncommittal. It was deeply frustrating.

It wasn’t just that you never got a decision. He would constantly push for more discussions, go to other teams, make presentations, and so on. On the surface that’s healthy. It was taken to extremes.

We wanted to change the firefighting time from six weeks to something less. Getting it changed to four weeks took six months of work, and me needing to bulldoze it past him. To change what should be a 5 minute conversation.

Big stuff … well that just never happened. It just went on forever.

Let me add a tactic used at Amazon. You have type 1 decisions, the big stuff that matters. Then type 2 decisions, stuff that doesn’t matter or can be pivoted or reversed in a (mostly) straight forward way. Thinking of stuff this way helps to identify that most things don’t matter. It can be reversed, or changed, so just make a decision and move on. You can always put something in the calendar to review if it worked out.",2025-04-14 16:36:57,2,jl2352,programming
mn3hbr0,1jyxu3p,reddit,">In my experience, managers are very forgiving when you make a technical call and it ends up being incorrect. 

lulz, where ""forgiving"" is being called into an uncomfortable meeting with a bunch of people who have had their plans and expectations dashed and being asked ""So I thought you agreed and committed, what happened?""",2025-04-14 17:42:16,2,-grok,programming
mn58shl,1jyxu3p,reddit,"I often come across experienced people who are frustratingly overconfident, and I can't think of a single case where an experienced coworker seemed too indecisive and weak.

Even if you were a world-renowned expert, you'd still need to adjust for the fact that:

- The correct answer is often ""we don't know"" or ""it depends"" - which means that if you give any other answer, you'll be wrong.

- External forces will pressure you into *seeming* correct, even if that just means making something up or steam-rolling your colleagues. It takes a lot of effort to avoid that trap.

- In this profession, knowledge quickly goes out of date. Have you ever worked with somebody who still thinks that 90s-style enterprise OOP is the right way to do things?

- Experience often means specialisation, which means that you will have failed to improve in lots of other fields. Your junior coworkers may be budding specialists in a field where you have no experience. When the junior starts chirping about how exciting AI is, do you actually listen to them, and treat their ideas with respect?

- Senior staff are often outnumbered by their more-junior colleagues. You'd need to be really, really good to consistently outperform five or six other clever engineers, even if they have less experience than you do.

- If you want to make good decisions, knowing the specific context of the decision is more important than having good general knowledge. Junior staff are better at building up that context than you are, because they're more likely to be assigned to one task rather than being spread thin.",2025-04-14 23:14:38,2,hiddenhare,programming
mn65w82,1jyxu3p,reddit,"What If I'm wrong??   Then now that you've practiced being committed.... Evaluate the new circumstances and decide what to do ... Quickly.

Medical professionals do it all the time; evaluate the patient, decide what to do, do it,. Rinse and repeat.  Be brave and take a leaf out of their book.

Making decisions from imperfect data, and extrapolating missing data, is a high level skill that consulting engineers are expected to have.   If you can't or won't do that let, then go back to being a junior engineer",2025-04-15 02:32:49,2,stueynz,programming
mn2lv93,1jyxu3p,reddit,"The article is a bit strange.

It goes from ""not committing is cowardly"", but ... how does this cover all use cases?

If there are only two choices to be made, and I dislike both, for specific reasons, would I not be able to pick option three? What if option three is better in the long run? And if I do not yet know whether it is better or not, how could I commit to it? Or to the other two choices?

Big decisions may carry disadvantages and drawbacks. Take the Rise of worse is better approach:

https://dreamsongs.com/RiseOfWorseIsBetter.html

May be too long to read, so just as summary: most people may pick the ""perfect academia approach"", because it sounds better on paper (and possibly is better, objectively). But ... the quick-and-dirty easy-mode hacking-away-at-things-until-the-work, is in my opinion often more successful because it is faster, and leads (or led) to faster development cycle, despite people not ""recommending"" it. So which variant is then better? Should I commit to the perfect academia approach, even if it is slow as hell in development cycle?

Agile is often critisized these days, but one core promise they did were faster development cycles with more feedback. I think agile focuses too much on promo, but being able to be fast, while also getting more feedback in as you go, that's not bad.

In reality if you do some decisions there are always trade-offs to be considered. Some are worse than others, some people are better at making decisions, but some are slow. I am slow like crazy. I'd wish I would be faster but I am not. I often found that after writing code for many days, certain things are better to do - such as solid and intelligent specifications (both up front, but also after you started a project; you can start, but then never forget the specification). Similar rationale applies to high quality documentation - that should always be part of a good project. Everyone finding excuses such as ""code is self-documenting"" is building up on an illusion (and the code often really just plain sucks; ruby has this problem especially, people are happy writing code, then abandon the project and the documentation is non-existing - for many projects. There are of course exceptions, but this still plagues ruby today).

I just feel this is not so easy to classify this as ""engineers who won't commit are cowards"".",2025-04-14 15:05:53,2,shevy-java,programming
mn289xt,1jyxu3p,reddit,"You don't need the perfect plan, you just need a backup plan if the one you start with is problematic.",2025-04-14 13:54:12,1,hejj,programming
mn28lkk,1jyxu3p,reddit,"Yeah, my strategy for this is: instead of fearing that I will choose incorrectly, assume that I will whatever I do. Then, what is the fastest way to discover that it was incorrect empirically? Implement that alongside the decision.",2025-04-14 13:55:58,1,KazDragon,programming
mn2fnkc,1jyxu3p,reddit,I tell my kids that sometimes it's hard to choose because both options look good. But that means there's no bad choice and that's a good thing. Just pick one.,2025-04-14 14:33:53,1,lurgi,programming
mn3jr03,1jyxu3p,reddit,"On being wrong, my experience tells me that except in research-heavy work like language design, protocol design, system software design, any specifications that fulfills requirement and is future proof is correct enough.

Then, boundary, interface, and abstraction can be set to defer decision making on the implementation part.",2025-04-14 17:53:47,1,stdmemswap,programming
mn4dzg9,1jyxu3p,reddit,"A few years ago, my asshole tech lead suggested something over slack. Not having a lot of context to the issue, I replied with ""that could work."" 5 weeks later when it wasn't done (I don't remember why) those 3 words were cited as me committing to that work and a timeline. I don't say shit about things I don't know about since.",2025-04-14 20:25:21,1,durandall09,programming
mn4kk8s,1jyxu3p,reddit,Two words: action bias.,2025-04-14 20:58:46,1,sigwinch28,programming
mn52ts3,1jyxu3p,reddit,"I don't think the right term is cowardly, I think it is closer to not caring.

A lot of ""engineers"" just want to write (bad) code that does stuff. They don't really want to solve problems (despite insisting that they do).

Learn who these people, pray to god that they are not in tech leadership and cut them out of the convo.",2025-04-14 22:39:53,1,SikhGamer,programming
mn5xqtd,1jyxu3p,reddit,"I like to present several options and then say this is this is the most favored because of x

I have never really seen engineers be non comittal.   Are you saying you ask professionals a question or approach and they don’t answer?   Seems unprofessional",2025-04-15 01:42:11,1,galtoramech8699,programming
mn5xy8n,1jyxu3p,reddit,I do atomic git commits,2025-04-15 01:43:26,1,galtoramech8699,programming
mn6hwlv,1jyxu3p,reddit,"Hm.

I feel this misses some elements.

Usually it is about a choice over a few options and it is good to express the *level of confidence* in committing to one of them.

It is also good to change one's opinion. ""Reaction to change over following a plan"", as the manifesto says. Even if the change is that something was learned in the meantime.",2025-04-15 03:57:05,1,goranlepuz,programming
mn6ymtx,1jyxu3p,reddit,I usually commit several times a day,2025-04-15 06:26:04,1,DoorBreaker101,programming
mn74b88,1jyxu3p,reddit,Just throw ideas into a hat and pick.  Hat oriented architecture.  The business will ruin the design anyway so it doesn't matter.,2025-04-15 07:25:58,1,lechatsportif,programming
mncrps0,1jyxu3p,reddit,"I agree with what’s said here, but on the other hand I really dislike when someone commits to a decision and can’t face the facts that there’s a better approach and relies on political tactics to appear right.  I find that really unpleasant.  Some technical decisions are really not easy to conceptualize or measure the impact of and I’ve seen some folks in my career take advantage of this to like make them selves “appear right” to a less informed audience.  I really don’t appreciate that.  I get that there’s like an incentive to pick a side and like be a higher level engineer, but I’d really love it if folks would be willing to not take a strong stance if they’re not very familiar with what they’re talking about.  Not sure why I’ve seen that happen a few times in my career.  Maybe it’s a “fake it till you make it” thing or maybe it’s like the dunning Kruger effect.  I just think too many strong decisions by someone who doesn’t really know what they’re doing can accrue a ton of tech debt fast.",2025-04-16 03:59:29,1,Ok-Willow-2810,programming
mn22ovk,1jyxu3p,reddit,[deleted],2025-04-14 13:21:45,0,N/A,programming
mn35768,1jyxu3p,reddit,"This blog post resonates as being very true to me.

It brings to mind a TNG episode (Attached, season 7 episode 8) where Picard and Crusher are lost on an unknown planet while being telepathically linked.

The exchange goes like:

> CRUSHER: I'm not sure whether we should go over this hill or that one. The topography on this map is a little vague.
> 
> PICARD: Let me see. This way.
> 
> CRUSHER: You don't really know, do you?
> 
> PICARD: What?
> 
> CRUSHER: I mean, you're acting like you know exactly which way to go, but you're only guessing. Do you do this all the time?
> 
> PICARD: No, but there are times when it is necessary for a captain to give the appearance of confidence.

I think a big part of the professional successes I've enjoyed comes from being able to commit to a decision, with limited knowledge, in situations where peers have been unwilling or unable to do so.

You often get more desirable outcomes from being wrong quickly, then from being correct eventually.",2025-04-14 16:43:14,0,pitiless,programming
mn3hy8p,1jyxu3p,reddit,"This resonates with me so much! I’ve agonized over large commits, double and triple checking. 
In the grand scheme it doesn’t matter (unless the build is broken in a very bad way), commit,fix any problems, move on. 
At least I keep telling myself this.",2025-04-14 17:45:16,0,timetofirstfix,programming
mn3koys,1jyxu3p,reddit,Love this article. Ability to commit to technical decisions in a variety of conditions is often what separates good from great.,2025-04-14 17:58:17,0,wpevers,programming
mn21qpd,1jyxu3p,reddit,Just the advice I was needing to hear! :tada:,2025-04-14 13:16:00,-3,lwjohnst,programming
mk6x5yu,1jlkqcy,reddit,This is wild. Running Go on a PS2 is such a cool mix of retro tech and modern language. Makes you wonder what other “obsolete” systems could be brought back to life with today’s tools. Super fun read,2025-03-28 14:43:52,42,tomasartuso,programming
mk4jqkn,1jlkqcy,reddit,Wow this is awesome work ! Good job !,2025-03-28 03:17:13,29,HolaSoyCara,programming
mk5piv4,1jlkqcy,reddit,That is very very cool. mad props.,2025-03-28 09:48:04,8,The_0bserver,programming
mk4jjmx,1jlkqcy,reddit,This is so cool! Great work,2025-03-28 03:15:58,10,sorokya,programming
mk5hoof,1jlkqcy,reddit,This is cool btw,2025-03-28 08:22:12,4,devloperfrom_AUS,programming
mk6w431,1jlkqcy,reddit,Way cool! Thanks for sharing,2025-03-28 14:38:31,4,MediumRareInnards,programming
mk5arbs,1jlkqcy,reddit,People are awesome,2025-03-28 07:06:20,7,ikarius3,programming
mk4jssj,1jlkqcy,reddit,[deleted],2025-03-28 03:17:37,-8,N/A,programming
mk6zxw9,1jlkqcy,reddit,"Super cool, thanks for sharing!",2025-03-28 14:57:35,2,sonbn812,programming
mk9u18r,1jlkqcy,reddit,Go golang!,2025-03-28 23:32:32,1,goranlu,programming
mkc288z,1jlkqcy,reddit,"It's cool and all, but it is not as cool as making your own Lisp dialect for the PS2 to write your game in, before the console was even released.

https://en.wikipedia.org/wiki/Game_Oriented_Assembly_Lisp

Sorry for hijacking, but this tidbit will never stop being amazing to me.",2025-03-29 10:17:14,1,DeviationOfTheAbnorm,programming
mkbs6tp,1jlkqcy,reddit,"i don't know why, but matching Go with PS2 give me really good vibes",2025-03-29 08:24:19,0,uscnep,programming
mk6b3bk,1jlkqcy,reddit,Why not Rust?,2025-03-28 12:41:38,-14,deadcream,programming
ml9r0n7,1jqodtw,reddit,"Pleasently surprised that it sticks to the proven UI and does not use the vscode/electron style without menubar, padded buttons and monochrome icons.  
Other people will probably say it looks old (not “modern”).  
To me np++ has peak UI design, and the fact that it has been around for so long in this form, while other editors have waxed and waned (e.g. sublime), tells me I must be at least partially right. Thrilled to get a cross-platform version as I moved to mostly Linux because of the seemingly unstoppable enshittification of Windows.",2025-04-03 21:22:50,133,3dGrabber,programming
mla2nlh,1jqodtw,reddit,"I hope this goes well. I have since jumped ship to BBedit on MacOS, about 5 years ago since no notepad++ on macOS. Hopefully this thing gets stable and gets supper over time. It’d be rad if it grows into its own.",2025-04-03 22:27:37,10,this_knee,programming
ml9hawa,1jqodtw,reddit,Why does NP++ need to be re-implemented?,2025-04-03 20:33:51,37,zimboptoo,programming
mlamjga,1jqodtw,reddit,"Suggestion: Please add hover hint on icons at the tab bar.

Thank you I have been waiting for this all my life <3",2025-04-04 00:25:28,7,silencer07,programming
mlbzdt8,1jqodtw,reddit,Personally I prefer VSCODE de’s approach but still use Notepad++ because of some text manipulation plugins and macro recording that aren’t as good on VSC. Also useful for files that are a little too big for VSC.,2025-04-04 06:16:41,4,heavy-minium,programming
mlfapsj,1jqodtw,reddit,I feel like an opportunity to call this Notepad# was missed,2025-04-04 19:21:41,4,chicknfly,programming
mlaka07,1jqodtw,reddit,"Well, I gotta check It out. Notepad++ is my main editor for some programming languages.",2025-04-04 00:11:28,3,ricardo_sdl,programming
mlal9hw,1jqodtw,reddit,That's a quick git clone. Thanks for bringing this to my attention!,2025-04-04 00:17:36,1,Prudent-Elevator-123,programming
mldnbzk,1jqodtw,reddit,"Neat! Though I hope ""re-implementation"" doesn't mean they're not gonna fix some of NP++'s weaknesses (no vertical tabs...)",2025-04-04 14:23:24,1,terablast,programming
mledsls,1jqodtw,reddit,"Yes, Yes, Yeeessss!!!",2025-04-04 16:35:54,1,thekennysan,programming
mlid1he,1jqodtw,reddit,Nice. Been using Kate on Mac after gedit stopped working a few years ago. If Kate breaks this will come in handy.,2025-04-05 07:56:09,1,anonymous_subroutine,programming
mlp50cq,1jqodtw,reddit,Looking at the source code on GH I didn't see a single line of test? Did I miss something? How does a project of this magnitude work without any testing?,2025-04-06 13:43:49,1,mr_grumpyyy,programming
mlbiyar,1jqodtw,reddit,"AppImage  [far from the first time](https://github.com/IsmaelMartinez/teams-for-linux/issues/1340) doesn't support [fcitx5](https://github.com/dail8859/NotepadNext/issues/218) input method

FlatHub version supports fcitx5, but it doesn't support abomination of global menu, which was enabled in my distro. After disabling it, I got back the menu and a feeling that 2025 is not a year of linux desktop yet.",2025-04-04 03:57:46,1,Maykey,programming
mk96gy5,1jm3tc2,reddit,"“We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. Don’t let yourself be lulled into inaction.”

Bill Gates",2025-03-28 21:23:39,336,somkoala,programming
mk8ofvr,1jm3tc2,reddit,what is dead (inside) may never die,2025-03-28 19:52:50,249,Twistytexan,programming
mk91cbc,1jm3tc2,reddit,"> Just have a look at Linkedin job postings to get an idea of what is expected from junior developers. They are required to be novices, but at the same time have the tool belt and experience of a developer already working for years.

There was once a recruiting company that published data analysis results of their worker placement in the tech industry. One of their findings was that a successful job applicant should match on average 50% of the posted job requirements to land the job.

They sadly went out of business a few years ago. I can only imagine this metric deteriorated even further down - with the posted job requirements becoming a universal ""wish lists"" copy-pasted between Staff Embedded C++ Electric Engineer Automation role and Junior Summer Coop (Full Stack) roles.",2025-03-28 20:56:57,64,voronaam,programming
mk9yvwb,1jm3tc2,reddit,"I'm not really losing any sleep over an AI doing my actual job anytime in the foreseeable future. What I do is pretty damn niche with a ton nuance. Training someone on the basics is pretty easy, but actually being able to navigate the gray areas (especially in regards to international governance and laws around the shit) is incredibly difficult to really learn without years of time actually doing it - never mind trying to train an algorithm to handle it (though plenty of groups are out there trying... and fortunately for me, failing pretty hard).

What does keep me up, though, is the idea that one of those same groups might manage to convince my leadership into believing their shitty AI solution can handle what I do. And then some executive, dazzled by a flashy demo and a slightly lower price tag compared to my team, signs off on it, resulting in a bunch of us getting the axe.

So no, AI isn't going to replace me. But some douchebag techbro peddling glorified vaporware might just *eliminate* my job by convincing people who don’t know any better that it’s “good enough.""

Honestly, I think that’s what’s happening in most of these AI job replacements. It’s not that the AI is actually doing the work - it’s that leadership cuts people, throws some crappy tool at whoever’s left, and tells them to make do.",2025-03-28 23:59:54,79,absentmindedjwc,programming
mk8x7rt,1jm3tc2,reddit,"Good news, we are not dying. We are going to live forever!",2025-03-28 20:36:15,42,nattack,programming
mk9edq6,1jm3tc2,reddit,"> This could also be read as ""are the stake holders capable of instructing a LLM accurately with their wishes for the latter to really understand what they mean in order to let them know what is feasible or not and how to utilize it?"". I don't think so.

They hate us cuz they ain't us",2025-03-28 22:06:01,16,ForeverHall0ween,programming
mkaefx5,1jm3tc2,reddit,It'll die or it won't.  Let's just keep writing code while we can.,2025-03-29 01:31:41,6,longshot,programming
mkb0egt,1jm3tc2,reddit,"What is most unfortunate is there are marketing and executive folks out there who are actively trying to put people out of jobs acting in bad faith. Once this AI crap turns into production disaster SWE should ask 3x the last base pay to fix all of it. Also that crap is not even close to doing anything useful in real world engineering problems, I'm just going to enjoy the hysteria and the aftermath of AI layoffs, SWEs are going to make a bank after the disaster. 


I'm just sick of these vibe coding clowns they can't fix a simple syntax error if their life depended on it. ",2025-03-29 03:55:04,9,Scary-Mode-387,programming
mk90i3r,1jm3tc2,reddit,Based on the assumption that what is not possible today will not be possible tomorrow ,2025-03-28 20:52:45,26,avacadoplant,programming
mkcje0h,1jm3tc2,reddit,"Junior SWE are getting screwed here, but seniors are going to make bank with the way the software landscape is evolving.

AI has already reached a plateau, and we're not going to see any major improvements until the next breakthrough. No-code has also reached a plateau, in terms of profitability for the user.

When you really think about it : no-code is basically a paid programming language with a nice UI. It runs on hardware, most often in the cloud. That cloud service is usually just fly or heroku that ends up paying Amazon or Google for their servers. Every one in the chain is in to make a margin. Compare that with running your actual code on bare metal, and it's night and day. Once people realize that, it's a whole subject matter into ""reducing costs"" cause nobody wants to pay 1,000$ a month for a shitty app they think they can code in a day.

AI is the same. Everything runs at a loss right now. Once the actual price of using AI hits, you'll compare price / performance to an actual engineer and settle on the engineer. The highest paid ChatGPT plan is 200$ a month, and it's not even close to the actual final price of the AI. When you factor in energy costs, land, hardware (GPUs most likely), infrastructure for the datacenters and networking, the final price should be at least 10-20 times that.",2025-03-29 12:49:01,3,Dogeek,programming
mkc3ke5,1jm3tc2,reddit,"> Takeaway number 3 - teach them full stack development.

In other words, teach them _web_ development. Because it is well known in web circles that web development is the only real development that’s going on any more. So well known in fact that we don’t even need to remind readers we’re talking about web dev. </sarcasm, but not really>

Serious talk: narrowing development to web dev is overly restrictive. There is a _lot_ of programming going on elsewhere, so unless you want specialists right out of school you need to focus on more general fundamentals. And yes, that means we cannot possibly bridge the gap between curricula and any one industry.

_(Edit: Aaand I got the actual point of the article completely wrong, because I didn’t see it was laid out in 3 different pages.)_",2025-03-29 10:31:39,2,loup-vaillant,programming
mk9xyra,1jm3tc2,reddit,"So many people seem to know how AI is going to stop advancing before it destroys all biological life, but they never have any details of how they know that....",2025-03-28 23:54:37,6,Daegs,programming
mkbmqr9,1jm3tc2,reddit,RemindMe! 3 years,2025-03-29 07:22:30,2,ForgetTheRuralJuror,programming
mkcw13e,1jm3tc2,reddit,"Unifversity professors reasoning about the industry they have never worked in is always a wasteful read.
The industry is moved by raw interests, not by good practices. It is fun to watch how these SE professors are now teaching scrum, which is pretty much the anti-software engineering. Ofc in the street we are well in the post-scrum era, but professors need 10 years to notice of changing trends on average.",2025-03-29 14:11:15,2,st4rdr0id,programming
mkf4yw1,1jm3tc2,reddit,#SoftwareEngineeringLit,2025-03-29 21:33:27,1,nerdly90,programming
mkbizxu,1jm3tc2,reddit,"""Horses will never go away, and if New York keeps growing as it does, it'll drown in horse dung come 1920!""",2025-03-29 06:41:52,1,DocTomoe,programming
mka14i2,1jm3tc2,reddit,"""Dead"" is pretty completionist. SE doesn't have to die for it to be non-relevant.

There's still farriers, but transportation has utterly progressed beyond horse based technology.",2025-03-29 00:13:00,0,njharman,programming
mk95cm7,1jm3tc2,reddit,Well horse carriage still exists……,2025-03-28 21:17:42,-3,dantsdants,programming
mk9181j,1jm3tc2,reddit,"This is copium.

We are gonna be replaced eventually just like how cars replaced horses. It’s not a matter of if but when",2025-03-28 20:56:21,-27,itsjase,programming
mkalr38,1jm3tc2,reddit,Will coding as we known it today go away? Almost certainly. Are LLMs what kills it? Not a chance.,2025-03-29 02:15:40,0,jimbojsb,programming
mkebdy8,1jm3tc2,reddit,It’s always the people at the brink of being replaced screaming the loudest they can never be replaced lmfao,2025-03-29 18:50:25,0,ArkBirdFTW,programming
mk8oego,1jm3tc2,reddit,"Isn't full stack a bit of a failure? The stack gets higher every day.

Engineers do need to have a large variety of ""knowing of"" so they can go to the proper expert, but they still need to be an expert in something themself.",2025-03-28 19:52:38,-21,knightress_oxhide,programming
mk8x9w4,1jm3tc2,reddit,"that's like saying it will never reach a point of engineered completeness from an np-incompleteness standpoint.

Once you've met all np-complete sets being found and used, it is np-complete in its finite np-incompleteness, making the prospect np-incomplete as a halting problem.... the real reason it never dies.....",2025-03-28 20:36:32,-9,Any-Olive5779,programming
mkachh7,1jm3tc2,reddit,"is there a software engineering ?

I would have thought the unsolvavility of the halting problem meant there could never be software as engineering

but I will have to recheck my philosophy of art science and engineering that I made up cuz i'm too stupid to understand anything otherwise",2025-03-29 01:20:00,-6,naringas,programming
mlky1tt,1js8gqz,reddit,This was a wild read! Well written and sounds like fun.,2025-04-05 18:53:47,30,njacklin,programming
mlmvjte,1js8gqz,reddit,Website is down…,2025-04-06 01:56:06,3,amestrianphilosopher,programming
mlou8ab,1js8gqz,reddit,"Amazing achievemnt! It was exciting when Corellium managed to get it working, but in the end nothing public came out of it.",2025-04-06 12:28:47,4,moridinbg,programming
mlo9aib,1js8gqz,reddit,Really nice,2025-04-06 09:04:17,1,Aalexander_Y,programming
mlqx4cs,1js8gqz,reddit,"""Forward every call to a server, executing them and returning the result""  
What the fuck is this black magic fuckery?",2025-04-06 19:32:22,1,Omnidirectional-Rage,programming
mlshwef,1js8gqz,reddit,Legend!,2025-04-07 01:02:21,1,sonbn812,programming
mlmawyg,1js8gqz,reddit,"wow! just wow, excellent write-up",2025-04-05 23:41:28,1,sumwheresumtime,programming
mlynvxq,1ju1f1g,reddit,"Before git, I used SVN. It wasn’t fun.",2025-04-08 01:25:01,137,watabby,programming
mlzkwqs,1ju1f1g,reddit,I love how git is both indispensable to our industry and yet confounding enough that seasoned veterans sometimes wind up in bad places with it. You’d think we’d have something friendlier by now.,2025-04-08 05:16:34,55,auximines_minotaur,programming
mlynafs,1ju1f1g,reddit,still not enough to learn properly,2025-04-08 01:21:24,48,SltLt,programming
mlz69j3,1ju1f1g,reddit,"Last Thursday, I used git bisect run to find a regression while I went out and got a burrito.

I like git.",2025-04-08 03:21:10,27,Weshmek,programming
mlzjrkt,1ju1f1g,reddit,Kids.  I used Panvalet from Panshophic in the early 1980s.  It was that or store the program backups in punch cards.  At least we skipped paper tape!,2025-04-08 05:06:31,9,johnpmayer,programming
mm1dzg9,1ju1f1g,reddit,"Git kind of won.

Even then, I am not the biggest fan of it. I am not sure how a better system should look like, but git feels clunky to use all the time.",2025-04-08 14:19:48,4,shevy-java,programming
mlzq0j8,1ju1f1g,reddit,"My use tends to be simple enough with the odd rebase or two.

Hasn't failed me yet.",2025-04-08 06:04:15,2,YesIAmRightWing,programming
mm3819y,1ju1f1g,reddit,Perforce :(,2025-04-08 19:43:15,2,Snwspeckle,programming
mlzt3k8,1ju1f1g,reddit,Git can be annoying at times (mostly because people don’t know how to use it) but I will take got any day of the week over 10 devs using VSS,2025-04-08 06:32:43,2,Wiltix,programming
mm001wr,1ju1f1g,reddit,shit I missed git-day by 5 days,2025-04-08 07:43:23,1,realblobii,programming
mm4cw6r,1ju1f1g,reddit,Anyone ever use SCCS on Solaris?  It used to love that,2025-04-08 23:12:48,1,jargus74,programming
mlzb764,1ju1f1g,reddit,"nah, not wonderful. weird and shitty. just less shitty than cvs, svn, project_final_version_for_real.tar.gz",2025-04-08 03:56:33,-3,alonjit,programming
mondos4,1k6543s,reddit,"This goes further than just job satisfaction.

To use an LLM, you have to actually be able to understand the output of an LLM, and to do that you need to be a good programmer.

If all you do is prompt a bit and hit tab, your skills WILL atrophy. Reading the output is not enough.

I recommend a split approach. Use AI chats about half the time, avoid it the other half.",2025-04-23 18:09:35,304,Backlists,programming
monxxn5,1k6543s,reddit,"I have a similar feeling. Writing code is fun. Reading and reviewing code is not. 

AI-driven development is basically replacing 90% of your work time with code reviews. It's productive, sure, but terribly boring. 

I've found some positive results by switching things up: I don't prompt for code and instead just handwrite it using the AI as autocomplete, then I query the LLM to find bugs and discuss refactoring tips. Depending on what you're doing, this is probably faster than battling against an LLM trying to gaslight you.",2025-04-23 19:47:57,125,uplink42,programming
moptixz,1k6543s,reddit,"Totally agree, it just makes the work of a software engineer become the worst part of the job: code reviews and bug fixing.

I forced myself to use a code assistant for a week and although I saw improvements in the past year, if it was a person doing these things, their job would be in danger by the end of the week:

- never tried to run their code
- made changes I didn’t ask for
- introduced bad practices and vulnerabilities
- gave me buggy code to fix
- kept saying “I’m sorry” but not learning from their mistakes

AI has been helping me with typing, but when I ask for it to make full changes it’s a terrible coworker.",2025-04-24 01:52:16,15,Bubbassauro,programming
mopbv51,1k6543s,reddit,"All of the AI generated code is inferior to what i write. Its useful for syntax and maybe APIs but otherwise it seems stupid to me. I can see people who arent very good at coding finding it useful, but it will result in people better at coding having to rewrite it.

The real problem comes down the line when the AI tries to understand the rewritten code without understanding the reason why it was written and the context which wasnt captured. Then later on AI will start writing really ridiculous code.

Better to just use for syntax and debugging, maybe looking up APIs",2025-04-24 00:09:52,10,StarkAndRobotic,programming
mondjb7,1k6543s,reddit,"I was (and still am) apprehensive about using AI tools in my development...
this article encapsulates one of the biggest reasons for it, AI takes the creativity, the actual problem solving, critical thinking, and hence.... the joy out of engineering. 

One other aspect is, the energy implications, 
I get it, it might be stupid, but I cannot morally justify the energy cost of my LLM query compared to the value it brings to me... most likely this will reduce as this advances, But for now... idk",2025-04-23 18:08:51,62,AaravKulkarni,programming
mopxgge,1k6543s,reddit,"After using Cursor for a while, I feel like it saves a lot of time for small, isolated tasks. But for more complex features, debugging can actually take longer. Also, relying too much on AI makes me less familiar with the actual business logic. I think it’s best used as a helper, not a crutch.",2025-04-24 02:15:12,6,Hungry_Importance918,programming
moswe0u,1k6543s,reddit,"Senior developer here. In my domain of competence chat gpt is absolute trash and slows me down. Outside of my domain of competency i ask chat gpt questions like in language x i can do y, whats the equivalent in this language? Or ill send it a snippet of code and ask if there are any pitfalls or concerns and its pretty good at mentioning edge cases that i may not have considered. But i don’t really take anything it codes as that stuff is still pretty bad.",2025-04-24 15:18:34,7,Nullberri,programming
monypgo,1k6543s,reddit,"> if we lose the joy in our craft, what exactly are we optimizing for?

late stage capitalism optimizes for short-term advantage over other companies. Who cares who it burns out in the process",2025-04-23 19:51:42,20,Humprdink,programming
monfkt4,1k6543s,reddit,"I get a lot more joy out of ""raw coding"" now with AI specifically because I can offload the stuff I don't derive intellectual joy from to an agent.

Wiring up yet another API call is boring to me. Hand-crafting a function signature is similarly boring, especially since I need to actually adhere to the overall style of a project anyways. These do not deliver joy to me and they never have.

More time spent on harder constraints of a system and experimenting with different approaches is exactly the sweet spot of joy to me. Making more overall working software delivers the most joy.

What I think matters here too is that the things people derive joy from are wildly different from person to person. I fully expect some engineers out there to use AI to the fullest, for everything, even to their detriment, just because it's more enjoyable. And I also expect the exact opposite, and everything in between.",2025-04-23 18:18:42,33,phillipcarter2,programming
moq5896,1k6543s,reddit,"I had a similar growing feeling of unsatisfaction with programming but it came a few years age with the rise of open source software. One of my jobs devolved into searching, downloading and hooking up third party packages. Immensely more productive than writing from scratch but infinitely less satisfying.

I had a series of bug fixes which were spending some time Googling then make a small change to a configuration file somewhere. Ugh",2025-04-24 03:02:57,2,xxkvetter,programming
mopydsc,1k6543s,reddit,"Gemini is great for talking out problems, solutions, and trade-offs. You have to have clear understanding of your domain, though.",2025-04-24 02:20:32,1,midairmatthew,programming
moqf5mo,1k6543s,reddit,Pl,2025-04-24 04:10:56,1,Gabreigns,programming
mosi60s,1k6543s,reddit,"It's a false dichotomy - when you let AI produce code you couldn't (or wouldn't) write yourself you're not being more productive 

productivity is not code lines per hour nor working features with crazy tech debt. 

I use AI to help me think. IMHO prompts like ""suggest 3 ways to solve this race condition"" or ""imagine what would cause this function to break"" work much better than ""make this page look good on mobile""",2025-04-24 14:09:14,1,ynonp,programming
moszswj,1k6543s,reddit,"I feel like there's still a lot of effort I need to put in even with LLMs for the kind of software I build. But LLMs have made me lot more confident in picking up new areas in programming.

Maybe I'm a noob programmer, or as the author put, maybe my skills don't meet the challenge. But with AI, programming hard things has become fun again and I'm learning to program harder things better than ever.",2025-04-24 15:34:50,1,lungi_bass,programming
mot2zy2,1k6543s,reddit,"I still think the lack of focus on maintainability in software engineering is surprising with all the talk of LLMs.

Like does no one maintain anything anymore?

How quickly you can whip together a new feature doesn't matter if everytime you add something some other obscure feature breaks from years of slapping whatever the LLM thought was a good idea into your codebase.

Obviously that takes quite a while to happen to people but it isn't like it is surprising it is coming given that is half the reason code reviews are standard.",2025-04-24 15:49:52,1,Guvante,programming
motvif7,1k6543s,reddit,So that notional increased output comes with the translation of interesting momentum and craft building working into 100% stressful debugging of output from something tuned to conceal its mistakes. The extra output comes with a lot of stress.,2025-04-24 18:03:04,1,the_packrat,programming
moo5xoo,1k6543s,reddit,"As a computer science, major, I would love to explain to you why AI is fucking retarded, but I’m gonna let the AI tell you that",2025-04-23 20:26:33,-3,TheApprentice19,programming
monzber,1k6543s,reddit,AI has been a huge success for people generating traffic to their blogs and substacks about how “AI Bad!”,2025-04-23 19:54:37,-6,Informal_Warning_703,programming
moonr4f,1k6543s,reddit,"I just want to ship code fast.

Documentation and testing is the stuff I do the most and yes, is soul crushing!",2025-04-23 21:55:31,-4,Swimming_Ad_8656,programming
mlo20h4,1jsnn5b,reddit,"Two years into managing role. These are good advices, a starting point that you must adapt to your specific scenario. E.g., strategy and vision often depend on external factors, priorities may suddenly change (for whatever reason, like tariffs...).
Also, you not only have to take care of each team member, but also the team as a whole, the relationships between team members, more or less like a psychologist doing team therapy.
That's my short experience,  my two cents of course. ",2025-04-06 07:45:48,47,NoHopeNoLifeJustPain,programming
mlnupa2,1jsnn5b,reddit,"I'd boil it down to:

- Wants to lead
- Has an idea about what sort of leader they want to be

Leadership at the junior level can mean taking responsibility for a task, even if the individual isn't capable of completing the task themselves - e.g. bringing the right people together, pairing with more senior team members, seeking help.

Management roles on the other hand require a different set of planning and organisational skills, along with lived experience of various scenarios, charisma, common sense, and specific knowledge of how large companies (HR, Project, Product, QA, Architects, etc.) function.

I mean to say, any one can lead if they want to, but you rarely see a junior manager, because such people usually lack the experience to properly navigate the corporate world.

/thoughts",2025-04-06 06:33:37,87,Markavian,programming
mlp89bg,1jsnn5b,reddit,"One key skill I've found absolutely crucial for engineering leaders, yet often overlooked, is the ability to effectively document and transfer knowledge.

I've seen so many brilliant engineers fail in leadership roles because they never developed a system for capturing and sharing institutional knowledge. When they're promoted, all their technical wisdom stays locked in their heads.

The best engineering leaders I've worked with weren't necessarily the most technically proficient, but they excelled at:

1. Creating clear architectural decision records that explained not just what was decided, but why
2. Building knowledge graphs that connected different systems and components
3. Establishing documentation practices that the team actually followed
4. Using diagrams and visual explanations alongside code

These practices not only improved their own leadership capabilities but created a multiplier effect on their teams' productivity. Engineers spent less time rediscovering solutions and more time building new things.

As AI tools become more prominent in development workflows, this ability to structure and document knowledge becomes even more valuable - the leaders who can effectively capture context will get much better results from these tools.",2025-04-06 14:03:38,10,traderprof,programming
mlouuiz,1jsnn5b,reddit,"Managing client expectations, protect your team. This is leadership, not management. Managing is not leadership. Vastly different things.

That's about it. 

The client could be a customer, your marketing department, or a higher level of executive. The key is to understand what their expectations really are. You might need to bring their expectations down to earth, or you might need to prioritize certain aspects to meet them. For example, a marketing department wants things to be cool, look cool, act cool, etc. They don't care that you used technology X or Y. Yet, some customers might care to the point of this being a showstopper. Thus, understanding all the clients and how to meet their expectations. Some people use the BS term ""stakeholders"" but that crap term can end up encompassing so many people that suddenly the janitorial staff are somehow on the steering committee. Some people might say accounting is a stakeholder because of the budget. But that is not a stakeholder, that is a constraint.

Protecting your people is a very broad term. Often keeping them away from the predations of executives, etc is a big job, but some of the best leaders I've seen were happy to go to war with HR just to keep them from asking their people to fill out stupid forms for the new medical plan; a giant and usually avoidable waste of time. Protecting your people from the nattering nabobs of negativity or the downright assh*les, is very important. But a massive thing a leader can do is to keep anyone who thinks they are a manager with the right to treat ""their people"" like infants. Great leaders fire this sort of toxic nightmare in a heartbeat.

The best companies I've seen in terms of profitability per employee, low turnover, and productivity of employees only had a few people leading many teams and few if any people with a title which was manager or translated to manager. 

The proper place for managers is t focus on any required process; leaders focus on keeping people focusing on realizing a vision. There is a massive difference. There are products where a process is essential, and maybe even regulatorily required. This where you have managers managing the process, but not people. This is where leaders have their work cut out as they now need to hover over the process managers with a shotgun making sure they aren't diverting resources to their own stupid needs, as opposed to working with people to produce a great product which also happens to have followed a process, vs doing a process which they don't overly care if the product meets client expectations beyond meeting a regulatory requirement; or some internal process cooked up by a manager to justify their existance. 


An OK leader will protect their people from as much manager style BS as possible, but some companies have terrible toxic cultures where there are plenty of manager walking around generating BS meetings, and BS reports, and an OK leader will mitigate this as much as possible. A great leader will annaliate this. A near pure example of the pinnical of toxic management culture is when a company has agile coaches.

TLDR; management and leadership are not the same thing; and managers who don't understand this, but put into leadership roles, are a cancer.",2025-04-06 12:33:35,10,LessonStudio,programming
mloyndf,1jsnn5b,reddit,"\> Because leadership isn’t about code. It’s about people. And that means you need a different set of skills.

You don't need a blog article to point out this abundantly obvious fact.",2025-04-06 13:01:34,3,Greenphantom77,programming
mlnwrdq,1jsnn5b,reddit,"Company-sponsored lobotomy, if it's most managers i've known.",2025-04-06 06:52:57,25,dethb0y,programming
mlot943,1jsnn5b,reddit,"For a moment the headline looked like ""I asked an engineering manager how prompt engineers can prompt for leadership roles""",2025-04-06 12:21:01,2,Worth_Trust_3825,programming
mlq26xu,1jsnn5b,reddit,"Just read Management 3.0 by Jurgen Appelo, it's the only management book you'll ever need.",2025-04-06 16:48:31,1,eagee,programming
mltctw9,1jsnn5b,reddit,"I really don’t like the very common ”leader equals manager” assumption. I don’t ever eant to be a manager as I never want to be forced to judge people in money but I sure as hell am a leader in my team (and to some extent department and company), with compassion, experience, principles, interest and candor. I could probably be a better leader, as it’s not really an explicit choice, so I try to stay humble and listen to the people around me (and some pods).",2025-04-07 04:42:32,1,mirvnillith,programming
mlxslbc,1jsnn5b,reddit,Learn how to pass the buck and over/under estimate deadlines. Scope creep is a handy tool to stick developers with too in your leadership role. Favor the people that feed you the most bullshit and scorn the ones that actually own-up to their responsibilities.,2025-04-07 22:19:47,1,fliption,programming
mly8b43,1jsnn5b,reddit,It is about how you sell yourself than skills. It is how people perceive you in the organization (environemnt). Bullies/psychos that have charisma are leaders.,2025-04-07 23:50:19,1,Positive_Method3022,programming
mlnuaia,1jsnn5b,reddit,Throw away the list and do this instead: stop dragging developers into meetings.,2025-04-06 06:29:51,-16,DonaldStuck,programming
mkpuiso,1jo66p4,reddit,Quantum computing is so hard to read about. That shit is in the Stone Age and every article is always hyping it up like it’s about to become the new computing standard,2025-03-31 17:25:59,169,eightysixmonkeys,programming
mkpb54p,1jo66p4,reddit,42.,2025-03-31 15:49:26,167,jericho,programming
mkr1xdw,1jo66p4,reddit,"There have been hardware random number generators for ages, usually using something like background radiation measurements to generate them",2025-03-31 21:00:55,20,olearyboy,programming
mkpmxjx,1jo66p4,reddit,"I thought quantum-based random number generators for a while?  For example, based on shot noise in electronic diodes.  Or you could use decay of a radioactive isotope for this (e.g. the spacing of the noise from a geiger counter).  Is it the certification aspect that's novel here?",2025-03-31 16:48:23,37,Deto,programming
mkpizoz,1jo66p4,reddit,"Talk is cheap, show me the code",2025-03-31 16:28:26,13,anonymous-red-it,programming
mkphxnu,1jo66p4,reddit,"It's really a philosophical question as much as a physics one, isn't it? Is anything that happens in conventional, Newtonian/relativistic space truly deterministic? And if so, is what happens in the quantum space truly non-deterministic?

Of course, in regards to practical, cryptographic purposes, the answer is: it doesn't matter. Even if dice are deterministic, no attacker has the ability to parse all the specific conditions that go into determining its result. It *is* random. God already knows your password and He doesn't need to reverse-engineer your secret key.",2025-03-31 16:23:05,21,vomitHatSteve,programming
mkqfn9v,1jo66p4,reddit,Still no better than a coin flip but we'll get there!,2025-03-31 19:10:24,3,LoadCapacity,programming
mkrctmd,1jo66p4,reddit,At last. 4.,2025-03-31 21:58:49,3,msnshame,programming
mkru9mw,1jo66p4,reddit,tapping into the quantum realm just to get some rando number lol.,2025-03-31 23:38:14,3,david_nixon,programming
mkpkj01,1jo66p4,reddit,"> The result was a number so random, no amount of physics could have predicted it.

This is probably just watered down science journalism glossing over complexity, but if not… suck it determinism.",2025-03-31 16:36:15,14,CanvasFanatic,programming
mktk9pr,1jo66p4,reddit,"Genuinely curious. What significance does ""truly random"" have? Why is it important to achieve true random?",2025-04-01 07:20:47,2,redfournine,programming
mkpvjpv,1jo66p4,reddit,Did a Quantum computer finally do something meaningful?,2025-03-31 17:30:54,3,BlueGoliath,programming
mkr38d9,1jo66p4,reddit,It is said that quantum computers will be truly secure - but how can this be verified? Would it not be possible to have tampered with the hardware and either add a bias or some logging system that would also be impossible to detect?,2025-03-31 21:07:42,1,shevy-java,programming
mkr3a1x,1jo66p4,reddit,Joke's on you ha ! Cuz the universe is fundamentally deterministic,2025-03-31 21:07:57,1,Bachihani,programming
mks4i2n,1jo66p4,reddit,The title has nothing to do with the contents of the Nature paper,2025-04-01 00:39:57,1,jns_reddit_already,programming
mksd3ii,1jo66p4,reddit,"Oh shit, so it was non-deterministic?

Nobody tell God!",2025-04-01 01:33:07,1,MaruSoto,programming
mkskpmg,1jo66p4,reddit,42....  please tell me it was 42...,2025-04-01 02:20:32,1,painefultruth76,programming
mktin93,1jo66p4,reddit,"My brothers Statistics / Market research company has a random number generator that uses a particle counter and a small radioactive source. It generates real random numbers. Well it's claimed to anyway.

That's sort of quantum, isn't it ?",2025-04-01 07:02:47,1,malakon,programming
mkvbo3b,1jo66p4,reddit,    return 4;,2025-04-01 15:30:12,1,Drunken_Economist,programming
ml0hw11,1jo66p4,reddit,"Finally, something truly useful to show for all the VC funds invested.

Right?",2025-04-02 12:33:45,1,ainiku-esp,programming
ml0qqgh,1jo66p4,reddit,"> As complex as this web of rules might appear, the fact they are each predetermined to have a single outcome by physics leaves room for patterns that could be exploited by a sufficiently smart computer.

Isn't that in contradiction with Chaos Theory? Without knowing the exact initial state you cannot accurately predict a complex physical system and have to live with significant amounts of limitations and uncertainty.",2025-04-02 13:31:08,1,josefx,programming
mli2cjq,1jo66p4,reddit,We have random numbers at home.,2025-04-05 06:11:04,1,Wyg6q17Dd5sNq59h,programming
mlqw6za,1jo66p4,reddit,"Wow, nobody remembers that reverse biased zener diodes have been used to generate quantum random numbers for decades? It was invented in 1950, but the effect was discovered in 1934. I heard about it in high school in the '70s.

I just loooove reading about how someone ""for the first time ever"" using a multimillion dollar machine did something that has been hobby level technology for 70+ years.

Can't these guys even figure out how to use a search engine?",2025-04-06 19:27:13,1,Far-Dragonfly7240,programming
mkq25dc,1jo66p4,reddit,"And then this quantum randomness turns out to be a bunch of “if” expressions in the code running our simulation.

> or your Dungeons and Dragons half-elf paladin to have a truly random charisma score

Attack or save roll, not charisma score! Those aren’t supposed to be random, they’re the constants *added* to the random rolls!",2025-03-31 18:03:03,-1,Linguistic-mystic,programming
mjuxhn4,1jkdiku,reddit,I had to (and still have) use next.js app router on cloudflare pages (edge runtime). It’s the worst experience I’ve ever had in my career and I had to work on multiple 20+ years old codebases…,2025-03-26 16:39:45,99,Parachuteee,programming
mjugp70,1jkdiku,reddit,"Honestly, first time seeing the concept of ""adapters"" for hosting platforms. Sounds a lot like something user for shared hosting of PHP, circa 20 years ago.

Next.js can spit out standalone build. You can host that yourself, you can pack it in a docker container and give to majority of cloud hosting providers.

Is it serverless edge computed on your router? No. Can you scale those in response to traffic spikes? In my experience, yes.",2025-03-26 15:17:14,64,slvrsmth,programming
mjxoyq9,1jkdiku,reddit,"Unrelated, but that website is fucking awesome - genuinely one of the most unique good frontends i ever saws.",2025-03-27 00:55:44,12,RedstoneEnjoyer,programming
mjxfv1f,1jkdiku,reddit,NextJS is a Trojan Horse.,2025-03-27 00:04:22,14,theQuandary,programming
mjw2k79,1jkdiku,reddit,"> The official React documentation, which the Next.js team help maintain, says that Next.js can be deployed to «any serverless hosting», but there is no official documentation whatsoever for this.

Not surprising that Vercel would poison React once they got their grubby hands on official recommendation

Shame on the React team for allowing this, while gaslighting the community that all is fine",2025-03-26 19:57:15,38,drink_with_me_to_day,programming
mjw414c,1jkdiku,reddit,So what should you use instead?,2025-03-26 20:04:16,13,cedear,programming
mjyp7aa,1jkdiku,reddit,"Used nextjs for the first time last year, deployed it to self managed server, and it was a horrible experience (for me). Plus, the over engineered framework stuff that requires referring to the docs every time and slow DX when switching routes really threw me off. I built the entire website anyway in nextjs, but regretted the decision.
I don't need this level of complexity and friction to lear a framework built by a for-profit company when literally n number of alternatives are available.",2025-03-27 04:55:39,3,paramvik,programming
mjzq27t,1jkdiku,reddit,"Good read, thanks for sharing.  Have some tech debt to replace the stack for a recently ejected CRA; this and their handling of this security incident will be good information to add to that issue so that we make a more informed choice.  I'm in the camp of not using a framework until we need one, baby steps.",2025-03-27 11:09:07,2,Educational-Ant-173,programming
mjx1ktz,1jkdiku,reddit,"Why is this article formatted using latex or some other spacing mechanism that makes it absolutely treacherous to read?

```
My     job      involves
```
No. Absolutely not.",2025-03-26 22:47:40,4,7heWafer,programming
mk0kpy5,1jkdiku,reddit,"Really good read, especially for folks who are thinking of jumping into Next.js without fully understanding the trade-offs. I’ve seen a lot of devs treat Next.js as the ""default"" choice without realizing how much is abstracted under the hood — which can be a problem once you need to debug or scale.

I appreciate how the article breaks down the magic and points out what you’re really committing to. Curious to hear if anyone here has run into real-world pain points from not knowing these things upfront?",2025-03-27 14:21:37,1,tomasartuso,programming
mmjj9s7,1jwjw7b,reddit,"> Honestly, basing a framework decision solely on a startup time difference of less than even `1 500 ms` is likely overthinking it for most applications

*cue Casey Muratori's VS rant*",2025-04-11 10:56:39,93,ShinyHappyREM,programming
mmj4wly,1jwjw7b,reddit,"I think the non-uniform rendering engine would be a nightmare to deal with. Not only different engines (chromium vs safari vs webkit), but also different versions of the same engine.",2025-04-11 08:33:50,79,Programmdude,programming
mmjzgz4,1jwjw7b,reddit,Are you really sure that the memory consumed by the webview is showing up under same process and not elsewhere?,2025-04-11 12:51:37,16,petereteq,programming
mmk7wt4,1jwjw7b,reddit,"There's a stack of benchmarks that they included a link to which suggest *higher* memory usage for Tauri compared to electron.

Not only does this not make sense, but it contradicts the article's claims-- which make me wonder why they included it or whether their claims are accurate.",2025-04-11 13:40:45,10,Coffee_Ops,programming
mmj2ztu,1jwjw7b,reddit,For I second I thought it was r/Stargate and I was confused by the title.,2025-04-11 08:13:06,22,pur3pwnage,programming
mmjctyj,1jwjw7b,reddit,"If you are targeting only one and the latest OS then Tauri is fine, else Electron is less trouble for the developers.",2025-04-11 09:57:30,12,AKMarshall,programming
mmmmqn5,1jwjw7b,reddit,"At the end of the [Startup time](https://gethopp.app/blog/tauri-vs-electron#startup-time) section it says:

> For more detailed benchmark data across frameworks, check out the [Web to Desktop Framework Comparison repository](https://github.com/Elanis/web-to-desktop-framework-comparison?ref=hopp#benchmarks).

So I clicked that link, and scrolled down to [the startup times table](https://github.com/Elanis/web-to-desktop-framework-comparison?tab=readme-ov-file#start-duration). And... and empty Tauri app, build in release mode, takes 25 seconds to start on Linux?

This can't be right...",2025-04-11 20:54:58,3,somebodddy,programming
mmlt5d6,1jwjw7b,reddit,"So you guys are building an ultra low latency screen sharing service and then choose a web technology? Just why 😭 why is everyone obsessed with using web for native applications, it just sucks. Pretty sure the memory usage on windows will be much higher. Ms Teams has plenty of these WebView2 instances that hog memory like crazy",2025-04-11 18:24:06,6,emdeka87,programming
mmjfmx0,1jwjw7b,reddit,568% more segmentation fault errors in runtime and 1% probability that your binary which depends on this f\*king os-native webview will launch on random machine (windows 7 - 0% probability),2025-04-11 10:24:30,10,vanbrosh,programming
mmnzqh5,1jwjw7b,reddit,"Why noone is talking about ""ToDesktop"" ?",2025-04-12 01:47:48,1,RealMadHouse,programming
mnefmcz,1jwjw7b,reddit,"Numbers are insane! Still not going to make me learn Rust, but wow from afar 🤣",2025-04-16 12:50:20,2,Competitive_Jump4281,programming
mmlnb30,1jwjw7b,reddit,"Tauri relies on a lie: ""platform native webview"". This doesn't exists. Cellphones might have one, windows forces edge and osx forces safari, but linux, bsd, chromebook, steamdeck and anything that's based on today's linux desktop doesn't.

When you say ""bundle size is `8.6 MiB`"" that's a lie. If I download your tauri application it won't run on my machine, I don't have webkitgtk installed nor want to, so your application better includes it. According to my package manager, it has to download 246MB if I tried to install it, which would put your application right back at electron's size.",2025-04-11 17:54:54,-3,RandomName8,programming
mmoksnb,1jwjw7b,reddit,Might as well just benchmark Rust vs JS...,2025-04-12 04:14:48,-1,WorkingSubstance7618,programming
ml6k0a0,1jqc8gy,reddit,"I've been using [uv](https://github.com/astral-sh/uv) for a while now which does this, nice to see a standard being pushed for all the other ways of managing python stuff.

uv is the only way of managing python projects that hasn't made me want to tear my hair out while screaming obscenities.",2025-04-03 11:17:18,95,Wolfy87,programming
ml5xx38,1jqc8gy,reddit,">Actual adoption remains open-ended

All the big tools have already said they'll either entirely switch to it or at least support it.",2025-04-03 07:37:47,133,SV-97,programming
ml6mxyp,1jqc8gy,reddit,"March 31, 2025: Python boldly steps forward into the early 2000s!",2025-04-03 11:39:50,141,Xyzzyzzyzzy,programming
ml67bgz,1jqc8gy,reddit,"Oh, neat, Python finally has a `Gemfile.lock`.",2025-04-03 09:19:18,50,slvrsmth,programming
ml871zt,1jqc8gy,reddit,Is this going to fix the fact that there are at least 14 different tools to work around python's global library nightmare?,2025-04-03 16:47:08,7,wildjokers,programming
ml75vc8,1jqc8gy,reddit,Definitely a good thing; python feels like a broken language with how dependency resolution works now.,2025-04-03 13:40:41,12,CVisionIsMyJam,programming
ml75pgu,1jqc8gy,reddit,Can only be a good thing. Python packages are a mess unless you use `uv`,2025-04-03 13:39:47,8,mr-figs,programming
ml881h2,1jqc8gy,reddit,"We moved to uv on all python projects, don't think about dep management and python versions anymore",2025-04-03 16:51:56,3,Yarden-zamir,programming
ml8695b,1jqc8gy,reddit,"Why is this called a lock file? I think of a lock file like the UNIX concept of a lock file, to indicate that a file is already opened by another task.

This doesn't appear to be that, it's a version control file. Is that right? Why is it a ""lock"" file?",2025-04-03 16:43:12,6,happyscrappy,programming
ml8607l,1jqc8gy,reddit,virtual environments and the entirely library install process is something where python is very far behind. Too many solutions none of them great.,2025-04-03 16:41:59,2,manzanita2,programming
ml8z3x2,1jqc8gy,reddit,Will this format specify the Python version?,2025-04-03 19:04:26,1,yawaramin,programming
ml9ei70,1jqc8gy,reddit,Python yarn basically,2025-04-03 20:20:23,1,faze_fazebook,programming
mlev1s0,1jqc8gy,reddit,"Dumb and genuine question, what's the difference between this and a requirements.txt file with specified package versions?",2025-04-04 18:01:30,1,Confused_AF_Help,programming
mlsriw9,1jqc8gy,reddit,is this gonna fix python rot,2025-04-07 02:05:53,1,KawaiiNeko-,programming
ml6ewxl,1jqc8gy,reddit,I can't see if this PEP supports PyTorch like stuff which have different versions based on different accelerator support.,2025-04-03 10:34:43,0,eiennohito,programming
ml7ip0f,1jqc8gy,reddit,"Good, I stick to google colab mainly because python package management sucks and eats gigabytes of disk space and many hours of my time just to end up in some state that wont work with something made over 6 months ago",2025-04-03 14:47:21,2,HeadAche2012,programming
ml6836e,1jqc8gy,reddit,"First, my knowledge of python comes almost exclusively from working with machine learning projects, so maybe I'm not sure what the actual issue is they are trying to solve with the proposal, but it sounds exactly like https://github.com/pypa/pipenv which I greatly enjoyed until uv started picking up.

You install your dependencies, it creates a pip file that holds all the deterministic information needed to verify and recreate it, you can address conflicts as it goes and then you can lock it so it hashes the packages for security reasons. The file contains all the versioning and everything, even if you build a wheel yourself and install manually. The only drawback that makes me prefer uv is the overhead during installation. Is this the issue they are trying to address? Or is it literally ""we don't want you to have to repackage the list if you decide to switch managers""?",2025-04-03 09:27:29,-8,tavirabon,programming
ml6sdj5,1jqc8gy,reddit,"> There have been at least five well-known solutions to the problem in the community, including PDM, pip freeze, pip-tools, Poetry, and uv,

Kind of reminds me of:

https://xkcd.com/927/

To the question ""Your thoughts?"":

I think there are tangible benefits such as:

> The file format also is designed to not require a resolver at install time.

What I find annoying is how they changed the infrastructure - pip, setuptools, wheels, flit_core, whatever-goes-and-the-mother-likes. It's quite strange how a popular language such as python, goes monkey-mode again and again. In two years it'll all be different again ...",2025-04-03 12:18:16,-6,shevy-java,programming
ml7xt02,1jqc8gy,reddit,"So they finally adopted JS package.json and PIP will not install/remove same package 5 times in row ? 

I wonder, what happen so Pyhon bosses stepped back from own stupidity?",2025-04-03 16:01:20,-2,Mundane-Apricot6981,programming
mm5jg1v,1juufhv,reddit,I really enjoyed this video. Had no idea about any of that. I always just assumed it was a flat image.,2025-04-09 03:26:08,46,cheezballs,programming
mm5i2ws,1juufhv,reddit,"Nice short video.

IIRC Nintendo also used to do the same thing with the Gameboy Advance, but instead of a copyrighted logo it was the Nintendo trademark itself. That's why you knew that a GBA cart was going to fail to load when the Nintendo was missing. I believe it also went to court and lost.

More generally, the courts have consistently upheld that there is nothing illegal about playing an unlicensed game on a console because preventing it would be anti-competitive, and you can't use traps like this as a loophole.",2025-04-09 03:16:43,30,Isogash,programming
mm6eyts,1juufhv,reddit,The more I learn about the og PlayStation the more I’m impressed. It blows my mind that the creators of Crash (or was it Spyro?) had to use the game to “hack” the ps system to get more memory or something similar,2025-04-09 08:08:04,6,peppersrus,programming
mmapdja,1juufhv,reddit,"I enjoyed the video, but I think the title is misleading.  I wouldn’t call that hacking, that’s just fiddling.  It doesn’t really compare to serious hacks such as the old [ECDSA nonce reuse hack](https://www.youtube.com/watch?v=j6yU9z8mtRE) that allowed installing arbitrary firmware.",2025-04-09 23:04:58,0,ScottContini,programming
mkp2kip,1jo59ba,reddit,"Can't wait for this to be supported by all browsers, I had to reimplement the select element way too many times in order to accomodate design requirements",2025-03-31 15:06:12,122,Giannis4president,programming
mkq1n5t,1jo59ba,reddit,"Huzzah. Now we just need to wait for Firefox, which shouldn't be long, and also Safari, and then five years for older versions of Safari that don't receive renderer updates because they're not on the latest version of OS:X to slip out of use",2025-03-31 18:00:34,55,BellerophonM,programming
mkp5l7o,1jo59ba,reddit,Freaking finally.,2025-03-31 15:21:32,43,Raunhofer,programming
mkpr3jd,1jo59ba,reddit,Our long nightmare is finally over.,2025-03-31 17:09:12,30,CanvasFanatic,programming
mkqw4lg,1jo59ba,reddit,"this shit should have been default in all browsers 10 years ago

along with a good date picker, the browser provided one is still far too variable and inconsistent

i dread to think the carbon footprint of select2/choices/chosen",2025-03-31 20:32:02,30,Lewke,programming
mkre6gu,1jo59ba,reddit,"lol. “Just use standard web technologies.”

Browser UI has been in the dark ages since its creation, and has no intention of ever catching up.",2025-03-31 22:06:20,10,editor_of_the_beast,programming
mkpba3j,1jo59ba,reddit,Thank God. I can’t believe it took this long.,2025-03-31 15:50:08,18,jack0fsometrades,programming
mkqu2vy,1jo59ba,reddit,What about select multiple?,2025-03-31 20:21:52,7,Alive_Scratch_9538,programming
mkrjp69,1jo59ba,reddit,This is great! Now let's do date pickers...,2025-03-31 22:37:50,7,lurco_purgo,programming
mkpsbv6,1jo59ba,reddit,holy shit it is about time,2025-03-31 17:15:17,6,personman,programming
mkqjamx,1jo59ba,reddit,Nice. Now add support for a native search box in it. Do it. Go on. Do it! DO IT!,2025-03-31 19:28:36,5,krileon,programming
mkxuaia,1jo59ba,reddit,"While they are at it, wish they add support for virtualization of content inside elements at a generic level to improve performance. E.g. virtualized rows inside a table, items inside a drop down.",2025-04-01 23:26:44,2,cpnemo,programming
mksny20,1jo59ba,reddit,Wonderful!!! No more messy html and javascript just to control the styling of select controls.,2025-04-01 02:41:26,1,SwiftySanders,programming
mkr3jrr,1jo59ba,reddit,"That's great, but is this a web-standard or a Google-standard?",2025-03-31 21:09:22,0,shevy-java,programming
mljlx6c,1jrlr8r,reddit,"I'm trying to wrap my head around what they mean by ""native"". The article waffles a lot but I think they mean they wrote their own Python JIT interpreter?",2025-04-05 14:26:09,45,Supuhstar,programming
mlif46y,1jrlr8r,reddit,Ok.,2025-04-05 08:18:43,11,standing_artisan,programming
mlgc61o,1jrlr8r,reddit,Good,2025-04-04 22:44:58,4,WillemDaFo,programming
mlk7m7x,1jrlr8r,reddit,How is this different from Jax?,2025-04-05 16:28:19,3,AmbitiousTour,programming
mlipg1r,1jrlr8r,reddit,If only they put as much effort into their drivers as they do stuff like this.,2025-04-05 10:14:27,7,nekokattt,programming
mmh77md,1jw88ct,reddit,"Time to update this...

https://imgur.com/a/5VzAdep",2025-04-10 23:37:31,191,bakery2k,programming
mmgo4m8,1jw88ct,reddit,Kind of confusing that there's now both `string.Template` and `string.templatelib.Template`.,2025-04-10 21:49:26,68,roerd,programming
mmggmiz,1jw88ct,reddit,Will this be usefull for day to day f string users ?,2025-04-10 21:10:02,22,WERE_CAT,programming
mmh93kg,1jw88ct,reddit,"Why are Python users so illiterate?  Click the link, read the (short) motivation, it provides the reason for the PEP pretty clearly.

https://peps.python.org/pep-0750/#motivation",2025-04-10 23:48:44,27,Halkcyon,programming
mmj0opb,1jw88ct,reddit,I was mildly surprised that internationalization wasn't mentioned as one of the examples in the motivation section.,2025-04-11 07:48:31,3,mgedmin,programming
mmgwau2,1jw88ct,reddit,"TIMTOWTDI, famous Python principle after all.",2025-04-10 22:34:49,14,lood9phee2Ri,programming
mmkuy5t,1jw88ct,reddit,Kind of amusing that Python will manage to ship string templates before Java (https://openjdk.org/jeps/459). The design itself is very similar to what is now being considered by the OpenJDK devs for when they bring the feature back.,2025-04-11 15:36:03,2,Hueho,programming
mmhrdc0,1jw88ct,reddit,We've reinvented str.format(),2025-04-11 01:40:28,4,rlbond86,programming
mmkxwd3,1jw88ct,reddit,"The feature itself looks useful, but really feels like they could have come up with literally any other name for it",2025-04-11 15:50:19,1,sysop073,programming
mmqsdhm,1jw88ct,reddit,"The `_ = TemplateMessage` example I think shows why i wish they went with javascript style template tags. 


Maybe they could have found a comprise syntax that doesn't exclude adding other letters later. I guess this doesn't stop them from adding one later.",2025-04-12 15:10:59,1,looneysquash,programming
mmumn0o,1jw88ct,reddit,"```
my_string = “a string that uses {uninterpreted} parts”.format(uninterpreted=“dynamic”)
```

So, the template string isn’t necessary a way to lazily evaluate strings—meaning it doesn’t replace the above code? But instead, it just offers a high level api over the semantic parts of the template? But it still evaluates and needs all the variables present immediately?",2025-04-13 05:06:26,1,DuckDatum,programming
mmhvp4t,1jw88ct,reddit,I use Jinja2 like a mf,2025-04-11 02:07:29,-1,__Blackrobe__,programming
mmh4s34,1jw88ct,reddit,This is silly.,2025-04-10 23:23:15,-13,redneckhatr,programming
mk13u14,1jkya80,reddit,"My hot take is that if tags are mutable, then GitHub shouldn't even allow them to be used as a reference. The whole point to pinning a version is to make sure it can't change and break, which makes them unfit for purpose. That's before we even talk about security implications.

They also absolutely should not have any documentation that uses that as an example if it's insecure by default.",2025-03-27 15:55:17,202,xeio87,programming
mjzswyk,1jkya80,reddit,"Our org used tj-actions but had already started pinning SHAs prior to this incident.

In your org’s GitHub Action settings you can create an allow list for actions, including which ref tags are allowed.",2025-03-27 11:31:37,51,Sinisterly,programming
mjzsor9,1jkya80,reddit,"> If you specify a Git commit ID instead (e.g. `a5b3abf`), 

ofc nothing stopping them from pushing a tag named `a5b3abf` right?",2025-03-27 11:29:52,53,ben0x539,programming
mk0w1zh,1jkya80,reddit,"Note that the provided command will look at GitHub Actions not only in your own project, but also in other subdirectories, such as `node_modules`. To look only at the GitHub Actions in your own repo:

    find . -path './.github/workflows/*' -type f -name '*.yml' -print0 \
      | xargs -0 grep --no-filename ""uses:"" \
      | sed 's/\- uses:/uses:/g' \
      | tr '""' ' ' \
      | awk '{print $2}' \
      | sed 's/\r//g' \
      | sort \
      | uniq --count \
      | sort --numeric-sort

(That just changes the `find` path from `*/.github/workflows/*` to `./.github/workflows/*`.)",2025-03-27 15:17:33,12,doublecastle,programming
mjz3dpr,1jkya80,reddit,Submitted article mirror: https://archive.is/J2wUM,2025-03-27 07:17:20,11,throwaway16830261,programming
mk1vjz9,1jkya80,reddit,Interesting article. I always was concerned about GitHub secrets being read by actions.,2025-03-27 18:05:54,8,RedEyed__,programming
mnfbhad,1k0mdpn,reddit,"The worst part about reddit is that you can only upvote something once. 

Great write-up, it's easy to forget how little substance most programming related posts typically contain nowadays until you encounter something like this that reminds you what technical blog posts should look like. <3",2025-04-16 15:37:36,41,loptr,programming
mnfxjgr,1k0mdpn,reddit,"I believe the 6502 was the last CPU a human can fully understand. I sometimes write VCS 2600 programs just to reconnect to the machine.

Also: Hail the Omnissiah",2025-04-16 17:25:06,27,nsn,programming
mnfoqu5,1k0mdpn,reddit,Interesting read and felt like a time machine. Long time ago I was programming assembler on the C64 and it was always fun fiddeling with the stack or doing some self modification stuff (although always ugly to debug).,2025-04-16 16:43:18,7,Bontaku,programming
mnh2gw3,1k0mdpn,reddit,"Is still the most convincing behaviour, in my opinion (quite old at this point in time; almost nobody has computers like that anymore):

https://tenor.com/view/guaton-computadora-enojado-computer-rage-gif-14480338",2025-04-16 20:47:45,1,shevy-java,programming
mmppg34,1jxeinw,reddit,"Hey r/programming,

This post acts as an introduction to writing WebGL shaders. It starts by building a mental model for writing shaders and it then walks through how to create a flowing WebGL gradient effect from scratch.

It's a lengthy post that touches on many topics — gradient noise, interpolation, color mapping, and generally how to write fragment (pixel) shaders. I hope you like it!",2025-04-12 10:53:41,27,XLEX97,programming
mmptkoh,1jxeinw,reddit,"This is super interesting to me, I became a web developer but always wanted to explore things that involve graphics. I avoid it because I utterly suck at math, so I have a debt to myself to eventually become comfortable working with graphics.",2025-04-12 11:30:17,9,peperinus,programming
mmqpw8a,1jxeinw,reddit,Now this is actually a good article. Finally some good content on this sub.,2025-04-12 14:57:37,7,Hidden_driver,programming
mmpr9ti,1jxeinw,reddit,"Weirdly this is completely broken on mobile, known issue?",2025-04-12 11:10:20,13,JaggedMetalOs,programming
mmq031a,1jxeinw,reddit,Well made writeup and cool result!,2025-04-12 12:21:01,3,Jewelots,programming
mmqwq5h,1jxeinw,reddit,"Terrific write-up, thank you.",2025-04-12 15:34:22,2,civildisobedient,programming
mmrbnc3,1jxeinw,reddit,"Always had an interest in computer graphics and shaders, having a step-by-step breakthrough of what seems like a complex shader seems like a godsend! Thank you, will definitely check out the full article.",2025-04-12 16:52:02,2,Medafu,programming
mmrmyr6,1jxeinw,reddit,Amazing write up. Thank you!,2025-04-12 17:48:53,2,mattv8,programming
mmul6xw,1jxeinw,reddit,I don't upvote things often but this deserves it.,2025-04-13 04:54:01,2,grimtooth,programming
mmve0ms,1jxeinw,reddit,"Awesome site and great blogs, really liked your blogs.",2025-04-13 09:42:37,2,N/A,programming
mn3up2v,1jxeinw,reddit,Absolutely love this! I’ll have a look at this later.,2025-04-14 18:48:08,1,Jellycake222,programming
mn76xre,1jxeinw,reddit,Absolute banger of a write up,2025-04-15 07:54:18,1,hardstuckBronze68,programming
mmsokkp,1jxeinw,reddit,"This is an exceptionally well-written introduction to shader programming. The step-by-step breakdown makes a traditionally intimidating topic much more approachable.

The author's approach of starting with a simple gradient and progressively adding complexity is exactly how shader programming should be taught. Too many tutorials jump straight to complex visual effects without establishing the fundamentals.

What's particularly valuable is the explanation of the mental model - thinking in terms of computing values for each pixel independently. This shift in perspective is critical for anyone coming from traditional imperative programming.

For those interested in going deeper, I'd recommend looking into:
1. Spatial data structures for more complex scenes (octrees, BVH)
2. Signed Distance Functions (SDFs) for creating complex geometry
3. Ray marching techniques that build on these same gradient principles

The WebGL API can feel verbose, but the core shader concepts translate well to other platforms like Three.js, Unity, or even mobile graphics frameworks.",2025-04-12 21:15:58,0,traderprof,programming
ml21f3v,1jpll84,reddit,Oh very nice. Can't wait to see how all these improvements will improve KDE Plasma desktop even more.,2025-04-02 17:27:35,18,JRepin,programming
ml0kljp,1jpll84,reddit,"Still one of best C++ RAD tooling, alongside VCL/Firemonkey on C++ Builder.",2025-04-02 12:51:48,28,pjmlp,programming
ml04w11,1jpll84,reddit,Nice,2025-04-02 10:52:42,80,HansLuft778,programming
ml0f8xd,1jpll84,reddit,"""Improved Emoji-Handling""

I desperately need more variants of the poop emoji. It has brought so many new ideas for epic games substituting emojis for images!",2025-04-02 12:15:12,23,shevy-java,programming
ml0uzjl,1jpll84,reddit,that's cute,2025-04-02 13:56:09,7,Few-Understanding264,programming
mktj5t2,1jop2wi,reddit,"Source? Reference? Anything to show that this is real?


EDIT: pre coffee and assumed the sub was against april fools jokes, my bad!",2025-04-01 07:08:27,212,epos95,programming
mkttddu,1jop2wi,reddit,Will there be a proper DIN standardisation for this proposal? I'm willing to donate fax machines for achieving the most efficient communication between the members of the standardisation committee.,2025-04-01 09:05:36,35,RabbitDev,programming
mku1fvw,1jop2wi,reddit,There was an article last week about a new memory safe C++ standard. It is basically a subset of the full language that excludes dangerous features like raw pointers. Linus Torvalds is reportedly backing it as an alternative to Rust for new Linux kernel contributions as it's more familiar to all the existing C programmers who contribute patches.,2025-04-01 10:32:17,19,Silhouette,programming
mku1qhf,1jop2wi,reddit,You a**holes you got me! 🤣🤣,2025-04-01 10:35:08,31,jolly-crow,programming
mktgp8z,1jop2wi,reddit,[deleted],2025-04-01 06:41:43,5,N/A,programming
mkujl3b,1jop2wi,reddit,Who will enforce the usage of Seed7? I hear Europol is already quite swamped & with Trump going ballistic Interpol has other security concerns.,2025-04-01 12:52:39,3,Sairony,programming
mku67g2,1jop2wi,reddit,"ok, thank you for this joke! :)",2025-04-01 11:15:25,3,tehnic,programming
mkubh6r,1jop2wi,reddit,"Demanding the standarized use of a programming language across the industry is the most European Union thing possible so I'm going to believe it's true

EDIT: Ah, damn it. You got me",2025-04-01 11:56:53,2,MileiMePioloABeluche,programming
mkufc8t,1jop2wi,reddit,It was hard choice between brain fuck and seed7,2025-04-01 12:24:14,3,hk19921992,programming
mktiaw7,1jop2wi,reddit,"Its good they are thinking about this.

But I wonder for lighter stuff will Python and JS need replacements? Can they be replaced?",2025-04-01 06:59:02,1,ProdigySorcerer,programming
mktkstu,1jop2wi,reddit,LUA FTW /s,2025-04-01 07:26:45,1,-1_0,programming
mku05es,1jop2wi,reddit,To think they would use Seed7 versus Sn33d.,2025-04-01 10:19:29,1,-Y0-,programming
mkucqoj,1jop2wi,reddit,"Haha! good one

Just stupid enough to be credible. Bravo!",2025-04-01 12:06:13,1,EnGammalTraktor,programming
mkuihh9,1jop2wi,reddit,"> 70% of Rust developers are calling unsafe code through foreign functions.

... to interface with existing native libraries?

> Seed7 is the clear winner. It is the clear winner because it is memory safe and has no unsafe parts

... which means it can't benefit form existing native libraries and it can't be used to implement a lot of things, especially any hardrware-software interfaces and low-level code.",2025-04-01 12:45:37,1,Pharisaeus,programming
mkxf8be,1jop2wi,reddit,"First april so ...

> This is seen as long term commitment of the European Union to improve software quality 

The commission is not very competent, but the Dutch are:

https://www.reuters.com/world/europe/dutch-parliament-calls-end-reliance-us-software-2025-03-18/

I don't refer this primarily in regards to ""become less dependent on US companies"" per se, but more about becoming more independent in general. Although I would not mind becoming less dependent on US companies pushing the narrative for crippling tariffs - I hold them also responsible, so the dutch approach makes double sense to me. (Sadly, not everyone in Europe is as willing to change as the dutch are. Rest of Europe is snail-pacing behind ... and Germany is even going backwards here.)",2025-04-01 21:59:39,1,shevy-java,programming
mkyyi6a,1jop2wi,reddit,I was gettin’ real mad lol,2025-04-02 03:45:44,1,o5mfiHTNsH748KVq,programming
mkudy2d,1jop2wi,reddit,/r/Angryupvote,2025-04-01 12:14:28,1,Kwantuum,programming
mkyy9zw,1jop2wi,reddit,Don’t believe anything posted today. It’s April fools.,2025-04-02 03:43:59,1,BiteFancy9628,programming
mkvgpcr,1jop2wi,reddit,"*This is a bold move indeed. I hadn't looked into Seed7 much before, but this definitely puts it on the radar. The part about tax incentives for rewriting libraries is huge—curious to see if companies will actually adopt it at scale or if it’ll stay more academic. Have you seen any real-world projects already running in Seed7?*",2025-04-01 15:55:57,0,tomasartuso,programming
mkty6h5,1jop2wi,reddit,"Memory safety is one of the least interesting correctness problems. If you can't be trusted to manage your own memory, why would I trust you to get anything else right?

And now I'm gonna get a bunch of people complaining at me who were told manual memory management is an impossible problem and never tried their own hand at figuring out how to do it consistently. Of the ones who did try, I can guarantee you that some 95% of them tried calling malloc every time they wanted to store something in the heap, got into a tangled mess, and never asked what would happen if they didn't write spaghetti code. The last 5% have something interesting to say.

The problem isn't language features, it's culture. Everyone is told to be scared of the problem, so they run from it instead of attacking it, solving it, and sharing their victories with their peers. If you try to share your victories, then you get browbeaten by know-nothings who think you're being prideful when all you've done is reach a basic level of competency. Of the people who are willing to try, this petty behavior speedbumps them hard and makes it not worth sharing anything.

Knee-jerk less, you judgmental twats, and maybe you'll actually learn something.",2025-04-01 09:59:02,-8,Sabotaber,programming
mobfrhs,1k4hg9j,reddit,"Awesome, did a ELI5 video on that topic awhile ago [https://youtu.be/zsB-8v9LC7w](https://youtu.be/zsB-8v9LC7w)",2025-04-21 20:37:55,35,hougaard,programming
mobr853,1k4hg9j,reddit,Here is the repo: [https://github.com/LukasNiessen/oauth-explained](https://github.com/LukasNiessen/oauth-explained),2025-04-21 21:35:48,10,trolleid,programming
modteh6,1k4hg9j,reddit,"**Question:** *Why not just send the access token in step 6?*

redirect\_uri is very important. It's used in step 6

The markdown numbering is broken, there is no step 6",2025-04-22 05:06:55,8,One-Blueberry73531,programming
mobyskq,1k4hg9j,reddit,"Here is a talk I gave that you might find educational.

https://youtu.be/r0BCki3U2AM?si=UiY4EJwKNHKJHiNz",2025-04-21 22:16:59,3,NotMyself,programming
moe1tx5,1k4hg9j,reddit,"How does LinkedIn know that the one\_time\_code that Google replied with belongs to me and not say, someone else halfway around the world doing the same thing?",2025-04-22 06:24:46,3,Zahand,programming
momomer,1k4hg9j,reddit,Great writeup. [This]( https://stack-auth.com/blog/oauth-from-first-principles) is another blog post that can help understand why it is designed this way.,2025-04-23 16:10:01,3,nyctrainsplant,programming
modjhb1,1k4hg9j,reddit,AI generated?,2025-04-22 03:51:18,7,dmitrysvd,programming
momysrs,1k4hg9j,reddit,"I also wrote a guide on OIDC if you're interested :-)  
[https://github.com/LukasNiessen/oidc-explained](https://github.com/LukasNiessen/oidc-explained)",2025-04-23 16:59:19,1,trolleid,programming
moehxa9,1k4hg9j,reddit,"> Note: So OAuth solves an authorization problem! Not an authentication problem. See [here][ref1] for the difference.

It's the other way around, OAuth handles authentication, not authorization",2025-04-22 09:17:11,-1,Rinkin-,programming
mobim6z,1k4hg9j,reddit,"LOL, no one understands how OAuth2 works.

Remember, it was designed by a committee of big tech companies to be incredibly complicated so they could sell it as a service. This is why the lead author of OAuth1 and an early OAuth2 spec lead left the project.",2025-04-21 20:51:49,-25,wildjokers,programming
mn964km,1jzujux,reddit,"I'll be honest, the most surprising part to me is that, apparently, a huge amount of people can even use these tools. I work at BigNameCompanyTM and 90% of the things I do simply cannot be done with LLMs, good or bad. If I just hook up one these tools is some codebase and ask to do something it will just spill nonsense

This ""tool"" that the blog is an ad for, it just crudly tries to guess what type of project it is, but it doesn't even include C/C++! Not only that but it it's unclear what it does with dependencies, how can this possibly work if my dependencies are not public?",2025-04-15 16:09:53,188,teerre,programming
mn8yyh4,1jzujux,reddit,"AI gives you quantity, not necessarily quality. Still need a solid dev process.",2025-04-15 15:34:10,74,isaiahassad,programming
mn9b5xp,1jzujux,reddit,the ai-generated image slop detracts from your article.,2025-04-15 16:35:02,111,PurpleYoshiEgg,programming
mn9fwpa,1jzujux,reddit,"The number of people calling out AI... While saying people use AI with out reviewing, testing or understanding the code depresses me. 

But the same thing was true when people worked and just copied and pasted Stack Overflow code without testing it...  There IS a solution. 

If someone at your company tries to check in AI code which doesn't work, you should treat that as if someone checked in code that is broken, they essentially shouldn't be employees in the long term.  It's one thing if they do this on a specific change, or there's a rush to get the code in, but if the code doesn't work in a direct test... what test did they run?  

If you use AI to generate the code or stack overflow or pound on the keyboard... it doesn't matter, you as a developer are the one with the name on that code, not the AI. 

Basically 90 percent of the problems people have (poorly written code, non working code) isn't a AI problem necessarily, it's a developer problem who accepts that code.    Hallucinations do happen but at that point you'll realize after a quick compile/google.  

I'll continue to use AI because when I have to write a function, 90 percent of the function works, and usually I write a system design to AI that makes it understand WHAT I want to do, WHY I want to do it, and HOW I expect to do it.    It's faster to generate that code at that point, and review it.  There's actual productivity there, and besides having a system design is a good thing.",2025-04-15 16:58:16,19,Kinglink,programming
mn92p0g,1jzujux,reddit,"AI flat out lies in a confident manner, and when caught admits it and lies again. It itself admits it doesn’t know if its lieing but generates a probable answer, has the ability to check itself but doesn’t, and requests the user to hold it accountable. But heres the problem - inexperienced or less knowledgeable persons are not capable of that.

AI also cheats at chess by making illegal moves and adding pieces when jt feels like it.",2025-04-15 15:52:34,24,StarkAndRobotic,programming
mn8w5ij,1jzujux,reddit,"After months of using AI coding assistants, I've noticed a concerning pattern: what seems like increased productivity often turns into technical debt and maintenance nightmares.



Key observations:

\- Quick wins now = harder maintenance later

\- AI generates ""working"" code that's hard to modify

\- Security implications of blindly trusting AI suggestions

\- Lack of context leads to architectural inconsistencies



According to Snyk's 2023 report, 56.4% of developers are finding security issues in AI suggestions, and Stack Overflow 2024 shows 45% of professionals rate AI tools as ""bad"" for complex tasks.



The article explores these challenges and why the current approach to AI-assisted development might be unsustainable. 



What's your experience with long-term maintenance of AI-generated code? Have you noticed similar patterns?",2025-04-15 15:20:11,47,traderprof,programming
mn8yjf9,1jzujux,reddit,"Another shit article, generated by Ai, about how bad AI is, posted on r/programming. Is this broadly all some kind of posts-ironic art piece?",2025-04-15 15:32:05,33,GregBahm,programming
mn95jxg,1jzujux,reddit,"I think it's fantastic for small snippets and to use as a rubber duck. For it to code for you use it to code is a no go. It's sort of like grammar checking in word, sometimes it's useful, but it's a tool. I tried to code something with power automate. It makes a table, close but unable to adjust it at all. Could I make it work, yeah probably but it's dogshit.",2025-04-15 16:06:54,4,Icy_Party954,programming
mn9g3kt,1jzujux,reddit,"No offense but one of these article gets posted once a day and this offers nothing new and nothing substantial. More slop.

Also, I don’t trust a report from 2023 about LLM code “vulnerabilities”. I’m not saying trust code automatically, but comparing models from 2023 to ones now is hilariously wrong. Gemini 2.5 is very good when used properly",2025-04-15 16:59:11,13,HaveCorg_WillCrusade,programming
mnbh2u2,1jzujux,reddit,I tried some ai-assisted coding for a while and did not like it.,2025-04-15 23:12:48,3,TheDevilsAdvokaat,programming
mn9en4k,1jzujux,reddit,"Hey here's a thought, how about you use the tools to generate code in circumstances in which they are currently capable, and then, idk, review that code before accepting it?  BTW whatever the AI generated fuck this blog  is is fundamentally revolting.",2025-04-15 16:52:11,6,dbqpdb,programming
mn9116b,1jzujux,reddit,[deleted],2025-04-15 15:44:27,4,N/A,programming
mn953f6,1jzujux,reddit,"Bad developers produce bad code with AI. Lazy developers think AI tools absolve them from needing to adhere to strict documentation, design patterns, or things like TDD and they end up creating garbage slop.

These things are even *more* important because LLMs are like a junior engineer with debilitating ADHD. They’re good in small bursts, but you need to check their work every step of the way.",2025-04-15 16:04:34,2,o5mfiHTNsH748KVq,programming
mn92lfp,1jzujux,reddit,"For me the biggest win is that I can tell the AI I have a certain data frame and I want a graph showing something or other. And then I can iterate on the suggested code to get the graph to look more or less the way I want to. I've never learned matplotlib very deeply, and I find it's API very confusing, but ChatGPT can somehow make me at least 3 or 4 times quicker to get to the result I want.",2025-04-15 15:52:06,2,jotomicron,programming
mnb0m9g,1jzujux,reddit,Yeah and chatgpt is becoming dumb now...,2025-04-15 21:40:59,1,TCB13sQuotes,programming
mnb45pw,1jzujux,reddit,"I haven’t used TDD or BDD, but thinking of the LLM as another actor makes sense—it thrives on structure and consistency.

You’re right, it’s a lot like requirements/decisions docs. LLMs force us to reframe old problems—hence all the new tooling just to consistently instruct llms(jinja, yaml, prompt classes, etc.).

TDD is interesting since tests capture intent and outcomes—exactly what we do when prompting LLMs. I have no experience with llms and TDD. 

To help the assistant, I changed how I organize code—by feature instead of type. Each feature holds its own schema, service, controller, etc., so I can work on it end-to-end without needing tons of context. It sped things up a lot—adding new features got 10x faster.

Design thinking happens when I hit new territory, but the structure makes it easy to zoom in on a feature or discuss things project-wide.

Your last point is crucial if you want to relay more and more on ai agents. Small mistakes are amplified overtime. It’s easy to get to a point where code is unmaintainable.",2025-04-15 21:59:54,1,MothWithEyes,programming
mnbkl3n,1jzujux,reddit,"Let's be honest here, how often you violated SonarQube and Fortify rules?",2025-04-15 23:32:24,1,BoBoBearDev,programming
mnd7wj6,1jzujux,reddit,"It is bad for complex tasks. But it’s absolutely amazing for boilerplate code and documentation. For the latter, writing as well as reading. Not everyone invent containers when programming.",2025-04-16 06:15:38,1,MrOaiki,programming
mngsy5f,1jzujux,reddit,It's just a terribly inefficient way to generate code. We've already been using code to write other code. This just adds an enormous computational expense to an existing practice without due cause,2025-04-16 20:00:46,1,oclafloptson,programming
mndfin9,1jzujux,reddit,"Jesus the AI hate in this sub is extreme. Is it Pearl clutching and fear of obseletion masked as ""I dont trust it""? Well ofc not, it is a tool, like your computer or IDE, apply it smartly....",2025-04-16 07:33:41,1,Timely-Weight,programming
mn98jrd,1jzujux,reddit,[deleted],2025-04-15 16:22:15,0,N/A,programming
mn989fx,1jzujux,reddit,"These are the ""the web is a fad"" articles of the late 90s",2025-04-15 16:20:56,-3,strangescript,programming
mn96sgj,1jzujux,reddit,"I've been using it to help me integrate with a payment processing API.


I'm still writing the code, but using the AI to assist with parsing API documentation, and asking specific architectural questions in regards to the provided documentation.


It has increased productivity drastically and allowed me to capture everything in clean tests, with all of the leftover time.",2025-04-15 16:13:25,-4,WalterPecky,programming
mnxocr5,1k2rgwq,reddit,Everyone loves a quine! Nice work.,2025-04-19 14:53:54,28,igorpk,programming
mnxkr6c,1k2rgwq,reddit,"Classic ""write a program that outputs its own code"" that replaces printf with CreateGif..",2025-04-19 14:34:17,20,Ateist,programming
mnwhuqd,1k2rgwq,reddit,wow that's cool,2025-04-19 09:38:49,5,FederalRace5393,programming
mo6ea8v,1k2rgwq,reddit,Ever heard of xpm?,2025-04-21 00:21:55,1,Foreign_Hand4619,programming
mo7s5rf,1k2rgwq,reddit,Love it!,2025-04-21 06:15:23,1,Kok_Nikol,programming
mo8n4ol,1k2rgwq,reddit,"Fucking hell 70 MB? You're aware that gif has a compression algorithm, right?",2025-04-21 11:27:28,1,araujoms,programming
moepcd2,1k2rgwq,reddit,So cute,2025-04-22 10:32:09,-1,Silly-Advertising826,programming
mnwcdhm,1k2rgwq,reddit,Haha awesome gotta love’s this one 😹,2025-04-19 08:39:23,-24,old-bot-ng,programming
mnxuvaa,1k2rgwq,reddit,That’s clever but not difficult.,2025-04-19 15:28:54,-37,postmaster3000,programming
mn4tnha,1jz0azj,reddit,"This is interesting to know, good find. I however rarely care for this kind of micro-optimization in Python. Not saying there is no merit to it, but I'd hope not to need them when I write Python. If something like this made a meaningful difference in my program, maybe I shouldn't be using Python. In this case, I'd generally favour `len` simply because it is more explicit and will error if the variable is `None` or something without length.",2025-04-14 21:47:29,170,jdehesa,programming
mn4lvw7,1jz0azj,reddit,"I always use ""if not list"" , even though I didn't know it's faster, for the simple reason that it is shorter to type. At the end of the day I am not using Python to write fast code but to write code fast. 

It makes sense though, that calling a function and then doing a comparison is slower than just doing a direct ""comparison"".

Although, if THAT is causing you performance issues, then you are probably using the wrong language for the task.",2025-04-14 21:05:37,101,Swoop3dp,programming
mn5bsel,1jz0azj,reddit,"I always see such comparisons and think ""who cares about the microseconds, it's python"", but just several days ago I needed to optimize a hot loop, in python! One of the things it did was comparing a var to ord('@'). A profiler showed it took 10%! Probably because it's a function call. I replaced it with a hard coded ascii val and a comment, ugly but saved me a couple of minutes per each run. ",2025-04-14 23:31:41,22,unaligned_access,programming
mn4jous,1jz0azj,reddit,Sane language standard libraries would have IsEmpty to guide programmers away from shooting themselves in the foot without having to know about language internals.,2025-04-14 20:54:17,59,FF3,programming
mn79sra,1jz0azj,reddit,"Before anybody blindly starts changing their code, be aware that `len(foo) == 0` and `not foo` are not equivilant expressions. Some list-like objects return true for the former and false for the latter.",2025-04-15 08:25:48,4,maep,programming
mn6tozy,1jz0azj,reddit,Makes sense to optimize the idiomatic way.,2025-04-15 05:37:22,4,oweiler,programming
mn5c82y,1jz0azj,reddit,"Except `if not list` is not the same. It works for `list = None`. It works for `list = False` and `list = True`. Hell, it works on any object. 

As to why you'd want an empty list to coerce to `False` is beyond me, but it is defined: https://docs.python.org/3/reference/datamodel.html#object.__bool__

But you're not testing the fact whether someone is actually passing in something that has `len()` method. 

So I'd block your PR based on trying to be smart by actually making the code more stupid, as now I need to go through much more mental gymnastics to figure out what the actual type is of whatever you're testing against.

Oh, and in case you're wondering: I'm a big proponent of types. I don't get why you'd want to develop without. And when you have that information you can get rid of so much cruft.",2025-04-14 23:34:10,5,AnnoyedVelociraptor,programming
mn70khv,1jz0azj,reddit,"I don't know why but Dive into Python told me so 20 years ago, thanks Dive into Python.",2025-04-15 06:46:07,1,ivenvd,programming
mn8sr6e,1jz0azj,reddit,Hate python. It’s the new Ruby ,2025-04-15 15:03:04,1,hopfield,programming
mn8tewg,1jz0azj,reddit,Good to know if you’re doing a metric ton of Len calls,2025-04-15 15:06:24,1,jeremiah15165,programming
mn9a139,1jz0azj,reddit,"Guys i need someone who is learning c++.
Need help contact me asap",2025-04-15 16:29:16,1,abdurrohman18,programming
mna3yhe,1jz0azj,reddit,Im a cs student and my question is why didnt they make the compiler optimize this on its own? I mean it cant be that hard right?,2025-04-15 18:56:33,1,PitifulEcho6103,programming
mn52xad,1jz0azj,reddit,"I don’t have a lot of programming hangups, but the word “Pythonic” always just makes me mad. It’s such a cop out for so many style arguments: “do it because the style guide says to!” Like, whatever man. It might even be a good idea, but the use of the word makes me _want_ to not like it.

That said, makes sense that there’s a short path for the Boolean conversion.",2025-04-14 22:40:28,-1,SnS_Taylor,programming
mn61vkj,1jz0azj,reddit,Python and performance are two mutually exclusive terms.,2025-04-15 02:07:36,-1,Foreign_Hand4619,programming
mn5awrk,1jz0azj,reddit,"This is really great because, serendipitously, I’m dealing with a high performance Python list testing problem at work.",2025-04-14 23:26:41,0,visicalc_is_best,programming
mn7favc,1jz0azj,reddit,"The correct answer is ""because there isn't an optimisation for this extremely obvious case"".

The more correct answer is ""because Python is a terrible language that doesn't provide an `Any()` or `None()` method for lists"".

It never ceases to blow my mind how people use ""simplicity"" (or in this language's case, ""Pythonic"") to justify objectively bad language design-by-omission.",2025-04-15 09:26:41,-4,IanAKemp,programming
mn3x6bi,1jz0azj,reddit,"> That's an almost 2x performance difference for something as fundamental as checking if a collection is empty. This operation occurs millions of times in any non-trivial Python application.

Way to go Python.  Someone remind me again how this became such a popular programming language.

We lost something when SICP switched from Lisp to Python such that 'programmers' can seemingly no longer intuitively understand that checking a structures length isn't as inherently fast as checking if it's dereferenced value is null/nil instead. 

Bring back basic comp sci for 'programmers' and get frd of all the ""batteries included"" BS that modern programming languages provide as standard to the detriment of a deeper, more well structured, and considered understanding of first principles.",2025-04-14 19:00:31,-34,church-rosser,programming
mleallx,1jrc228,reddit,"If you are thinking of doing this project, please do yourself a favour a do the newer 6502 project first.

  
Its way more begginer friendly and a nice introduction before spending 100 hours assembling the 8 bit computer",2025-04-04 16:19:42,58,urielsalis,programming
mldn4lf,1jrc228,reddit,I highly recommend this project if you have a lot of spare time (half your time will be spent cutting and stripping wire and making everything neat). [I did it three times and made my own small improvements with each iteration.](https://austinmorlan.com/posts/8bit_breadboard/),2025-04-04 14:22:20,20,vertexmachina,programming
mldz3vp,1jrc228,reddit,If you wanna do this “virtually” check out “Turing Complete” on steam,2025-04-04 15:22:15,9,itsjase,programming
mlezbrb,1jrc228,reddit,"I've also heard good things about this course:
[NAND2TETRIS](https://www.coursera.org/learn/nand2tetris2)",2025-04-04 18:23:07,5,Br3ttl3y,programming
mldwi8l,1jrc228,reddit,"Yep, Ben Eater's great.",2025-04-04 15:09:17,7,khedoros,programming
mleagf4,1jrc228,reddit,"Love it, but fuck that. XD

My fingers are just too stubby to enjoy breadboard work.",2025-04-04 16:18:59,2,a_printer_daemon,programming
mlfbywp,1jrc228,reddit,"You can implement this with Logisim if you're looking for a way to achieve this without the kit. It won't necessarily run super fast if you try and run long programs, but it will teach you the logic fundamentals.

I started with the ben eater video PC and ended up slowly upgrading it into a 6502-lite:

https://imgur.com/a/wbF5j57",2025-04-04 19:28:15,2,TheKrumpet,programming
mlfpccb,1jrc228,reddit,"First thing I thought was, has OP seen Ben Eater's stuff?

Oh, then I followed the link. :)",2025-04-04 20:37:01,2,greebo42,programming
mlicnq0,1jrc228,reddit,"Brings back memories. Growing up in Yugoslavia in 80s, building your own computer was a way to have one. Importing was forbidden, so one guy (Voja Antonić) came up with the idea to build one from scratch (Galaksija), write an OS for it and publish schemas and code in a computer magazine. He expected that maybe 100 will be built in the whole country, but the initial number reached over 10000 and people are still building it for fun.",2025-04-05 07:51:52,1,drvobradi,programming
mllfdul,1jrc228,reddit,"or install logisim-evolution which is free and simulate your CPU way faster and easier.
 
you are not limited by wires and the ICs you buy and you can do 16 or even 32 bits, you can do a single cycle CPU up to a superscalar out of order CPU",2025-04-05 20:32:19,1,takethispie,programming
mlfd2ws,1jrc228,reddit,"Can't you get basically single chip 32bit CPU's i.e flash storage and ram on the same chip? 

Seems a pointless novelty to me.",2025-04-04 19:34:05,-4,Plank_With_A_Nail_In,programming
mlcot5n,1jr2vdc,reddit,Wow what a hot take. Nobody has thought this before.,2025-04-04 10:35:57,156,Kenji776,programming
mlcwjex,1jr2vdc,reddit,"""The abacus is the original ALU""",2025-04-04 11:39:18,37,GeneReddit123,programming
mlek6x8,1jr2vdc,reddit,"Oh, really? /s",2025-04-04 17:07:55,4,RedEyed__,programming
ml7kcq7,1jqg3d4,reddit,"How long did the process of engineering take for this solution, and how big of a team was involved?

This reminds me of some problems I've worked with, and the frustration all around of trying to fit this into Jira XD (half kidding, sounds like a lot of experimentation was involved)",2025-04-03 14:55:23,30,kreiggers,programming
ml7x9w5,1jqg3d4,reddit,"I believe virtualized rendering is an example of the more general [flyweight pattern](https://refactoring.guru/design-patterns/flyweight) - you're not creating and rendering all the elements, just a minor subset and recycling that subset with different properties each time, so that you don't have to create, update and destroy elements each time they go out of view.",2025-04-03 15:58:41,18,GimmickNG,programming
ml6modt,1jqg3d4,reddit,"**\[ Disclaimer - I’m an engineer at SigNoz \]**  
  
If you’ve ever tried rendering a million `<div>` elements in a browser, you know what happens, everything freezes, crashes, or becomes completely unusable. This was the same challenge we were faced with when we started to build visualisation of traces with million spans in SigNoz.I’ve detailed all my findings and wisdom in a blog, which broadly covers,

* Smart span sampling
* Virtualized rendering
* Lazy loading and chunked data fetch
* Browser memory optimizations

All built with performance in mind, so engineers can analyze massive traces with confidence.Give this blog a read and let me know if you’d do anything differently!",2025-04-03 11:37:52,65,vikrant-gupta,programming
ml82ytz,1jqg3d4,reddit,"This is one thing that I was surprised to see how poorly AWS manages. X-Ray tracing is really easy to integrate with if you're already in the AWS ecosystem. But if you have a large amount of segments/subsegments on your traces, the UI just chokes. Loading the exact same trace in Grafana is often much smoother.",2025-04-03 16:26:57,6,FlinchMaster,programming
ml6op5a,1jqg3d4,reddit,I thought you were talking about `Span` from C#,2025-04-03 11:52:29,37,SureConsiderMyDick,programming
ml7x1bj,1jqg3d4,reddit,"Having a native virtual list element has been one of the longer waits. I remember close to 10 years ago using Polymer's iron-list and we're still nowhere closer to having native. I mean hell, we're just now starting to get the ability to style `<select>` options so maybe it's asking to much.",2025-04-03 15:57:30,7,shawncplus,programming
ml6r65n,1jqg3d4,reddit,Hey i have been following signoz for some time now. It feels like an amazing tool for Otel observability. The UI is also nice. Its interesting to know that you guys are using clickhouse under the hood. Have you ever considered using rust instead of golang. Want to know if you faced any challenges with golang at scale. Since I keep hearing about companies moving from go to rust because of gc,2025-04-03 12:09:58,5,RoXyyChan,programming
mlbkg6d,1jqg3d4,reddit,"Amazing work u/vikrant-gupta , the idea to limit the data sent from backend with the offsets is interesting. How do you handle if the user searches for a span which is outside of this limit? Based on my understanding, this would take some time to load it right?",2025-04-04 04:09:13,2,confucius-24,programming
mlgdalg,1jqg3d4,reddit,This article makes me feel old.,2025-04-04 22:51:43,2,macca321,programming
mlhsa6t,1jqg3d4,reddit,"Cool article but there is one small, tiny issue: the browser can definitely handle 1 million spans without serious problems, just a small delay in rendering.  Just don't use react for it, react would have terrible problems due to the virtual DOM.

/pedant mode, sorry",2025-04-05 04:39:06,2,SirPurebe,programming
ml76inb,1jqg3d4,reddit,awesome article! I thought the flattening of the graph was a pretty good idea.,2025-04-03 13:44:20,2,CVisionIsMyJam,programming
ml9epum,1jqg3d4,reddit,"I had a similar problem where I wanted to draw millions of spans, but I wanted a lot more on screen at once.


I ended up just drawing everything in a canvas and simulating clicks by tracking x/y coordinates, that worked fast enough.",2025-04-03 20:21:25,1,Kasoo,programming
mlg5nw2,1jqg3d4,reddit,"Why did you not use a canvas element?
Do the span need some interactivity?",2025-04-04 22:06:00,1,zaidazadkiel,programming
ml6wdiz,1jqg3d4,reddit,Thanks for sharing this.,2025-04-03 12:44:35,1,greybeardthegeek,programming
ml8uw5i,1jqg3d4,reddit,Will check this out today - been running into just these types of issues with some data intensive webapps :) thanks in advance for the writeup,2025-04-03 18:43:26,1,chsiao999,programming
ml8wti4,1jqg3d4,reddit,Great write up.,2025-04-03 18:52:58,1,wwww4all,programming
mlaa3od,1jqg3d4,reddit,"> Rendering millions of spans in a browser isn’t easy.

Could have saved a lot of time and energy by not using a browser. I don’t know why people insist on using the browser for everything. 

Rendering quads and text is really really easy and really really fast. There are countless profilers that do this in DearImGui without breaking a sweat.

I mean good job and kudos on good engineering. But seriously people, stop using web browsers by default. They kinda suck and are terrible.",2025-04-03 23:10:39,-1,forrestthewoods,programming
ml8y32c,1jqg3d4,reddit,"Programmer discovers scalability in the age of super computers, news at 11.",2025-04-03 18:59:15,-14,VictoryMotel,programming
mon2s6d,1k6460t,reddit,"As someone who wrote serious C++ for almost 35 years (and still have to at work for now) I was one of those people who reacted negatively to Rust, and made a lot of the same arguments C/C++ people are still making. But now, three years in, no way I'd use C++ if I had a choice.

Rust is a systems language and it will take a while to really get not just comfortable with but adept at (something many C++ people ignore about C++ because they've been doing the slow lobster boil learning experience for many years or multiple decades.) But, once you get really comfortable with it, it's just vastly superior to C++. 

Even if it weren't for the memory safety, which is a HUGE benefit, just the much more modern capabilities, lack of UB, vastly greater consistency, good safe defaults, lack of silent but deadly magical conversions, sum types, etc... it's just far easier to write solid code with.

BTW, in the example where you were allocating a vector, it's still perfectly legal in Rust to use an output parameter in cases where you are wanting have something filled in on a rapid basis and want to reuse it. And it's completely safe. If you don't want to do that, then destructive moves means you can safely swap a vector in and get it back out via return.",2025-04-23 17:18:15,298,Full-Spectral,programming
morred6,1k6460t,reddit,"> `while((len = *src++) != 0) {`

I swear 99% of the bugs in c/cpp code are from people trying to seem clever. Code is for humans. Let the compiler do its thing.",2025-04-24 11:29:39,17,MooseBoys,programming
mon74y1,1k6460t,reddit,Didn’t read bc text overflows on my phone screen and I have to scroll left and right,2025-04-23 17:38:40,85,miramboseko,programming
mon3nak,1k6460t,reddit,Rust is like having a really strict coach following you around putting pedantic but useful roadblocks in your way to ensure you follow good form. The compiler essentially MAKES you write memory safe code.,2025-04-23 17:22:16,70,Dirty_South_Cracka,programming
moo93n8,1k6460t,reddit,"Even excluding the memory safety guarantees, the rust compiler is strict about implementing good coding practices. A project written in rust implies a base level of quality.

This might not be a big deal in large projects developed under strong technical leadership. But for any random piece of software you might use, while not guaranteed to be bug free, does give some assurances that code quality is important enough for the developers to be willing to use rust. That counts for something, to me at least.",2025-04-23 20:41:50,14,BananaUniverse,programming
mon1hoo,1k6460t,reddit,Volvo doesn’t make you driving much safer if you always drive like an idiot.,2025-04-23 17:12:12,23,phil_gal,programming
mooda9j,1k6460t,reddit,Yes.,2025-04-23 21:01:58,2,nyctrainsplant,programming
moodte3,1k6460t,reddit,It’s a good language!,2025-04-23 21:04:34,4,GabeFromTheOffice,programming
mouhvum,1k6460t,reddit,"I can write shitty, insecure code in AND language.",2025-04-24 19:52:20,1,Gipetto,programming
mop2v56,1k6460t,reddit,"But ... it seems like the end upshot is ""a basic fuzz tester would have caught all of these and is still required even for Rust"".",2025-04-23 23:19:02,-2,buzmeg,programming
mon2xai,1k6460t,reddit,"Interesting fact - half of all popular crates uses a lot of unsafe rust code and actually not memory safe. C has bound checking. No one cares about invariant static analysis. Nice ad.

Edit: Rust woke people hello, I hope one day you will become mature and start learning something except ads on internet ahahah",2025-04-23 17:18:54,-77,morglod,programming
mor1lq9,1k6460t,reddit,Techno-vegan Femboys with programming socks literally cannot tell an Ad from genuine article.,2025-04-24 07:24:00,-17,DearChickPeas,programming
mlftrir,1jrlv3y,reddit,">That said, most high-level languages (JS, Java, C#, …) capture variables by reference:

Java captures all variables by value. Under the hood, the values are simply copied to the fields of the lambda object.

So how does it avoid having the following code behave non-intuitively (translated from the article)?

    var byReference = 0;
    Runnable func = () => System.out.println(byReference);
    byReference = 1;
    func.run();

It's actually very simple: the code above will not compile. To stop people from incorrectly assuming variables are captured by reference, it simply bans the situation where it makes a difference, i.e. captured variables cannot be reassigned.

If you want to be able to reassign, you just need to create a separate final variable for capturing:

    var byReference = 0;
    var byValue = byReference; // <---
    Runnable func = () => System.out.println(byValue);
    byReference = 1;
    func.run();
    // prints 0 obviously

If you want to emulate capturing by reference, use some mutable box thing, like Mutables from Apache Commons, or a 1-element array. Both options are obviously ugly:

    var byReference = new int[]{0};
    Runnable func = () => System.out.println(byReference[0]);
    byReference[0] = 1;
    func.run();
    // prints 1",2025-04-04 20:59:58,64,vytah,programming
mlftpss,1jrlv3y,reddit,"I came in with finger on the downvote button for another low-quality ""`0 == '0'` lol"" post...and it's actually pretty interesting, as a Typescript dev. I've been bitten before in the wild by the string length one.",2025-04-04 20:59:43,56,annoyed_freelancer,programming
mlgci8l,1jrlv3y,reddit,"Nice collection of language design blunders...

However, the Unicode-related gotchas are not really on JS but much more on Unicode. As a matter of fact, the approach JS took to implement Unicode is still one of the saner ones.

Ideally, when manipulating strings, you'd want to use a fixed-length encoding so string operations don't need to scan the string from the beginning but can be implemented using array indexing, which is way faster. However, using UTF32, i.e. 4 bytes for representing a code point is pretty wasteful, especially if you just want to encode ordinary text. 64k characters should be just enough for that.

IIRC, at the time JS was designed, it looked like that way. So, probably it was a valid design choice to use 2 bytes per character. All that insanity with surrogate pairs, astral planes and emojis came later.

Now we have to deal with this discrepancy of treating a variable-length encoding (UTF16) as fixed-length in some cases, but I'd say, that would be still tolerable.

What's intolerable is the unpredictable concept of display characters, grapheme clusters, etc.

This is just madness. Obscure, non-text-related symbols, emojis with different skin tones and shit like that don't belong in a text encoding standard.

Unicode's been trying to solve problems it shouldn't and now it's FUBAR, a complete mess that won't be implemented correctly and consistently ever.",2025-04-04 22:47:01,23,adamsdotnet,programming
mlmedi4,1jrlv3y,reddit,"    for (let i = 0; i < 3; i++) {
      setTimeout(() => {
        console.log(i);
      }, 1000 * i);
    }
    // prints ""0 1 2""

Are we forgetting our history? This works because it is a `let` declaration, which is block-scoped. `var` declarations will screw this up, because they are function-scoped. But the distinction between `var` and `let` isn't mentioned in the article, so it feels like the real logic here is being glossed over.

Though, it is admittedly a little arbitrary that the `()`s after `for` are ""inside"" the block scope. But very useful in practice!",2025-04-06 00:03:11,4,Booty_Bumping,programming
mllnnur,1jrlv3y,reddit,"In .NET it's actually little bit different/complicated.

This:

```csharp
using System;
using System.Collections.Generic;

var byReference = 0;
Action func = () => Console.WriteLine(byReference);
byReference = 1;
func();
```

returns `1` - as the article says.

```csharp
using System;
using System.Collections.Generic;

var list = new List<Action>();

for (int i = 0; i < 3; i++){
	list.Add(() => Console.WriteLine(i));
}

list[0]();

```

this returns `3` - as the article says.


But this:

```csharp
using System;
using System.Collections.Generic;

var actions = new List<Action>();
int[] numbers = { 1, 2, 3 };

// same code but just with foreach
foreach (var number in numbers)
{
    actions.Add(() => Console.WriteLine(number));
}

actions[0]();
```

This prints `1` - suprise!!!


This was explicitly changed in .NET 5 - https://ericlippert.com/2009/11/12/closing-over-the-loop-variable-considered-harmful-part-one/.

So in a way this is similar fix as the one used in javascrips.


### For loops 

I actually tought that in .NET 5 they fixed this problem for both `for loops` and `foreach loops`. But to my suprise they didn't. I guess you learn something new even after years of writing using the same language.

The good news is that for the first two problems my IDE (Rider) shows hint ""Captured variable is modified in the outer scope"" so you know you are doning something weird.",2025-04-05 21:19:22,3,melchy23,programming
mllugqw,1jrlv3y,reddit,Are sparse arrays really that bad for perf? I remember trying to test it a while ago and it wasnt that bad.,2025-04-05 21:59:58,2,username-must-be-bet,programming
mliby2v,1jrlv3y,reddit,"I honestly think the `eval` thing is pretty reasonable. It lets new code opt into a less powerful, safer, more optimizable form of `eval` (see [""Never use direct eval()!"" on MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/eval#never_use_direct_eval!)) without breaking existing code written with `eval`.",2025-04-05 07:44:04,2,190n,programming
mlkwvhn,1jrlv3y,reddit,Nice post!,2025-04-05 18:47:08,1,bunglegrind1,programming
mlg431d,1jrlv3y,reddit,one of the silliest things i've found is indexing into a number like 1\[0\] is undefined in javascript. I am not sure what chain of casting or whatnot causes this to happen (and not e.g. throw an error...),2025-04-04 21:56:54,-7,bzbub2,programming
mlgs5fe,1jrlv3y,reddit,"The behavior of variable scope in for loop makes perfect sense.

`document.all` need to be scrubbed from the standard

`;` should be mandatory, no ASI  
`NaN === NaN` should be `true`  
`typeof null` should be `""null""`",2025-04-05 00:23:19,-15,Blue_Moon_Lake,programming
mmu0fx0,1jxxdnz,reddit,Pfft.  The writer means just at first.  Here I thought I finally had figured out how to retire.,2025-04-13 02:20:15,165,FF3,programming
mmu4uzr,1jxxdnz,reddit,"> solve your administrative burdens—domain name, certificates, billing—when it’s easy. When there’s no pressure. Your stakeholders aren’t pressuring you to ship because it’s been no time at all.

The core idea of this article seems to be build a solid foundation first as its much easier to start with a solid foundation as opposed to trying to solidify there foundation layer, which I fully agree with.

That said, the reality of a lot of big tech companies is that for most projects there’s never no pressure. There’s always some stakeholder who wants results yesterday and shipping a blank website and talking about all the under the hood problems you’ve solved won’t appease them. Most developers don’t skip these foundational steps by choice. They skip them because they aren’t given the time to do them.",2025-04-13 02:50:30,133,Drugba,programming
mmudfio,1jxxdnz,reddit,"Article is getting some hate but we kind of do this any time we spin up a new service: get a hello world working in prod ASAP, then start shipping functionality. 

Nothing worse than being “feature complete” but having to deal with a bunch of bullshit to get to prod. Also, you can just have one resource tasked with doing the hello world and move people over once it’s up.",2025-04-13 03:52:35,38,lupercalpainting,programming
mmwa18a,1jxxdnz,reddit,"Had a colleague — let's call him J — who had… his own opinions on how to do things. He iterated fast, so management was impressed, and they _wanted_ quick results, so they didn't appreciate other developers like me warning them of the end results.

He made lots of bizarre snap decisions. One day, he wanted to rewrite the whole thing in PHP, arguing he could iterate even faster that way. He even registered a website with what he thought the product's branding _should_ be, and deployed a PHP-based implementation there, without management's consent or knowledge. He used it to pressure management into accepting his approach. Now, if you're a PHP shop, go ahead and use PHP. But we're largely a .NET shop, so if you were to ask me, that's a terrible idea — most of the devs can't maintain the result. Well, J _did_ ask, and I told him as much. So he went to the boss to complain.

They compromised, without consulting anyone else, on using the then-new .NET Core 1.1. The argument was that this was ""a lot less enterprise-y"" than .NET Framework. OK.

Anyway, weeks later, it came time to ship. J proudly announced he was ready! …and left for vacation. I guess nobody had told him to either publish the app himself, or at least give someone instructions on how to do so. But management had been promised that it's ready, right? So they went to us and asked. We spent the evening trying to deploy an app targeting a frankly immature toolchain in production. Three people at 9 PM frantically trying to get it working on an IIS that had heretofore never heard of ASP.NET Core, while we all also wanted to go home. None of us had much experience with .NET Core yet, because we were busy enough keeping _everything else_ running.

He was ultimately fired not long after. But his code base remained, and someone else was left to maintain it, full of byzantine decisions, and of course shortcuts, as, guess what, he had run out of time by rewriting it _twice_ (from .NET Framework to PHP, then from PHP to .NET Core). No code review, little knowledge of design decisions, just a bunch of stuff on your desk with ""_you_ figure it out"".

Oh, and the product ultimately failed. This wasn't really his fault, certainly not entirely, though his costly decisions of course did hurt the economic calculus.

Which brings me to the article. Leave aside J's attitude, his egocentric approach to decision-making, management's eagerness to trust him because what he was selling sounded really good on paper; what ultimately remains is that, had he instead started with a _much_ simpler product and then tried, just once tried, to deploy it on a real web server, we could've _iterated_ instead. Maybe even continuously reviewed the code he was writing. And _then_ what would've been the cherry on top would've been (enough) paying customers once the product had reached some maturity.

Real artists ship.",2025-04-13 13:59:19,7,chucker23n,programming
mmu76d5,1jxxdnz,reddit,"I think the author may be under-estimating the degree to which product requirements inform infrastructure decisions. Sure, some things you can always get to work on, like setting up your cloud account and domain, but there's only so much platform setup you can do before business logic starts calling the shots.",2025-04-13 03:06:32,23,tolerablepartridge,programming
mmwnhlt,1jxxdnz,reddit,"Related: run some A/A tests before you do any A/B testing. If they perform differently, then there are bugs in your testing infrastructure.",2025-04-13 15:12:38,6,sciolizer,programming
mmvvo6x,1jxxdnz,reddit,"This is something that I realized recently. I worked on a large project where we built all the software out before figuring out deployment and had a ton of integration issues. For our next iteration, I built a ""hello world"" app with all the IaC and CI/CD set up, then built the actual application and it was much smoother.",2025-04-13 12:25:42,6,itijara,programming
mmynrm0,1jxxdnz,reddit,"Obligatory: https://github.com/kelseyhightower/nocode

>No code is the best way to write secure and reliable applications. Write nothing; deploy nowhere.",2025-04-13 21:33:52,2,vytah,programming
mmx5gwq,1jxxdnz,reddit,This is clickbait trash nonsense.  Make a dumb headline then use the article to walk it back.  Classic bait.,2025-04-13 16:46:51,4,VictoryMotel,programming
mmub9p1,1jxxdnz,reddit,"That’s not going to work out in many cases. You should have a plan to iterate over your software features and about building/ testing/ deploying the product. You develop all aspects at the same pace. You should define a clear vision on how and where you would like to test, how you would like to build and where you will be running in the end and possibly in between.
consider it as part of your development routine to improve a bit in every aspect each sprint. Have a story from every aspect of the development process in your sprint and solve it (!)",2025-04-13 03:36:21,2,asciimo71,programming
mmvnnpt,1jxxdnz,reddit,"Oh. Some people are catching up it seems.

I've been programming for 35 years (20 of which professionally) and have a computer science degree.

Even to this day, the first thing I create when starting a new project is ""Hello world"" and then I go from there, only adding one small thing at a time, testing this one thing to the max and only proceeding to the next thing if it always works. All functions are also provided with doc-comments.

I rarely have to debug my own code because of this. If it is written, it'll work; especially when I'm writing in Rust.

On the other hand: I'm not the fastest programmer on the planet. You will be waiting longer for your end product.",2025-04-13 11:20:18,2,Xatraxalian,programming
mmuqcjs,1jxxdnz,reddit,I was going to reply,2025-04-13 05:38:49,1,TheApprentice19,programming
mmwhboh,1jxxdnz,reddit,"> Nobody has ever configured a production server by hand.

<Awkward Look Monkey Puppet>",2025-04-13 14:40:10,1,nirreskeya,programming
mn0l3hs,1jxxdnz,reddit,"i did something like this once where I spent 2 weeks writing a test harness for a new service that didn't exist yet nor were any endpoints even defined. I needed this to hand off the service for development to other people. otherwise it wouldn't have been sufficiently tested to my standards. we had three months to deliver so it was fine.

probably the worst, most expensive failure of a project I've ever worked on started like this as well. software architecture via baby steps doesn't always just ""work out"".

this article is primarily focused on saas so its not particularly applicable to software development in a broader sense, but I can see how this approach would make sense in that context.",2025-04-14 05:18:38,1,No_Technician7058,programming
mn0snsm,1jxxdnz,reddit,"AKA ship a ""walking skeleton""",2025-04-14 06:31:28,1,oschvr,programming
mmum6zs,1jxxdnz,reddit,"“Let’s just test it directly in production — it’s faster that way.”  
  
(edit: Of course, if you have 0 customers using your app, you can have fun deploying a ""hello world"" wherever you want. Just don’t call it *production* — most people call that a *dev environment*, or an [alpha release channel](https://en.wikipedia.org/wiki/Software_release_life_cycle).)",2025-04-13 05:02:33,0,u362847,programming
mnejwhs,1k0jmww,reddit,I often use Godbolt. He's got a pretty interesting surname ngl.,2025-04-16 13:14:20,39,DataBaeBee,programming
mnepwkk,1k0jmww,reddit,Recommend this read https://people.freebsd.org/~lstewart/articles/cpumemory.pdf,2025-04-16 13:48:35,31,Sefrys_NO,programming
mneraiy,1k0jmww,reddit,"I didnt watch all of the video, but one of the most eye-opening exercises in the Algorithms class I took in college was about CPU cache strides and branch prediction. 

In essence there was the same algorithm implemented two different ways: evaluating a certain 2-D recurrence relation in a dynamic programming table, meaning I needed to compute the entries of a 2-D array A[i][j]. One implementation was a nested for-loop: ""i"" outside and ""j"" inside, and the other was the reverse. The first method was about 10x faster, even though it was literally the same calculation. It blew my mind.",2025-04-16 13:56:05,34,cant_read_captchas,programming
mnf8qdi,1k0jmww,reddit,It’s the man himself! His compiler tool is one of the coolest webapps I’ve ever seen!,2025-04-16 15:24:05,13,flying-sheep,programming
mng71at,1k0jmww,reddit,"I love that he introduced the `llvm-mca` tool in this talk. It's a neat way to make what is normally a hard to see, seemingly theoretical concept (pipelining) much more concrete, especially when trying it on real code! I was going to give a presentation on it at work, actually.

The only downside is that it relies on the scheduling models for a given processor to be committed to the public `llvm` repository. For example, using `llvm-mca` on my M1 Mac isn't necessarily guaranteed to give accurate results AFAIK, because it [uses the scheduling model for the Apple Cyclone microarchitecture](https://github.com/llvm/llvm-project/blob/6ccc9280ba891bbea349c12a064bf23bdf9000e7/llvm/lib/Target/AArch64/AArch64Processors.td#L1254).

Presumably the real scheduling information for the M architectures are committed in Apple's internal fork of `llvm`?",2025-04-16 18:10:04,8,SereneCalathea,programming
mnjjpoe,1k0jmww,reddit,"I highly recommend Computer, Enhance! to anyone that’s interested in learning more about how the CPU actually runs the code we write.",2025-04-17 06:23:08,4,Ashken,programming
mnijslc,1k0jmww,reddit,I agree. this was one of our first CS courses tho.,2025-04-17 01:52:42,3,AmeliaBuns,programming
mnep1e2,1k0jmww,reddit,"Good talk, thanks for sharing! I didn't know about the stride predictions caches make.",2025-04-16 13:43:48,5,qq123q,programming
mneifvk,1k0jmww,reddit,"TLDR: Not all programmers have a comp sci degree that taught the basics of computing, and yet we still often call those same programmers 'software engineers', why?",2025-04-16 13:05:56,-36,church-rosser,programming
mnegqvg,1k0jmww,reddit,"""Every programmer""? Don't think so.",2025-04-16 12:56:33,-25,gofl-zimbard-37,programming
mng1x7z,1k0jmww,reddit,"Seriously? NO, most programmers don't need to know this. They need to understand their own problem domain.",2025-04-16 17:45:44,-19,tclbuzz,programming
mmvvsc8,1jy3qb0,reddit,"""Business people can just draw UML diagrams of the system and generate software from it"". ;)",2025-04-13 12:26:33,292,Pharisaeus,programming
mmvrkro,1jy3qb0,reddit,"I used an AI to generate a config file for me but I told it exactly what I wanted in the prompt and I still had to clean some stuff up. So can an AI write something if you have a good idea of what you need already? Maybe. But it's that ""knowing what you need"" part that is tricky.",2025-04-13 11:53:47,75,LainIwakura,programming
mmvyigv,1jy3qb0,reddit,"[https://www.cs.utexas.edu/\~EWD/transcriptions/EWD06xx/EWD667.html](https://www.cs.utexas.edu/~EWD/transcriptions/EWD06xx/EWD667.html)

seems appropriate. 

if ceebs reading the whole thing this exert kinda describes it all

""In order to make machines significantly easier to use, it has been proposed (to try) to design machines that we could instruct in our native tongues. this would, admittedly, make the machines much more complicated, but, it was argued, by letting the machine carry a larger share of the burden, life would become easier for us. It sounds sensible provided you blame the obligation to use a formal symbolism as the source of your difficulties. But is the argument valid? I doubt.""

For me that's what AI feels like. I already can write code, anything else trying to reach natural language only hinders my ability to deliver. 

I understand how this maybe amazing for those that can't, but realistically, since AI isn't there, they'll still need to learn to actually code, which is only the beginning of the journey as well, after they learn to code, then they must learn to express themselves well.

Just like when we learn to talk its not the end of the journey.",2025-04-13 12:46:32,33,YesIAmRightWing,programming
mmvit5s,1jy3qb0,reddit,We tried NoCode some odd 20 years ago. Didn't replace a single programmer.,2025-04-13 10:33:21,71,Vectorial1024,programming
mmw12kg,1jy3qb0,reddit,"I think natural language is not a good language for specifying behavior of complex systems. If it was, we wouldn't need maths to describe the laws of physics for example. So, I don't think LLMs will replace programmers. Natural language is the problem, not the solution.",2025-04-13 13:04:18,35,Accomplished_Yard636,programming
mmwdxna,1jy3qb0,reddit,If someone would just invent some way of specifying the exact logic to the AI then we could finally go NoCode!,2025-04-13 14:21:32,5,DrunkSurgeon420,programming
mn03lk3,1jy3qb0,reddit,I don’t find these discussions very gratifying. People pretending it’s way more useful or way less useful than it is with little nuance.,2025-04-14 02:57:44,3,RICHUNCLEPENNYBAGS,programming
mn0kd6k,1jy3qb0,reddit,CEOs will be replaced by AI before they replace programmers it seems.,2025-04-14 05:12:04,3,zayelion,programming
mmvzy7y,1jy3qb0,reddit,How exactly is this a paradox?,2025-04-13 12:56:38,8,phillipcarter2,programming
mn1qpom,1jy3qb0,reddit,"No one with a brain is surprised LLMs can't program well. They lack the ability to work with a project over a long period of time, interact with it to see if its behavior matches their goals, and then refine their goals when the goal itself is the issue.

The fundamental misunderstanding here is that people who don't know how to design something don't understand what's required to make something. They just complain, and if they have money they hire competent people and then constantly interrupt their work with their complaining. These idiots think the complaining is what gets the job done, and it's not. That's why they see LLMs as free labor.",2025-04-14 12:03:18,1,Sabotaber,programming
mmxa9cf,1jy3qb0,reddit,"I feel like this reflects the broader trend of new age programmers wanting their code to write code for them. Everyone these days is so obsessed with how their code looks, that how it actually functions has taken an almost secondary role. I think it was better when we just wrote more code and kept the constructs and tooling simple.

There's also a simultaneous obsession with preventing all errors before writing a single line of code, by building safety directly into the language. I think this is a mistaken approach too because the fact is, we can't forsee everything, and often the very things we have to do are inherently unsafe. It used to be that, if we made an error, we fixed it and moved on, and the program was simply refined through iterative improvement.

I think all this concern with AI, safety, and language constructs helps corporate more than actual programmers, because those things lower the barrier to entry and, as a consequence, make more programmers available for hire for cheaper due to increased competition.",2025-04-13 17:11:03,0,SIeeplessKnight,programming
mmy4w16,1jy3qb0,reddit,"lol this dude is legit trying to be a professional quote maker. This post is literally a link to a random linkedin post. It's just a bunch of pseudo-intellectual gobbledygook. How much do you want to bet that OP is the guy from linkedin, or one of his friends?

Point by point:

> LLMs can produce syntax, but not insight

What does that even mean?

> They predict patterns, not purpose

Purpose is a pattern.

>The compiler checks for correctness, not alignment with your goals

In this scenario, it's the LLM's job to enforce alignment with your goals (in addition to generating syntactically correct code). It's not the compiler's job to enforce alignment with your goals.

>And even a slight deviation in logic or structure can lead the compiler — and the system — down a completely unintended path.

And?

>That gap makes AI struggle with tough coding tasks.

The reason LLMs struggle with tough coding tasks is simply because they're not that smart. It has nothing to do with the fact that compilers are stricter than natural language.",2025-04-13 19:51:28,-2,billie_parker,programming
mmxgxu2,1jy3qb0,reddit,Sounds like this idea was produced by someone who doesn’t have much experience with AI or coding,2025-04-13 17:44:59,-1,daishi55,programming
mmw8gif,1jy3qb0,reddit,The solution is obvious. Make LLMs to compile the programs. The next step would be to eliminate the high level programming languages altogether and have LLM generate executable binaries!,2025-04-13 13:50:20,-4,fatty_lumpkn,programming
mmyilnp,1jy3qb0,reddit,"What do people not understand about LLMs improve multiple times a year. 

The problems of today are temporary",2025-04-13 21:05:05,-3,reddituser567853,programming
mmwq563,1jy3qb0,reddit,">Funny thing: AI was supposed to replace us ...

In due time my friend. 

Most people are like those spectators at a Wright brothers plane demonstration and says: ""That thing will never work, [not in a million years](https://en.wikipedia.org/wiki/Flying_Machines_Which_Do_Not_Fly).""

For now, programmers don't really have to worry. AI is the future of programming, but not yet, it will be tho, it will be...",2025-04-13 15:26:34,-8,AKMarshall,programming
mmxkw12,1jy3qb0,reddit,"There might be something else be going on. Most LLM assistants have a context window which is too small to work with enough information to arrive at the correct solution to complex problems. If you are working with a large code base, the LLM just can't  consider all the relevant code it would have to be aware of to generate a good solution for your problem. It might start hallucinating, estimating what the environment it is supposed to be working with looks like, instead of knowing what it exactly is. One possible solution is using RAG and organizing your source code in a hierarchical way to improve an LLM assistant's efficiency.",2025-04-13 18:05:01,-3,JulesSilverman,programming
mok5k39,1k5okeu,reddit,"In the beginning of the film “28 Days Later” (2002) Jim wanders the city of London shouting “Hello”. He receives no replies, so we don’t know if anyone heard him.  Without a reply he keeps shouting, “Hello.”

Consider now, “Toast of London” (2013) where Steven Gonville Toast is recording lines. The work experience kid Clem Fandango says, “Hello Steven this is Clem Fandango can you hear me,” and Steven replies, “Who the fuck are you?”  In this scenario we know explicitly that Clem Fandango can send a message and that Steven is able to receive it and reply.  However, we don’t know yet whether that message has been successfully received by the original sender and so we need a third message, finally, from Clem Fandango to Steven so that all parties know that they can both send and receive to each other.  This is why we need a three way handshake.",2025-04-23 04:56:49,182,kurtrussellfanclub,programming
mojn4ve,1k5okeu,reddit,"I could make a joke about the efficiency of UDP, but I don't know if you'd get it.",2025-04-23 02:46:35,531,AnnoyedVelociraptor,programming
mok5ojl,1k5okeu,reddit,"3-way handshake, not 3 handshakes...  3 steps, one handshake. ",2025-04-23 04:57:51,200,Mundane-Vegetable-31,programming
mojrad0,1k5okeu,reddit,What someone really needs to do is write a bunch of awesome books on TCP/IP that people can reference so this kind of writing is unnecessary.,2025-04-23 03:12:42,75,jet_heller,programming
mojv0zj,1k5okeu,reddit,Dropping your .edu email address in a random blogs comment section is savage 🫡,2025-04-23 03:38:04,51,sssanguine,programming
mokj2ud,1k5okeu,reddit,"One thing the article doesn't mention is the benefits of the 3-way handshake for the security of the Internet as a whole. In protocols that don't have a handshake, source IP spoofing allows an attacker to use legitimate servers (which are thus hard to just block) to perform DoS attacks on 3rd party victims, by amplifying the traffic with a small request generating a large response. This was a common problem with DNS servers in particular, as DNS responses can be much larger than the request.

The attack pattern is simple: the attacker crafts small request packeta with the source IP of the victim and sends them to the server. The server receives and processes them and sends large response to the source IP, so to the victim device. This floods the victim with much more traffic than the attacker could have otherwise generated. In TCP this attack doesn't work, as the SYN-ACK response is very small, and any higher level request would only happen after the attacker has successfully received this SYN-ACK packet, so it can't just establish this connection using the source IP of the victim.

This is important to note, because it constraints the design of TCP and any other similar protocol. If this attack didn't exist, we could have optimized TCP by optimistically sending data in the SYN and SYN-ACK packets and skipping the rest of the handshake if the data is successfully received (using a pre-agreed initial SEQ number, such as 0). That would have some extra cost for bad connections, but would have much lower latency for the more common case of no packet loss. But, it would make TCP susceptible to this attack, and so it can't be deployed on the internet without other precautions (such as SYN cookies, i.e. relying on an older successful connections as proof that the src IP is not spoofed).",2025-04-23 07:03:59,15,tsimionescu,programming
mojm4bw,1k5okeu,reddit,It needs to make a firm grip.,2025-04-23 02:40:21,31,BlueGoliath,programming
mok10o3,1k5okeu,reddit,Why do I feel I already saw this? Oh because I did. Guy reposting the same article after 6 months https://www.reddit.com/r/programming/comments/1frsz7s/why_tcp_needs_3_handshakes,2025-04-23 04:21:21,31,Dunge,programming
mol2xco,1k5okeu,reddit,3 handshakes? In this economy?,2025-04-23 10:31:29,4,MrChocodemon,programming
momylyy,1k5okeu,reddit,"tldr

can you hear me?

yes, can you hear me?

yes.",2025-04-23 16:58:25,3,petenpatrol,programming
mol6dm3,1k5okeu,reddit,https://i.imgur.com/FPupCJb.png,2025-04-23 11:01:01,2,PGLubricants,programming
mojus2i,1k5okeu,reddit,Something something two generals problem,2025-04-23 03:36:20,4,redditasaservice,programming
mokuuxs,1k5okeu,reddit,Three handshakes? In 2025? Just scream your SYN into the void and hope for the best.,2025-04-23 09:10:40,1,pyeri,programming
mol3jlp,1k5okeu,reddit,"> The presence of RST packets in a production environment often indicates potential problems.

That's a very weaselly way of admitting that, often enough, it does not indicate a problem. It might, and it's certainly a place to look, but seeing RSTs doesn't necessarily mean there's any ""problem"" that someone wielding wireshark would care about. Some applications use them as a normal part of production comms.",2025-04-23 10:37:07,1,Coffee_Ops,programming
moniiu1,1k5okeu,reddit,Just because for reliability and authentication,2025-04-23 18:32:59,1,diljan_484,programming
mopc9p5,1k5okeu,reddit,"When we went to restaurants in Quebec, we did the following 3-way handshake to establish a conversation:

Staff: Bonjour.

Us: Hello.

Staff: Hello.",2025-04-24 00:12:12,1,PenlessScribe,programming
mokem2t,1k5okeu,reddit,"Because four would make it .., ( there must be a dad joke there)",2025-04-23 06:19:20,0,Tintoverde,programming
mokfi0q,1k5okeu,reddit,Dude the secret handshake is how we know you’re cool.,2025-04-23 06:28:06,0,stupid_cat_face,programming
mokfqlq,1k5okeu,reddit,"Ok, this article is amazing, thank you! It explains TCP really well.",2025-04-23 06:30:28,-1,raindropsdev,programming
mntaqe6,1k2b0d7,reddit,"I want to know what someone thinks about \*maintaining\* a project with 60k lines of lua.  Writing it is the easy part IME, maintaining is the hard part.",2025-04-18 19:51:13,224,CitationNeededBadly,programming
mnu8l9n,1k2b0d7,reddit,World of Warcraft says Hi,2025-04-18 22:59:01,36,NoleMercy05,programming
mnwg4e9,1k2b0d7,reddit,"> Those functional vibes were quite surprising to me. I can illustrate it with something like this:

>     local pref = item_struct.node_tree[""item_prefab/root""] and ""item_prefab"" or ""group_prefab""

> [caption: With syntactic sugar aka “Haskell vibes”]

As far as i can tell this is neither syntactic sugar nor ""Haskell vibes"": 

1. The ""sugar"" seems to be just that they spell the logical `and` and `or` as `and` and `or` rather than `&&` and `||`?
1. You can pull the same kind of stunt with `and`/`or` in any language with truthy values, like Python, but Haskell will actually require you to only provide arguments of type `Bool` to `and` and `or`; `pref` would wind up holding just a boolean value.
1. To look haskellian, it  would rather be something like `local pref = if item_struct.node_tree[""item_prefab/root""] then ""item prefab"" else ""group_prefab""`, i.e. just using an if expression the way they'd use the ternary expression in C++.",2025-04-19 09:19:52,24,syklemil,programming
mnwcg9g,1k2b0d7,reddit,"I work a lot with Lua code and I do quite like it, but dynamic typing is definitely both a blessing and a curse.

I've personally found that the code has gotten much more maintainable since we started adding more [LuaLS annotations](https://luals.github.io/wiki/annotations/) to it. It makes you less likely to misuse functions and it's especially helpful when working with ""classes"" and other table objects.",2025-04-19 08:40:12,13,LordofNarwhals,programming
mnt71ep,1k2b0d7,reddit,"I'm more interested in what you think of Defold.
I tried my hand at it a while back and it seemed pretty great but I had no ideas at the time so never really went any further than pong haha",2025-04-18 19:31:25,7,mr-figs,programming
mnu6je1,1k2b0d7,reddit,"Been using Lua for years, easily my favourite language without fail, I wish it was used more",2025-04-18 22:46:44,20,Limp_Day_6012,programming
mny2bbs,1k2b0d7,reddit,"Even though Lua has it's quirks, I quite enjoyed working with it. It has a really nice combination of low complexity in the design and implementation, many possibilities and still quite a nice readability.

Since Lua 5.2 the ""global by default"" issue which can be problematic for larger programs can fortunately be solved by a single line:

    local _ENV = nil",2025-04-19 16:07:56,4,dravonk,programming
mo7tr09,1k2b0d7,reddit,"This ""article"" seems like a mix of incoherent, AI slop, and bad jokes. Look at this paragraph for example:

> After that, I went back to Dmitry and asked him if my understanding of “everything is a table” was correct and, if so, why Lua was designed this way. Dmitry told me that Lua was created at the Pontifical Catholic University of Rio de Janeiro and that it was acceptable for Pontifical Catholic Universities to design programming languages this way.

Wtf? So he asked why and he got ""it was created at a place"" and then he *accepted that answer*?",2025-04-21 06:31:55,3,kankyo,programming
mo1701c,1k2b0d7,reddit,"OP: Great question thanks for asking

OP: No problem

I'm not judging, I too pretend people ask me questions I got tired of waiting for someone to ask me.",2025-04-20 02:53:43,1,grady_vuckovic,programming
mnwkj8l,1k2b0d7,reddit,fuck languages with dynamic typing,2025-04-19 10:07:12,0,obetu5432,programming
mnt1v3w,1k2b0d7,reddit,"I stopped reading at “Tabs!”

Edit: Hey “Spaces!” team, we’re losing here - some backup maybe? :)",2025-04-18 19:03:51,-26,meowsqueak,programming
mnx7ayy,1k2rz06,reddit,That's beautiful!,2025-04-19 13:14:02,16,loptr,programming
mnxjdk3,1k2rz06,reddit,"My goodness! I wrote some graphics and programming language code in 1980's, but not in the same program. Doing this in that era Basic is even more impressive.",2025-04-19 14:26:40,14,hoijarvi,programming
mnxkqon,1k2rz06,reddit,nice ! how long did it take you to write ?,2025-04-19 14:34:12,10,naruto--420,programming
mnxqln4,1k2rz06,reddit,I loved programming on my Acorn BBC B. Inline assembler was just the cherry on the cake.,2025-04-19 15:06:03,4,ziplock9000,programming
mnxsn30,1k2rz06,reddit,"Remember those days well. Did an O Level in computing while in lower 6th form (yr 12 in modern years). One large and five small projects. I did each in a different language, because there was nothing saying you couldn’t.

So much wish I had the large project still, but lost to the years.

Great project OP, and I’m especially jealous that you still have it",2025-04-19 15:17:01,4,jodonoghue,programming
mnxvmqj,1k2rz06,reddit,Wow you created control flow graphs in BASIC!,2025-04-19 15:32:54,3,S2kDriver,programming
mnzr080,1k2rz06,reddit,"In '86 or '87 I wrote a program in Apple Pascal on Apple II hardware that used turtle graphics to generate bar, line or pie graphs for my high school senior project. It had keyboard routines so you could enter some number of points (I forget how many, I think up to 10) and labels for those points.


The entire system only had about 24K of RAM to work with, so I had to swap everything, including the keyboard routines, out to the floppy disk. Every time you hit a key, you'd see the floppy light blink briefly. I also had to do the pie graph one on a separate floppy because the whole thing plus the Pascal environment wouldn't fit on one.


It might sound trivial today but it remains one of my favorite projects for how much I was able to squeeze out of the environment at the time. If I'd had an Apple assembly environment available at the time, I might have tried to write it in that. I'd taken an assembly course a couple years earlier over the summer at one of my local universities. It was probably possible to cobble one together using pokes in BASIC but that was well beyond my capabilities at the time.",2025-04-19 21:36:35,3,FlyingRhenquest,programming
mo15qf6,1k2rz06,reddit,Very nice. I wish I still had all of my BBC Micro programs :(,2025-04-20 02:45:06,2,meowsqueak,programming
mo2vr90,1k2rz06,reddit,I do appreciate the fact that you recorded the sound; this is so lovely.,2025-04-20 12:17:40,2,heptadecagram,programming
mo7susb,1k2rz06,reddit,"This is truly beautiful, and impressive honestly.",2025-04-21 06:22:30,2,Kok_Nikol,programming
moq16av,1k2rz06,reddit,So cool. Back when programming was magical.,2025-04-24 02:37:17,2,alwaysoffby0ne,programming
mnxt5l0,1k2rz06,reddit,"Here I was happy if I could get anything text based working, very well done!",2025-04-19 15:19:47,4,Cube00,programming
mnwg249,1k2rz06,reddit,this is what I call vibe-coding,2025-04-19 09:19:10,4,FederalRace5393,programming
mnae8ee,1jztbbv,reddit,"Simple IIR filters commonly run slowly on Intel CPUs on default floating point settings, as their output decays into denormals, causing every sample processed to invoke a microcode assist.

On the Pentium 4, self-modifying code would result in the entire trace cache being flushed.

Reading from graphics memory mapped as write combining for streaming purposes results in very slow uncached reads.

The MASKMOVDQU masked write instruction is abnormally slow on some AMD CPUs, where with certain mask values it can take _thousands_ of cycles.",2025-04-15 19:48:25,17,ack_error,programming
mn9dplm,1jztbbv,reddit,Upvotes angrily.,2025-04-15 16:47:42,29,XEnItAnE_DSK_tPP,programming
mnbcp8b,1jztbbv,reddit,Reminds me of this: https://nrk.neocities.org/articles/cpu-vs-common-sense,2025-04-15 22:48:00,6,immaculate-emu,programming
mnac7w4,1jztbbv,reddit,"Here is a fun one.  Imagine a function that calculates the minimum and maximum values of an array.

     void range_array1(int* array, int count, int* low_out, int* high_out)
     {
         int low = array[0];
         int high = array[0];

         for (int i = 1; i < count; i++)
         {
             if (low > array[i])
                 low = array[i];

             if (high < array[i])
                 high = array[i];
         }

         *low_out = low;
         *high_out = high;
     }



This is all fine, but we can write an optimized version that handles two elements at a time.  This executes fewer instructions and takes a lot longer to run due to bad branch prediction.  \*Assuming the array is not sorted.

     void range_array2(int* array, int count, int* low_out, int* high_out)
     {
         int low = array[0];
         int high = array[0];
         int i = 1;

         for (; i + 1 < count; i += 2)
         {
             if (array[i] < array[i + 1])
             {
                 if (low > array[i])
                     low = array[i];

                 if (high < array[i + 1])
                     high = array[i + 1];
             }
             else
             {
                 if (low > array[i + 1])
                     low = array[i + 1];

                 if (high < array[i])
                     high = array[i];
             }
         }

         if (i < count)
         {
             if (low > array[i])
                 low = array[i];

             if (high < array[i])
                 high = array[i];
         }

         *low_out = low;
         *high_out = high;
     }",2025-04-15 19:38:24,12,mccoyn,programming
mncn12n,1jztbbv,reddit,"The [`RDSEED` instruction](https://www.felixcloutier.com/x86/rdseed) is a very slow instruction [on pretty much all x86 processors](https://uops.info/html-instr/RDSEED_R64.html), though I don't know whether that violates the rules.",2025-04-16 03:25:44,3,YumiYumiYumi,programming
mn9wqrv,1jztbbv,reddit,"Somewhat ironically, writing slow code can be harder than writing fast code these days because, as the article mentions, some hardware features will work against you. Though both objectives rely on the same (inverted) principles. 

This [book](https://csapp.cs.cmu.edu/) has some chapters which explore various aspects of software performance, and which delve further into some ideas discussed in the article. 

A small caveat is that the article focuses on CPI as a measure of software performance, which might be inaccurate. Having a lower CPI rate will not improve performance if it you also need to execute more CPU instructions to perform a given task. This metric is more often used to gauge the performance of CPUs, compilers, and combinations thereof.",2025-04-15 18:20:18,5,wake_from_the_dream,programming
mna7ner,1jztbbv,reddit,"- Another thing that may slow the CPU down is [false sharing](https://en.wikipedia.org/wiki/False_sharing), i.e. variables that are in the caches of several CPUs or CPU cores.
- Transferring data across devices, e.g. from main RAM to the GPU, is slower than accessing just main RAM.",2025-04-15 19:15:12,4,ShinyHappyREM,programming
mnbt1pk,1jztbbv,reddit,this fucking rules,2025-04-16 00:21:19,1,moreVCAs,programming
mna5ulv,1jztbbv,reddit,"this is an awesome blog post. 

I wonder if a slow code like this could be faster than fast Python/Ruby/JS code. Sure, you don't have many IPC, but they all do meaningful work.",2025-04-15 19:05:57,0,zanza19,programming
mnaix3c,1jzyffc,reddit,I see Raymond Chen… I upvote Raymond Chen.,2025-04-15 20:11:23,58,razialx,programming
mnc8agd,1jzyffc,reddit,"Back in the Windows NT 3.1/3.5 days I had an embedded system that was hanging every few days with moderate use. I could make it occur more quickly if I forced a lot of UI activity. 

The thing is we had a kernel-level watchdog timer that was supposed to pull the reset line if it wasn’t tickled every few minutes.  The system stayed happily running but frozen. Hmmmmm. 

Turned out a use-after-free condition was corrupting the UI thread list causing it to crash and completely hang. Non UI processes, including our kernel driver and tickler, were happily running thus no reset. 

It took us a LONG time to debug but we eventually got Microsoft to use a remote kernel debugger (from Redmond to Los Angeles) to look into the system and they figured out what was going on pretty quickly and issued us a patch. 

That was fun.",2025-04-16 01:52:08,37,lisnter,programming
mne8zfk,1jzyffc,reddit,"He references his own 22 year old blog post ""Why you should never suspend a thread"". What a legend",2025-04-16 12:08:24,14,DJTheLQ,programming
mn9wefo,1jzyffc,reddit,Ah yes the UI,2025-04-15 18:18:36,-26,websey,programming
mnbthcs,1jzyffc,reddit,An excellent case for Rust,2025-04-16 00:23:51,-51,IsleOfOne,programming
mo9txhp,1k48mey,reddit,Yeah Jsonb is the ultimate example that any specialized database will end up better implemented as a postgres feature or a postgres extension,2025-04-21 15:40:37,60,light24bulbs,programming
mobeyxe,1k48mey,reddit,Did a full text search implementation in Postgres and not only was it fast I got to keep an all my fun sequential stuff.  It’s pretty great,2025-04-21 20:34:02,12,s0ulbrother,programming
mot2dbj,1k48mey,reddit,"> This allows storing profiles with wildly different shapes while keeping common fields queryable.

This is precisely why I lean away from JSONB. It's duck typing for your schema. As soon as I start messing with the data I have to think, ""Okay, wait, what could be in there? This is essentially one big sum type where the set of possible values is defined by the behavior of all code histories that have ever acted on it""

There's no place where the ""common fields"" have been defined. Defining related tables in, e.g. Rails is pretty straightforward; I'd rather deal with the complexity up front and not have to speculate later. Typically, even when the schema is rigidly defined it's not actually all that difficult to update later.",2025-04-24 15:46:56,3,d0liver,programming
mo8igq6,1k48mey,reddit,https://martendb.io/ is a ORM and much more for .NET that uses this approach.,2025-04-21 10:47:54,14,Nisd,programming
mmx644b,1jy78sa,reddit,I really don’t find websockets to be that complex or difficult to use.,2025-04-13 16:50:10,205,shogun77777777,programming
mmx42tr,1jy78sa,reddit,"I completely agree that websockets are overused & introduce unneeded complexity throughout the entire stack. And yet I disagree with most of these points.

Websocket messages are indeed not transactional. Neither are messages over an http stream. Syncing state & operations between clients in real time is an extremely hard problem, and the transport is largely irrelevant. The example api in this article is naive, and like the article points out, for the api to support multiple clients, there needs to be some kind of guaranteed delivery mechanism, handling or avoiding conflicts, handing stale clients, etc. Using http streams does not change this problem.

That's not to say that http steams aren't awesome. I use them regularly & unless I truly need a bidirectional stream, they are indeed much easier to maintain & reason with. I'd recommend using server-side events with fetch (not EventSource), as they are well defined & more friendly with load balancers, proxies & other infrastructure, as some things will buffer the streams in chunks.",2025-04-13 16:39:24,83,markus_obsidian,programming
mmxys1g,1jy78sa,reddit,Or use a higher level abstraction like SignalR and let it decide the optimal transport.,2025-04-13 19:18:35,26,shadowndacorner,programming
mmzjj35,1jy78sa,reddit,Just post to an iframe already.,2025-04-14 00:44:33,10,dhlowrents,programming
mmwilke,1jy78sa,reddit,"Http streams are great but as far as I know you cannot use them if you plan to stream data from the client.

So unless you’re ready to ditch http web sockets are fine. Of course you need to know the details, but that applies for everything.",2025-04-13 14:46:55,29,KeyIsNull,programming
mn0mem6,1jy78sa,reddit,"> WebSocket messages aren’t transactional

Correct me if I'm wrong, but isn't this problem solved, if not manageable using event acknowledgements. I'm thinking of the [socket.io implementation](https://socket.io/docs/v4/tutorial/api-overview#acknowledgements) specifically",2025-04-14 05:30:43,5,eazieLife,programming
mn0y8yq,1jy78sa,reddit,"I’m curious why the author didn’t even mention [SSE](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events). (The answer is probably because they wanted to advertise their own library, but it’s still strange to not even mention as a contender.)

Also kind of an odd choice to reinvent the wheel instead of building on something like RxJS which has well-defined patterns and a decent ecosystem. In fact, I’m reading through [the docs](https://hntrl.github.io/eventkit/guide/concepts/transforming-data) and this looks like almost a 1:1 copy of RxJS lol",2025-04-14 07:29:08,4,tj-horner,programming
mmyn3ay,1jy78sa,reddit,"Use WebSockets, but with another layer on top of it. Personally I like JSON-RPC. And find a library that can manage it for you, so it'd handle things like closing/opening/pinging.",2025-04-13 21:30:08,2,somebodddy,programming
mn11ad9,1jy78sa,reddit,"If you want browsers to talk to each other, you need to relay the messages. This is why I created WebSocket Relay, which dramatically simplifies the process:

[https://github.com/nick-hill-dev/wsrelay-server](https://github.com/nick-hill-dev/wsrelay-server)

[https://github.com/nick-hill-dev/wsrelay-client](https://github.com/nick-hill-dev/wsrelay-client)",2025-04-14 08:02:14,2,nahill,programming
mn0udls,1jy78sa,reddit,i actually love websockets so i think i need them :(,2025-04-14 06:48:58,2,FederalRace5393,programming
mmxn1m6,1jy78sa,reddit,[deleted],2025-04-13 18:16:11,-6,N/A,programming
mkxh3y7,1joczc6,reddit,"The 68000 detected illegal instructions and call a Trap interrupt.

The 6502 did have ""Quasi Opcodes"" which were not reliable 100%, though some games used them to save clock cycles.",2025-04-01 22:10:24,6,UVRaveFairy,programming
mkr5seu,1joczc6,reddit,Article is from 2023. Good read.,2025-03-31 21:21:06,10,Initial_Low_5027,programming
mnezv9q,1k0lt3s,reddit,"Did I understand it correctly, that kotlin notebooks are now available in the community edition? That would be so amazing",2025-04-16 14:40:19,49,some3uddy,programming
mnkdq43,1k0lt3s,reddit,"Couldn't help but notice they're ditching an extremely useful modal commit dialog in favor of VSCode-like approach, having unprecedented backlash because of it and not giving a damn about negative feedback at https://youtrack.jetbrains.com/issue/IJPL-177161

This is quite spectacular to watch JB going downhill, especially for a long-time [UPD] paid user like me.",2025-04-17 11:17:12,17,develop7,programming
mnf3red,1k0lt3s,reddit,I just wish WSL wasn't broken for basically the last 1.5 years. But looks like it'll be broken for a bit longer.,2025-04-16 14:59:29,43,Actual-Many3,programming
mnfnbhz,1k0lt3s,reddit,">The ability to download drivers from Maven or other custom repositories

>Version 2025.1 allows you to add custom repositories for downloading drivers. To do so, add the repositories you need to the mirrors attribute of the HOME\_PATH/.m2/settings.xml file.

Fucking finally. [Only took them 7 years... ](https://youtrack.jetbrains.com/issue/DBE-6690/Data-Sources-driver-download-should-use-configured-Maven)",2025-04-16 16:36:17,20,MrNighty,programming
mnycgi6,1k0lt3s,reddit,This version is painful to work with. Compilation errors take forever to show-up. I have to literally restart this piece to crap to work with - and I have the ultimate version.,2025-04-19 17:01:40,2,hope11223,programming
mnhu9qv,1k0lt3s,reddit,"Can no longer open any Jetbrains IDEs on Arch...

Edit: nvm got it working again  
Edit 2: This was huge, can't believe I didn't know: [https://blog.jetbrains.com/platform/2024/07/wayland-support-preview-in-2024-2/](https://blog.jetbrains.com/platform/2024/07/wayland-support-preview-in-2024-2/)",2025-04-16 23:19:17,3,superman1113n,programming
mnfny3u,1k0lt3s,reddit,Have they added multiple projects in the same window yet?,2025-04-16 16:39:24,2,BlueGoliath,programming
mnl4zno,1k0lt3s,reddit,Is their free AI assistant any good?,2025-04-17 14:05:01,1,HypnoToad0,programming
mnli8l2,1k0lt3s,reddit,Dev Containers _still_ broken (docker compose),2025-04-17 15:10:32,1,kevleyski,programming
mnj01gj,1k0lt3s,reddit,ai chat and junie are too unstable and too slow. It's like the situation with google bard when chatgpt was first released. It is important to properly create quality services.,2025-04-17 03:37:29,1,hogu-any,programming
modox9r,1k4iwkq,reddit,When do we get the g-strings?,2025-04-22 04:31:25,135,NinjaBreaker,programming
mobprz5,1k4iwkq,reddit,"f-strings
t-strings

Python likes fancy strings.

    name = ""World""
    template: Template = t""Hello {name}!""

I can't yet decide whether this is good or bad. First impression is that it is quite verbose.

> If you’ve worked with JavaScript, t-strings may feel familiar. They are the pythonic parallel to JavaScript’s tagged templates.

I didn't even know JavaScript had tagged templates. Need to update my JavaScript knowledge urgently ...

I read the rest of the article, but I am still not certain where or when t-strings are necessary. Are they simply or primarily just more efficient Strings? What is the primary use case, like if someone wrote some small library in python with a few functions, how do t-strings fit in there?",2025-04-21 21:28:14,48,shevy-java,programming
mohz6vy,1k4iwkq,reddit,"I was there when f strings were introduced and I thought it was a fad. But later on I found it useful. 

Now we have t strings. I see what it could be used for but when I use Django everywhere I need to do html templating I don't find it useful. Though it looks like it might be useful in other ways.",2025-04-22 21:07:02,2,lamp-town-guy,programming
modthee,1k4iwkq,reddit,"I guess it doesn't fix the need to rewrite { and } as {{ and }} everywhere, which is my biggest annoyance.",2025-04-22 05:07:35,-6,zhivago,programming
mofkzut,1k4iwkq,reddit,Python doesn't need more batteries :(,2025-04-22 14:04:18,-3,mr-figs,programming
mlkzkyg,1jsasl3,reddit,"Don't tell me, another backspace rescue shell bug.",2025-04-05 19:02:27,105,BlueGoliath,programming
mlmmtq9,1jsasl3,reddit,"> Integer overflow in ReiserFS

Is not it gone from the Kernel as of the last release? A little late to fix this one, imho",2025-04-06 00:57:42,29,voronaam,programming
mlohuau,1jsasl3,reddit,"GRUB2 has been fairly disappointing - way too many bugs. There is something fundamentally wrong with the GRUB2 development process; I don't know why, but many other projects work significantly better and I don't think the bootloader is necessarily more complicated than LLVM, mesa, the linux kernel, gcc or glibc really. Plus, grub-legacy kind of worked better in many ways; I understand that things got more complicated in the last ~15 years, but there is still something wrong with the development process. It also causes secondary problems, such as installers using grub no longer working; I am not claiming the latter is the direct fault of the grub2-developers of course, but people write code for installers for linux-based systems, and the more brittle and unreliable grub2 is, the more often code breaks or does not work. I've run into this problem in regards to GoboLinux a few times, and while I am not saying this is necessarily the direct fault of grub2-developers, any downstream software developer also depends on upstream writing good solid code. And documented code, too.",2025-04-06 10:36:20,13,shevy-java,programming
mloj5di,1jsasl3,reddit,"One bug is about overflowing an integer representing the length of a string.
Technically a bug but practically nonsense. 


In what universe will a bootloader read a 4 gigabyte string?",2025-04-06 10:49:45,5,rep_movsd,programming
mll0k6d,1jsasl3,reddit,Thanks Microsoft. Who about testing a little known closed source software that is is full of CVEs? I think it's called Windows,2025-04-05 19:08:02,7,Accomplished-Moose50,programming
mlmuvsp,1jsasl3,reddit,"I still don’t believe it’s AI that’s doing the work. What is happening that discussion about same bug may have been lying it some small public website which never got any attention. AI is just finding that piece of information and since we never scroll to one million search results after first 100, but AI does it. So we believe it’s thinking.",2025-04-06 01:51:40,-31,akash_kava,programming
mll6yga,1jsasl3,reddit,"Good job.  Leveraged co pilot to find vulnerabilities, hackers haven't found in 15 years...  mayvevlookbatvyour own shit...",2025-04-05 19:44:54,-62,painefultruth76,programming
mnf2yg1,1k0mf09,reddit,[Previous discussion 6 years ago](https://www.reddit.com/r/programming/comments/8rlr3a/fibonacci_hashing_the_optimization_that_the_world/),2025-04-16 14:55:34,27,ketralnis,programming
mnfpt48,1k0mf09,reddit,"> And everyone should be using it.

A year before, at CppCon 2017, Matt Kulundis presented Abseil and its hash-table in particular. During the course of the presentation, he notably argued that bad hashes are bad hashes, a programmer error, and hash-table implementations shouldn't penalize programmers who do their homework for the sake of those who don't. It's against C++ philosophy of ""You Don't Pay For What You Don't Use"".

Just like prime number hashing is one of those ""post-hash"" fixes which attempt to fix-up bad hashes, so is fibonacci hashing.

So in essence it may be that it's not so much the world over forgot Fibonacci Hashing, and more that it's useless whenever hash frameworks are of good quality by default. C++ and Java being, perhaps, the most obvious outliers there...

(I really wish [Type Don't Know #](https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3980.html) had been adopted...)",2025-04-16 16:48:25,52,matthieum,programming
mng6qj1,1k0mf09,reddit,"\`& Mask\` and \`>> (BitWidth - Bits)\` are just ways to extract the low or high bits of a value.

So the multiply in FiboHashing is purely for hashing purposes. so comparing it to \`& Mask\` and saying to hashes better is kind of obvious, the fair comparison is with >>

That said multiply does stack entropy in the high bits, and most other hashing tricks can be used to stack entropy in the high bits too. So definitely can get very good results with using >> instead of &.

But as always Hash Maps and Hash function NEED to be co-designed to get good results.",2025-04-16 18:08:34,7,mAtYyu0ZN1Ikyg3R6_j0,programming
moucn7k,1k6peto,reddit,"There are so many software devs in so many different roles and work environments that I think trying to generally ascribe burnout to individual causes is only going to work from the perspective of a single bubble.

For me, though, it's cognitive load. Even in just a typical web app project you need to know everything from the principles and details of frontend stuff through all kinds of frameworks, libraries, languages (including somewhat complex concepts such as async programming), tooling, networking, security (*), user management, backend programming, transaction management, databases, automatic testing, build systems, version control, CI/CD systems, container engines, and probably a cluster management system. Not to mention knowing and preferably understanding the best practices of each of those. And a whole bunch of underlying general knowledge such as operating systems and scripting languages.

(*) really not a single topic

Or at least you need to know a significant subset of those things, and you have to interact with the rest one way or another.

None of those are rocket science individually but it all builds up. And software development is one of those fields that necessitate learning new (and often somewhat complex) skills from year to year. That can be rewarding, and it's generally good and even healthy to keep learning new things. But once it becomes a necessity, it can be a double-edged sword: in order for learning to be rewarding and healthy, it needs to be challenging but not something you need to *force* yourself to do for prolonged periods of time.

Challenge (especially with external pressure to succeed) means stress, and stress can be good. But uncontrolled stress is generally bad, and long-term uncontrolled stress can be disastrous.

The stress from cognitive load and from the culture of constant learning and improvement can turn either way.",2025-04-24 19:26:15,46,Objective_Mine,programming
mos0pxk,1k6peto,reddit,Disagree with one if the conclusions; HR is not your friend. But yeah we need to work out how to end scrum/jira/agile/mba nonsense because its killing you too,2025-04-24 12:32:00,276,faldo,programming
morsc34,1k6peto,reddit,"Most of what was in this video I've never seen, not sure that I trust the conclusions.",2025-04-24 11:36:29,64,wineblood,programming
mos5e3o,1k6peto,reddit,"Sounds very familiar unfortunately. 
I am a big advocate against overtime and I am very vocal about it in meetings to make sure juniors don't get pressured into doing it easily. It has never stopped my career progression. 
But I agree I have to work on not overdoing it when I want to finish features and advocate for periods of rest so it does not become the new norm. The parts that get rushed out always end up biting you in the end so you really are not gaining time in the end...",2025-04-24 12:59:52,44,PasteDog,programming
mouzmbo,1k6peto,reddit,"I think a large part of the burnout is because we lack the things that lead to motivation: [Autonomy, Purpose, and Mastery](https://www.youtube.com/watch?v=rbR2V1UeB_A).

We end up doing a lot of things that we don't choose to do, things we think are the wrong thing, and things that are ultimately meaningless to us. Lots of work, no real reward, thus burnout.",2025-04-24 21:20:09,9,Legitimate_Plane_613,programming
motzqbb,1k6peto,reddit,"I don't agree that this is unique to developers, at least in relation burnout/suicide.  Pretty much any high salary and competitive career makes the same lists.",2025-04-24 18:23:12,8,fakehalo,programming
mosh7su,1k6peto,reddit,This guy is not a good source of information.,2025-04-24 14:04:27,62,Mojo_Jensen,programming
motd9sz,1k6peto,reddit,Useless video.,2025-04-24 16:38:33,17,peripateticman2026,programming
mouv32y,1k6peto,reddit,"1M USD per year, if you work for faang is that true?",2025-04-24 20:57:00,3,JIrsaEklzLxQj4VxcHDd,programming
movm3i6,1k6peto,reddit,"From my experience (25+ yeas as a dev, working in several companies and different countries) coding is one of the easiest and less stressful jobs out there. Not sure what data he is basing his main premise on. The problems he described (bad management, deadlines, interruptions) are also solvable with simple ""No"", which is true for any work in general. Coders are in best position to push back since it's really hard and costly to replace them (my company has been looking for a font and back end devs for months, there is real shortage).",2025-04-24 23:22:33,5,Evgenii42,programming
moyth8z,1k6peto,reddit,Crazy to see two subreddits I follow intersect,2025-04-25 13:28:52,1,Junior_Pie_9180,programming
mour273,1k6peto,reddit,Management.,2025-04-24 20:37:16,0,joshthecynic,programming
morq7ew,1k6pgf2,reddit,"Paywalled. What is this exactly?

Are we compiling Python to CUDA kernels, kinda like Jax?

Does this offer anything over Jax/XLA? Cause with XLA, you get portability to non-Nvidia devices too, like Google's TPUs. I don't immediately see a reason to use something CUDA specific when Jax exists.",2025-04-24 11:20:53,66,cbarrick,programming
mot1gc6,1k6pgf2,reddit,"This looks very similar to an already existing project : [NVIDIA Warp](https://developer.nvidia.com/warp-python)([github](https://github.com/NVIDIA/warp)) that already enables you to write **CUDA kernels** in (a subset of) **Python**.

Thank you for the sharing, I'll keep an eye on its development.",2025-04-24 15:42:37,12,moonzdragoon,programming
movi4y2,1k6pgf2,reddit,Numba: am I a joke to you,2025-04-24 23:00:40,2,caks,programming
morx2h0,1k6pgf2,reddit,thanks for sharing,2025-04-24 12:08:43,-9,Weary_Performer9450,programming
mossdor,1k6pgf2,reddit,"It's actually good for all ""scripting"" languages. Mind you, the other ""scripting"" languages aren't anywhere near as close as python is in regards to number of people using it (even JavaScript is quite a step behind python now), but it kind of shows a paradigm shift slowly taking place. I am not saying there isn't a speed penalty, of course, but the paradigm shift is that developer time (efficiency of time) now has a higher ""decision-making value"" than it had, say, 10 years ago. And I think this is good.

Hopefully the speed-penalty issue becomes less of an issue in the future.",2025-04-24 14:59:18,-11,shevy-java,programming
mjt290h,1jk7319,reddit,If there is a performance gain from this I'm not seeing it. Running the code pen raises cpu usage by 20 points and scrolling another 10. Using content visibility auto doesn't seem to improve it.,2025-03-26 09:45:38,92,Kozmyn,programming
mjt30ew,1jk7319,reddit,"Using it for like a year, had a bunch of problems on iOS safari mobile and no perceivable performance gain, removed",2025-03-26 09:53:21,47,cokeplusmentos,programming
mjt3yum,1jk7319,reddit,">When to Use It

>This optimization is particularly effective for:

> * Long lists of items (like product catalogs)
> * Complex dashboards with many components
> * Infinite scroll implementations
> * Tables with many rows

>[...]

>**If search functionality is crucial for your use case**, you might want to:

> Disable content-visibility: auto for searchable content

I have to admit, it is more likely that people will use the website's built in search tool to find what they want. But then again, if they did and they got a long list of elements...

I'll shake my fist at the search-function-ception going on here and move along...",2025-03-26 10:02:49,29,not_perfect_yet,programming
mjum3o5,1jk7319,reddit,"NEVER use this because I just can't stand when ctrl-f doesn't work, websites keep doing this for no reason (apart from destroying the social media space with infinite scroll). Just stop doing insane single page websites and implement normal pagination, nothing wrong with it.",2025-03-26 15:44:21,32,ficiek,programming
mjvix2n,1jk7319,reddit,"My pet peeve: Blog posts that talk about a well documented topic without linking to that documentation.

So for reference:

- [content-visibility - CSS: Cascading Style Sheets | MDN](https://developer.mozilla.org/en-US/docs/Web/CSS/content-visibility)
- [contain-intrinsic-size - CSS: Cascading Style Sheets | MDN](https://developer.mozilla.org/en-US/docs/Web/CSS/contain-intrinsic-size)",2025-03-26 18:21:12,8,OMG_A_CUPCAKE,programming
mjtunnu,1jk7319,reddit,"There are also some accessibility caveats, notably with [hidden elements](https://web.dev/articles/content-visibility#a_note_on_accessibility)",2025-03-26 13:21:26,6,i_still_have_a_core2,programming
mjtd51r,1jk7319,reddit,"Not sure if the performance gain would be big enough to notice on the example the website gives.

It's not like the browsers are rendering (painting) the entire website, even what you can't see at all times, that would destroy mobile devices. So I doubt adding blur to elements does anything to test.

So probably the property helps by skipping layout calculations and DOM work on invisible elements, but since we are testing just a static list, content visibility auto doesn't do much, and regular performance optimizations kick in instead.

A better test would use css animations or js to dynamically change the size of random elements on the list, even invisible ones.",2025-03-26 11:24:22,12,Cold_Meson_06,programming
mjswwn1,1jk7319,reddit,"Excellent! I feel like this should be common knowledge, but I certainly wasn’t familiar with it beforehand.",2025-03-26 08:47:44,0,AwesomeTheorist,programming
mjua9mg,1jk7319,reddit,is this theoretically a sub for list virtualization?,2025-03-26 14:45:08,0,lunacraz,programming
mmu7m7t,1jxuvey,reddit,Worked at a FAANG did you? I think I can guess which one.,2025-04-13 03:09:40,28,visicalc_is_best,programming
mmtz2rz,1jxuvey,reddit,"What does ""active in your workflow"" mean?",2025-04-13 02:10:57,5,teerre,programming
mmv1u66,1jxuvey,reddit,"I've been wanting something like this! I use git lens and its history is so busy it's useless. Most of the noise is the branch merged commits, hoping yours hides that",2025-04-13 07:31:30,6,Humprdink,programming
mmu6meo,1jxuvey,reddit,"I was just about to comment this looks like Smartlog at work, good job :)",2025-04-13 03:02:42,8,Cidan,programming
mmwnyku,1jxuvey,reddit,I use https://git-fork.com,2025-04-13 15:15:06,3,ryo0ka,programming
mmwnpgu,1jxuvey,reddit,"This looks great, I do miss ISL sometimes 😅",2025-04-13 15:13:46,2,Rubysz,programming
mmyjkch,1jxuvey,reddit,"this looks really intuitive, probably a lot easier to understand for beginners, and looks a lot nicer to use than the usual command line :p",2025-04-13 21:10:24,2,code_mc,programming
mn1xkg4,1jxuvey,reddit,I don't like it requires github cli. git itself should be enough.,2025-04-14 12:50:03,2,EsoLDo,programming
mmu6pd2,1jxuvey,reddit,"Looks interesting, I'll try it.",2025-04-13 03:03:16,1,somazx,programming
mmwey6e,1jxuvey,reddit,This looks really cool! Are you planning to open source it?,2025-04-13 14:27:08,1,CraftMechanics,programming
mnhh4qq,1jxuvey,reddit,"Yo I finally tried this out today and I like the general intent. Unfortunately I can’t use it at work because we don’t commit to master, but to develop branch. Can you make this customizable?",2025-04-16 22:05:15,1,MedicOfTime,programming
mmyn5i3,1jxuvey,reddit,"Git gui? 
What a waste of effort.",2025-04-13 21:30:28,-10,N/A,programming
mmxnbwd,1jxuvey,reddit,Git doesn’t need a UI. Grow up,2025-04-13 18:17:42,-20,bobvdvalk,programming
mmwzvts,1jxuvey,reddit,https://www.reddit.com/r/webdev/comments/1jv8xez/godaddy_review_why_you_need_to_avoid_them/,2025-04-13 16:17:22,-12,KrazyKirby99999,programming
mo6civb,1k3xz7r,reddit,"Nice talk! It's great to see this clear goal of going towards data oriented programming. We have been moving towards it, and it has reduced code complexity by a lot. Way less state management and more streamlined data flow. Oh, and sum types are insanely useful. It's true what he says about them. Once you know them, you cannot stop seeing a place for them everywhere.",2025-04-21 00:11:30,38,Gleethos,programming
mo6dbjp,1k3xz7r,reddit,"Some pretty negative comments in here. I don't write Java and I don't pay attention to the language. Is its development scarred with slow execution on JEPs as this thread would lead me to believe?

Every time I read about newer Java versions I typically see good things!",2025-04-21 00:16:15,41,anxxa,programming
mo5tazo,1k3xz7r,reddit,TL;DR the same path it's been going for the last 3+ years.,2025-04-20 22:14:54,160,BlueGoliath,programming
mo88kf3,1k3xz7r,reddit,Kinda interesting to see ADTs finally going mainstream!,2025-04-21 09:09:01,4,syklemil,programming
mo5tlck,1k3xz7r,reddit,Why do languages need to go places? It's been around for decades FFS.,2025-04-20 22:16:39,46,myringotomy,programming
moas8jg,1k3xz7r,reddit,"A lot of complaints about Java ITT, but compare how its grown & changed compared to C++ over the same amount of time and you'll see it's actually on a very positive trajectory.",2025-04-21 18:41:33,3,CVisionIsMyJam,programming
mo6vapa,1k3xz7r,reddit,"After using Scala and Python, I just can't bring myself to use Java anymore.",2025-04-21 02:02:38,6,Hungry_Importance918,programming
mo60t28,1k3xz7r,reddit,"Nowhere, slowly; one could reliably guess.",2025-04-20 23:01:07,11,Quiet-Detail-3939,programming
moaqexj,1k3xz7r,reddit,"It's a good question. On the one hand it still evolves slowly; on
the other hand there are changes that were inspired by other
languages, and more changes too. Some ideas I like a lot, such
as GraalVM. I hope ""the powers that be"" really push GraalVM
so that it can also become a ""unified platform"" (whatever that
means; I just want to also easily integrate some ruby code or
other languages too, having a single .exe is so convenient 
for people who are not computer techies).

The one thing I still dislike is how Java insists on project
structure when finding files. I'd love a free-form variant; ruby
spoiled me here. I do have a specific layout for my ruby code,
but I also want to have the ability to simply tell java where 
code is, rather than java insisting I have to lay it out in a 
specific way. Why can I not easily use java code residing
ANYWHERE on my local filesystem? Why does java want
to be different to other programming languages? The world
is not coming to an end if we can easily tell java where code
is.",2025-04-21 18:32:34,1,shevy-java,programming
mo6e0rh,1k3xz7r,reddit,"Wherever it’s going, it is traveling light and on a slow boat.",2025-04-21 00:20:22,0,manifoldjava,programming
mo63fhf,1k3xz7r,reddit,"I've generally noticed over the last 5 or so years that most Java libraries I am interested haven't been updated in a very long time.

One of my rules when dipping my toes into a new language/framework/env, is to check out how fresh, and how many stars their common github libs have. I like to see 2k+ stars, and I love it when I see the last update was this week. With java, not so many have that many stars, and 3+ years since the last update isn't uncommon.

This is not a healthy sign.

My personal opinion is that it was the philosophy and people who crowded around enterprise java which killed it.",2025-04-20 23:16:48,-11,LessonStudio,programming
mo890jc,1k3xz7r,reddit,Hopefully to the trash can,2025-04-21 09:13:46,-2,Ziprx,programming
mo8aprl,1k3xz7r,reddit,"to hell, I hope",2025-04-21 09:31:50,-4,91945,programming
mo64v4w,1k3xz7r,reddit,Hopefully anywhere I'm not going. My only criteria for my next job is that it isn't in Java,2025-04-20 23:25:35,-26,king_Geedorah_,programming
mo63ugs,1k3xz7r,reddit,[deleted],2025-04-20 23:19:18,-8,N/A,programming
moa59rm,1k3xz7r,reddit,"I think it is taking the wrong path: trying to be cool like Python or the new kid in the block at the cost of breaking the ""everything is an object"" paradigm. Somehow OO design is too complex for today's *coders*, so lets reject OOP entirely since it is not cool anymore.

It might as well follow the very wrong path of C++.",2025-04-21 16:50:47,-1,st4rdr0id,programming
mo9xoqg,1k3xz7r,reddit,"I don't actually care, I'm not going to use it anyway.",2025-04-21 16:12:29,-5,itaranto,programming
mkbnzcr,1jm7b8i,reddit,"Extreamly good list. I absolutely adore danluu.com his blog post are so insightfull and well written. Notice how many of those sites are small, minimalistic and mostly without any javascript. How sites like these fly on modern hardware is amazing.",2025-03-29 07:36:26,26,reveil,programming
mkb58el,1jm7b8i,reddit,nullprogram being #37 is a crime. Should be top 10.,2025-03-29 04:32:22,8,Steampunkery,programming
mkamw0j,1jm7b8i,reddit,"This is really interesting! I've been a Hacker News lurker for years and always half wondered which personal blogs consistently rise to the top there.

Looking at the list, it's no surprise Paul Graham tops the charts - his essays are practically required reading in tech circles.

I've found some of my favorite technical writers through HN over the years. It's like a filter for high-quality tech content that cuts through the SEO-optimized fluff that dominates Google results these days (though some takes I disagree with, it's at least interesting insights)

Anyone else notice how many of these top blogs use minimal styling? Simple HTML with good content seems to be the winning formula. I should probably stop messing with my site design and just focus on writing better! Which I'll do after one more redesign...",2025-03-29 02:22:51,3,sevenadrian,programming
mkbdwlk,1jm7b8i,reddit,So dumb. What exactly id a “helpful blog”? I’ve read dozens of blogs way better than this garbage,2025-03-29 05:49:09,-12,BigBrainGoddess,programming
mmedu1e,1jvxwpu,reddit,"TIL there is still significant usability development on GCC. I love the improvement of template error messages, they are always a pain to read.",2025-04-10 15:04:31,58,MortimerErnest,programming
mmgpb2z,1jvxwpu,reddit,"Love the indentation and color changes.

Not sure how I feel about the ASCII art; especially for the given example of an infinite loop, it feels like the important information is spread out and sprinkled into a bunch of unnecessary information and scribbled lines.",2025-04-10 21:55:43,4,DavidJCobb,programming
mmevj5a,1jvxwpu,reddit,"Honestly, I hate this... a 29-line warning that includes emoji and 140-column rows? More unreadable dark-blue-on-black text because the GCC developer uses a ""not actually dark blue"" as ""dark blue""?

EDIT: And that 29-line warning is just saying that n is not modified in the loop.",2025-04-10 16:31:57,19,RealDeuce,programming
mmhw0co,1jvxwpu,reddit,Nice work on both the improvements and the helpful examples. All the best to you and the release effort.,2025-04-11 02:09:25,3,Manixcomp,programming
mmifx36,1jvxwpu,reddit,Thanks!,2025-04-11 04:31:02,3,AReluctantRedditor,programming
mmiux3q,1jvxwpu,reddit,"I am already using the latest git clone checkout. I do, however had, also have to say that a few programs fail to compile with gcc, so I keep 14.2.0 in another prefix available too and just symlink the binaries (e. g. the latest gcc, or the 14.2.0 binaries); that approach kind of works.

What the article does not go into much at all (aka none) is how GCC 15 compares to llvm/clang. GCC is fine as it is, but to me it feels as if LLVM has way more momentum than GCC. I could be wrong but usually when other projects have more momentum, they may become more and more used by other folks (see the crystal language running on llvm; nobody seems to want to do this with GCC, as one example of many more).",2025-04-11 06:48:09,1,shevy-java,programming
mmpupl3,1jvxwpu,reddit,As someone who has no 20/20 vision I often keep terminal about 90 characters wide to not squeeze at wtf is going on. Some messages look too wide to the point I will not be bothered to read them,2025-04-12 11:39:49,1,Maykey,programming
mkpi5dk,1jo5r2j,reddit,"> Here’s the dirty secret: Freelancing isn’t about coding. It’s about becoming a therapist, negotiator, and amateur lawyer who occasionally writes code

I tried freelancing and starting my own business.

I learned the hard way that I am not a business man, and never want to deal with business and sales again. It was exceptionally demotivating.

Not everyone is cut out to be an MBA or a salesperson.",2025-03-31 16:24:10,248,i_ate_god,programming
mkqyyct,1jo5r2j,reddit,"I negotiate half up front, no exceptions. If they can't afford half up front or are hesitant about it, you haven't sold your services correctly and you probably don't want to work with them anyway. You can use an escrow service, that's what they are for. You can just be a deliverer of solutions if that's what you want if you learn to say ""no, but.""

I've had great success saying ""no, I don't want to do that. Here's how you could do that better and here's someone who could help you with that."" It requires immense domain knowledge, but you retain clients that respect you, your rates, and ultimately your time.

You build in punitive clauses about scope, time delays and expectations because that's how real businesses work too. Those motivate clients to treat your efforts as time sensitive, instead of the default where your concerns are at the bottom of an actively self immolating totem pole.",2025-03-31 20:46:02,41,knottheone,programming
mkqboaf,1jo5r2j,reddit,"I must be the odd one out, because I honestly enjoyed the ""businessy"" part of freelancing. Helping clients, educating them, receiving praise for well done work - that made it so much more worthwhile than just banging out code.",2025-03-31 18:50:40,34,deceased_parrot,programming
mkq8nuy,1jo5r2j,reddit,"Why the hell are you 200 hours in without the client paying anything?

Most of this is just a list of perfectly avoidable shit. If you don’t want to be a PM don’t work for tiny clients. If you don’t want to really run a business, use one of the myriad of contracting services.

Freelance can mostly be writing code… if that’s what you want it to be.",2025-03-31 18:35:33,46,soft-wear,programming
mksr8nm,1jo5r2j,reddit,"Designers have dealt with this forever. There's a great video on this: ""F*ck you. Pay me."" 
https://www.youtube.com/watch?v=jVkLVRt6c1U&t=63s",2025-04-01 03:03:18,6,bawiddah,programming
mktfjlf,1jo5r2j,reddit,"Title makes me think

> 99% of gamblers quit right before they hit the jackpot!!",2025-04-01 06:29:27,5,iris700,programming
mkzmtbl,1jphmgw,reddit,"Just fix the problems in the first version:

- Iterate over the set and use Collections.binarySearch on the sorted list to invert the check (since the set is much smaller, and the list is sorted)
- intersection is copied needlessly
- consider using ArrayDeque for fast appends at front to avoid the Collections.reverse (or return a reverse iterator if using a JDK with sequenced collections)
- don't consider using LinkedList (it wraps every element and has poor cache locality)",2025-04-02 07:32:36,85,john16384,programming
mkziqcg,1jphmgw,reddit,"The math is not correct on the improvement. Also there many other things you optimise. Maybe use a stack instead of an array, or a linked list to avoid reversing? Or use a sorted TreeSet to check for matches.",2025-04-02 06:47:40,17,kennyshor,programming
ml0efre,1jphmgw,reddit,It's always beautiful to see Cunningham's Law at work.,2025-04-02 12:09:20,13,TyDie1212,programming
mkzv157,1jphmgw,reddit,Thread.Sleep(1000); //cpu usage fix,2025-04-02 09:08:35,16,DonutConfident7733,programming
ml05enh,1jphmgw,reddit,"How about this, with a single helper Set. I'm assuming items (B) is HashSet. As little as possible allocations, resulting array and helper set preallocated.  
  
With 2K B-items there's little need for parallelization, 10K A items is on the edge of being useful to go through in parallel but I doubt that it would be beneficial, especially if there's multiple requests going on at the same time.

    private static List<String> sortItems(List<String> sortedItemList, Set<String> items) {
        if (items == null || items.isEmpty()) {
            return Collections.emptyList();
        }
        if (sortedItemList == null || sortedItemList.isEmpty()) {
            return new ArrayList<>(items);
        }
        // Find the intersection of A and B
        // Create list C containing the intersecting items, ordered as they appear in A
        // preallocate capacity
        List<String> result = new ArrayList<>(items.size());
        // Collect appended items, preallocate capacity
        Set<String> appendedItems = new HashSet<>(items.size());
        for (String item : sortedItemList) {
            if (items.contains(item)) {
                result.add(item);
                appendedItems.add(item);
            }
        }
        // Append all remaining items from B to C
        for(String possiblyNotAppendedItem : items) {
            if(!appendedItems.contains(possiblyNotAppendedItem)) {
                result.add(possiblyNotAppendedItem);
            }
        }
        // Reverse the list to get the final desired order
        Collections.reverse(result);
        return result;
    }",2025-04-02 10:57:19,5,m-apo,programming
ml1yztd,1jphmgw,reddit,"If you sometimes return Collections.empyList(), you shouldn't also be returning a raw ArrayList. The differing mutability will end up being a bug at some point. Someone somewhere will be adding to that list until the 1 time you return the empty version, and it blows up. You should return Collections.unmodifiableList(result) at the end.",2025-04-02 17:16:21,3,vips7L,programming
ml1gma6,1jphmgw,reddit,"Something like:


`list = new ArrayList(items);`
`list.sort(Comparators.comparingInt(s -> map.getOrDefault(s, Integer.MAX_VALUE)).reversed());`
`return list;`


Looks easier than that list -> array -> list thing. You're sorting stuff anyway, might as well just make sort do its job. Also, spares array allocation, which is nice.",2025-04-02 15:46:19,2,Igigog,programming
ml0f2jr,1jphmgw,reddit,"You can just simplify the routine with a LinkedHashSet. Less loops is the name of the game, no need for reversing multiple things, etc. 

```
  private static Collection<String> sortItemsRedo(List<String> sortedItemList, Set<String> items) {
        if (items == null || items.isEmpty()) {
            return Collections.emptyList();
        }
        if (sortedItemList == null || sortedItemList.isEmpty()) {
            return new ArrayList<>(items);
        }
       
        // Clone the full set of items and add them all in reverse order by default
        final LinkedHashSet<String> itemsCloned = new LinkedHashSet<String>();
        for (String item: items) {
            itemsCloned.addFirst(item);
        }

        // Move the items in the sortedItemList to the end, since we're in reverse order
        for (int i = sortedItemList.size() - 1; i >= 0; i--) {
            itemsCloned.addLast(sortedItemList.get(i));
        }

        return itemsCloned;
    }
```

Doodle showing it matches output: https://www.jdoodle.com/ia/1FfZ",2025-04-02 12:13:56,3,Scyth3,programming
mkzsefi,1jphmgw,reddit,why not just hashmap the smaller one ?,2025-04-02 08:37:46,1,liprais,programming
mkurwwl,1jovme5,reddit,You got me up until “Adopt Schrödinger’s tests” 😂,2025-04-01 13:43:46,42,Took_Berlin,programming
mkwtczx,1jovme5,reddit,"Isn't this pretty much how selenium, playwright, etc. browser driven tests work anyway. Most of the time red but sometimes green? That's when you deploy. /s",2025-04-01 20:04:52,18,MaverickGuardian,programming
mkvu06g,1jovme5,reddit,You think this is a joke but I've been at this company.,2025-04-01 17:04:26,25,s-mores,programming
mkvpzev,1jovme5,reddit,I was angry for awhile.,2025-04-01 16:43:56,6,UK-sHaDoW,programming
mkupue3,1jovme5,reddit,"On this _special_ day, I wanted to share with you a new software testing paradigm.",2025-04-01 13:31:19,17,teivah,programming
mkwcuki,1jovme5,reddit,"Finally, a sane alternative to fuzzing.",2025-04-01 18:39:46,5,Sabotaber,programming
mkvwelh,1jovme5,reddit,"Slight grammar boo-boo: ""assertions that favor optimism by silently ignore mismatches"".",2025-04-01 17:16:34,2,youngbull,programming
mkxc25j,1jovme5,reddit,"This is not new, I just put the “eventually” limit to be green before I commit the code.

Yeah, it sounds funny if you extend it beyond that and makes for a good joke.

On the other hand, writing tests before and/or as you write the code has merit. If you get accustomed to it, might save you time even.",2025-04-01 21:41:54,2,azhder,programming
ml2vm3b,1jovme5,reddit,"Hah, my company has been doing this for years.",2025-04-02 19:53:20,2,ThatNextAggravation,programming
mkxd7uu,1jovme5,reddit,"Congratulations, you've invented [test driven development.](https://wiki.c2.com/?TestDrivenDevelopment)",2025-04-01 21:48:19,0,FlyingRhenquest,programming
moy9kfl,1k71q0q,reddit,Spoiler: they use Elasticsearch,2025-04-25 11:22:21,42,shmorky,programming
movmsyd,1k71q0q,reddit,Technical blog posts to sweeten up for the IPO,2025-04-24 23:26:29,167,twigboy,programming
mouyol4,1k71q0q,reddit,Yet it can't show messages older than 5k+ in an server.,2025-04-24 21:15:16,206,Soccer_Vader,programming
moxiex7,1k71q0q,reddit,"Discord has the worst discovery UI. you can't even search in a specific group, or see where new messages are posted. why can't they have a simple UI like any other messaging service thats actually usable",2025-04-25 06:58:05,46,ECrispy,programming
mow96h5,1k71q0q,reddit,"if they index this shit itd be lovely if anything was ever recallable

 i guess the index is for office data mining use only !",2025-04-25 01:33:05,37,RiskyChris,programming
moy53xw,1k71q0q,reddit,"Found myself facepalming through a lot of that. Yeah, if all your indexes are single sharded with no replicas, it's hard to do system maintenance!",2025-04-25 10:46:48,6,esquilax,programming
mozency,1k71q0q,reddit,why is the quality of discussion so low here? just a bunch of dismissals,2025-04-25 15:16:17,4,0pet,programming
moz9kwd,1k71q0q,reddit,"This is easy, I just busted this out in under a minute. Is Discord hiring?
    
    Map<String, String> index = new HashMap<>();

    public void addMessagesToIndex() {
        for (long i = 1; i <= 1_000_000_000_000L; i++) {
            index.put(""message_"" + i, getMessage(i));
        }
    }",2025-04-25 14:51:46,4,wildjokers,programming
moxw7g3,1k71q0q,reddit,"Short answer: a lot of money, few hundreds managers and single junior made it possible. Never seen before approach. Hooray!",2025-04-25 09:21:53,-7,eocron06,programming
movlgf1,1k71q0q,reddit,Using a database of some kind? How creative,2025-04-24 23:18:59,-80,PrimeDoorNail,programming
mowncxe,1k71q0q,reddit,By using Java.,2025-04-25 02:54:23,-27,dhlowrents,programming
moxk7oc,1k71q0q,reddit,Why not Quickwit or Clickhouse? You had an opportunity here.,2025-04-25 07:16:13,-14,TonTinTon,programming
mmahizy,1juxmy5,reddit,predatory cookie settings on that site,2025-04-09 22:19:58,10,mr_dfuse2,programming
mm6lcux,1juxmy5,reddit,Right - do we now need a quantum computer?,2025-04-09 09:18:10,-30,shevy-java,programming
mntwpne,1k2cfpp,reddit,"Feature flags are great, but don't forget to delete them after the feature's launched and that configurability is no longer needed. Too many feature flags can complicate development and testing.",2025-04-18 21:48:41,104,virtyx,programming
mnt6kv4,1k2cfpp,reddit,Next one will be „Git branches For the Win: decoupling feature developmen“,2025-04-18 19:28:57,102,PositiveUse,programming
mnvvgi8,1k2cfpp,reddit,Feature flags are to be used sparingly since they explode exponentially. How do you supposedly test all the combinations?,2025-04-19 05:47:18,23,tecnofauno,programming
mnwujoc,1k2cfpp,reddit,"How do you implement them ? In the client, does that mean that you to make a bunch of additional API calls to get the feature flag configuration ? In the server, do they live in environment variables ? Alternatively, separate configuration files that are accessed over the network ?

The article is interesting but I feel like it would be much more valuable if it also considered the potential downsides and examined in more details when to use, when **not** to use, and when to remove feature flags. “Everything in software architecture is a trade-off.”",2025-04-19 11:41:43,5,Equivalent_Bet6932,programming
mnx176k,1k2cfpp,reddit,We use it a lot via launchdarkly.,2025-04-19 12:32:48,2,tepfibo,programming
mo2euzd,1k2cfpp,reddit,"“How do you test all the permutations?”
I see this one comes up a lot with conversations around feature flags. The short answer is you do and you don’t. 
The way I’ve used feature flags in the most sustainable way is that the switching of said feature flag is still tied into your release process, albeit the artifact that represents it is trivial in complexity. 
I’ve used such things as a yaml file that is in VC and are subject to TBD where main is the desired state. 
I’m much less a fan of a model where your feature flags are configurable in every environment, that welcomes chaos and I see as an applicable in only emergency scenarios. 

As it is now within your release process, it is subject to all the usual QA activity that occurs there and that means that your testing the current state as is, if a change is to switch on a flag then we test that state and move to release. If another is to be removed, we test that state and ship it. 

Each change to the feature flag state is atomic and therefore its own change with all that comes with that.
This is reliant on a robust regression suite but that is achievable. 
At that point you are testing permutations but being pragmatic about what states are possible because that state is centralised, continuously deployed and can’t change under your feet",2025-04-20 09:39:37,2,zuanshibei,programming
mo1qckg,1k2cfpp,reddit,"My team uses this extensively and so do I but I've always treated it as a form of vandalism of the codebase - something devs only do to spite the organization for not tackling the real root cause of the issues which are shitty DevOps processes and poor planning.

You end up with if-clauses everywhere in the code and for us because we store the flags in a central database - a database full of thousands of these feature flag entries which have to be retrieved by every running instance on startup and which nobody will ever clean up.

That database then also becomes a single point of failure for all instances and loss of data here from a mistyped query would be akin to losing the entire repository because the code would no longer function as normal unless and until all the entries are restored as they were (this has happened before, just not yet in prod).

In other words, I only do it because it's not my software and so I don't really care.",2025-04-20 05:27:15,0,sphqxe,programming
mkbfexb,1jm79nx,reddit,"Also, when using uuids in an index, using something like V7 improves performance a lot. If you use v4 (truly random) uuids, your index will constantly need to rebalance the btree, causing much slower inserts/updates",2025-03-29 06:04:09,61,robbiedobbie,programming
mkb5o6z,1jm79nx,reddit,90% of this is not specific to PostgreSQL...,2025-03-29 04:35:55,24,bigdamoz,programming
mkcagck,1jm79nx,reddit,">This isn't even Postgres specific, just please name your tables using the singular form of a noun.

This barely makes any sense, really.

But anyway, I want to address the ""soft"" deletion and auditing requirements. A lot of solutions come down to these ""flags"": ""deleted"" or ""revoked\_at"" as in your case. This metadata often just pollutes your business logic. We'll come back to this topic a bit later...

The next topic is ""Represent statuses as a log."". This is just a straight messy solution also introducing some ""flag"" columns such as ""latest"" or ""valid\_at"". The author is creating a new table just to track the adoption status changes, which eventually might lead to heavier joins. So, what to do instead? Enter temporal/history/versioned tables. Instead of having the ""adoption\_approval"" table, you can have ""adoption"" table and ""adoption\_history"" table, which pretty much contains all the same columns as the ""adoption"" table but without pkey or fkey constraints.

How it works:

Initially, you'd create a new record in the ""adoption"" table with status ""submitted"". When you update the status, you update the record in the ""adoption"" table and insert the old record in the ""adoption\_history"" table (can be done via trigger). This way, we can track all the changes for the given record in the history table and have an insight into the current state of the data in the so called ""snapshot"" table (""adoption"" table). The beauty of this approach is that it also comes into play when it comes to the deletion of records. In the same manner, we can delete the record in the original table, and recreate it in the history table.

However, the question arises when we cannot actually delete the record due to the constraints (foreign keys in the context of databases). In that case, it's probably time to reconsider your business logic.

For example:

1. Do I also want to delete the correlated data?
2. Is the ""deletion"" really a deletion or a status change? Marking the domain object as inactive, unused, disabled, etc.

The other advantage of temporal/versioned/history tables is that the historical data can be deleted separately and without affecting the current data.

When it comes to downsides, well, this is definitely a more performance-intensive action.",2025-03-29 11:38:39,14,rom_romeo,programming
mkcggvx,1jm79nx,reddit,Database altering postgresql patterns!!,2025-03-29 12:27:38,6,n_lens,programming
mkcu6a3,1jm79nx,reddit,This was posted here like 3 weeks ago,2025-03-29 14:00:13,4,bushwald,programming
mkfcu4e,1jm79nx,reddit,More discussion on the same article posted 11 days ago: [https://www.reddit.com/r/programming/comments/1je3ph0/life\_altering\_postgresql\_patterns/](https://www.reddit.com/r/programming/comments/1je3ph0/life_altering_postgresql_patterns/),2025-03-29 22:18:45,2,Ordinary_Leader_2971,programming
mjv7lvs,1jkfpbj,reddit,That's so cool. What is missing from the FLS to match the expectations for a full official language specification? Is rustc aiming to be fully compliant with the FLS? Would this mean rustc and the ferrocene compiler are in direct competition in the safety critical space?,2025-03-26 17:27:30,22,Linguaphonia,programming
mkpdmg2,1jo66kx,reddit,"Why the f are they uploading to NPM to debug this stuff? would be 100x more efficient to just run it locally, see that it doesn't work locally, and debug there ¯\\\_\(ツ\)\_\/¯",2025-03-31 16:01:41,16,Takeoded,programming
mkrkjx7,1jo66kx,reddit,what a thrilling story!,2025-03-31 22:42:48,2,somnamboola,programming
mn1xcxj,1jyvozr,reddit,">## What makes it secure?

>PrimJS (and by extension QuickJS) are written in C/C++; integrating them as-is in your program means you inherit any security issues that might be lingering inside them.

>Hako compiles down to WebAssembly, a memory-safe, sandboxed execution environment. This means even though Hako is written in C/C++, programs it is embedded in have an extra layer of protection from any potential memory vulnerabilities.

I didn't expect ""compile to wasm instead of native"" to be how C/C++ gets to some memory safe state, but, uh, OK.",2025-04-14 12:48:43,48,syklemil,programming
mn1t8pt,1jyvozr,reddit,These are not words i expected to see with js lol,2025-04-14 12:21:11,11,AciD1BuRN,programming
mn206qx,1jyvozr,reddit,Atwood's law,2025-04-14 13:06:26,4,abhijitht007,programming
mn2d3gq,1jyvozr,reddit,"> Hako being a fork of PrimJS means we inherit many of the improvements it made. In sythentic benchmarks, Hako shows performance gains of 28% over QuickJS. Compiling to WebAssembly has no noticable impact on performance as the amazing JIT compilers of JavaScriptCore/Bun, V8/NodeJS, and Wasmtime allow code to run at near-native speeds. I’ve also implemented a number of optimizations (including SIMD) for a few hot paths.

Wouldn't a rust fork with SIMD be even faster?",2025-04-14 14:20:20,1,badpotato,programming
mlvf93b,1jtk7ky,reddit,"If OP own this website, you should check your site on mobile phone.

Anyway, great article, I agree with all of your propositions.",2025-04-07 14:57:36,35,_shulhan,programming
mluvvnw,1jtk7ky,reddit,Those are great attributes of programmers. The best software engineers I know are good at questioning the requirements and adapting them to what's easiest to implement and that meets all the hidden requirements like durability and adaptability.,2025-04-07 13:09:58,30,gladfelter,programming
mlzq5f2,1jtk7ky,reddit,"""Read the error message"" truly underrated. You wouldn't think it was a skill of its own until you have to help your colleagues figure out which part of ""error: directory does not exist"" tells you that the error is that the directory does not exist :)

Of course, other times the error message is just random words from the brain of the original developer, so you have to apply some time-traveling telepathy to translate it into English.

Or the hard part is finding the error in the first place since either the script kept going for 30 minutes after the failure or it follows the actual error with a hundred run-on errors or repeatedly reporting that something else failed earlier.",2025-04-08 06:05:36,9,olsner,programming
mlw82jc,1jtk7ky,reddit,"Brief summary:    
Do well and do not do badly.  
Help everyone if you can make your help visible.  
Learn.

I will add to this article my own:  
Remember that the best engineers and happy engineers are two different groups, and they overlap only a small part.

Most of us strive all our lives to become the best engineers. It is not hard (see article). But what about becoming a happy engineer? That is what is really hard.",2025-04-07 17:24:58,22,YahenP,programming
mlzupu4,1jtk7ky,reddit,Thought he was going to give us the names of the best programmers he knows,2025-04-08 06:47:55,3,Apterygiformes,programming
mlvspgx,1jtk7ky,reddit,"> To know a tool well, you have to know:
>
> * its history: who created it? Why? To solve which problem?
> * its present: who maintains it? Where do they work? On what?

Respectfully WTF?",2025-04-07 16:06:28,14,somebodddy,programming
mm1u8ym,1jtk7ky,reddit,"One thing that is really lacking: Best programmers resist the temptation to use the latest and greatest frameworks, tools, and tech and to change/refactor things that are working.",2025-04-08 15:41:17,2,_z_o,programming
mm4d0ur,1jtk7ky,reddit,"This website has been temporarily rate limited

You cannot access this site because the owner has reached their plan limits. Check back later once traffic has gone down.

If you are owner of this website, prevent this from happening again by upgrading your plan on the Cloudflare Workers dashboard.",2025-04-08 23:13:33,2,thefinest,programming
mlysnec,1jtk7ky,reddit,how many programmers does he know? 5?,2025-04-08 01:53:51,2,zaphod4th,programming
mm1i547,1jtk7ky,reddit,"In addition to your post, I think keeping it simple is up there in importance. 

Also, adding to the working code isn't always the answer. I can't tell you how many times I've seen devs add a feature that was already there, the project just needed the slightest adjustment to the current code or, at times, a deletion if a few lines to get the expected result.

Great devs can fix/improve the code base while not adding craft.",2025-04-08 14:41:15,1,ktoks,programming
mm4rbms,1jtk7ky,reddit,"You should add ""understands the business and product context of the code they are writing"". Let's stop encouraging developers to be silo-ed in code world and encourage the next generation to fight for a seat at the decision making table.",2025-04-09 00:35:57,1,EruLearns,programming
mm8cuy7,1jtk7ky,reddit,"> The best devs I know read a lot of code and they are not afraid to touch it. They never say “that’s not for me” or “I can’t help you here.” Instead, they just start and learn. Code is _just code_. They can just pick up any skill that is required with time and effort. Before you know it, they become the go-to person in the team for whatever they touched. Mostly because they were the only ones who were not afraid to touch it in the first place.

I mostly agree here, but I don't particularly agree with ""Code is _just code_"":

1. It's never just code. See at the very least [Conway's law](https://en.wikipedia.org/wiki/Conway%27s_law).
2. Programming languages aren't just reskins of the same general idea. There's a lot of [different paradigms](https://webperso.info.ucl.ac.be/~pvr/book.html), and [different values](https://www.youtube.com/watch?v=Xhx970_JKX4). A good programmer won't fall to ""the blub paradox"", but they can recognise the ""power levels"", good and bad design decisions, tradeoffs made in language design.",2025-04-09 16:02:19,1,syklemil,programming
mlxmf13,1jtk7ky,reddit,"good article

It's written with common sense and can be applied to many other crafts.",2025-04-07 21:44:55,1,UXUIDD,programming
mo9lvvr,1k4c5g5,reddit,"    SELECT c_count, COUNT(*) AS custdist
      FROM
      (
        SELECT c_custkey, COUNT(o_orderkey) AS c_count
        FROM customer
        LEFT OUTER JOIN orders
          ON c_custkey = o_custkey
          AND o_comment NOT LIKE '%unusual%'
        GROUP BY c_custkey
      ) AS c_orders
    GROUP BY c_count
    ORDER BY custdist DESC;

---

    FROM customer
    |> LEFT OUTER JOIN orders
        ON c_custkey = o_custkey
        AND o_comment NOT LIKE '%unusual%'
    |> AGGREGATE COUNT(o_orderkey) AS c_count
      GROUP BY c_custkey
    |> AGGREGATE COUNT(*) AS custdist
      GROUP BY c_count
    |> ORDER BY custdist DESC;

---

Shameless [edgeql](https://geldata.com/) shill time:

    select (
      group Customer
      using c_orders := count(
        .orders filter .comment not like '%unusual%'
      )
      by c_orders
    ) {
      c_count := .key.c_orders,
      custdist := count(.elements),
    }
    order by .custdist desc;",2025-04-21 15:00:00,21,kaelwd,programming
moaody4,1k4c5g5,reddit,Try elixir,2025-04-21 18:22:37,9,hearthebell,programming
moapm4z,1k4c5g5,reddit,"I am confused.

Isn't that just method-calls on objects?

e. g. he used this example:

    fizz.get(bar).get(buzz).get(foo)

What is the difference? I don't even understand the word ""pipelining"". I thought about x | y | z piping.

Or this example:

    data.iter()
            .map(|w| w.toWingding())
            .filter(|w| w.alive)
            .map(|w| w.id)
            .collect()

I mean, that's method-chaining right? And the (|w| w.alive) that is almost
identical to e. g. in ruby block syntax, as a contrived example:

     cat.jumps_to(:jimmy_the_mouse) {|mouse| mouse.die! }

""Versus the SQL Syntax she told you not to worry about:""

    FROM customer
    |> LEFT OUTER JOIN orders

And that reminds me of elixir now.

I am super-confused. What is pipelining really?",2025-04-21 18:28:39,9,shevy-java,programming
mobu9n0,1k4c5g5,reddit,->>/->,2025-04-21 21:51:55,4,deaddyfreddy,programming
mohnj7f,1k4c5g5,reddit,I'm an old shell programmer who thought pipelines were about parallelism.,2025-04-22 20:09:47,3,TheAncientGeek,programming
moa8p7m,1k4c5g5,reddit,"> This is not real Rust code. Quick challenge for the curious Rustacean, can you explain why we cannot rewrite the above code like this, even if we import all of the symbols?

[What?](https://youtube.com/clip/UgkxQJJ_wSWdcEAL0SlM3my2FQoeYM2WoxNf?si=vPsfudiE2KZXy99A)... 

_Sure_, It doesn't _exactly_ work without full qualification as these functions are implemented on traits not just free functions in a namespace. You don't even need imports.

[All you need is some turbo fish](https://play.rust-lang.org/?version=stable&mode=debug&edition=2024&gist=c2f56a2cc250ff6fee2b486e52e8abc9).",2025-04-21 17:07:18,6,valarauca14,programming
mocvryf,1k4c5g5,reddit,"Are you familiar with [monad comprehensions](https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/monad_comprehensions.html), OP? I think that's the perfect example for pipelines in Haskell (or functional programming in general).",2025-04-22 01:25:21,2,BlazeBigBang,programming
mokc6fa,1k4c5g5,reddit,"From reading that, I'm not sure what the Rust code has to offer that is better than LINQ.",2025-04-23 05:55:52,1,jssstttoppss,programming
mnnlu6f,1k1lu1o,reddit,You’re going to ask for our password to check if it’s compromised aren’t you.,2025-04-17 21:20:10,50,Subsum44,programming
mnoj9zi,1k1lu1o,reddit,"I’ll repeat here what I said on /r/netsec:

> gs-loc.apple.com is an endpoint used by Apple to request user's location information.  It was called during a 3-minute recording of the traffic from a single opened app - Make More game. It didn't turn up ever before [when I was analysing other apps] + this game is on the Gravy list.
> 
> However, I don't want to make false claims saying that this app was responsible for Apple's request – that endpoint is not accessible directly for any app except for iOS itself, so in order to get the information from it an app needs to call a dedicated Apple API method and have corresponding permissions. Or maybe not?

I’m very curious about this.  If location services are turned off, apps should not be able to get this data. Bi want a part 3 if you figure this out.",2025-04-18 00:29:16,23,ScottContini,programming
mnpi7ko,1k1lu1o,reddit,"I bought some static IPs. I'm based in one state, those IPs were based in another. In a couple months, Google associated all of those IPs with my location - even ones that weren't enabled. So that's fun.",2025-04-18 04:24:37,21,Somepotato,programming
mnn3cnj,1k1lu1o,reddit,That's frickijg creepy!!,2025-04-17 19:48:32,11,TheShadowCraft,programming
mnq9x9w,1k1lu1o,reddit,"I'm not really understanding the location sharing implications that the title claims.  I fully acknowledge it might be because I'm ignorant. But what i understand is that apps and ads contact thousands of endpoints with your information they can find and that the requests have keys like Lat and Lon and Loc, etc and.. IP address.  Are the lat and lon somehow accessing your precise location with location services turned off or something?",2025-04-18 08:56:52,4,rav3lcet,programming
mnn3g5z,1k1lu1o,reddit,"Nice try, Tim, but you won't get me with the same trick twice!",2025-04-17 19:49:01,5,11fdriver,programming
mobeyec,1k4j6us,reddit,"A classic. I love this part:

*We could, for instance, begin with cleaning up our language by no longer calling a bug a bug but by calling it an error. It is much more honest because it squarely puts the blame where it belongs, viz. with the programmer who made the error. The animistic metaphor of the bug that maliciously sneaked in while the programmer was not looking is intellectually dishonest as it disguises that the error is the programmer's own creation. The nice thing of this simple change of vocabulary is that it has such a profound effect: while, before, a program with only one bug used to be ""almost correct"", afterwards a program with an error is just ""wrong"" (because in error).*",2025-04-21 20:33:58,113,NakamotoScheme,programming
mob1uhz,1k4j6us,reddit,"This is from 1988!? This is incredibly (and frustratingly) just as relevant today, if not more.",2025-04-21 19:29:02,19,larikang,programming
mod0cwu,1k4j6us,reddit,"If he genuinely accepts the premise that a mammalian brain evolved in a natural environment and therefore is better suited to certain kinds of concepts and conceptual relations then there's little reason to reject the use of these kinds of relations as teaching tools. In fact, there's every reason to suspect that without these thinking crutches most of us -- or perhaps none of us -- could master the advanced and abstract concepts which are the cornerstone of what he calls 'abstract science'.",2025-04-22 01:51:58,16,DragonSlave49,programming
mof5tka,1k4j6us,reddit,">The usual way in which we plan today for tomorrow is in yesterday's vocabulary. 

Yeah!

>It is the most common way of trying to cope with novelty: by means of metaphors and analogies we try to link the new to the old, the novel to the familiar. 

Yeah!

>our past experience is no longer relevant, the analogies become too shallow, and the metaphors become more misleading than illuminating. This is the situation that is characteristic for the ""radical"" novelty.

Yeah!

>The other thing I can not stress enough is that the fraction of the population for which gradual change seems to be all but the only paradigm of history is very large, probably much larger than you would expect. 

Yeah!

>[...]

>Finally, in order to drive home the message that this introductory programming course is primarily a course in formal mathematics...

What. The. Fuck.

>(Formal math? The thing I know and enjoy teaching?
>>""Teaching to unsuspecting youngsters the effective use of formal methods is one of the joys of life because it is so extremely rewarding.""

>Surely this is the answer.)

------

Good piece of writing, but the conclusion is so absurdly the exact same trap he described initially *AND* not solving it at all, is hilarious.",2025-04-22 12:35:57,7,not_perfect_yet,programming
mog2w8e,1k4j6us,reddit,">(2) the subculture of the compulsive programmer, whose ethics prescribe that one silly idea and a month of frantic coding should suffice to make him a life-long millionaire

spotted vibe coding 40 years ago",2025-04-22 15:34:15,2,NotMNDM,programming
modqe0r,1k4j6us,reddit,"Dijkstra was one of those hardliner mathematician who thought programming is mathematics. You may prove certain properties of a program here and there but some properties cannot even be proved.

How will you prove a Chrome browser or a video game? Thank god nobody listened to him, and rightly so otherwise we would never have any games ever because you cannot prove them. Programming is not mathematics nor is it science. 

Program proving is a very niche but very important field and there is every reason to be excited but seriously Dijkstra was kinda nuts. I once wanted to read him and in a preface he says something about I couldn't care less about bibliography, lmao. That turned me off. 

Also, Computer Science is a terrible word for this field. It is neither about computers nor is it a science.   I like the word Informatics that they use elsewhere.",2025-04-22 04:42:18,1,Symmetries_Research,programming
mocxsto,1k4j6us,reddit,It’s a bug dammit,2025-04-22 01:37:10,1,Nice_Set_6326,programming
mobccin,1k4j6us,reddit,This could have been written in less than a quarter of the copy. I also disagree with most of it.,2025-04-21 20:21:15,-7,Icy_Foundation3534,programming
mnlhh34,1k1dylg,reddit,"Good description of what seems to be certainly a bug in Apple's symbol loader. A bug that was not in iOS 18.3. It relates to dlsym (a function for fetching and resolving imports from a dynamic library).

Well written too, not overly wordy or AI slop. Recommended.

I gotta say though, I'm well over the ""considered harmful"" stuff. It's trite and adds no information. With a title like ""our efforts finding a new pointer signing bug in iOS 18.4 - and why Apple's code doesn't suffer from it"" would be nicer.

One of the two security bug fixes in iOS 18.4.1 relates to pointer signing. I wonder if it relates to this bug?",2025-04-17 15:06:50,69,happyscrappy,programming
mkdonty,1jmq53i,reddit,Best development environments are the ones that keep things as simple as possible.,2025-03-29 16:49:59,121,Isogash,programming
mkdrrfp,1jmq53i,reddit,"If it's a multi day project just for someone new to your code to get it running; that's entirely on your shitty code.

Containers shouldn't be a crutch to solve bad dev practices.",2025-03-29 17:06:21,73,Ok-Kaleidoscope5627,programming
mkgghps,1jmq53i,reddit,"Devcontainers support per-dev customisation in two ways I use all the time (I use vscode, not the devcontainers CLI, so I can't speak to how it works with that, but I'd hope these are supported, and if not they're possible):

* Per-user default features
* dotfiles home dir repos

The `dev.containers.defaultFeatures`user config option allows users to define a list of extra features that get installed into each devcontainer they open, in addition to the features configured on the devcontainer itself. You can use this to add tools you always use, or even write your own custom features to enable some custom workflow specific to you.

You can automatically install a dotfiles repo into the devcontainer, to set up your shell with the configuration you like, and install user-specific programs. You can use any dotfiles manager you like, e.g [https://yadm.io/](https://yadm.io/)

OP seems to dislike the idea that you'd invoke a package manager inside a container, and I feel like that's a bad take. Immutable environments are one use case for containers, not what every container should aspire to be. A container is just a loose concept for one or more processes that's isolated from the host OS to some degree. It's basically just a way of automating using a bunch of linux features like cgroups. This non-strict definition makes containers very practical as dev environments, as you can always poke more holes into them if you need to reduce the isolation to get something done.

I've been using devcontainers for years, and find them to be really practical and flexible for the most part. They are also great for increasing your level of familiarity with containerisation in general, as when you do bump into issues you generally need to know something about how containers work to understand/fix an issue. 

I do wish the vscode devcontainers extension was not proprietary though, as it's got a lot of room for improvement:

* The experience when a devcontainer image fails to build is terrible. VSCode makes you open a ""recovery container"" to try to edit the Dockerfile/devcontainer.json to fix whatever is broken. The recovery environment sucks, and afterwards you get a recovery devcontainer left sitting in your devcontainer history list for no reason.
* Managing/viewing your devcontainers is terrible, there's no sensible way to see them all and work out if you still need one, without opening it by searching by name/most recently used and then manually assessing if it's useful.
* It's not uncommon that it randomly breaks in some way, requiring a VSCode window reload, or restart of the container itself",2025-03-30 02:16:13,9,h4l,programming
mkdsqis,1jmq53i,reddit,"docker + nix does seem like pretty good idea on paper but I've never been able to get nix to work well for myself at least; how does it handle building for different linux variants?

a lot of people dont like or want to use nix so wrapping it up in a devcontainer, or some custom version of dev containers, seems nice to me.",2025-03-29 17:11:29,8,No_Technician7058,programming
mkhkpkd,1jmq53i,reddit,"I at least, encountered a problem, I never thought I would never have to think of. 


I wanted to develop an foundry but module. Thought docker ( for windows) would be a good idea. 


You have a module directory, and the rest is basically static, yes I could build the container every time I want to test the code


Or access the module directory directly in windows with my editor. 


But you don't have access to the directory within Windows in docker for windows...


So I installed the windows version of foundry lol",2025-03-30 08:05:46,1,Bitter-Good-2540,programming
mkfm4f7,1jmq53i,reddit,Nix nix we like nix,2025-03-29 23:12:58,2,Apterygiformes,programming
mkflw3i,1jmq53i,reddit,"Initially read that as ""Crack in containerized development"" and I thought we were talking about something else.",2025-03-29 23:11:39,1,Ambitious_Tax_,programming
mn2mbak,1jz0ena,reddit,"FWIW, while the Microchip XC32 compiler is officially paid, it's also a fork of GCC four point something. So you should be able to obtain a copy relatively easily. Not sure if any Linux platforms actually use it, but it's used with their MIPS microcontrollers.",2025-04-14 15:08:11,34,jaskij,programming
mn9lffd,1jz0ena,reddit,How do you debug a rust program that compiles to C? Just print statements? Or maybe a way to associate debug info with the Rust source?,2025-04-15 17:24:45,1,mungaihaha,programming
ml0n3fw,1jpn7oo,reddit,"LLMs are the killer of stack overflow, but like hunter and prey, when SO is dead, the LLMs will have nowhere to get their software question/answer training data from.

They can only exist together, so if by then AI can’t completely replace software engineers, the AI companies will need to set up something like SO.",2025-04-02 13:07:58,189,m-sasha,programming
ml0mkw2,1jpn7oo,reddit,This Reddit post has been marked as a duplicate.,2025-04-02 13:04:37,46,solve-for-x,programming
ml0ih6y,1jpn7oo,reddit,"Stack Overflow has been like a toxic friend that is helpful but a pain to be around. When there was no alternative place to get help, everyone used it despite the obnoxious tone maintained by the moderators and several of the participants on the platform. 

Now that there are alternatives, everyone is distancing themselves from the toxic friend. For me, the Stack Overflow culture is much more of a reason and an interesting story than another “AI killed it” piece…",2025-04-02 12:37:46,33,LoopVariant,programming
ml0x878,1jpn7oo,reddit,"i personally find so many questions on SO are actually duplicates. 

i bet almost 98% of the questions this week have a HINT OF AN ANSWER somewhere on SO. not an exact answer, but enough that the question should be a duplicate.  seriously, it is very rare that a real programming question (excluding problems that should be on github issue)  has no HINT OF AN ANSWER on SO. very fucking rare. 

unfortunately tho, people want EXACT ANSWERS to their very specific questions and don't want to read anything else, hence all the complaints about their question being a dupe.",2025-04-02 14:08:22,24,Few-Understanding264,programming
ml2axhz,1jpn7oo,reddit,"> However, with the rise of AI-driven coding assistants, the platform’s relevance has taken a hit. 

Perhaps AI took a further hit on SO, but the problems of SO have more to do with the design.

I remember several years ago, I was asking a question about mixing licences in a software project. It was a honest question, not a troll question.

Within 5 minutes, I was downvoted to something like -7 or so, in other words a few people simply downvoted it. Ok. Of all who downvoted, how many do you think explained their vote?

Zero. Nada. Nobody even responded to the question.

I checked the next few days and nobody wrote anything either; and the few who may want to write, were
discouraged by the negative votes already as-is. So, I am sorry, but the SO platform simply sucks for asking questions. I still find SO has value in older questions and answers, but this is just one problem of many. I asked a question, expecting people to say something useful, and got zero results. So basically I was wasting my time with SO here.

I am sure others can find related problems and anecdotes, but this is an example of the underlying design of SO simply not being good. They should have changed their voting and participation system a long time already really. They failed to do so, for whatever the reason. Since then it went further downhill.

AI may put the final nail in the coffin, but SO died prior to that already.",2025-04-02 18:12:17,8,shevy-java,programming
ml8g7rk,1jpn7oo,reddit,"1. Stack overflow was doomed before AI. ai just acelerated it

2. Llms dont need SO",2025-04-03 17:31:35,3,R3PTILIA,programming
ml10cxr,1jpn7oo,reddit,"I told the LLM to create a “stackoverflow” site and it did a pretty good job, then I told it to populate the site with questions and answers and again, it did a pretty good job. Now it can learn from itself, forever.",2025-04-02 14:24:31,3,rwrife,programming
ml0mx3l,1jpn7oo,reddit,"I don't get the hate around SO, being critical about your code isn't cool anymore or what?",2025-04-02 13:06:49,4,walkingcontradict1,programming
ml0yitf,1jpn7oo,reddit,"The only questions that will be most affected by AI at the ones where: 

- you want an answer
- and not an insult

If you're ok with one (or none) of those things, then Stack Overflow is the perfect choice.",2025-04-02 14:15:07,-6,Top_Meaning6195,programming
mjv1no1,1jk6q79,reddit,"I think the most important piece of information is missing. How well does it work?

It needs some kind of benchmarking.",2025-03-26 16:59:33,14,almost_useless,programming
mjww04j,1jk6q79,reddit,Inspired by [this](https://youtu.be/a0CVCcb0RJM)?,2025-03-26 22:17:56,8,sargeanthost,programming
mjtj4pl,1jk6q79,reddit,But does it use a middle out algorithm?,2025-03-26 12:08:43,17,3Eyes,programming
mkbskko,1jk6q79,reddit,"cool! i'll get a look at the repo. i'm learning Rust and the ""Audio"" world is so interesting",2025-03-29 08:28:47,1,uscnep,programming
mjv0yf5,1jk6q79,reddit,"Neat, can you expand on the fast audio recognition aspect? how does it identify the song? call to API somewhere?",2025-03-26 16:56:16,0,Successful-Peach-764,programming
mo38bd0,1k3mjlz,reddit,"> This part will focus on why I think it is an important improvement over the git's status-quo and why I use it daily.

It feels like the article never really went into explanation on why it's an improvement over git.",2025-04-20 13:43:47,111,jhartikainen,programming
mo55pa5,1k3mjlz,reddit,"
I think saying changes are branches is pedagogically confusing. Bookmarks should be understood as branches. Then you can just say that the unit of work is not a branch, but a commit, which is in fact the biggest jj strength

Personally I'm not a big fan of ""here's git but jj"" kinda of articles. They usually don't really highlight jj's best features. This one does go over the, very good, feature of always having everything committed, but that's kind it. The real power of jj is how you can manipulate the version history easily and safely

I think if you gonna talk about jj, it should highlight how `new/rebase/squash` gives you full power over your history and `jj op log` makes it impossible to screw it up. It should be contrasted with how much, much more difficult and dangerous the same actions are in git. This article makes it seems jj is harder than git and it definitely isn't, on the opposite, jj is vastly easier than git

edit: hijacking my comment to recommend the absolutely wonderful https://github.com/idursun/jjui. If you liked magit (and its clones), lazygit or even just vim, just will be right up your alley. In no exaggeration, I do all kinds of complex manipulations on my git history without even thinking with this plugin. Just incredible UX",2025-04-20 20:00:15,28,teerre,programming
mo5ibqo,1k3mjlz,reddit,"Does it support pre-commit hooks yet? Many workplaces seem to be using those as a way to prevent accidentally committing and pushing secrets into their repos. Without that, Jujutsu won't be a viable replacement there.

EDIT: even if the process looks slightly different with Jujutsu, if it can provide some way to fail out before 'recording' any data, it should still be viable.",2025-04-20 21:10:42,9,yawaramin,programming
mo3hd9m,1k3mjlz,reddit,That's a lot of words and no concise explanation of what's different/better. Does it just automatically throw every change into a commit?,2025-04-20 14:36:21,16,wineblood,programming
mo3a084,1k3mjlz,reddit,I can't think of of a use case where I would want to track every key press. Which seems to be the only feature that's not just a renamed and over complicated git feature.,2025-04-20 13:54:00,26,Few-Satisfaction6221,programming
mo41xqd,1k3mjlz,reddit,"I think it’s important to note

> Jujutsu is an experimental version control system. While Git compatibility is stable, and most developers use it daily for all their needs, there may still be work-in-progress features, suboptimal UX, and workflow gaps that make it unusable for your particular use.

Also it still uses Git on the backend so right now it’s more of a front-end tool for Git than a full fledged VCS.

It’s got some interesting features, mostly taken from other VCS, but rn it’s just something that might be worth a revisit once it’s more mature.",2025-04-20 16:27:31,8,arpan3t,programming
mo81ly1,1k3mjlz,reddit,"Fancy, send like it's basically a frontend for git. Including, from the article I could not gather exactly what issues from git it solves. The keeping track of all writes seems neat but would do nothing for me, personally.",2025-04-21 07:55:28,2,Efficient_Role_7772,programming
mo3zqrl,1k3mjlz,reddit,"If changes are linked by IDs that are not content-addressed, how can they be shared by multiple people?",2025-04-20 16:15:54,3,lifeeraser,programming
mo87ioj,1k3mjlz,reddit,"> In Jujutsu, one doesn't make a merge of branches. Instead, one makes a change with several parents: jj new rev1 rev2 rev3, where rev1, etc. are either change-ids or branch-names (or some other interesting things we did not talk about yet).

That is LITERALLY what merge commit is.

Git's commits are snapshots of state of the tree that just happen to have parent added. Merge isn't special here at all",2025-04-21 08:57:59,2,CrunchyTortilla1234,programming
mo6wa4s,1k3mjlz,reddit,"I used to use CSV, but now I manage all my projects with Git. I'm so deep into the code every day that I don’t have time to keep up with version control updates.",2025-04-21 02:08:33,1,Hungry_Importance918,programming
mo7iejg,1k3mjlz,reddit,"There are so many posts here discussing that JJ is already some standard thing that everyone uses and people not using it are uncool, that the entire thread reeks of astroturf. 

Of course it's a Google project. In a world where Microsoft bought GitHub, Google has to regain control somehow.",2025-04-21 04:42:42,1,postmodest,programming
mo5ptuz,1k3mjlz,reddit,"In the usual Google project fashion, `jj` attempts to solve issues quite literally no one else in the entire world has with existing version control solutions.",2025-04-20 21:54:04,-4,Mrucux7,programming
mo3brlk,1k3m2fd,reddit,"    fn main() {
        println!(""Max Verstappen"");
    }",2025-04-20 14:04:26,257,Bumblebeta,programming
mo34wxj,1k3m2fd,reddit,Cool project. How did you come up with the driver stats? Eg difficult to quantify yukis skill in wet in a car he's only driven once so far.,2025-04-20 13:22:39,31,s32,programming
mo4ia8i,1k3m2fd,reddit,"WAT

================================================================================
2025 FORMULA 1 GRAND PRIX - JEDDAH CORNICHE CIRCUIT
Location: Jeddah, Saudi Arabia
Track Length: 6.174km - 50 laps (308km)
Weather: Dry - 29.2°C, Rain: 12%
================================================================================


QUALIFYING RESULTS
------------------------------------------------------------
|   Pos | Driver            | Team            |   No. |
|------:|:------------------|:----------------|------:|
|     1 | Kimi Antonelli    | Mercedes        |    87 |
|     2 | Lewis Hamilton    | Ferrari         |    44 |
|     3 | Lando Norris      | McLaren         |     4 |
|     4 | Max Verstappen    | Red Bull Racing |     1 |


RACE RESULTS
--------------------------------------------------------------------------------
|   Pos | Driver            | Team            |   Start | Change   | Time/Status   | Pts   |
|------:|:------------------|:----------------|--------:|:---------|:--------------|:------|
|     1 | Lando Norris      | McLaren         |       3 | ↑2       | 74:02.033     | 25    |
|     2 | Nico Hulkenberg   | Kick Sauber     |      13 | ↑11      | 74:16.514     | 18    |
|     3 | Max Verstappen    | Red Bull Racing |       4 | ↑1       | 76:20.735 FL  | 16    |
|     4 | Esteban Ocon      | Haas            |      11 | ↑7       | 78:13.426     | 12    |
|     5 | Carlos Sainz      | Williams        |       9 | ↑4       | 80:34.012     | 10    |
|     6 | Fernando Alonso   | Aston Martin    |       7 | ↑1       | 80:38.745     | 8     |",2025-04-20 17:53:05,21,afranke,programming
mo3muin,1k3m2fd,reddit,Let's just say I did not read the F1 bit at first,2025-04-20 15:06:17,13,robidaan,programming
mo5zl2r,1k3m2fd,reddit,AI slop spotted,2025-04-20 22:53:35,9,bruhmanegosh,programming
mo4pydf,1k3m2fd,reddit,So how good was it to predict the first few weeks of the season so far ?,2025-04-20 18:33:35,3,Ythio,programming
mnrleo7,1k217n0,reddit,Couldn't you also include a vertical reflection of the board and then not  have to account for whether the white king was above or below the black piece?,2025-04-18 14:41:19,12,goodnewscrew,programming
mnqywbi,1k217n0,reddit,"Well this checks if the king could be in check, but I don’t see how you’re checking that there isn’t a piece in between, say, the king and a queen.

What I’m saying is that there are two pieces on the board, then you’ll get the right answer, but if there are three, then how do you know an attack is not blocked?

Interesting technique tho!",2025-04-18 12:33:00,9,DXTRBeta,programming
mnxar5r,1k217n0,reddit,Love this. Would be interested to see his approach to testing false positives though. Obviously he can't test every board configuration..,2025-04-19 13:36:02,1,Ok-Regular-8009,programming
modd9nu,1k4sur2,reddit,"Sad. Seems like the main reason for withdrawing it is concerns over performance for deep value comparisons. The alternative proposal is for a library-type that uses interning so that equality comparisons will always just be a pointer check -- I wonder why that optimization couldn't be left as an implementation detail for JavaScript engines?


Deep value comparisons don't even seem that concerning to me tbh -- in Rust-land deep comparisons are everywhere and they're almost never problematic. ",2025-04-22 03:09:03,62,JoJoJet-,programming
mn1blkg,1jyue2l,reddit,so Smalltalk-y,2025-04-14 09:53:47,15,phil_gal,programming
mn279rx,1jyue2l,reddit,Interface Builder still ships with Xcode and you can use it when building with AppKit or UIKit,2025-04-14 13:48:38,16,__deinit__,programming
mn1g4vx,1jyue2l,reddit,"Tools like OpenStep Interface Builder, VB, or MS Access are dated, but they nailed rapid GUI building. There’s still a gap today for something that lets you quickly sketch and wire up a UI with minimal effort.",2025-04-14 10:37:56,59,Evening_Total7882,programming
mn286ok,1jyue2l,reddit,"The example text typed into the text field: ""sfsadfsdfa sdf"". There's something very satisfying about the utility of that rather than a probably-focus-grouped-example like ""OpenStep's Interface Builder will change programming""",2025-04-14 13:53:42,12,buckenmuck,programming
mn1wblz,1jyue2l,reddit,"What year is it?

This is a video from 1991 where Bill Gates shows VB, which was mind boggling and ground-breaking at the time: https://www.youtube.com/watch?v=Fh_UDQnboRw",2025-04-14 12:41:58,13,baal80,programming
mn38ept,1jyue2l,reddit,Love your username.,2025-04-14 16:58:56,4,happyscrappy,programming
mn3ki5b,1jyue2l,reddit,Steve Job's young years when he rebelled by having as little collar as possible.,2025-04-14 17:57:24,2,gomsim,programming
mn5ef40,1jyue2l,reddit,"Here's an [older video](https://youtu.be/rf5o5liZxnA?t=1387), from 1992 or so.",2025-04-14 23:46:50,2,self,programming
mn72drz,1jyue2l,reddit,Relevant: https://paulhammant.com/2013/03/28/interface-builders-alternative-lisp-timeline/,2025-04-15 07:05:13,2,paul_h,programming
mn7rq1y,1jyue2l,reddit,Stating the obvious for those without context: it all fell apart the moment you have to collaborate on such files with version control tools such as git.,2025-04-15 11:23:10,2,macchiato_kubideh,programming
mn2koc6,1jyue2l,reddit,VB was far ahead of this,2025-04-14 14:59:46,3,ziplock9000,programming
mn18i1n,1jyue2l,reddit,"It’s a clever design.

But … didn’t they nix OpenDoc later on after Steve returned to Apple? And was OpenDoc a part of OpenStep or vise versa?",2025-04-14 09:20:39,2,this_knee,programming
mn62ch9,1jyue2l,reddit,"aaaaand we have VSCode now 🙄, FML",2025-04-15 02:10:34,0,jfalvarez,programming
mn1bf30,1jyue2l,reddit,"This reminds me of how we were making apps (ehem, excuse me, Applications!) in the 90s. That was terrible.",2025-04-14 09:51:54,-8,Evgenii42,programming
mn1im0v,1jyue2l,reddit,Then Microsoft came out with Visual Basic,2025-04-14 10:59:54,-8,NailRX,programming
mork5mk,1k6ljdb,reddit,Because it has to count everything.,2025-04-24 10:32:31,257,editor_of_the_beast,programming
mos0frv,1k6ljdb,reddit,Does that apply to other relational DBMSs (like SQL Server and MySQL) too? I have the impression that SQL Server's count(*) always is super fast.,2025-04-24 12:30:14,28,life-is-a-loop,programming
mot79lg,1k6ljdb,reddit,"> xmax, initially set to null, denotes the transaction ID that deleted or updated **the column**.

I think you meant deleted or updated **the row**",2025-04-24 16:10:04,12,evinrows,programming
moxaha3,1k6ljdb,reddit,"An actually interesting article, thanks!",2025-04-25 05:43:01,5,ffekete,programming
mov3317,1k6ljdb,reddit,"Sometimes people write queries like this to see if any records are in a table:

    select @cnt = count(*) from TBL
    if @cnt > 0 begin … end

When that will have a lot of reads to do the count. Something like this is way better:

    if exists (select 1 from TBL) begin … end

Back in 2002-2003 I was at a retail company with a large IBM DB2 presence. They had shell scripts everywhere using the first with select(\*) and they always complained about too much CPU. I told them to use the exists syntax but they didn’t want to listen to some 25 year old.",2025-04-24 21:38:16,3,dpenton,programming
mos3flr,1k6ljdb,reddit,This ... This is just how RDBs work... Why is this an article?,2025-04-24 12:48:25,16,cheezballs,programming
mosqyfk,1k6ljdb,reddit,"I wish HyperLogLog were easier to use with Postgres.

https://en.m.wikipedia.org/wiki/HyperLogLog

It's the algorithm that powers elasticsearch cardinality estimates, and I've found it to be a great compromise.

I'm not suggesting that Postgres replace their Count implementation with HyperLogLog.

Sometimes you want a cardinality estimate and you're fine with a certain amount of imprecision.",2025-04-24 14:52:28,2,GameCounter,programming
mos1dnb,1k6ljdb,reddit,Count(1),2025-04-24 12:36:02,2,Bldyknuckles,programming
motiehy,1k6ljdb,reddit,"Do people ever execute `count(*)` on the entire table without any filters in WHERE clause? And even the article states that having a filter by any indexed field in WHERE solves it. And people should have indexes matching their performance-sensitive queries at least...

I do not think I have ever done `SELECT count(*) FROM table_name;` ... Even if I want to check if the table is empty or not, I'd do `SELECT * FROM table_name LIMIT 1` - as I am likely interested in what kind of data is in that table...",2025-04-24 17:02:29,2,voronaam,programming
mozgu1m,1k6ljdb,reddit,"Postgres is missing Index Skip Scan, that is why.",2025-04-25 15:26:48,1,sweet-arg,programming
motf80s,1k6ljdb,reddit,"We want to count rows, not _stars_! There's too many stars in the cosmos to count them quickly.

/s",2025-04-24 16:47:45,1,pihkal,programming
mouk38s,1k6ljdb,reddit,I always wonder why PG doesn’t pre calculate the count on write operations.,2025-04-24 20:03:08,1,pinpinbo,programming
mkh6cpl,1jn099y,reddit,I found found the atop title bug everyone is going crazy about: duplicate word!,2025-03-30 05:34:36,98,Paddy3118,programming
mkfzlkh,1jn099y,reddit,"If Bismuth found this ""in minutes"" with AI, I wonder how many exploits have been found by the NSA and other countries using similar tools.",2025-03-30 00:32:13,75,prescod,programming
mkh24s0,1jn099y,reddit,"Fun ad, but if you're looking to pay for a service coverity has been finding this kind of bug for decades.",2025-03-30 04:56:36,31,happyscrappy,programming
mkhwn2z,1jn099y,reddit,"What does this tool even do? I'm struggling to find a terse description.
It's project/task manager right? Kanban/agile?",2025-03-30 10:16:44,1,MartynAndJasper,programming
mle8iqn,1jn099y,reddit,"Who expects a service to run on _an ephemeral port_?

Forget the protocol bug, expecting to find a specific service on _an ephemeral port_ means someone missed Linux 101. Ephemeral ports are for the OS to allocate, one should NEVER bind to one.

So, quick rundown, in Linux:

 - Port 0 is NOT a real port. Asking for port 0 actually means Linux will pick up an ephemeral port for you.
 - Port 1-1023 require root access, that's where 22 (SSH), 80 (HTTP) and 443 (HTTPS) run, for example.
 - _Typically_ Ports 1024-32767 are for the user to manage.
 - _Typically_ Ports 36768-65535 are ephemeral ports, for the OS to manage.

But really, each Linux host can be configured differently, so the actual ephemeral range should be queried, for example by reading `/proc/sys/net/ipv4/ip_local_port_range`.

Now, of course, I know. Not everybody knows about ephemeral ports. Sure. But for the authors of a sysadmin tool... this certainly raises questions. I wouldn't be comfortable using `atop` when they miss such ""trivial"" sysadmin knowledge, who knows what else they miss.",2025-04-04 16:09:07,1,matthieum,programming
mkiyp9j,1jn099y,reddit,"Another day, another critical security issue in a fundamental ecosystem tool relied upon by millions.

I know it’s dangerous to mention the R-word on r/programming, but this problem would not have existed if the program was written in that certain other language. How many more millions are we willing to sacrifice by stubbornly sticking to our dangerous and outdated guns?",2025-03-30 14:57:16,-5,simonask_,programming
molfz2e,1k5vplf,reddit,"It may be technically academically interesting that they've pushed it so far, but do beware [licensing](https://cheerpj.com/cheerpj-core/#compare-plans) with CheerpJ.

> CheerpJ is commercial software, but it’s free to use for FOSS projects, personal projects and one-person companies. Affordable and transparent licensing apply to small businesses.

[TeaVM](https://www.teavm.org/
) OTOH is conceptually a bit different - it's ahead-of-time compilation of Java bytecode to js/wasm for later in-browser run, dropping some functionalities - but is full open source [Apache 2](https://github.com/konsoletyper/teavm/blob/master/LICENSE), and still lets you write in nice sensible Java instead of icky ECMAScript/""Javascript"" for the client side. 

> TeaVM is an ahead-of-time compiler for Java bytecode that emits JavaScript and WebAssembly that runs in a browser. Its close relative is the well-known GWT. The main difference is that TeaVM does not require source code, only compiled class files. Moreover, the source code is not required to be Java, so TeaVM successfully compiles Kotlin and Scala.",2025-04-23 12:11:24,27,lood9phee2Ri,programming
monmkf0,1k5vplf,reddit,"finally, java applets in the browser?",2025-04-23 18:52:36,11,obetu5432,programming
mopjrbd,1k5vplf,reddit,"Holy shit, time is a flat circle",2025-04-24 00:55:18,4,light24bulbs,programming
momdmi4,1k5vplf,reddit,Java 11? JNI? What year is this?,2025-04-23 15:16:47,2,BlueGoliath,programming
mm48gof,1jukuv3,reddit,Nice writeup!,2025-04-08 22:47:57,9,organman91,programming
mm5vda8,1jukuv3,reddit,"Hey OP, cool article.

One minor note: you may want to mention that `where` is a zsh-only built-in. I just checked and no other shell has it. I thought you'd mistyped `which` at first.",2025-04-09 04:56:31,7,pihkal,programming
mm4qcch,1jukuv3,reddit,"> We know that ELF is the traditional binary format that Linux uses 

I couldn’t help but recall the [trauma of the migration to ELF](https://web.archive.org/web/20040713171954/http://www.ibiblio.org/pub/historic-linux/distributions/slackware/3.9/docs/ELF-HOWTO) from a.out when I read “traditional binary format.”

Hardly traditional, a.out as the Linux binary format is a historical footnote, rightfully omitted.",2025-04-09 00:30:12,8,Admqui,programming
mmd4pjh,1jukuv3,reddit,I had a prof who always pronounced it hash-bang,2025-04-10 10:21:28,2,StarkAndRobotic,programming
mmor8xs,1jukuv3,reddit,"Nice one!

Another related series: https://cpu.land/",2025-04-12 05:08:54,2,Still-Knowledge-5302,programming
mkubcku,1jos4s2,reddit,"I spent over an hour trying to get copilot to do something and then 5 minutes on stack overflow finding the right answer. I’m sure for some things it works well, but if you have something a bit more complicated in a lesser used language then it struggles.",2025-04-01 11:55:55,148,RandomisedZombie,programming
mkuab9x,1jos4s2,reddit,"I usually don't read these kinds of articles but I feel like you did a great job articulating the problem with too much AI interaction: you're no longer in the drivers seat which means you start losing important skillsets that make you good at your craft.  
  
I still use AI for really basic autocomplete via codeium extension, so its much less obtrusive as others.  
  
For rubber ducking I do talk to AI about topics, but I make sure lead the conversation, not the other way around. So for instance, I explain the algorithm I have in mind and we discuss if that would work well in a specific context to get another perspective rather than ""I have this problem what should I do"".",2025-04-01 11:48:13,61,Craiggles-,programming
mku50o1,1jos4s2,reddit,"I never really tried co-pilot. I always thought having AI auto complete block of your code is just too much/intrusive. But as modern rubber ducking tools, it's nice.",2025-04-01 11:05:22,42,aaulia,programming
mkx2kma,1jos4s2,reddit,[deleted],2025-04-01 20:51:02,22,N/A,programming
mkwe17i,1jos4s2,reddit,I am learning C after learning Python before as a hobby and I find Copilot in Neovim way too disruptive. I enjoy the chat as I can ask it to explain the code or concepts but the code completion mostly works against me as I need to type it myself to learn. Had to disable it.,2025-04-01 18:45:52,5,Mnaukovitsch,programming
mkzy9ng,1jos4s2,reddit,"I replied to a [similar post here](https://www.reddit.com/r/programming/comments/1joeiaj/programming_with_an_ai_copilot_my_perspective_as/mktvhux/) and think the comment is relevant to yours.

I've heard many senior devs make similar observations--and this is not meant to be a criticism--but I wonder if this is the same sort of elitist attitude craftsmen in the past would have had to new industrial machinery. 

Essentially, I think you are broadly correct but it became clear to me very early on that 'prompting' is basically programming in human language. Non-deterministic yes, but programming nonetheless. It's just as non-deterministic as human programmers implementing the specifications from software architects and project managers. We're just at another level of abstraction and human language will become a form of programming language.

Current programming languages are different in that they are more precise and specifically designed to communicate with computers. That doesn't necessarily mean they're intrinsically better at building systems though. Programming languages are definitely better _right now_ because that's the tool we've learned to use.

We haven't learned to use human languages to build software but people have been building things with human language long before software came along. Maybe we just haven't yet learned to use human language in place of computer language. There's no reason you can't constrain human language to be more precise. There's also no reason that building systems necessarily needs to be very precise. Perhaps the lack of precision can be made up by very quick iteration.

Think about how Agile came along when 'the professionals' were using Waterfall. People thought that the 'chaotic' nature of Agile wouldn't work, yet Agile proponents made it work, and arguably it's the most popular methodology he have right now. There is still a need for Waterfall, and there'll always be a need to have very precise language to specify what a computer should do. Nevertheless, most projects don't need Waterfall, and maybe most people won't need the precision of dedicated programming languages.

Our profession is still in the very early stages of this thing and I suspect that prompting will be the coding of the future. There will still be the need for low-level coders to some extent, but most people won't program in the way we do now.

When I was at school, we first learnt to program using logic gates, diodes, transistors, ICs and other electronic components. Afterwards it was BASIC, Pascal, C, and so on. Fast forward into the future and I no longer need to solder components onto a circuit board, nor do I need to compile a program because I mostly use Python and a bunch of web technologies to make things happen.

I don't need to be concerned about all the lower level stuff. I don't even need to remember to allocate or deallocate memory, keep track of my pointers, or clean up garbage collection. It's all done for me.

I think it will eventually be the same with AI coding. We'll tell the AI what we want and it'll figure out the details, then produce the application. This isn't some baseless hypothesising either. My workflow now has the basics of this being put in place.

I have a requirements assistant that helps me translate a client's informal discussions into a BDD document. I'll then feed that into a software architect assistant that will recommend the basic components for the solution. Then I can use something like Replit or other AI coding assistant to give me a quick prototype. From there I can start building out the components 'for real'.

Yes, all of this still requires a hands-on approach and 25+ years of programming experience. But I do wonder if future programmers will need everything I've learned, or if we'll need as many techs as we do now.",2025-04-02 09:45:36,4,anothercoffee,programming
ml5ylaj,1jos4s2,reddit,"Very good article, and summarizes my thoughts completely.

Putting aside the fact that AI is not always generating useful code, the biggest problem I see with AI is the fact that it removes you from the equation. I believe that in the end, if everyone can prompt AI the same way you can, you are no different and very disposable. Learning and expertise come from the journey, not the destination, and it seems like AI is here to eliminate the journey altogether.

P.S. Nice blog, and lovely design.",2025-04-03 07:45:03,2,skwee357,programming
mkutucu,1jos4s2,reddit,"I""m an intermediate and I simply can't keep up with senior engineer velocity without leveraging cursor. They themselves will use AI for all but domain modelling. The speed at which you can add unit/integration tests, frontend storybooks, and reimplement existing patterns in your codebase is hard to beat. For context, it's a full stack role in a startup working on new features (ie we're not a product company in maintenance mode). 


The top comments talking about dabbling in GitHub copilot 2 years ago aren't relevant to the discussion. A coworker from my last job just sent me a screenshot of his eng slack this morning - they've moved from vsc to cursor as their default IDE.",2025-04-01 13:55:08,4,Lersei_Cannister,programming
mky24uw,1jos4s2,reddit,"Lots of crazy talk in here.  I started using cursor about a month ago and the experience has been nothing short of amazing.

Gone are the days of grunt work unit tests and coding out each crud page by hand - it’s now a 5 minute task.  

Learn how to use it or be left behind.",2025-04-02 00:14:15,0,dtown123,programming
mkugbg0,1jos4s2,reddit,"I'm not saying you should use these tools on every task, in every project or with every tech stack, but generalizing to ""if you use this too much, you will lose your skills"" is nonsense.  Eschew these tools if you want, but I think you're doing so at a great risk to yourself. 

The comparison to self-driving made me think: OP was always a bad driver, self-driving just made them realize it.",2025-04-01 12:31:03,-8,elh0mbre,programming
ml1lsjo,1jos4s2,reddit,Next up: how i gave up on C and started using assembly to great success.,2025-04-02 16:12:10,0,tschellenbach,programming
mk8b2tp,1jlsyzq,reddit,"Would be nice if they'd release actual features too, instead of just ways to specify features. The development of WASM has been nothing short of glacial.",2025-03-28 18:46:08,53,pip25hu,programming
mkac0cz,1jlsyzq,reddit,I'm a huge supporter of the need for formal semantics and provable properties of code bases. This is an immense step forward in complex language management and sustainability. Congratulations to everyone who contributed to this! Well done.,2025-03-29 01:17:09,7,rajandatta,programming
mk6dev4,1jlsyzq,reddit,"Stop slacking and make fucking DOM access instead instead of wanky ""features""",2025-03-28 12:55:50,16,CrunchyTortilla1234,programming
mkap94f,1jlsyzq,reddit,ASCII will be much easier to parse than trying to grab the grammar from the RST files.,2025-03-29 02:38:09,1,SCI4THIS,programming
mkd7yhd,1jlsyzq,reddit,"Ok but ... what does this enable us to do? I am a bit confused as to what this is useful for, in practice.",2025-03-29 15:18:35,1,shevy-java,programming
ml7j4yz,1jqk43q,reddit,"That’s honestly extremely impressive.

Is CSS turing complete these days? It never would have occurred to me to wrap so much custom logic all within CSS.",2025-04-03 14:49:32,19,MakesUsMighty,programming
ml8a3oe,1jqk43q,reddit,Too bad the performance sucks on mobile. Really sluggish scrolling. ,2025-04-03 17:01:55,8,blamethebrain,programming
ml9u5ow,1jqk43q,reddit,"ah, of course it doesn't work on safari macOS, but Firefox nice!",2025-04-03 21:39:54,2,bonnydoe,programming
ml79hor,1jq7o3e,reddit,"Without going too much into singing praises, it's remarkable to see a:

- new graphic editor 
- FOSS
- written in Rust
- using nodes (i.e. non-destructive editing) 
- supporting both vector or raster.

Kudos! I'll get to donation page ASAP.",2025-04-03 14:00:34,10,-Y0-,programming
ml51xgi,1jq7o3e,reddit,"As we finish off Q1 of this year, here's a look back at last year's Q4 progress. Stay tuned for updates on this quarter's developments, which includes shiny features like **animation!**

Graphite is a data-driven creative design engine that combines an artist-friendly image editing environment with a procedural graphics renderer built with Graphene, a custom Rust-based compiled functional programming language for portable, scriptable graphics pipelines.

Also: this is the last week to apply for a summer internship building Graphite with us, in Rust! Info here: [https://graphite.rs/blog/internships-for-a-rust-graphics-engine-gsoc-2025/](https://graphite.rs/blog/internships-for-a-rust-graphics-engine-gsoc-2025/?utm_source=reddit&utm_campaign=programming)",2025-04-03 03:03:12,9,Keavon,programming
mlxmjdo,1jtp3z2,reddit,is openrsync compatible with rsync?,2025-04-07 21:45:34,14,wapskalyon,programming
mlyg4dn,1jtp3z2,reddit,Can't be worse than make 3.81.,2025-04-08 00:37:41,4,happyscrappy,programming
mmr1oaq,1jtp3z2,reddit,"I'm so grateful for this article, because when the behavior changed, I couldn't figure out why, particularly when they both claim to be the same 2.6.9 version (or at least ""compatible"" with it). Long story short, if you're finding that directory-based include/exclude rules are not working, try adding a trailing slash to the source path. old rsync didn't need it (and could apply the same set of rules to multiple input directories), new one totally does (you have to hide the parent directory for it to make sense of generic layout rules).",2025-04-12 15:59:52,2,kehawk2,programming
mmdjxrf,1jtp3z2,reddit,"The next replacement will have to be called `openestsync` since this one is already `openr`. 

... I'll show myself out",2025-04-10 12:19:21,1,Carighan,programming
mmlleg1,1jtp3z2,reddit,If you care about what happens when you type rsync then you should probably not be relying on the system rsync. Just install the one you want.,2025-04-11 17:45:37,1,bananahead,programming
mlux24x,1jtjzl5,reddit,"Something about this rubs me the wrong way.  I don't necessarily disagree with it from a broad standpoint but I think it adopts a black and white view where it shouldn't.  I think I've got 2 main problems:    
  
1) It seems to advocate for either unit testing or integration testing rather than a combination of both.  Integration tests are fantastic at tell you something is wrong but unit tests are a much better resource for identifying exactly what is wrong.  I think the hardest part of testing is identifying the right line.  People frequently go too fine grained on their unit tests to the point where they become impossible to maintain which leads them to doing integration only testing.       
  
2) It seems like it advocates process and convention to compensate for bad design.  I 100% agree that you shouldn't mock useState but that's not because it's a framework dependency, it's because it's a mutable value you don't control.  Once you've introduced useState, your function input is no longer predictable and your unit tests are brittle.  It's no different than having a test dependency on a class property when testing something in OOP.",2025-04-07 13:17:28,43,darkpaladin,programming
mlvsxnj,1jtjzl5,reddit,"I'd argue that something as fundimental as useState being mocked is a code smell in your design. You're supposed to test the whole unit, and the unit presumably takes in some props, and maybe fires events. What are you doing mocking the state when you can control the input data to directly drive the test in the dom.",2025-04-07 16:07:40,19,blind_ninja_guy,programming
mlw6clm,1jtjzl5,reddit,">Create Thin Adapters Around Libraries

Don't mock your framework - create thin layers  
It is like saying I flood my house to protect it from fire hazards",2025-04-07 17:16:19,14,gjosifov,programming
mm2lsip,1jtjzl5,reddit,"I used to hate unit tests. They were nightmare to maintain, they broke a lot and never found anything.

It all changed with Ian Cooper's video:  
**TDD, Where Did It All Go Wrong (Ian Cooper)**  
[https://www.youtube.com/watch?v=EZ05e7EMOLM](https://www.youtube.com/watch?v=EZ05e7EMOLM)

I switched to Chicago School of tests and later the whole team switched. Now the unit tests are fun, they give us fast feedback if the feature is working. Event TDD started to make sense. And what's more important, the test don't break when refactoring happens.

How? We tests the behaviors of **modules,** not classes/methods in isolation. And since all classes collaborate, we don't need mocks. Inputs and outputs of the module are covered by Fake objects (plain builders, easy to control and reuse). Of course to make it work you have to isolate your business logic from your infrastructure code. But you all know that from Hex Architecture.",2025-04-08 17:54:12,5,steve-7890,programming
mlw027x,1jtjzl5,reddit,"Unit tests have a lot of obvious value on static code, and are easy to write for static code.

But for anything other than static code I have to say I have lost any sense of value of anything that isn't a true end to end integration test.

IMO if something is important, it should be either static logic (and thus easily testable) or capturable by examining user interactions via an integration test. Otherwise - why / how is it important, exactly? All a system is, is its behaviour in response to user interactions and time. That's all any system is - there is literally no other variable. The tests act as regression checks on code mutation.

There's no point testing that the right separation of first+last name gets inserted into the DB, if that is never surfaced to the user in a meaningful way. What difference could it possibly make to anyone if that behaviour changed but the user interactions did not change? It's a waste of a test.

I honestly think anything else is just misdirection, or made necessary because your system is not up to scratch (EG, people mutating DB directly causes need for excessive service tests).

Once you have a comprehensive suite of integration tests I think it's the best possible place to be. They are good at describing what is wrong, and it may take a little more effort to find out what went wrong, but any error is linked to a changeset so it's hardly onerous.

And, as a bonus, an integration focused way of testing lets you capture business requirements and failure cases extremely easily in tests. Much more easily than translating user interactions into what _you think_ the DB structure should be, so you can do a service level test on it.",2025-04-07 16:44:26,10,Inevitable-Plan-7604,programming
mlxw8ct,1jtjzl5,reddit,">Google's Testing Blog later gave this concept a URL in a 2020 ""Testing on the Toilet"" article titled [Don't Mock Types You Don't Own](https://testing.googleblog.com/2020/07/testing-on-toilet-dont-mock-types-you.html?ref=laconicwit.com) which warned:

> > The assumptions built into mocks may get out of date as changes are made to the library, resulting in tests that pass even when the code under test has a bug.

More Google testing advice ([see previous](https://abseil.io/resources/swe-book/html/ch13.html#:~:text=A%20real%20implementation%20is%20preferred,a%20list%20or%20a%20map.)) which says that the problem with unit tests is that they aren't integration tests 😒.

I swear, all the hate that stubbed fakes get stems from (1) issues caused by *functional* fakes (which people conflate with stubbed fakes) (2) arguments that they don't catch issues caused by interactions between components (when that's not the goal of a unit tests).",2025-04-07 22:40:57,5,you-get-an-upvote,programming
mlwj6k6,1jtjzl5,reddit,"The first two points as to why you shouldn't mock frameworks are reasons to mock frameworks. If your tests make assumptions about how third party libraries work and the libraries change, your tests should fail. That is true whether they use mocks or integrations. That being said, it is a problem that your code is too coupled to framework APIs, but that has nothing to do with mocks. It is just good system design. Create clear integration points with third-party libraries, that way if the library changes, you just update the single integration point.

In my opinion, integration with third party libraries is a clear use case for mocks, but, as the article says, you shouldn't mock the third party library directly, but instead create a thin abstraction that you mock so you can control the interface. Integration tests are \*not\* sufficient to unit test code that integrates with third-party libraries as you are unlikely to be able to test error states (on top of other issues, like apis that have quota limits, violate SPAM laws, or create payments).",2025-04-07 18:20:15,2,itijara,programming
mlv67hw,1jtjzl5,reddit,Here is a better idea: Mock only as a last case resort.,2025-04-07 14:10:55,2,-Y0-,programming
mlysesf,1jtjzl5,reddit,"When it comes to testing web services specifically, the best approach I've found is to use something like Playwright and focus most of your efforts on writing integration tests that only query/interact with elements using markup-agnostic selectors (e.g aria-label).  I'll write unit tests for complicated bits of code I know I'm going to screw up.

The advantage to this approach is you can test the functionality on both the client and the server while avoiding the implementation details.  This is especially nice if, for example, you decide one day to switch your communication mechanism from JSON to Protobufs.  Because your tests don't care about those implementation details, you got the closest thing to ""fearless refactoring"".

The downside is if you're not familiar with the codebase, you're going to have a hard time figuring out what the problem is if a test breaks.  Another is writing the unit tests are a pain in the butt since you need to manually create data for your service to interact with, and then on top of that, you need to write the selectors to interact with the web page.  And while the markup-agnostic selectors do help, you're still at risk of breaking your tests if you decide to shuffle some components around.

Is anyone else doing something similar?  This approach is far from perfect, but I think it gets you the most bang for your buck.",2025-04-08 01:52:25,1,Aggressive-Pen-9755,programming
mnlwuwy,1k1fmd1,reddit,"It’s not really diskless. It just puts the responsibility of the disk in someone else’s hands by replicating to object storage.

Kafka officially coming to eat WarpStream’s lunch.",2025-04-17 16:21:14,42,sleeping-in-crypto,programming
mnlo2h7,1k1fmd1,reddit,100% less durable,2025-04-17 15:38:42,1,visicalc_is_best,programming
mnqf1ab,1k1fmd1,reddit,...or just use https://buf.build/product/bufstream and save money while you're at it.,2025-04-18 09:50:32,0,brutal_seizure,programming
mlsk6w2,1jsr4ue,reddit,TL;DR: epoll,2025-04-07 01:17:34,12,commandersaki,programming
moufq79,1k703z1,reddit,"TL;DR - He sent them a letter asking for the GPL text and they mailed it to him, although he asked for v2 and they sent v3. Basically the entire rest of the post is the author learning about the American postal service, stamps, and paper sizes.",2025-04-24 19:41:43,202,sysop073,programming
mouuid4,1k703z1,reddit,This is truly on the mild side of mildly interesting,2025-04-24 20:54:08,49,FlanSteakSasquatch,programming
movrm7e,1k703z1,reddit,"Nothing says age by being mystified by stamps, or mailing a letter internationally as if it's the first letter someone mailed. 

Now that I think about it, my daughter probably has never mailed a letter.",2025-04-24 23:53:14,12,Kinglink,programming
mou9wtc,1k703z1,reddit,I clicked on the link in 2025 and I received a blogpost from 2022,2025-04-24 19:12:38,72,ClownPFart,programming
movncdn,1k703z1,reddit,The typography is horrific. They seem to have taken the 80 column version of the license file and printed it the way notepad.exe would. Which is a real shame because they do have official HTML and LaTeX versions of that very document.,2025-04-24 23:29:29,11,Booty_Bumping,programming
mov64hw,1k703z1,reddit,You haven't done written handwriting in *several years*??? What the fuck?,2025-04-24 21:54:16,25,abakedapplepie,programming
moxigeb,1k703z1,reddit,"Why is he treating sending letters as some ancient, esotheric practice?

> Writing the address on the envelope was awkward, as I haven’t used a pen in several years;

???",2025-04-25 06:58:28,2,NenAlienGeenKonijn,programming
moy2e29,1k703z1,reddit,"> Although GPLv3 is the most current version, I commonly encounter software that makes use of GPLv2.

GPL is in general a fine licence. I use GPLv2 exclusively though; GPLv3 I understand going about the problem of software-as-service workarounds, but I didn't like the direction, so for me it stopped at GPLv2. I am fine with GPL in general though. For my own projects I don't care that much about, I tend to just use BSD/MIT; it seems much easier for everyone involved (I understand the ""corporations abuse you if you don't use GPL"", but often for smaller projects I really don't care either way; for some libraries GPL makes sense). Anyway, the reason I write this is because, from this point of view, the ""most current version"", makes no sense to me. GPLv3 is simply a different licence to GPLv2. Yes, they overlap a LOT, perhaps 99% or something like that, but it still is a different licence, so I would not call it ""the most current version"" - ever.

""if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.""

That's also interesting, I tend to ignore that. I'd never write to that address. But interesting to point out that you could.

> I was disappointed to find out that the UK’s Royal Mail discontinued international reply coupons in 2011. 

This is also annoying - everyone wants to close down oldschool mail. I get that this is not heavily used anymore in the age of email, but shutting this down is annoying. We kind of lose functionality here and while email is in general much better, I have had real situations where people never received an email. In about 95% of those cases, a regular letter would instead have arrived.

> Writing the address on the envelope was awkward, as I haven’t used a pen in several years

Ok ... this is getting weird.

I actually use a pen almost daily. I also use a computer daily.

People need to stop losing functionality like writing with a pen. Yes, computers are better, I get
it, but it seems mankind becomes DUMBER AND DUMBER by the day. Computers are great
aids, but the brain is the master, not the computer.

> Anyway the letter inside contained the full license text on 5 sheets of double-sided paper.

That's nice of them to respond. I'd never go through the hoops he did, but good that they used
that oldschool technique called sending physical letters.

> The first thing that came to attention, the paper that the text was printed on wasn’t an A4, it was smaller and not a size I was familiar with.

A4 is kind of big. But very common. Letters seem to be more in the A5 format; I'd typically fold an
A4 when stuffing it into a cuvert (interesting this is an ""envelope"", but we use the word cuvert / kuvert here, which sounds a bit french).

> There was a problem that I noticed right away, though: this text was from the GPL v3, not the GPL v2.

That's interesting too. Perhaps the person who received it, simply misread.

>  In my original request I had never mentioned the GPL version I was asking about.

Well perhaps the person who wrote the letter, forgot something. :)

> The original license notice makes no mention of GPL version either.

I am not sure I agree with this. The implicit version would logically be the one it is
attached to, so in this case GPLv2.

> Or should I have mentioned that I was seeking the GPLv2 license?

Well of course you should have! It would have SIMPLIFIED this weird request.

It would have been just one more word, right? ""GPLv2"". Not that big of a deal.",2025-04-25 10:22:38,2,shevy-java,programming
mozvy2y,1k703z1,reddit,Wait the British post doesn't do international??,2025-04-25 16:40:24,1,Supuhstar,programming
mkrp4i6,1joanyp,reddit,[removed],2025-03-31 23:08:44,26,N/A,programming
mkrypuo,1joanyp,reddit,"Turbo Pascal 3.0 was where things peaked. It’s all been downhill since then. 

Source: Am an ancient programmer",2025-04-01 00:04:30,20,grout_hater,programming
mkqk3pe,1joanyp,reddit,"VS2005 was peak IDE.

I worked with a team making an OG Xbox game back in the day. Their daily routine consisted of

1. Get the latest code from Visual SourceSafe
2. Turn on Xbox.
3. Hit F5.
4. Edit and Continue all day without ever restarting anything.
5. Hit Shift-F5.
6. Turn off Xbox and go home.

Software development has been all downhill from there.",2025-03-31 19:32:45,30,corysama,programming
mksnwse,1joanyp,reddit,1976-2025: vi,2025-04-01 02:41:12,9,Cube00,programming
mku7dff,1joanyp,reddit,"> Not a single developer today could stand a week in Turbo C 1.0, which didn’t even have syntax highlighting. 

Challenge accepted![1]

I have here, next to me, my Borland  TASM manual and Turbo C++ 3.0.

I will happily (i.e. ""for money"") write the application of your choice, over a week using nothing but those two applications, running on dosbox.

Just tell me what type of 1-week application you need for MSDOS, and I'll give it to you.


[1] Some of my fondest memories were writing C in TC++3.0, *with no syntax highlighter*.",2025-04-01 11:25:07,6,lelanthran,programming
mkulvhb,1joanyp,reddit,"Eclipse is one of the best non-web windows-era IDEs. People complaining it was slow because they installed a ton of plugins on top of the already bloated JavaEE version was unfair. The Barebones Java version is one of the fastest and most complete Java IDEs out there, it runs in circles around the IntelliJ cruft. It has versions for Python, C and many other languages. 

I remember I carried the Python version in a pendrive to college back in the day (it is portable). I had a full black-themed IDE where I could create Python unit tests literally with a right click. Meanwhile the others were wrestling with emacs because that's what the professor insisted on using. Overall most of the class spent 2 full days getting accustomed to emacs.",2025-04-01 13:06:58,7,st4rdr0id,programming
mkyk7wl,1joanyp,reddit,"I bought Turbo C the day it came out. I had pre-ordered or reserved a copy at my local Egghead (remember that store) and drove in the pouring rain to get my copy - skipping class, I’m sure. I was so excited as I installed it via 5.25” floppy disk on my Compaq Luggable. Such fun. 

Up to that point I’d been using Epsilon (Emacs clone) and Aztec(?) C and later MS C compiler.",2025-04-02 02:07:26,3,lisnter,programming
ml06x3p,1joanyp,reddit,Influencer AI Medium spam makes me long nostalgically for the days of corporate blog spam.,2025-04-02 11:10:33,3,not_a_novel_account,programming
mkt8q7n,1joanyp,reddit,"1983-2025: emacs (and clones mince*, jove, and loosely X-Code).

*Edit: Mark of the Unicorn ""Mince"". An Emacs clone with low memory requirements ran on CP/M and early MS-DOS. I originally used in on the CP/M 86 OS. After it was ported to early MS-DOS systems, the publisher released full source code. I enhanced it to support macros (not Lisp) and expansed memory systems up 1mb.",2025-04-01 05:21:38,2,brettmjohnson,programming
mkr410m,1joanyp,reddit,"I'd like all editors and IDEs to be modular to no ends.

I am using an ancient editor that has been abandoned decades ago already, so a bit like Linus with his microemacs. I'd like to change to a better editor too, but I would also lose some key functionality (I tried many editors). I really wish it would be easier to combine features and functionality as well as different programming languages. 

This isolationist approach in editors and IDEs should really be a thing of the past. Like the emacs versus vim debate, should be pick-what-you-like-in-emacs and pick-what-you-like-in-vim - and then it should work without having to write C code like a dinosaur.",2025-03-31 21:11:52,3,shevy-java,programming
mky9yog,1joanyp,reddit,Underware's Brief text editor for MS-DOS had a moment in the late '80s.,2025-04-02 01:03:11,1,emotionalfescue,programming
mksls2a,1joanyp,reddit,"Sorry, folks, computers didn't begin in 1986. Many of us rolled our own IDEs that worked just great and did exactly what we wanted, exactly how we wanted it done. Often a combination of editors, shells, and small tools well integrated.",2025-04-01 02:27:23,-2,gofl-zimbard-37,programming
mooc7kj,1k645rt,reddit,Wow TIL.  Its not often I see a list with tricks I haven't seen before.  \_\_slots\_\_ alone slipped by me somehow.,2025-04-23 20:56:49,8,daidoji70,programming
moomclg,1k645rt,reddit,"I haven't done Python in ages, but I believe the proxy example is incorrect, in particular, it says

> The `__repr__ `method handles property access (returning default values).

IIRC this is intended for use with the repr function and print will fall back to calling it, if there's no `__str__` or something like that. It's in no way related to property access. 



Python does not allow distinguishing between accessing a property or calling a method. Rather, everything that calls a method is a property access first, where descriptors (which do the binding) and then in a su subsequent step, calling invokes `__call__`",2025-04-23 21:48:12,6,vqrs,programming
moonxht,1k645rt,reddit,"I saw a youtube vid where the presenter showed how you can monkey patch the function that creates classes and do whatever you want with it. 

He then showed how that leads to meta classes",2025-04-23 21:56:29,2,AcanthisittaScary706,programming
mor8cmy,1k645rt,reddit,"> If you search for Top 10 Advanced Python Tricks on Google or any other search engine, you’ll find tons of blogs or LinkedIn articles going over trivial (but still useful) things like generators or tuples.

So true. The spam of low effort content is real.",2025-04-24 08:35:27,2,Skaarj,programming
mos0y4b,1k645rt,reddit,"All these features are nice, but I’ll probably never use them. In companies, you're writing code that can be maintained by practically anyone. Writing overly complicated code is a good way to end up on your code reviewers' shit list.

It's usually better to write ""worse"" code that’s easier to maintain. The next person working on your code isn’t going to read PEP XXX just to understand what it does. They’ll either rewrite everything or reach out to you asking why the hell you used some obscure Python feature and then bug you for help just to make their own code work.",2025-04-24 12:33:23,1,FromageDangereux,programming
mota5v0,1k645rt,reddit,"A lot of these toe the line between ""Practical advanced python"" and ""showing off a feature that is just hard to use"".


Like the part on match restructuring is  cool, but once it gets to trying to integrate the walrus operator it loses tons of readability.


Also, for-else statements are just plain dumb/unintuitive. The example would be better off just assigning `primary_server = backup_server` *before* the loop and just overwriting it with whichever server is available in the loop. No additional boolean variable needed.",2025-04-24 16:23:50,1,Muhznit,programming
movqqt5,1k645rt,reddit,"I knew most of these, but I learned about the walrus operator, which seems like a horrid love-child of C and Pascal.",2025-04-24 23:48:24,1,pavilionaire2022,programming
mo8qy70,1k45lwh,reddit,"I'm so glad this brings up the ""RDBMS is because disks"" bit because I was bewildered when I first saw it and am always surprised it gets so little attention.

It's probably what first taught me that Bob will literally make shit up to make a point.

Network and hierarchical DBMSs existed _before_ the relational model and are much closer to the models Bob cheers on. 
 Codd introduced the relational model in a response to their shortcomings, which are all to do with consistency, flexibility, abstracting query patterns from storage layout etc.  All semantic things.  Performance considerations are barely talked about as a throwaway in [the OG paper](https://dl.acm.org/doi/10.1145/362384.362685).

To steal a [quote from Wikipedia](https://en.wikipedia.org/wiki/Hierarchical_database_model#cite_ref-1) (my bold)
> When the relational database model emerged, one criticism of hierarchical database models was their close dependence on application-specific implementation. This limitation, along with the relational model's ease of use, contributed to the popularity of relational databases, **despite their initially lower performance** in comparison with the existing network and hierarchical models.[1]",2025-04-21 11:56:55,15,therealgaxbo,programming
mo8066d,1k45lwh,reddit,">In my opinion, anecdotes can be a very powerful persuasion technique. Nothing like a good anecdote to prove I am right and you are wrong, although it is still a logical fallacy.

I like this quote about anecdotes

I have to add something also, IT anecdotes are really bad, because if you are following anecdote as a rule and the anecdote is from 80s or 90s, then you are following advice that was useful in 80s and 90s

Like the Java knock, knock joke from late 90s  
It was true at the time, however a guy name Cliff Click fix the problem and the joke isn't true from the past 20 years

Take IT anecdotes with big grain of salt, especially if they are too old and learn how they came to be, because 9 out of 10 time, most of those anecdotes aren't true anymore",2025-04-21 07:40:11,12,gjosifov,programming
moejq3f,1k45lwh,reddit,"> THE DATABASE IS A DETAIL

that's all you need to know that it's shit. the DB often long outlives the app code",2025-04-22 09:36:43,2,randompoaster97,programming
mo8vj7z,1k45lwh,reddit,Fantastic post! Hopefully this closes the book on the issue: your database is _not_ an ignorable detail. The semantics of your chosen DB affect your user in every way. Not accounting for this is sheer insanity.,2025-04-21 12:29:06,4,editor_of_the_beast,programming
mo9458i,1k45lwh,reddit,"On point 2 you're strawmanning a bit. While I dislike Bob on many points, he's saying you should not use frameworks that allow you to directly manipulate/pass around rows and tables in your database because this causes too much coupling. He's not saying not to use your data. He's saying you shouldn't be coupling your application to the row/table schema of your database, which I think is correct. 

Changing your denormalization scheme should not need changes everywhere in your code.",2025-04-21 13:24:07,4,Proper-Ape,programming
mo7tcu9,1k45lwh,reddit,"I was about to comment angrily on ""THE DATABASE IS A DETAIL"", but I'm happy I looked at your blog post before.

Please be careful about your title, as it conveys Martin's opinion and not yours.",2025-04-21 06:27:49,4,nfrankel,programming
mo9wcs4,1k45lwh,reddit,"What a strange rant of an article. It tries to argue that database choice is a significant architecture element, but does so by listing reasons why it's not...


What if I told you it can be both?


From one point of view it is important for all the various reasons. From another it is an implementation detail, because treating it as such is beneficial.


Treating DB as a detail lets you decouple from from this decision and as a consequence pospone this decision. To a point where you know more about the system in question. Possibly replacing it when needs change. Or even using multiple if conflicting needs arise.",2025-04-21 16:05:22,2,Januson,programming
mobvt5f,1k45lwh,reddit,"Nice article, found reading it was easier than reading the actual books. On a touching note: does anybody else had a problem with reading technical books like Clean Code/Clean Architecture? I can't find a way to pick on where I left with it and usually I leave the book for more than 3 days if I leave it. I don't read that often, but when I want to I start where my bookmark is and then can't catch up on what the hell author is talking about cause nothing makes sense. Feels like I have to start reading from the start. Clean code at least has a ""Code smells"" section for quick lookup.. maybe it's just abscense of a good reading habit but can't tell really with my inexperience",2025-04-21 22:00:18,0,Strict-Criticism7677,programming
moe32xc,1k45lwh,reddit,"I agree with most of the article. A good phrase I heard once was ""Architecture is anything you can't change in a week"", which I use as a good guideline for how much you think about up front rather than as you go along.


The maths of the AI content did amuse me...


> Explicit Adoption: Approximately 20–30%...
>
> Implicit/Partial Adoption: Around 70–80% o...
>
> Non-Adoption: The remaining 20–30% 


So 110-140% then.",2025-04-22 06:37:32,0,Old_Pomegranate_822,programming
mo8ujwt,1k45lwh,reddit,"And somehow Martin manages to br overall correct for like 99% of projects. And most of the code in the remaining 1%.

Data storage is an implementation detail. Abstract it away and forget about it.",2025-04-21 12:22:27,-11,Blecki,programming
mmmq85m,1jwxxbn,reddit,Looks cool. I see it only supports linux host and guest. What's its value over containers?,2025-04-11 21:13:35,19,Dayzerty,programming
mms59ix,1jwxxbn,reddit,what changed for CoW? how was it working before? I didn't really understand what you started doing differently.,2025-04-12 19:28:24,2,No_Technician7058,programming
mmmdxa2,1jwxxbn,reddit,Thanks that was interesting!,2025-04-11 20:09:58,3,HolyPommeDeTerre,programming
mk42wkd,1jlbmzj,reddit,"> Here, I’ll build on that by showing how this technique can be used outside of niche academic languages

We have done nothing to deserve this slander 😢

But otherwise, a good article. I knew it was doable in C, but this article showed a way simpler approach then what I was thinking of.",2025-03-28 01:36:22,15,davidalayachew,programming
mk31ibf,1jlbmzj,reddit,"Some good tips here!

> With Parse, Don’t Validate, you will never run into the situation of accidentally swapping parameters around in a function call

Unfortunately this is not true - if a function takes two email_ts (e.g. from and to), they can still be swapped.",2025-03-27 22:16:02,25,theuniquestname,programming
mk5qdnp,1jlbmzj,reddit,"Very good article, much better than what I expected. It’s a good “how-to”, and not a “hight level description of some ideals”.

---

However it does highlight a big flaw in C. The easiest way to express that something is optional is to use a pointer. Which means that that the easiest way to express that a function is faillible is to either return NULL or a dynamically allocated objet, which tanks performances (mostly because it’s much harder for the optimizer to do its job, not because malloc is that slow).

If I had to write this code, instead of `email_t *email_parse (const char *untrusted)`, I would probably write `bool email_parse(const char* untrusted, email_t out)` to remove the unnecessary dynamic allocation.

This digression doesn’t remove anything from the article.",2025-03-28 09:56:41,9,robin-m,programming
mk288lc,1jlbmzj,reddit,Good article but your link to opaque types is broken.,2025-03-27 19:20:49,3,BlueGoliath,programming
mk6x9wi,1jlbmzj,reddit,"Loved this one. The distinction between parsing and validating is subtle but *so* important, especially when dealing with low-level languages like C. It’s the kind of mindset shift that prevents entire classes of bugs. More devs need to read this.",2025-03-28 14:44:26,3,tomasartuso,programming
mk9dwe7,1jlbmzj,reddit,"Great Article! I want to follow your Blog, but you dont offer an RSS feed x/",2025-03-28 22:03:23,2,Wolfspaw,programming
mkaj2ma,1jlbmzj,reddit,Just read this and other posts in your blog. Very enjoyable. Great writing. I’ll use these concepts.,2025-03-29 01:59:09,2,Manixcomp,programming
mk5qcga,1jlbmzj,reddit,"> You parse them once into the correct data type, and then code deep in the belly of the system cannot be compromised with malicious input, because the only data that the rest of the system will see is data that has been parsed into specific types.

Now that is just plain wrong and the kind of overpromise that puts people in danger. Which is a shame because I otherwise agree with the approach.

What is true is that using a type system you can establish a boundary between validated and unvalidated inputs. This is great and should be used more often, even within the code base (for example distinguishing different types of cryptographic keys with different types is a basic but effective strategy to limit the risk of mixing them up). It is also true that enforcing validation greatly limits the amount of bugs that can be exploited.

However parsing is generally really hard and many bugs happen in parsers. In the same way validating inputs is really hard and in many cases it's the wrong approach altogether (which is why to fight injections for example it's best to escape rather than sanitize, or in the case of emails actually where validation will almost always be either uneffective or too restrictive and simply sending a validation link is almost always the better approach). Granted ""validation"" can mean a great many things in practice, but that's just the point: to say that no bug can be exploited because your data was validated supposes that your validation is absolutely perfect and encompasses all risks present and future.

I'd feel a lot more enclined to recommend this article to people it it wasn't promising things it can't deliver on.",2025-03-28 09:56:20,-3,cym13,programming
mk4q69x,1jlbmzj,reddit,"Finally, some good advices instead of yet another RiiR written by people who clearly lack qualification to write a secure software

I'd make a step even further and say, wherever possible, don't parse at all. Instead, get the necessary data from where it's already present. And if software holding your data lacks necessary API, then make a PR to that software. If some data format or protocol makes it hard to parse, then come up with better data format or protocol. Like, store different kinds of data in different files, use CLI args, etc etc etc.",2025-03-28 04:01:09,-8,void4,programming
mmzjci3,1jwxvtn,reddit,This needs crossposts :),2025-04-14 00:43:22,1,przemo_li,programming
mmq7qcs,1jwxz74,reddit,I had no idea the default size of h1 was depending on nesting level.,2025-04-12 13:13:24,14,thomas_m_k,programming
mm96b5e,1jv9wi3,reddit,"Niche fitting is a very interesting feature of Rust to us low-level meganerds. Even in the most basic instance, the fact that `size_of::<Option<Box<T>>>() == size_of::<Box<T>>()` is really nice, because it means there is literally no cost to take extra type safety (or “null safety” if you like).

The fact that enum discriminants are chosen from available niches in the general case is just extra awesome.",2025-04-09 18:23:25,36,simonask_,programming
mm99ffe,1jv9wi3,reddit,"Enums are always a fun sandbox to play in. Largely because they can yield some hilariously unexpected performance optimizations without you changing a line of code. All during compile time too.

To give an example, Java has enums too (though you guys have a different interpretation than we do -- Sum types vs Constrained Value Domain), and one super clever optimization is how we handle them in Sets.

A Set in Java follows [the mathematical definition](https://simple.wikipedia.org/wiki/Set) -- a collection of elements where there are no duplicates.

Well, since enums are just plain old classes in Java, with fields and methods and constructors, one would think that you would need to hold at least a hash of the instance when storing in memory, but that is not so.

Since all the instances are known of ahead of time (it's an enum!), Java has a specialized [Set](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/Set.html) called an [EnumSet](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/EnumSet.html). Instead of using hashes or object inlining to denote inclusion/exclusion for the Set, the EnumSet literally uses a `long` (or a `long[]`, if there are more than 64 values in the enum), and just uses ***index (ordinal)*** to denote set inclusion ***by flipping the bits of the `long`***.

That is terrifyingly fast. It makes it the fastest Set implementation in the JDK because checking if an instance is in the Set is literally just a [Logical AND](https://en.wikipedia.org/wiki/Logical_conjunction). You basically CAN'T get faster than that without dipping into things like SIMD or the equivalent.

Compared to [HashSet](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/HashSet.html) (from my informal performance tests), I saw 300% speed improvements, and it used a fraction of the memory. And to make matters worse, HashSet is unordered, but EnumSet is ordered! That actually makes this an unfair comparison for EnumSet! To give a true apples to apples comparison, we would need a Set implementation that includes ordering, which is [TreeSet](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/TreeSet.html), and the speed difference was almost 500%.

The only real competition EnumSet has in the JDK is another specialized Set -- the [unmodifiable internal Sets returned by Set.of()](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/Set.html#of\(E...\)), and those are backed by objects like [Set12](https://github.com/openjdk/jdk/blob/a2a7703370caf07afd88b5cfe44e1a78eed699e9/src/java.base/share/classes/java/util/Set.java#L470), which is literally [just an object with 2 fields lol](https://github.com/openjdk/jdk/blob/a2a7703370caf07afd88b5cfe44e1a78eed699e9/src/java.base/share/classes/java/util/ImmutableCollections.java#L775). Those are so specialized that you literally get a different implementation, depending on how many values are in your factory method lol. Set.of(1, 2) will return a different implementation than Set.of(1, 2, 3) lol. And the second you go for [the array version](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/Set.html#of\(E...\)), which can hold any number of params, then you are right back to EnumSet being the fastest implementation. In fact, in Java 24, once you get past [3 parameters](https://github.com/openjdk/jdk/blob/a2a7703370caf07afd88b5cfe44e1a78eed699e9/src/java.base/share/classes/java/util/Set.java#L695), EnumSet becomes the fastest, though I think that might change soon.

That shows the type of crazy stuff that enums can do. And I haven't talked about other fun ones, like [EnumMap](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/EnumMap.html) or how they interact with Switch cases/expressions or pattern-matching.

Enums are my favorite feature in any programming language, let alone Java. Such a simple, yet powerful concept. And it's great in any language that it's in, even though Java's Enums are better than all other languages' versions.",2025-04-09 18:38:36,30,davidalayachew,programming
mmcy092,1jv9wi3,reddit,"> What’s going on? The Rust compiler knows that while char takes up 4 bytes of memory, not every value of those 4 bytes is a valid value of char. Char only has about 2^21 valid values (one for each Unicode code point), whereas 4 bytes support 2^32 different values. The compiler choses one of these invalid bit patterns as a niche. It then represents the enum value without using tags. It represents the Some variant identically to char. It represents the None variant using the niche.


Is this hardcoded in the compiler? Or can this be expressed as a Rust type declaration? 

Could I write a type `MyChar`  where the compiler would know that it doesn't use all bit patterns and does the same optimization?",2025-04-10 09:13:18,3,Skaarj,programming
mmcyhjk,1jv9wi3,reddit,"> The representation of the value Outer::D(inner) is identical to the representation of inner!

Does this have influence on binary compatibility (ABI compatibility)? 

When I would accept or return a enum value through a public funtion of my library `whatever.so`, does the enum use the same format? That means that the use of this optimization must be predictable and can't be changed in the future, right?",2025-04-10 09:18:26,1,Skaarj,programming
mnuv2ow,1k2b1v4,reddit,"I really liked putting the parameters in the middle of the function name. Are there any other languages that do that? I always thought ObjC was very readable, but the lines to get long quickly. I know a lot of people don't like the syntax, but I never had an issue with it.

I don't know why the C++ standard library authors think there are a shortage of letters, so every function name needs to be as short as possible.",2025-04-19 01:17:25,30,turniphat,programming
mnu5wk1,1k2b1v4,reddit,I wish there was a reason to use objective-C outside of maintaining old iOS/Mac applications. I always thought the brackets were a fun departure from other languages. Too bad that isn’t a good enough reason to use it.,2025-04-18 22:42:53,11,Stroggi,programming
mnvc8bh,1k2b1v4,reddit,"> These were not curt, Hemingwayesque sentences, but long, floral, Proustian ones

I think this broke my pretentiousness meter.",2025-04-19 03:10:14,15,Monsieur_Moneybags,programming
mnysczp,1k2b1v4,reddit,Paywalled,2025-04-19 18:23:50,2,nekokattt,programming
mnz3mzr,1k2b1v4,reddit,One of the best languages. ObjC with https://objfw.nil.im/home objfw is an awesome choice for development,2025-04-19 19:25:56,2,Limp_Day_6012,programming
mnwhdzt,1k2b1v4,reddit,"Such a powerful language. Progressive type system, static and dynamic dispatch, message passing, method swizzling, optional protocol functions, plus bidirectional interoperability with C.

AFNetworking’s API is a modern take on NSUrlSession (wish more modern wrappers existed). Function names don’t magically change when using Swift. You still have to pass in the `includingPropertiesForKeys` named parameter to `FileManager.enumerate` 🤷‍♂️",2025-04-19 09:33:40,4,amirrajan,programming
mnwq1rn,1k2b1v4,reddit,"Personally, ObjC is second lowest, right above Closure.",2025-04-19 11:02:12,1,andricathere,programming
mluo5uj,1jtjp2c,reddit,nailed it!! concise and to the point.,2025-04-07 12:18:13,3,ashemark2,programming
mlwaw3a,1jtjp2c,reddit,IBM MQ?,2025-04-07 17:38:51,1,Valendr0s,programming
mm04tfv,1jtjp2c,reddit,btw your header gets shortened to “System Design but SIMP” on my phone,2025-04-08 08:36:51,1,hellishcharm,programming
mjyjhol,1jkvfcd,reddit,"> Can’t you simply open a ticket at your IT department? Certain situations may make a deeper architectural solution impossible on the timescale that a project needs delivering, happenings need to happen and things need to thing

Yeah, should add to this disclaimer that doing this will get you fired on the spot for circumventing security controls. I’m at some dozen, maybe 15 developers I’ve personally gotten fired *this year* for circumventing security controls. And I’m one of an entire team of incident responders. ",2025-03-27 04:08:53,83,usernamedottxt,programming
mjz6jwc,1jkvfcd,reddit,"I have to say it’s very well written and a thorough explanation! It’s also good to see Nix and Windows support side by side in one article, giving it a more comprehensive feel. 

+1 to “this could well get you fired for IT Policy breaches” of course. If you’re doing this in an actual corporate network on a daily basis, you’re probably doing the wrong thing for the wrong reasons. 

However it’s a great way to learn!",2025-03-27 07:52:01,10,Agreeable_Assist_978,programming
mk2eblh,1jkvfcd,reddit,"Way to go to get yourself fired or criminally prosecuted. Not to mention that SSH tunnelling is like several decades' old and every self-aware company has means in place to detect it, because every self-aware IT-monkey in the world has tried it at some point since the 90s.",2025-03-27 20:22:29,-3,zam0th,programming
mk5sra6,1jkvfcd,reddit,"I feel like all the suggestions are over-engineered. If you have control over both the server and client, just use `socat` to redirect ssh traffic through a dead simple xor-based encrypter/decrypter using a pre-shared key. Obviously it's fairly easy to decode if you want to, but there's no way an automated system is going to do that and identify it as ssh traffic. From the firewall's perspective, it just looks like random bytes going to a random port. If you want to further obfuscate it, wrap it in some http headers.",2025-03-28 10:20:02,0,MooseBoys,programming
mk0fd17,1jl3gi0,reddit,"This is a terrible article. The first half is technically correct but the writing is bad. The second half maintains the bad writing but goes off the rails on facts and terminology. 

> The iPhone sends an authorization request to the payment network. It contains the request cryptogram and transaction details. Put simply, DAN never leaves the iPhone for security.

The DAN, which is a 15- or 16-digit card number provisioned for the individual device, is not a secret. When you tap to pay, the card number is always transmitted to the terminal in clear text. That’s just how EMV Contactless works. If the DAN didn’t leave the device, the merchant wouldn’t have a card number to charge. Moreover, it’s the payment terminal sending the request. The iPhone’s duties are handled offline.

Edit: I try to avoid too much self-promotion but I actually wrote [a detailed explanation of how Apple Pay works](https://kirklennon.com/a/applepay.html) back when it launched. I haven’t updated it to reflect online Apple Pay purchases, but it’s otherwise current. My website has no ads, no third-party tracking, nor any other sort of revenue generation.",2025-03-27 13:53:37,278,kirklennon,programming
mk0gp6s,1jl3gi0,reddit,Im still a little confused as to how digital wallets are able to process transactions without internet access. I understand that NFC is being used but how does the payment service get notified/verify a transaction. Is it because the card reader is connected to the internet so it sends all the needed data to the payment service? Or is the transaction just logged on the phone and the next time the user get internet access all transactions get sent to the service?,2025-03-27 14:00:43,62,JohnFish2734,programming
mk2d7jf,1jl3gi0,reddit,"This is not how ApplePay works. ""Payment network"" term is wrong, since that is not what processes transactions when you try to pay with ApplePay. ""Credit card"" doesn't make sense since ApplePay works with any plastic. ApplePay won't work **at all** unless the issuing bank implements corresponding transactional gateways.

>The card reader creates a transaction record, which contains details such as the payment amount and date.

This is outright false as it's not how a POS-terminal functions. OP has not the slightest idea about transaction processing and card payments.",2025-03-27 20:16:34,30,zam0th,programming
mk2jh5d,1jl3gi0,reddit,This article is factually incorrect. Probably AI-generated.,2025-03-27 20:48:32,9,st4rdr0id,programming
mk08r9p,1jl3gi0,reddit,"I know I’m gonna get hate from Apple dislikers, but Apple Pay is for me the sole reason to buy an iPhone instead of the competition. It’s the key feature for me.

Google and Samsung wallets are a joke compared to this.",2025-03-27 13:16:28,77,Calm-Success-5942,programming
mkbscf0,1jl3gi0,reddit,"That's interesting, thank you. I'll send it to my mom—she doesn't want to *put* her credit card on the phone xD",2025-03-29 08:26:09,1,uscnep,programming
mk20c1p,1jl3gi0,reddit,Like all other Apple products. It just works. /s,2025-03-27 18:28:57,-6,Ironamsfeld,programming
mk23q6d,1jl3gi0,reddit,In my experience the way it works is that it often doesn't.,2025-03-27 18:45:33,-6,IAmASolipsist,programming
mk1160j,1jl3gi0,reddit,Ireland 1%corp tax,2025-03-27 15:42:33,-13,NoleMercy05,programming
mmf8xdp,1jw39fl,reddit,I think recognizing that leaf applications (non libraries) have different needs than libraries is great.,2025-04-10 17:36:56,81,mpinnegar,programming
mmgxcxv,1jw39fl,reddit,"I get the appeal as a library developer, but I absolutely hate it as an application developer.

If I haven't updated an old app for two years, I don't want to have to crawl through dozens of release notes to figure out where the breaking changes happened and what they were. With SemVer, there is a clear demarcation, so I know exactly where to look.


If I want to know when a version was released, I just look at the date of the release notes.",2025-04-10 22:40:52,58,jessepence,programming
mmhp7pi,1jw39fl,reddit,"Calver is great for apps and services, for libraries, it may be a bad idea.",2025-04-11 01:27:03,10,pfc-anon,programming
mmg62q7,1jw39fl,reddit,"How do you handle patches? Say you introduced a bug or security issue in 2025.4, how would you add patches in the same month? 2025.4.10?",2025-04-10 20:18:15,3,Jolly-Warthog-1427,programming
mmh90lk,1jw39fl,reddit,"What about using a combination of the two?

MAJOR.YYYY.x?",2025-04-10 23:48:15,2,KrazyKirby99999,programming
mmn711k,1jw39fl,reddit,"Calendar versioning is fine, but please never for APIs…",2025-04-11 22:49:28,1,PositiveUse,programming
mnj2qnm,1jw39fl,reddit,"I’ve tried to blend the best of both worlds: [/r/golang/comments/1jzucpw/scalable\_calendar\_versioning\_calver\_semver/](https://www.reddit.com/r/golang/comments/1jzucpw/scalable_calendar_versioning_calver_semver/)

Versions may look a bit long at first, but the idea is to use only as much detail as your release cadence needs. You can start, say `1.2025` for a yearly release. As the project grows and releases speed up, the format “stretches” to stay ordered: after `1.2025.72` you can cleanly jump to `1.202509.0` and keep perfect numeric sorting.

* `1.2025.0` < `1.2025.1` < `1.2025.2`
* `1.202503.0` < `1.202503.1` < `1.202503.2`
* `1.2025.0` < 1.202503.0 < 1.20250301.0
* `1.20250410.0` < `2.2026.1` < `3.20260310.0`

Format: `MAJOR.YYYY[MM[DD]].PATCH`

Progressions: `MAJOR.YYYY.PATCH` → `MAJOR.YYYYMM.PATCH` → `MAJOR.YYYYMMDD.PATCH`

Bottom line: it stays **SemVer‑compatible** while adding CalVer clarity and can be ""stretched"". Examples and details here [veiloq/scalver](https://github.com/veiloq/scalver)",2025-04-17 03:57:15,2,NecessaryVictory9087,programming
mmfxrea,1jw39fl,reddit,"Unless you have a specific reason to use SemVer, calendar versioning is far superior.

In other words, calendar versioning should be the default.",2025-04-10 19:38:27,-16,Rodwell_Returns,programming
mli8oi5,1jrluud,reddit,"From one perspective it's an extremely technical subject and from another, like the hacker News example, it's an extremely obvious technique. It's nice to have the procedure explained because it's something I've done already without having a name for it",2025-04-05 07:10:31,11,dakotapearl,programming
mlq68c8,1jrluud,reddit,Not refactoring if functionality changes.,2025-04-06 17:09:53,2,TrumpIsAFascistFuck,programming
mntodas,1k2b3ns,reddit,"For C/C++ it would be better to use the standard atomic stuff instead:

https://en.cppreference.com/w/c/atomic

Obviously that's C, C++ is similar and even a little bit better. Use the C++ stuff if you are using C++ (the C stuff will work, but why do that?).

It would be better to actually identify the variables which are being operated on with the order dependencies. That allows the compiler more freedom to reorder other stuff. But if you are just going to do it like MS does it here with explicit standalone barriers then the equivalences are this:

    #define MemoryBarrier() atomic_thread_fence(memory_order_acquire)

    #define __lwsync atomic_thread_fence(memory_order_acquire)

    #define __sync atomic_thread_fence(memory_order_acq_rel)

I never found a suitable replacement for what they call _ReadWriteBarrier() in here. Maybe someone else knows. You can use the stronger barrier __sync above. Or you can hack it like this:

    #define _ReadWriteBarrier() asm volatile ("""" ::: ""memory"");

If you need _ReadBarrier() and _WriteBarrier() too then you can define them to the same as _ReadWriteBarrier(). This is not strictly the same thing, it's a little stronger than necessary. It will work.

Generally I would suggest not using lockless programming.

This article from MS likely came about because PowerPC has a much more relaxed memory order than x86 does. And so code which seemed otherwise fine (and would be fine without an optimizing compiler) would fail on multi processor PowerPCs. And Xbox 360 was a multiprocessor PowerPC.",2025-04-18 21:02:52,13,happyscrappy,programming
mnuallo,1k2b3ns,reddit,XBox360 article in 2020? Intresting,2025-04-18 23:10:57,10,Limp_Day_6012,programming
mlo2wdt,1js8w4w,reddit,"Writing Go in Java is like writing Java in Go and both are like giving yourself a vodka enema to get really drunk without chundering. 

It works, but you really shouldn't.",2025-04-06 07:55:05,39,BroBroMate,programming
mlr30sy,1js8w4w,reddit,"So that code to save the file lets you potentially overwrite server files 

I haven't tried it but it potentially also lets me read server files as well by putting .. in the path.",2025-04-06 20:03:58,3,nekokattt,programming
mlonfms,1js8w4w,reddit,"Kotlin as an alternative language with extension methods, and finally Native Image for compilation could make this pretty useful for extremely small projects.

The big problem is that Java and Go are separate mindsets, even though they are incredibly close thanks to colorless functions, and a clear orientation on where they come into place.
Much like a JavaScript developer might not fathom on writing 3 lines of code yourself instead of importing a framework, Go comes from the anti-C++ mindset, while Java is... complicated. Java's Enterprise-y-ness is both a joke and reality.

Of course a Java dev will instead use something like Spring Boot for big projects, and something smaller but still 3rd party for smaller projects. It comese from the Java ecosystem being pretty stable and pretty high quality.

Using 3rd party stuff in Go meanwhile is rare, because the std lib might be one of the best ones possible. And on the other ends of the spectrum we have JS development. Or - an ecosystem somehow perfectly combining all the worst parts - C++. The tools and language design influence the mindset of the language's users.


Still a pretty nice article for showing of a new feature.

One recommendation: going with JStachio as a templating engine instead might increase type safety of the templates more, and comes even closer to the beauty that is Templ in Go.",2025-04-06 11:31:22,5,n3phtys,programming
mlpw03u,1js8w4w,reddit,"Brought to you by the authors of ""You can write Java in every language"".",2025-04-06 16:14:52,2,txdv,programming
mllniru,1js8w4w,reddit,You can rip JAX-RS from my cold dead hands. ,2025-04-05 21:18:32,-1,vips7L,programming
mlhuwe7,1jrvnx9,reddit,"In this post, the author essentially redefines ""open source"" as ""the source code is available"". This is not necessarily a widely accepted view point.


In the Open Source community, software is considered Open Source if it provides Software Freedom, when it has a license that allows anyone to inspect, modify, and share the software for any purpose.


Software where the source code is public but which doesn't have Open Source licensing is more clearly called ""Source Available"".


Of course, the author makes some good point that hold for both Open Source and Source Available software:


* users are not owed support
* the project might not accept outside contributions
* access to the software might not be gratis",2025-04-05 05:01:31,177,latkde,programming
mljcp87,1jrvnx9,reddit,"I do have to agree with one of their points at least.  
Developers of opensource software owe you absolutely nothing (assuming they've not done anything malicious).",2025-04-05 13:29:23,11,cfehunter,programming
mli60a4,1jrvnx9,reddit,"My guy should have just stuck to his strongest points. Trying to conflate source-available with open source really sours the otherwise good argument. The core point of ""open source is just open source"" is kinda undermined when your starting point is begging the question of what open source even is.",2025-04-05 06:43:59,24,zixaphir,programming
mlhwlhq,1jrvnx9,reddit,"Open source was a term and concept invented to provide a more corporate friendly alternative to the GPL and the FSF. At the time Microsoft was waging an all out war on open source calling it communism, funding the SCO lawsuit (that one was a doozy if you ever want to read some history), and paying online pundits to post blog posts saying crazy things.

Now it seems like the leopards are eating the faces of the open source developers as the likes of Amazon just prey on the successful projects and everybody scrambles trying to figure out how they are going to make a living picking leftover crumbs in the footprints of the giants.",2025-04-05 05:16:47,19,myringotomy,programming
mli12wr,1jrvnx9,reddit,"The distinction between free as in beer and free as in speech is not made. I don’t know if the author understands the GNU. Definitely does not respect the 30+ years of custom. 

I don’t think the author understands he does not get the right to determine the definition of open source. That’s [aleady been done](https://www.theopensourceway.org/the_open_source_way-guidebook-2.0.html). He can create his own scheme, more power to him.

License matters and explains the rules. He only gets to determine license for software he wrote and owns the copyright for. Anything that he includes, its license must be respected. When was the last time you saw anything that was 100% Unlicense licensed? When he uses copyleft work, his work is copyleft as well. Some permissive licensing also requires attribution.",2025-04-05 05:59:08,26,zaskar,programming
mlk3l6p,1jrvnx9,reddit,Unrelated but I love this layout,2025-04-05 16:05:47,2,Rude-Researcher-2407,programming
mliqzu8,1jrvnx9,reddit,"Open Source means free scrapping of your code by ""AI"" companies inorder of replacing you and make you redundant",2025-04-05 10:31:05,0,SoftEngin33r,programming
mlifdl8,1jrvnx9,reddit,">When software is open-source, it means it is open-source – that the source is open – nothing more. This simple fact is frequently misunderstood, so let me be crystal clear about what open-source does *not* automatically mean by default:

>It does not mean open to contributions;

>It does not mean support is offered;

>It does not mean you’re entitled to feature requests;

>It does not mean the developer owes you their time;

>It does not mean you’re entitled to anything;

>It does not mean it is *free* and open-source (FOSS).

Some may say this doesn't mean open source, but source available isn't open source and open source isn't a free beer, but free speech  
That is just philosophical difference

In practical terms the author is 100% correct  
Because software has two costs - initial cost to build the software in some usable state and maintaining cost

Closed source has both costs  
Open source has maintaining cost, that in most cases nobody wants to pay it

When you define open source from cost perspective, things are more clear for the users of open source and the maintainers of open source

Things like source available, licencing, true open source licences, none restrictive open source and other details are irrelevant to those that want to participate in open source  
and we all see now after so many people burn out in the past decade

These details are only good for those that want to exploit open source",2025-04-05 08:21:36,-4,gjosifov,programming
mliquay,1jrvnx9,reddit,">It does not mean open to contributions;

>It does not mean support is offered;

>It does not mean you’re entitled to feature requests;

>It does not mean the developer owes you their time;

>It does not mean you’re entitled to anything;

>It does not mean it is free and open-source (FOSS).

If it isn't free, then it **does** automatically mean that i'm absolutely entitled to any and all of the things listed above. If you make customers pay for your product and not offer SLAs/OLAs then you're just an asshole.

If it's free **and** open-source indeed then, well, it's a grey area. Do you want people to see you as a total jerk? In that case feel free to ignore your customers and/or tell them to fuck off. The only thing this achieves is that someone else will fork your software and offer users everything that you don't, and/or make your software better on their own but, oh wait, that's not *your* software anymore and they will never merge upstream because you actively resist that! **That** is open-source.",2025-04-05 10:29:30,-8,zam0th,programming
mkftgw5,1jmzkug,reddit,"I don’t think I would use this before I used a more established package manager like brew, chocolatey, or apt/yum.  Some people also like Ninite on Windows.

If I wanted to have repeatable dev environments I’d like use something like Ansible, Puppet, or Chef which can handle various arch/OS permutation: in conjunction with a package manager.  Nix is also good once you pay the learning curve.  I’ve also gone the dev VM approach for portability to any system.

For simple binary distribution I’ve used Dropbox, a home file server, or S3.

I don’t want to yuck your yum.  If this works for you and is a useful project that’s great, but I don’t think the problem it’s trying to solve is a problem I have.",2025-03-29 23:55:35,44,Ancillas,programming
mkgy5oa,1jmzkug,reddit,Have you seen Nix/NixOs?,2025-03-30 04:23:24,11,Ashamed-Gap450,programming
mkhssz9,1jmzkug,reddit,"This is very similar to dotslash from facebook, no? Are you aware of this project? If so in what it differs? https://github.com/facebook/dotslash",2025-03-30 09:35:41,5,blaizardlelezard,programming
mki86ik,1jmzkug,reddit,"Either this is no more complicated than a git repo with `bin-arch/$ARCH/` and a `PATH=$PATH:$REPO/bin-arch/$(arch)`, and I don't see the point of having a thirdparty script do it.

Or this is more complicated and i don't understand what features it offers and why.",2025-03-30 12:05:10,3,throwaway490215,programming
mkhruee,1jmzkug,reddit,This is amazing - thanks for creating this!!!,2025-03-30 09:25:03,1,ZachVorhies,programming
mkhw2e7,1jmzkug,reddit,"I think mise handles handles this case well, and more actually.",2025-03-30 10:10:39,1,zarrro,programming
mkjl4l7,1jmzkug,reddit,"Homebrew used to work this way (roughly), and still does for 3rd party tool repos. But they moved core away from git because it is really slow and has throttling/availability issues at scale (both # of users scale and # of tools/revisions scale). It makes sense for small use cases, but be wary of using this approach for anything substantial.",2025-03-30 16:54:54,1,dccorona,programming
mknfttx,1jmzkug,reddit,I use asdf for this purpose.,2025-03-31 07:37:40,1,elixir-spider,programming
mko755z,1jmzkug,reddit,"Please excuse my ignorance, but isn't that the same  feature as already provided by Ansibel? Sure, it's meant for servers, but I think it can be utilized for PCs as well",2025-03-31 12:03:14,1,cainhurstcat,programming
mkfufcb,1jmzkug,reddit,Very cool. Thanks for sharing,2025-03-30 00:01:13,1,pickledplumber,programming
monfteb,1k61drp,reddit,"My manager was asking me a few weeks ago to do something that didn’t make sense. I tried to explain to him why but he kept arguing with me. He’s also been pushing me to use ChatGPT more, so I decided to ask ChatGPT about this topic. It told me the same thing I was saying, so I sent him a link. He immediately changed his tune and agreed it wouldn’t work. He’s not a non-technical manager either. This idea that ChatGPT is an oracle and can reveal truths to you that a human can’t is surely leading people to trust ChatGPT far more than it deserves. I found another job and gave my notice, btw.",2025-04-23 18:19:52,58,huyvanbin,programming
momc9bz,1k61drp,reddit,"I'm going to quote someone

Think of AI as an overly enthusiastic junior developer with the confidence of a senior developer. 

Having that lens helps to put things into perspective IMHO",2025-04-23 15:10:08,89,atehrani,programming
mop3318,1k61drp,reddit,"You were shipping bugs before, now you just have bugs nobody in team actually wrote and code nobody actually understands.",2025-04-23 23:20:15,18,CrunchyTortilla1234,programming
mon97jf,1k61drp,reddit,I read this as shipping burgs at scale and I think we should aim to ship burgs not bugs thanks,2025-04-23 17:48:20,4,brandbacon,programming
momxrmd,1k61drp,reddit,"Here's a thought.

I do think that with AI we're normalizing shipping bad software. The argument I hear most is ""weren't we already, employing at scale, people that had no business calling themselves engineers?"". To which I had no reply, even though I was inclined to respond with ""but now it's different"". I  just couldn't articulate why. 

But reading this it occurred to me; it's the scale part. For a team of 1,000+, sure the average software output will probably be bad, let's say only 20% was good. But in a small team the impact of a few good engineers is much larger. With AI we're getting the ratio of big enterprise teams but now from small boutique teams. 

Does that make sense or am I just tripping here?",2025-04-23 16:54:25,9,hagg3n,programming
monndu8,1k61drp,reddit,TLDR;  yes,2025-04-23 18:56:33,3,ThereTheirPanda,programming
mopy3mi,1k61drp,reddit,"The kind of bugs AI introduces can be really subtle and easy to miss. And once you catch one issue, it often makes you question the whole logic, since you’re not sure what else might’ve slipped through. It's definitely helpful, but needs careful review.",2025-04-24 02:18:52,2,Hungry_Importance918,programming
moptw6r,1k61drp,reddit,Almost certainly,2025-04-24 01:54:24,1,Mojo_Jensen,programming
moqvuc1,1k61drp,reddit,Haven't we always been shipping bugs at scale?,2025-04-24 06:26:41,1,SwitchOnTheNiteLite,programming
mou1hn9,1k61drp,reddit,"I have been experimenting with two of these tools: Claude and ChatGPT.

The results vary from, ""oh, that was really useful"" to ""no, that doesn't even compile"" to ""oh, dear, that compiles, and it looks clever, but it is a really really bad idea"".

I have determined that these tools are very good at some things, like helping me develop documentation (can't overstate how good a productivity improvement this is, if done correctly), and helping me analyze production log files (if I tell them what to look for). Excellent at writing SQL (""I need a query that shows me..."").

Things the tools are not very good at: ""refactor this class to blah blah blah"".

These tools should not be used by anybody who doesn't already know what they're doing in that particular area. I fear for any situation where a non-technical manager thinks, ""fuck it, I can just whip up some prod code, I don't need that whiny evil\_burrito bitch"".

Kinda like what my calculus teacher told me about calculators a million years ago.",2025-04-24 18:31:43,1,evil_burrito,programming
momy07b,1k61drp,reddit,"lol medium no thanks. also the chance of someone actually knowing what the f they are talking about is is very low on medium. especialy now with ai, everyone is goddamn expert.",2025-04-23 16:55:33,-1,Temporary_Author6546,programming
mop3rme,1k61drp,reddit,"The way I have come to think of it, what AI does is it makes every developer an architect. If you can't (or don't) think of your code at that level, AI is going to enable you to do some damage. The good news is, if you have some experience, and/or a proper education, and use the tools consciously, you can learn how to get to the level you need to be.",2025-04-23 23:24:03,-2,Deathnote_Blockchain,programming
monqbga,1k61drp,reddit,">they often introduce critical security flaws, bad dependencies, and untested logic

Because that never happened before AI.

  
Consider the following cases:

1. User has an LLM write code which introduces an SQL injection bug.

2. User goes on stack exchange, finds a solution which introduces an SQL injection bug.

3. User goes on github, finds some code that suits their needs which introduces an SQL injection bug.

4. User finds a medium post on how to implement code that suits their needs which introduces an SQL injection bug.

  
We already had cases 2,3,4 with coders forever. Now we just added 1.

The only difference in instead of a junior coder taking a week to build some buggy code because they had to search around more and wait for replies on stack exchange they can write the same buggy code in a day.

> or security context,

The reality is I know absolutely phenomenal coders who still suck at security engineering because that is a separate domain expertise.

None of this is a substitute for proper testing.",2025-04-23 19:10:57,-6,robotlasagna,programming
mn0c8r2,1jyo8tl,reddit,"Im sorry and not trying to attack OP, but do we need another blog post explaining how javascript works? This information has been regurgitated so many times. Seems like every time a new developer learns how JS works we get a blog about it.",2025-04-14 04:02:52,36,theboston,programming
mn06unt,1jyo8tl,reddit,Very important information for programmers.,2025-04-14 03:21:27,-7,BlueGoliath,programming
ml15w7x,1jpq3sy,reddit,"""For every 25% increase in problem complexity, there is a 100% increase in solution complexity.""  Woodfield, 1979. *Almost 50 years ago.*^1

Also, intrinsic / inherent / domain complexity vs. extrinsic / accidental complexity.  
Yes, all of them have slightly different context associations, btu that's a good thing, I think. That's how language is.

But I vibe with the question, my go-to answer is: we, as a business, have ignored and belittled science as ""ivory tower"" for much too long, it's not a search for words as much as a better shared understanding, which leads to formalization, which leads to the words requested. 

Which would also, and I belive is the *actual* crux, maybe one day give us an idea how to teach programming. Something we utterly suck at. We are masters at identifying why a solution sucks, apprentices at recognizing a good solution, and drunk bumblebees when looking for a predictable, teachable path from problem to solution. 

---

^1 ^(Now, I'd need to read Woodfield to see if that factor of 4 is an observed typical value, i.e., accidental complexity, or if it's a minimum, i.e., an unavoidable ""tax"")",2025-04-02 14:52:29,36,elperroborrachotoo,programming
ml1u3si,1jpq3sy,reddit,"The practice of software engineering is applied fuzzy logic. It is inherently resistant to parsimonious, prescriptive frameworks, that's why they all suck if followed religiously.",2025-04-02 16:53:08,15,ub3rh4x0rz,programming
ml16p97,1jpq3sy,reddit,"I tried coming up with solutions without having to invent words, but I just ended up repeating the same generic ""too complex"" with different grammars. So, I have to agree.

Makes you wonder: how are words invented?",2025-04-02 14:56:30,6,Lisoph,programming
ml13zv6,1jpq3sy,reddit,"This article is going nowhere, ask me how i know it was done by manager with AI access",2025-04-02 14:42:57,33,semmaz,programming
ml5peb3,1jpq3sy,reddit,"Brooks, in ""No silver bullet"" introduces us to essential complexity (inherent to the problem) and accidental complexity (introduced by the approach to solving):
https://web.archive.org/web/20160910002130/http://worrydream.com/refs/Brooks-NoSilverBullet.pdf",2025-04-03 06:10:53,4,No_Perception5351,programming
ml603r5,1jpq3sy,reddit,"We do have words:
  - the complexity inherent to a problem: intrisic or existential complexity
  - remental, unnecessary complexity introduced by the design of the solution: accidental complexity
  - the complexity in a logical model versus the complexity in its implementation: not sure. I don’t
  really understand the difference with existential and accidental complexity
  - unidentified implicit interdependency: unnecessary unexpected coupling
  - individual software module’s software dependencies: internal dependency
  - dependencies in the environment: system dependency",2025-04-03 08:01:01,3,robin-m,programming
ml2il94,1jpq3sy,reddit,There is a dialect of English specifically spoken in Antarctica and most of their “unique” words are just multiple ways to describe snow.,2025-04-02 18:49:48,3,Artistic-Jello3986,programming
ml86s8j,1jpq3sy,reddit,"This is something I run into with USD (the 3d file format, not the currency).

USD can be intimidating, as it's a framework for composing time-sampled hierarchies that feels more like a data language than a data format. Explaining the finer details of USD can feel like explaining what a monad is — by the time you have a firm grasp on it yourself, you've used it enough that it's infected your vocabulary. If you say something like ""Loft parameters to the interface layer of component models so they're visible above the payload"" to someone who doesn't use USD, it won't even register as actionable advice for artists. 

After all, surely that advice is just for implementation details that can be hidden from the art department. It doesn't *sound* like creative advice, so do we really need to present these concepts directly to artists?

Yeah, we kinda do.

You can build a USD pipeline without making your artists learn USD vocabulary, but you don't really benefit from USD as a format if your creative team doesn't have a firm grasp on how USD works. Art isn't made in a vacuum; the affordances offered by your tools shapes both the idea and the implementation. Understanding USD's composition arcs and hierarchies gives you a set of tools that you can actively design with. Expressive tools, creative tools. Hiding those tools behind the automated machinery of your pipeline might make the transition to USD easier, but it also slows the rate at which folks learn USD and that makes hiring and training and standardization significantly harder than it needs to be.

We're seeing USD everywhere — folks are using it in film, gaming, BIM, robotics,  machine learning, and even augmented reality. All the major DCCs support USD I/O, but artists can't really *use* USD when their DCC doesn't have an equivalent layer stack and composition system. The gap between art students and junior artists keeps getting wider, because those art students don't even have the *opportunity* to learn concepts that are quickly becoming ubiquitous in production. They can't even learn the vocabulary. They're just left unprepared. 

And yet we wonder why costs keep going up.",2025-04-03 16:45:49,2,TheOtherZech,programming
ml2ita2,1jpq3sy,reddit,"aww, here i was hoping someone was working on hydrometeor classification algorithms.",2025-04-02 18:50:54,2,asphias,programming
ml6ion1,1jpq3sy,reddit,">Any ideas?

Hmmm, people have built graphs and ""ontologies"" e.g. this one https://graphologi.com/ ( I just searched for ""ontology management software"" and that was a top result ).

But the ones i have seen have not really convinced me that they are ""solving"" this issue.

There is something that can be done with nested assumption- / namespaces. ... ish?

Generally, we are not encountering this problem often enough that an automated solution is *really* necessary. We YAGNI and ""inline"" it and just use a verbose description of what we mean in our context, when we need it.

It doesn't feel satisfying to me either and I don't think it's a good solution for e.g. academia to do this all the time, and even if we ""unwrap"" a citation graph into one big text document, we would have an automated context of paper and subsection, but not necessarily a good mapping for a specific word.

So there **is** a need and use case and if / when the global academic community finally leaves the 1850's style of paper writing and publishing in print media, we have a good shot of getting a few attempts at a good solution.

My preferred organization scheme is that of decimal classification (not the library / dewey one, the general kind), which should look familiar because it's basically how IPs / URLs and in programming languages variables access are formed. The idea is simple, you invent words or index numbers and separate with a separator and the final identification of what you're talking about is formed that way.

E.g.

programming.concepts.class

vs.

biology.taxonomy.class

But there is no global dictionary that actually does this well (yet). 

With some amount of work, this kind of thing could be built in https://www.wikidata.org/  but that's superficial, since it's more about the contained graph than the infrastructure, and nobody has built a good, global graph yet, to my knowledge. There is no particular reason to pick any infrastructure or programming language or protocol over another, as long as they support some sort of graph / linked list structure.

tl;dr: yes there are other attempts, but mostly it's just hard and a lot of work.",2025-04-03 11:06:43,1,not_perfect_yet,programming
ml1oz3a,1jpq3sy,reddit,I could come up with a few offensive alternatives for vibe coding if that'd help the author.,2025-04-02 16:28:07,0,Cube00,programming
mm8pzxz,1jv9u41,reddit,"By going to school.

(Ba dum tssssss)",2025-04-09 17:06:45,55,Positive-Quiet4548,programming
mma3chl,1jv9u41,reddit,A compiler,2025-04-09 21:04:02,16,jonny_boy27,programming
mm900xh,1jv9u41,reddit,I wonder how assembly is being compiled… is on the top of my tongue 🤔,2025-04-09 17:53:31,16,OmicronFan22,programming
mm9uhvc,1jv9u41,reddit,If you are interested in the subject you should read “The Dragon Book” (I honestly can’t remember the actual title it’s Compilers: something…) or “Engineering a Compiler”,2025-04-09 20:20:53,10,ThePonderousBear,programming
mmcp7jl,1jv9u41,reddit,"Then from assembly it becomes machine code, what’s the question? Should you go to school to learn things? Yes.

You havn’t lived until you crunch operations through the kernel",2025-04-10 07:37:01,1,TheApprentice19,programming
mm8gw12,1jv9u41,reddit,it generally turns it into **byte code** not **assembly**,2025-04-09 16:22:20,-39,krista,programming
mkf7qw5,1jmwzpg,reddit,"This is amazing, i like this.  
Althought i wish there was a full screen editor and also the validate json button seams to be broken.",2025-03-29 21:49:15,7,Psychoscattman,programming
mkk3sf6,1jmwzpg,reddit,"Amazing ! I would have needed that a week ago...


Maybe having a way to create defs items would be really nice to avoid repetition


Also interface on mobile can get junky",2025-03-30 18:28:48,2,Anosema,programming
mnx452i,1k2uycx,reddit,"How do you cache this? There is a reason REST is designed the way it is. One reason is being able to leverage HTTP caching. When you no longer follow the convention of 'one resource, one url' you make caching very difficult. 

True REST is tricky, not well-understood, not well-supported. It's why I don't use it much, but what you are blaming REST for is actually because you haven't implemented it well. You complain about multiple calls, but if that is an issue you should be caching calls on the client side and designing your resources to be cacheable.",2025-04-19 12:53:10,56,TheWix,programming
mnx1sna,1k2uycx,reddit,"Pretty soon it's going to be JSX in the database.  Finally, those FE guys will be able to work full stack!",2025-04-19 12:37:02,101,c-digs,programming
mnxg6dt,1k2uycx,reddit,Thanks I hate it.,2025-04-19 14:08:35,44,D20sAreMyKink,programming
mnxeg3g,1k2uycx,reddit,This is great until you want to use your API for something other than rendering this exact React page at this exact version,2025-04-19 13:58:26,44,rooktakesqueen,programming
mnxclp4,1k2uycx,reddit,"JS devs never really stop and ask themselves ""is this a good idea?""",2025-04-19 13:47:24,62,MandalorianBear,programming
mnxm14x,1k2uycx,reddit,The example problem is exactly why Facebook created GraphQL which I think solves it better ,2025-04-19 14:41:13,13,New_York_Rhymes,programming
mnxyfay,1k2uycx,reddit,This is just htmx with extra steps,2025-04-19 15:47:22,15,Difficult_Loss657,programming
mnxvbs7,1k2uycx,reddit,"JSX is a pretty good templating language, it would be great if we can rip the templating language of other frameworks and replace it with jsx.",2025-04-19 15:31:18,10,d0pe-asaurus,programming
mnxqfxw,1k2uycx,reddit,Just go back to Rails/Django style design. Simpler. You are already almost there.,2025-04-19 15:05:13,6,pinpinbo,programming
mnxpqow,1k2uycx,reddit,"Terrifying. This guy probably discovered React yesterday.

(Intense /s)",2025-04-19 15:01:26,7,sickcodebruh420,programming
mnyy625,1k2uycx,reddit,"My knee jerk reaction is that an API response can be used by many different components. This model requires that every API be tightly coupled to the front end, requiring a new API for every way to display data.

I'm doubtful that this provides any worthwhile benefit.",2025-04-19 18:55:23,3,NiteShdw,programming
mnx5i1s,1k2uycx,reddit,A repost from mere 4 days ago.,2025-04-19 13:02:17,1,pip25hu,programming
mo0am2v,1k2uycx,reddit,"Finds “dangerouslySetInnerHTML”

NOPE",2025-04-19 23:30:39,2,listre,programming
mnzltnc,1k2uycx,reddit,"So I’m trying to understand this here. 


You have an API which is consumed by a BFF to make specific ViewModels (or in some cases JSX) for your frontend, which talks to the BFF rather than the API directly. 

There article reads a lot like a prior one that ultimately just was a long winded plug for NextJS, and in this case it’s the hint to RSC that does it.",2025-04-19 21:06:50,0,ObscurelyMe,programming
mnyp17p,1k2uycx,reddit,[deleted],2025-04-19 18:06:24,-9,N/A,programming
mo20hlk,1k2uycx,reddit,Did this guy... discover old-school server-side rendering that constructed the HTML file?,2025-04-20 07:06:40,-3,De4dWithin,programming
mo5hmm3,1k3hz8g,reddit,"how do GitOps strategies factor in, e.g. using Flux or Argo? Do they only affect the process of deploying?",2025-04-20 21:06:43,5,CheeseNuke,programming
mo867am,1k3hz8g,reddit,"Obvious gpt article, but still interesting as a kubernetes newbie.",2025-04-21 08:44:10,0,Vetinari_,programming
mnwdnxz,1k2jv1l,reddit,"Just learn SQL and the relational model ffs, your degree course probably covered it well enough hell the UK's A level courses for 17 to 18 year olds cover it well enough.

Do people really just want to learn one programming language and then call it quits?

The amount of effort people go to to not have to use SQL is astounding.",2025-04-19 08:53:06,44,Plank_With_A_Nail_In,programming
mnutx29,1k2jv1l,reddit,"lol, this was good

one of the ultimate examples of this is the configuration complexity clock [https://mikehadlow.blogspot.com/2012/05/configuration-complexity-clock.html](https://mikehadlow.blogspot.com/2012/05/configuration-complexity-clock.html) ...you increase in complexity going round the clock and then collapse right back to the platform itself",2025-04-19 01:10:04,32,bzbub2,programming
mnwskki,1k2jv1l,reddit,"My first thought when describing the SQL inner platform was: ORM.

It's debatable, but I don't like them for the core reason explain in this video. They make hard things harder and easy things easier. Prefer a query tool instead (kisely is one example)",2025-04-19 11:24:53,9,HolyPommeDeTerre,programming
molaszg,1k2jv1l,reddit,"u/cube-drone Thanks! 

Nice, short, explanation of a common pitfall.  Really well done!",2025-04-23 11:35:18,1,static_br,programming
mnwfi7o,1k2jv1l,reddit,"I'm astonished people don't realize SQL was an inner platform because auditors wanted to be able to scrutinize code for database access. It's untyped, prone to injection attacks, non modular, non source controlled and generally generated by another programming language anyway to keep in sync with the actual program code. People say ""use it"" because there is no alternative.",2025-04-19 09:13:08,-6,SnoWayKnown,programming
mnmspea,1k1kn02,reddit,"(Note that this is a re-post with the mod's permission after it was accidentally taken down yesterday)

Hey folks - just wanted to share this news about the future of Earthly, the open-source CI/CD framework, in case you’re a user. We’re incredibly grateful to everyone who tried Earthly, contributed, gave feedback, or just cheered us on. Thanks for being part of the ride ❤️

If you have any questions, I'll do my best to respond here.",2025-04-17 18:55:10,13,ketchupANmustard,programming
mnn7bsr,1k1kn02,reddit,"Really sad. In my mind, Earthly is ""the way"" to do monorepo with mixed language dependencies for the masses. There's no other solution that ""just works"" nearly as well. Sucks that there wasn't a business to be made there. The big companies have their tools, but good luck putting them to work with a team size between 1 to 100.

I'm not particularly interested in Earthly Lunar, but I realize I am not the target audience for that product; its something that will be sold to CTOs' looking to enforce software compliance with best practices across their armies of developers. Top-down sales is simpler and easier than the open source path; build the thing, hire a few tech sales people, land a few big contracts and the rest takes care of itself. I hope they are able to land a few big customers soon.",2025-04-17 20:08:17,7,CVisionIsMyJam,programming
mm0dxnb,1ju8qbn,reddit,"This strategy doesn't always alleviate delivery pressure. The idea of ""we'll fix it in the firebreak"" could pressure the developers to introduce technical debt because there's a clear time to address it. If that technical debt is introduced shortly after a firebreak, then work will be built on top of it between then and the next firebreak, leading to even more technical debt. If the team can't fully address technical debt during the firebreak, they'll continuously grow technical debt in the system.

Now, this idea does have merit. You even see similar ideas in other frameworks. Shape Up has a ""cool-down"" after the 6-week delivery cycle, where, for 2 weeks, the team has the opportunity not to schedule work. This can be used for planning, but it can also be used for fixing bugs, paying down technical debt, or even learning (which can help prevent reckless technical debt in the future). Even SAFe has an IP iteration that can and should be used for similar purposes.

A combination of strategies will need to be used. This includes being deliberate and prudent about what technical debt is introduced, actively managing technical debt (including planning high-impact resolution as a dependency to building other work), and considering techniques to regularly invest in tech debt paydown as larger efforts.",2025-04-08 10:14:30,31,TomOwens,programming
mm0w2lh,1ju8qbn,reddit,"You can do this but as a dev, it usually feels artificial and unmotivated - I have to sort through all of the tech debt that I've waded through in the past 3 months and somehow identify a project that is both (by some measure) important and one that can be tackled in a weeks' time.  Good luck with that.

""Fix it as you go"" will always be a better strategy.  If nothing else, you are consistently modeling the \_real\_ cost of software development to your management, keeping in check their unrealistic ""velocity"" expectations.  You can be sure the tech debt is topical and you have an accurate sense of how expensive it is to deal (or not deal) with.  You are still required to make good practical engineering decisions but that's true no matter how you address tech debt.

Tech debt has a real product and/or development cost -- otherwise it isn't really tech debt (it's just work not done).  That cost is how you justify your effort to your management.  If they don't understand/believe it, then you're doomed anyway.",2025-04-08 12:36:23,14,mcmcc,programming
mm0cowd,1ju8qbn,reddit,"I think it sets the wrong expectation with business. If you are not prioritising stability and productivity as part of your regular sprint, business will always pushback if it's not in their radar and features will always trump tech debt. If you always prioritise features, you deprioritise tech debt.


Being able to justify why you need to slow down features to address XFRs is a big part of a good tech leads arsenal.",2025-04-08 10:01:59,22,pkspks,programming
mm3n10k,1ju8qbn,reddit,"At Octopus Deploy we do ""Sharpening"" (the term is a nod to ""sharpening the saw""). This has a roughly similar shape to the Firebreak sprints the article describes, but is even less constrained, and we do it about 8x per year.
Developers can do whatever they want, with the general framing that you should try to improve, learn or experiment with something. One of our VP's once put it as ""a bet on Autonomy""; Sometimes the best ideas come from one developer who wanted to do something for fun.

Some people choose to use the time to do training courses or exercises. Some will use it to experiment with new platforms or tooling such as Kubernetes or AI. Some people use it to pay down technical debt, or scratch other itches that have been bothering them. Personally I've used it to fix a bunch of tech debt, improve the performance of our product, and do some learning; I wrote a proof-of-concept Docker Registry recently to learn more about how those work. Stuff like that.

I think the fact that we _don't_ just focus on tech-debt style things actually helps here. If we had something like a firebreak sprint, as other commenters rightly point out, it sets up the incentive to create more tech debt because we can always clean it up in the firebreak. But with sharpening, there's no expectation or guarantee that anyone will choose to use their time on tech debt. It removes that incentive to take shortcuts while still allowing developers to solve their own problems freely if they choose.

Other than that though, I agree with the article. Our codebase, company, developer skills and morale are all much better than if we didn't take the time for sharpening, and overall we are able to deliver product _faster_ than if we didn't do it.",2025-04-08 20:53:57,4,borland,programming
mm394sc,1ju8qbn,reddit,">Dedicated refactoring sprints often turn into death marches with arbitrary deadlines and management-dictated targets

This **is** a “dedicated refactoring sprint”. Non-engineers will either question the usefulness, or they will expect this week to yield quality benefits.

>“20% time” policies typically evaporate under delivery pressure

This **is** 20% time. Except it’s only 10% time. You say 3-4 times a year. Let’s say four. Given ~200 days a year (sick leave and vacation subtracted), or 50 a quarter, that’s 5 days a quarter, or 10%.

>“Just fix things as they go” is magical thinking when product roadmaps are already overstuffed

“They’ll fix it in their allotted one week a quarter” is the exact same magical thinking.",2025-04-08 19:48:32,3,chucker23n,programming
mm1re94,1ju8qbn,reddit,"1 week per quarter is not enough time to fix critical design flaws, I don't care what you call it",2025-04-08 15:27:08,1,angrynoah,programming
mm3totm,1ju8qbn,reddit,"Anything that causes an impromptu death march , even with the good intention of minimizing tech debt will cause burnouts. 

Hard to come back to normal when a large portion of the team, wishes they were anywhere else but on the job",2025-04-08 21:27:09,1,wapskalyon,programming
mnk9f2b,1k19ocm,reddit,"Hello, author here.

I'm using this technique to develop a Go project that supports only x86_64. In short, its a way to set up Linux VM with Go installed

It can help somebody.",2025-04-17 10:42:43,9,askoma,programming
mn9trsa,1jzt6n9,reddit,"> LLVM’s target triple list is the one that should be regarded as “most official”, for a few reasons

This is not quite true, if for no other reason than LLVM only supporting a relatively small subset of the *many* targets that binutils and GCC support. If you want a more complete picture of reality, you have to reference *all* of these projects.

It's also worth noting that LLVM will defer to other projects on target triples when it makes sense; LLVM rarely invents its own thing that's arbitrarily different.

> A major compiler (so, clang or rustc) uses it. Rust does a way better job than LLVM of documenting their targets, so I prefer to give it deference. You can find Rust’s official triples here.

Should probably have pointed out that Rust triples do not necessarily map 1:1 to LLVM triples. For example, `riscv64gc-linux-gnu` will not be recognized by LLVM/Clang. In Zig we similarly have target triples that (for sanity and regularity) differ from LLVM but are lowered to what LLVM expects.

> Of course, LLVM’s ARM support also sports some naughty subarchitectures not part of this system, with naughty made up names.

Should have included `aarch64_32`/`arm64_32` in this list. It's an absolutely bonkers Apple invention that for some inexplicable reason, as the only example of this, crams the ABI into the architecture component of the triple. So you get `arm64_32-apple-ios` instead of something more sane like `aarch64-apple-ios-ilp32`, like on other architectures (think `x86_64-linux-gnux32`, `mips64-linux-gnuabin32`, etc). `aarch64-linux-gnu_ilp32` was also introduced at some point, and sanity prevailed on that one, thankfully.

> When we say “x86” unqualified, in 2025, we almost always mean x86_64, because 32-bit x86 is dead. If you need to talk about 32-bit x86, you should either say “32-bit x86”, “protected mode”11, or “i386” (the first Intel microarchitecture that implemented protected mode)12. You should not call it x86_32 or just x86.

I disagree; given that almost nobody considers the actual i386 to be the baseline for 32-bit x86 anymore, and considering that `i386`/`i486`/`i586`/`i686` are all valid in a triple yet mean different things, it's misleading to use `i386` to refer to 32-bit x86 as a whole.

This is why Zig switched from `i386` to `x86` for this case in target triples (and simultaneously bumped the baseline to `pentium4`). We have not found this confusing in practice; it's understood well enough what is meant by `x86` and `x86_64` respectively.

(And, unfortunately, 32-bit x86 is not as dead as I'd like.)

> 32-bit x86 is extremely not called “x32”; this is what Linux used to call its x86 ILP324 variant before it was removed (which, following the ARM names, would have been called x86_6432).

It hasn't actually been removed (yet!).

> The vendor is intended to identify who is responsible for the ABI definition for that target. Although provides little to no value to the compiler itself, but it does help to sort related targets together. Sort of.

Fun fact: The vendor component does actually affect logic throughout LLVM/Clang [in some cases](https://github.com/ziglang/zig/blob/933beb4cbd82ce8026a7bd4e887d8096dd3784a9/src/codegen/llvm.zig#L164-L187).

> A lot of jankier targets use the ABI portion to specify the object file, such as the aforementioned riscv32imc-unknown-none-elf.

LLVM parses the ABI (""environment"") component of the triple in such a way that checks for the ABI do a ""starts with"" check, while checks for the object format do an ""ends with"" check. So it's still pretty odd that there isn't an extra, formal component for the object format, but there is actually a method to the madness here.

> And no, a “target quadruple” is not a thing and if I catch you saying that I’m gonna bonk you with an Intel optimization manual. 

[Come at me!](https://github.com/ziglang/zig/issues/20690)

> No idea what this is, and Google won’t help me.  

It's NEC's Vector Engine: https://en.wikipedia.org/wiki/NEC_SX-Aurora_TSUBASA

I have an architecture manual stashed [here](https://github.com/vezel-dev/hoard/releases/tag/ve) if you're curious.",2025-04-15 18:05:19,30,TheFakeZor,programming
mn9b35o,1jzt6n9,reddit,"I have always wondered what these compiler targets actually meant. After reading this article, I feel like I know even less than I did before. I actually appreciate how Go handles it, despite the fact that they basically made their own standard. It's apparent nobody else was following a real standard anyway.",2025-04-15 16:34:37,7,itijara,programming
mndtcq8,1jzt6n9,reddit,">After all, you don’t want to be building your iPhone app on literal iPhone hardware.

What an unfortunate mindset. It is a shame that a dominant computing platform is so hostile to creation, and that this is seen as normal.",2025-04-16 10:01:50,2,voidstarcpp,programming
mnduqx4,1jzt6n9,reddit,"> If you need to talk about 32-bit x86, you should either say “32-bit x86”, “protected mode”, or “i386” (the first Intel microarchitecture that implemented protected mode).

While it's historical information that's not relevant outside of the retrocomputing subculture (which does seem to be gaining popularity). This and the accompanying footnote:

> Very kernel-hacker-brained name. It references the three processor modes of an x86 machine: real mode, protected mode, long mode, which correspond to 16-, 32-, and 64-bit modes. 

Is incorrect. There are _four_ ""canonical"" modes of x86 CPUs, not three (plus two compatibility sub-modes).

""Real mode"" is the original 16-bit 8086/8088 ""mode"" (there were no other modes at the time) that supports up to 1MB\* address space divided into fixed 64KB ""segments"" that overlap at 16-byte intervals.

""Protected mode"" was introduced with the (still 16-bit) 80286 and supports up to 16MB address space, but divided into variable-sized (up to 64KB) segments with arbitrary, configurable locations in memory.

""32-bit (protected) mode"" was introduced with the 80386 and extends protected mode to support segments of up to 4GB over an address space of the same size. It also introduced ""paging"" (although the original 80386 allowed paging to be active in any mode, including real mode, this was never supported by Intel and was removed in later CPUs) which has replaced segmentation as the preferred way to manage memory on 32-bit OSs. The architecture also extended the CPU registers to 32-bits, but this is also usable (with some caveats) by 80386-specific code running in the old 16-bit ""modes"". There is also a sub-mode of 32-bit protected mode known as ""V86 mode"" that is designed to allow 16-bit real-mode code to work with a protected mode OS (the OS needs to contain a little 32-bit code for this mode to be used, but can be ""mostly"" 16-bit, like Windows 3.x).

""Long mode"" (i.e. 64-bit mode) was introduced with the original AMD Athlon 64 CPUs in 2003 (the only mode not invented by Intel) and extends the capabilities of the 32-bit mode to 64-bit, but removes some of the flexibility from the ""segmentation"" system available in the protected modes (as use of this was never particularly common on 32-bit systems). Analogous to V86 mode, there is also ""compatibility mode"" that allows 32-bit code to work with a 64-bit OS.

Saying ""protected mode"" when you mean 32-bit mode will cause confusion, since that originally meant the _16-bit_ protected mode of the 80286. Saying ""i386"" is generally better (and is used by the ""target triples""), but can also refer to code that uses 386-or-later opcodes in any mode. Basically, just stick to x86_32 if you want to be completely clear.

Using ""real mode"" to refer to all x86 16-bit code is just plain incorrect.

\* Since the silly MB/MiB distinction didn't exist until the late 1990s and didn't gain traction until the 2010s, I will be using the units as they existed at the time. 1KB=1024 bytes, 1MB = 1024\*1KB, 1GB=1024\*1MB.",2025-04-16 10:15:23,3,mallardtheduck,programming
mn9gt4p,1jzt6n9,reddit,[deleted],2025-04-15 17:02:39,-1,N/A,programming
mndbwy2,1jzt6n9,reddit,"Where is ISO or some other Standards body?

Great opportunity to make a committee cash in here, and improve the life for all of us. :)",2025-04-16 06:55:59,-2,McUsrII,programming
mn98muf,1jzt6n9,reddit,Surprised I read that whole thing.,2025-04-15 16:22:37,-4,Timothy303,programming
ml61cf0,1jqbm3m,reddit,"As a CPTO, I've been observing how AI tools like Copilot are highlighting a critical issue in modern development: the knowledge preservation crisis. While AI can help generate code, it often misses crucial organizational context and architectural decisions.

We've found that AI tools actually amplify the documentation gap - they can write code, but can't capture the ""why"" behind architectural decisions. This creates a dangerous cycle where teams rely more on AI while losing critical institutional knowledge.

I recently wrote about this challenge and how we're addressing it by treating knowledge preservation as a first-class citizen in our development process, focusing on capturing not just what we build, but why we build it that way.

What has been your experience with maintaining architectural knowledge while using AI tools?",2025-04-03 08:14:22,67,traderprof,programming
ml6alxm,1jqbm3m,reddit,"""\[...\] because AI is so incredibly cool and hip and for many people the only intelligence they know"" haha",2025-04-03 09:53:31,27,steos,programming
mld9su0,1jqbm3m,reddit,This article was posted here two days ago https://www.reddit.com/r/programming/s/IDyBc6GDGS,2025-04-04 13:08:02,2,OsmiumYummy,programming
ml727p7,1jqbm3m,reddit,"Lol, don't.",2025-04-03 13:19:49,3,voteyesatonefive,programming
mlnwvqz,1jqbm3m,reddit,"Exactly. What you're describing with Cursor rules is an excellent approach to the context problem. You're manually creating a structured knowledge system.

The challenge I've found is that this method requires considerable effort:

* Creating and maintaining these rules
* Ensuring they're updated when architecture changes
* Requiring someone with deep knowledge to explicitly document everything

I've been working on [PAELLADOC](http://github.com/jlcases/paelladoc)  a professional framework for managing architectural and technical knowledge. Rather than just automating, it establishes a structured methodology for capturing, organizing, and utilizing organizational knowledge in software development.

The concept is to provide a sustainable structure where knowledge is not only captured but evolves naturally with the code and can be integrated with LLMs to improve context accuracy.

Have you encountered challenges maintaining consistency in these rules when multiple developers work on the same codebase?",2025-04-06 06:54:01,1,traderprof,programming
mmg5y95,1jqbm3m,reddit,That's a perfect summary of my own thoughts and feelings too. It's tragic that some people who make decisions don't even want to hear feedback from those who are actually supposed to use these tools. Thank you for the link.,2025-04-10 20:17:40,1,neithere,programming
ml7o6gg,1jqbm3m,reddit,[deleted],2025-04-03 15:14:15,-10,N/A,programming
mokiowm,1k5bk2y,reddit,"You need to actually tie down what “constant expression” means in the intro, because you’ve kinda breezed past an important distinction, and as you’ve chosen to interpret it (i.e., all ways or none), it’s not particularly useful. E.g., you can’t use these to check that an array won’t end up as a VLA, or that something is sufficient for a bitfield or bit-int or `_Alignas` width or enum constant, or that something suffices for static initialization, and all of these are distinct from the sorts of constant expressions that can be consumed by `#if`—but even there, rules vary (e.g., expansion of macro incl. `defined`, use of `sizeof` [supp. by Borland]).

Your take on `__builtin_constant_p` may or may not be correct, for example. Early versions of `__builtin_constant_p` yielded nonzero iff their arguments were actually constant expressions, in the ISO `constexpr` sense. This was the case for GCC prior to 3.0ish, early Clang, and either older or all ICC/ECC/ICL.

Newer compilers, however, mostly yield nonzero if the compiler can see the value of something at compile time, which is a considerably laxer constraint and one that can enter your optimizer into causal cycles with itself. Thus, for example, you may get varying results for

	puts(__builtin_constant_p((const int){0}) ? ""yes"" : ""no"");

or if you apply it on the parameter of an inlined function. Also, the built-in functions treated as constant expressions vary *widely* depending on version and line, with both GCC and Clang migrating things to constexpr without warning and as is possible.

Also, `__builtin`s should not *generally* be treated as GNU-dialect broadly, but merely as features of some GNU-dialect compilers, which tend to slice and dice their preferred GCC manual version however they please. There’s a handful of other compilers that support GNU extensions (TI, IBM, Oracle, Metrowerks, Arm, Dignus, Keil), but not necessarily `__builtin_constant_p`, and they might reasonably implement it in either way, depending upon when in GCC history the compiler programmers started compat work, what the compiler’s actual needs are, and whether anything has compelled the newer, touchier behavior. There’s not even a requirement that `__builtin_constant` itself yield a constant expression, which is outside its intended use case of choosing between inlined and uninlined code, or between assembly sequences.

And then, you assume that 0 can be casted to whatever type you test, which is …adventurous, I guess. Also note that support for `__builtin_constant_p` does not at all imply support for `__attribute__((error))` or vice versa, and `__attribute` deserves to have its trailing `__` for consistency with the rest of the world. (Hell, why not just `attribute`, GCC 2 supported that!)

Moving back to your first thing, if C23 features (disregard Clang, it lies about C23 support) are a thing, you may as well make use of `constexpr`, which might actually come closer to what you want. Your code is flatly invalid for vacuous objects like `struct {}` or ZLAs, which aren’t prohibited by C (supported by most compilers).

The `static_assert` thing is kinda pointless; you could just as easily use something like `struct {unsigned foo : 1+0*!(x);}`. And a note of caution: MSVC is a goddamn mess for this one. All MSVCs in all modes from at least `_MSC_VER == 1900` on support `static_assert` as a keyword, whether or not that’s a good idea (mostly not, but helluva jump on C23); this is despite early MSVC “C11” modes not supporting `_Static_assert` at all. However, AFAIK unless in a C17 (or atl post-“‘“‘conformance’”’” push) mode specifically, you can’t just drop a struct/union/enum definition anywhere—anything in parens is a no-no, so no `sizeof(…)` or casts either. You *may* be able to abuse `#pragma warning` to enable it, but IDK offhand when that started to be a thing.

The `+0` thing makes me squirm—if all you care about is whether ICEs work, then the Linux kernel trick with null pointers (or rather, something less dependent on `sizeof` things being >1) will suffice. `+0` will fail for pointers to incomplete or function type, for example—e.g., `char (*)[]` or `struct untold *`—but those are constant enough for (e.g.) `static` initializers (which `static_assert` is too strict for). Comma operator is fraught, because nothing requires that it work outside block scope, even in a `typeof`.

Another issue with anything that duplicates its argument is token-space blowup, but whatever, that’s macros for you. Probably I’d’ve gone with a variadic macro for these where possible. because `{[]}` don’t guard the same as `()`, and so something like `*(int[]){0,}` would break thesw. Of course, then you need to split things if you need GNU89 or C89 support, but it seems we’ve assumed that cost to begin with.

Your compound literal thing is semi-pointless at block scope, because compound literals predate C99 by quite a bit. VLA comp-lits aren’t permitted in the standard because it would be in-place init, or at file scope becaif your compiler isn’t obscenely permissive (GCC may be), but GCC permits in-place init *and* both it and Clang will glibly fold VLA to CLA for you! So something like `((void)0,1)` may actually pass, even if `-Werror=vla` is enabled!

Another issue is that compound literals can’t appear *at all* in a static-storage local declaration, without slipping a storage qualifier in (which is rarest C23).

I also note that the maximum array size depends on context—a static variable, local variable, TLS variable, typedef, and parameter variable might all have different CLA size limits, and VLA size limits might effectively be anywhere under min {`PTRDIFF_MAX`, `SIZE_MAX`}.

The enum thing has the MSVC limitation. Also, you can produce `_Pragma`/`__pragma` inside `struct {}`s (after `{` or `;`), so if you use a struct *and* enum, you can potentially get a bit closer. But in practice, pragmas are at best a temporary one-off for warning suppression; if an `unused` or `maybe_unused` attribute won’t work, it’s probably best to find another approach.

Yeah, operator commas induce a sequence point (and can create syntactic ambiguity), which eliminates any possibility of constantness beyond GCC and Clang inadvisably V-to-CLA folding, and make it non-kosher to do anything at file scope.

That last thing about `error` being robust …absolutely not. No. LOLno. First of all, no attribute is. It’s like `#pragma`, but less tightly specified. Second, `error` and `warning` only actually trip if a dependency would be generated, and they’re only really supported by GCC, Clang, and IntelC from latter-days C1x on.

But none of this is robust, really—you bounce between treating rules-per-standards as hard and fast, but most aren’t, especially early on, and even within the standards, consistency is a mess.",2025-04-23 06:59:59,13,nerd4code,programming
mol60ef,1k5bk2y,reddit,This reminds me a lot of C++ around 2 decades ago when type traits & generic programming overall was starting to become a thing.,2025-04-23 10:58:03,2,Sairony,programming
mkx6785,1jp2n0t,reddit,As a Haskell-brained individual I support all efforts to extend the warm blanket of type-level logic across the unwashed masses,2025-04-01 21:10:01,35,anzu_embroidery,programming
ml2htim,1jp2n0t,reddit,"Didn't finish reading, but you mentioned that Java had sealed types to represent Sum Types.

Well, Java now has `record` to represent Product Types. Your `Transaction` example melts down to this.

    record Transaction(long timestamp, double amount)
    {/* your stuff here */}",2025-04-02 18:46:00,2,davidalayachew,programming
mmcdnrp,1jvlx0w,reddit,"It's annoying that the article didn't start with what e-graphs are and _why_ they're important, as it would've helped motivate the reader to read the article.",2025-04-10 05:41:22,10,fungussa,programming
mjzgkog,1jkefwx,reddit,Great... though my (personal) experience is that even 100ms for remote controls feels very laggy. And I'm an old man!,2025-03-27 09:42:26,5,klaasvanschelven,programming
molu7ge,1k5ap88,reddit,Am I the only one that hated working with airflow - felt super janky throughout.,2025-04-23 13:37:59,1,tittydestroyer69,programming
mohq9p5,1k5ap88,reddit,"“New UI” - looks at UI, yep, still an Apache project with UI designed by BSD admins.",2025-04-22 20:22:59,-19,jimbojsb,programming
mn6jstb,1jz0a2f,reddit,"A nice bit of history, thanks.",2025-04-15 04:11:58,3,Gibgezr,programming
mn7s091,1jz0a2f,reddit,"Nice digging. It did miss the opportunity to explore what sort of fonts the Greek used for delta back in the day.

I have to say I also like sites from graphics oriented people since they tend to include useful yet rare widgets, like a widget to play around with the pixels of a delta symbol.",2025-04-15 11:25:22,1,double-you,programming
mn2grnt,1jz0be6,reddit,"Nice blog, most people really don't know how to use git

That said, it's telling that to understand a git command you have to go read the source code. Classic. Use jj, people",2025-04-14 14:39:42,8,teerre,programming
mn2x38k,1jz0be6,reddit,"Nicely explained! That 'revert' example took me a bit. But it was a nice showcase of how versatile something like the generic logic of a ""3-way merge"" can be, by simply changing it's inputs.",2025-04-14 16:02:10,2,ThatWasYourLastToast,programming
mn8pe8s,1jz0be6,reddit,"Wait, why would one assume it is just a patch and be surprised that it is a merge like the other merges? The author kind of glossed over that.",2025-04-15 14:46:19,1,emperor000,programming
mnu5n6j,1jz0be6,reddit,"In the cherry-pick example, wouldn’t `A` be the base, given it’s the last common commit?",2025-04-18 22:41:20,1,Schmittfried,programming
mmq7aca,1jwni7m,reddit,Cool 🙂,2025-04-12 13:10:34,2,teodorfon,programming
mm9acjt,1jv830o,reddit,Was here yesterday: https://www.reddit.com/r/programming/comments/1ju1f1g/20_years_of_git/,2025-04-09 18:43:01,1,steveklabnik1,programming
mmkux09,1jwq9c2,reddit,"Obligatory: https://github.com/susam/mintotp

Previously posted: https://www.reddit.com/r/Python/comments/138ioae/minimal_totp_generator_in_20_lines_of_python/",2025-04-11 15:35:54,3,p-orbitals,programming
mmpv9p6,1jwq9c2,reddit,"This is a rite of passage when having to deal with providers that are adamant against providing service accounts because apparently ""that's insecure"". Cool, enjoy having my account credentials provided via CI and a python script that implements totp (not that it matters to them because I am the one breaking the contract of 1 user per account).",2025-04-12 11:44:20,1,Worth_Trust_3825,programming
mmkbokh,1jwq9c2,reddit,"Cool. Try my app

https://github.com/AllanOricil/esp32-mfa-authenticator",2025-04-11 14:00:16,1,Positive_Method3022,programming
mk5yy35,1jlrw8j,reddit,"> In modern development, Git handles version history

Correct. You don't need to document version history in comments anymore. However, documenting which version a (breaking) change was introduced in is still useful - e.g., if you're programming against some library, and you want to know which version ranges you can safely depend on, it's important to know when the APIs you are using were introduced and removed, and you want that information available in the (generated) documentation, rather than having to search through the source code in git.

> and many teams rely on self-explanatory code

Many teams *tell* themselves that their code is self-explanatory. It's usually not, at least not entirely. Documentation that just repeats what's already perfectly obvious from the code itself is bad (see the infamous ""increment i by 1"" comment), but anyone who insists that their code is 100% self-explanatory and needs to documentation whatsoever is delusional.

> Swagger (for APIs) i work with swagger in my controllers , but about other fucntions like repositories , services ect...?

Swagger (and similar documentation generators) can only show information that exists in the code; without any additional documentation efforts on your end, Swagger will only document which calls exists, which parameters they take, and what their types are. It will not tell the user anything about what those calls do, how you are supposed to use them, what edge cases there are, why they are structured the way they are, etc. There is no way around adding that information yourself.

> and IDE auto-documentation instead of manual inline documentation.

An IDE does not understand the code any better than a compiler, so just like Swagger, it can only ""auto-document"" things based on the information already present in the code, which is usually redundant. This stuff can be helpful as a *starting point* for your own documentation, providing a skeleton that contains stubs for all your methods, arguments, etc.; but that stub on its own is worthless unless you add useful information to it.

> So, is this style outdated?

This particular style, yes, but most of what it aims to achieve is still relevant.

A more modern style would:

- Omit version history information (we have source control for that)
- Put documentation that refers to specific identifiers (functions, constants, types...) close to where they are defined, rather than listing them at the top (we have documentation generators to extract this information and convert it to something human-readable)
- Omit function names from function documentation - by placing the documentation right before the function definition, this information becomes redundant, the documentation generator will extract it from the code itself
- Use a machine-readable commenting style to enable the use of said documentation generators (in many modern languages, documentation comment syntax is standardized or even part of the language syntax itself; where it's not, you should adopt a documentation generator of your choice and use the comment syntax it expects)

And even back then, stuff like this is redundant and useless:

> * BulletClass::~BulletClass -- Destructor for bullet objects. *

The name `BulletClass` already tells us that it's a bullet object, and `~BulletClass` is literally C++ destructor syntax, which means it's a destructor for bullet objects. This will be second nature for anyone who knows C++, and yet the comment regurgitates this exact information, and adds absolutely nothing else. Redundant documentation is worse than absent documentation, because it can (and thus, at some point, will) go out of sync with the code - e.g., someone might rename the bullet class, but forget to update the documentation, or someone might remove the destructor and instead rely on the default destructor, etc., but the documentation, which is now incorrect, will still be there.",2025-03-28 11:14:46,44,tdammers,programming
mk6rj9i,1jlrw8j,reddit,"> many teams rely on self-explanatory code

This is a lie people tell themselves. 

Code is never self-explanatory. Proof? Go back and read code you've written a year or two ago. You will most certainly be asking ""wait, why is this done like this?"". 

There's probably a quirk that was obvious at the time that you had to work around, but now it's lost to you and good luck trying to remember why the implementation quirk was made. 

Comments are extremely important. Updating comments is equally as important as code changes. Comments should provide ***context*** above all. The code describes the ""*how*"", but the comments describe the ""*why*"".",2025-03-28 14:15:05,93,Anodynamix,programming
mk6fm0d,1jlrw8j,reddit,"""Still Relevant"", ""old-school"", ""30-year-old [] source code"", ""modern development"", ""self-explanatory code"", ""IDE auto-documentation""

You're getting lost in the sauce.  Learn what's useful to yourself, and to your team.

Do you write javadoc/doxygen comments but they're stale and full of inaccuracies because you never use them or even build the docs to see the things so wrong the tool can detect and throw warnings? Then delete them.

Do you find generated docs so useful for quickly browsing through type definitions and function signatures that you do it even on uncommented code? Then adding some doc comments would probably make that even more powerful to you.

Having things like filenames, dates, change summaries in the file is redundant to the information in version control, but it is used even with version control tools.  Many tools have built-in clean and smudge filters (in git parlance) to edit that information into source files on retrieval.  Maybe it was an optimization before distributed VCS, maybe it's prevalence is tied to built-in support.  All I know is that it's not as popular anymore.

Even beyond just comments, there are in-code conventions that are adopted because they help a dev/team be successful.  For example RAII.  Nothing forces you to do it, it's only ""good practice"" insofar as if a dev/team tends to make errors that RAII prevents then it may be worth adopting.

In general, play it safe by sticking to the conventions of the project you're in, or the modern style for the language you're using.  Once you've done it long enough your experience will develop a sense of taste and knowing where your own common pitfalls are.",2025-03-28 13:09:00,2,old-toad9684,programming
mk85ywg,1jlrw8j,reddit,"The updated date and by who is outdated. However, the rest of it that describes what it does and the parameters it takes is absolutely not outdated. You should have something like that on all functions that are part of the API of the code (so in OO programming all public methods).

Most languages have support for this: 

* Java -- JavaDoc
* Python -- Docstrings
* JavaScript -- JSDoc
* Kotlin - KDoc
* Rust - Rustdoc

etc.

When the command and conquer code was released I looked at it and was quite pleased to see those comments in there that explain what it did and the parameters it takes. Makes it so much easier to figure out what is going on.

> self-explanatory code

Bullshit.",2025-03-28 18:20:48,4,wildjokers,programming
mk63f4m,1jlrw8j,reddit,"Having documentation available is almost always better than no documentation. (One can reason that incorrect and/or outdated documentation may be worse, and there is an argument for that, but even then I prefer this over no documentation.)

> So, is this style outdated?

So I would not call this documentation to be outdated.

I also think it should not matter whether git/github exists or not - the documentation and intrinsic quality of documentation should always be specific to the project at hand. Conversely, if github exists, and people remove documentation like that, then in my opinion this leads to a worse project (assuming the documentation is correct; if the documentation in itself is a joke, then removing it would actually be beneficial, but most documentation, such as this one here, is correct or mostly correct).

> In modern development, Git handles version history, and many teams rely on self-explanatory code

One of my simple rules is: if a team or a developer claims the code is self-explanatory, then this team or developer needs to be let go. Because code is NEVER self-explanatory, and that includes for instance ruby code. Ruby code can be super-natural, close to the problem domain via some kind of DSL (such as in rails). None of this is an excuse for omitting documentation, so anyone who claims ""my code is self-explanatory"", has to be removed from any important project at once. These people just find excuses for laziness - it is how the mind works. On top of that, code can be wrong, so ""self-explanatory code"" does not apply in this case; and often code can be written in different ways, so people may ask WHY that code was written in a particular manner. These are all reasons as to why documentation has to exist. (Whether this is in the same file, or elsewhere, is secondary; I usually begin to write some specification and documentation up front, at the least if a project becomes large. For small projects it is indeed often just easier to begin to write code and adjust as you go, then write the documentation. I am lazy too but I don't reason that omitting documentation is ever a good thing - documentation is almost as important as code, in my opinion. The style of documentation is also important, but as a secondary consideration. Personally I do like in-source-file documentation too, but I understand people who may decide to document things elsewhere; but often, there is simply no documentation at all and people abandon projects without ever writing any documentation.)

Case in point, by the way: I am currently revisiting opal (in ruby), because JavaScript annoys me to no ends. Opal's website can be found here:

https://opalrb.com/

I read it first in the past, years ago; I am now re-reading it. And I have to say ... if ruby projects continue to have such horrible substandard quality, I am no longer surprised that ruby is no longer among TIOBE top 20, sorry. Ruby is a great language, but the lack of documentation in various projects, is really just telling people to use python instead and be done with it. I don't understand why the ruby core team does not acknowledge this as one primary problem in the larger ruby ecosystem (I am aware it is not their fault, since these are of course external projects, nor am I implying that every single ruby project has such poor documentation, but this is not the only example here, just look at sinatra - I don't understand why so many ruby projects have a total joke of a documentation. There are of course exceptions too; rails has high quality documentation really, or Jeremy's projects, such as sequel, also have excellent documentation or at the least very good documentation. This should become a strict requirement in ruby really, aka ""if you lack documentation, you can no longer invoke the ruby parser"" - that would get people to commit towards better documentation really. Not that it would lead to a resurgence in popularity though ... but seriously, if ruby wants to be more relevant, then it HAS TO IMPROVE THE DOCUMENTATION SITUATION IN GENERAL, everywhere.)",2025-03-28 11:49:33,8,shevy-java,programming
mk8i54i,1jlrw8j,reddit,"This post set me off with the title.    Git fist and foremost is a Source Code Management system, it IS NOT a documentation system!!!!!!!   Sure Git provides a way to document commits but that has little to do with documentation of code.   Beyond all of that and possibly more important; commit comments are not contemporaneous with your code.  That is you can not read a comment inline with the code that comment impacts.

The concept of self documenting code is fine, in fact it is a great idea, in my day your where taught to write idomatic code which similarly refers to lucid easy to read code.   However code can do a perfectly good job of documenting itself but punt on the WHY?    Often it is the why that is important and forgotten.   

The ""why"" may or may not need to go into the SCM systems commit note but if it isn't in the code text you may never know that a why exists or be forced to take a long detore into the SCM system to try to find the why.   Frankly I can't understand why anybody would want to spread important information about how a piece of code works all over the place.",2025-03-28 19:21:12,3,spinwizard69,programming
mk9tx07,1jlrw8j,reddit,"Even if it's possible to dig the information out of the git history, anyone reading the file still needs to know that information *exists* before they'll even try searching, and the more a file's actively changed, the more that history will be cluttered with unrelated commits.

Mentioning the most important items inline? A form of caching, and adds additional metadata about the importance of specific issues. If you've ever heard an anecdote about a database query that used to take hours, cut down to minutes just by adding one carefully-thought-through index, how much more valuable would something that saves hours of *programmer time* be?",2025-03-28 23:31:53,1,Uristqwerty,programming
mkao4kc,1jlrw8j,reddit,"It's still appropriate for a module header comment to state the module's reason for being, plus copyright and perhaps first author.


All those per-method comments belong with the methods, and should generally be either longer, or excised if they only state the obvious (like the ""delete"" method.)


What's more interesting is how a team links its modules with the relevant design information and with the bug tracking system. Git doesn't just contain the date and author of each change, it also has to tie commits to the REASON for each change. This is true regardless of what source code control system you use.",2025-03-29 02:30:49,1,Leverkaas2516,programming
mkavld1,1jlrw8j,reddit,"Comments in code give much needed context that was understood at the time it was written but often long forgotten months or years later.

I write comments in code when I think it’s useful to understand WHY a piece of code is there.

“Self documenting code” is a misnomer. What people are saying is that you generally don’t need to write down WHAT the code is doing because people can read the code.

It doesn’t explain WHY it’s there",2025-03-29 03:20:40,1,NiteShdw,programming
mkbdbo1,1jlrw8j,reddit,"The Files are all caps and under 16 characters long, DOS.",2025-03-29 05:43:26,1,fryerandice,programming
mkc0phh,1jlrw8j,reddit,"I used to think it was possible to write self documenting code but it's not because everyone writes and understands code differently. 

I don't have hundreds of comments in my code but the ones I do have explain why a decision was made rather than what as why is normally the most important",2025-03-29 10:00:48,1,TheWobling,programming
mkc2icu,1jlrw8j,reddit,I wish more people commented code honestly,2025-03-29 10:20:16,1,ward2k,programming
mkcs4wj,1jlrw8j,reddit,"Thank you so much, everyone! Really appreciate this. I'm a junior dev, and ever since I graduated, I've been working at a small startup. Information like this is incredibly valuable to me.",2025-03-29 13:47:34,1,Faceless_sky_father,programming
mnh1zd3,1k0okkg,reddit,"You can taste the hatred of Python in every paragraph, lol.",2025-04-16 20:45:19,19,Business-Decision719,programming
mnm3cm1,1k0okkg,reddit,Comparing Rust performance against Python and saying it is an issue on Python makes it clear the author has zero understanding of programming languages,2025-04-17 16:52:45,8,omeguito,programming
mnflo0s,1k0okkg,reddit,"Overall a decent article, but the section on ""async"" feels a bit flippant. It relies too much on outdated clichés, and is sometimes either flat-out wrong or just poorly worded.",2025-04-16 16:28:03,6,simon_o,programming
mnm5lat,1k0okkg,reddit,"A lot of blog posts mention they almost don’t use debugger. I absolutely hate how debugger sucks in Rust, and I've tried all options. Debugging async is almost impossible or the experience sucks, I hate that I don’t have inline expressions too.",2025-04-17 17:03:24,2,javasuxandiloveit,programming
mnkn33p,1k0okkg,reddit,"Yes. My experience with rust ended because of that module system. When ""cargo"" overfilled my ""/home"" partition with files that were not needed for anything. And I just wanted to compile a simple rust program and somehow link /usr/lib/libsqlite3.so together.",2025-04-17 12:22:15,2,LowEquivalent6491,programming
mnhkyja,1k0okkg,reddit,"It feels as if all those languages, C, C++, Rust, to some extent Java and Go (but both less, IMO), become increasingly complex and complicated. Now, most languages naturally become more complex when more features are added, but there should be some objective metric we could use; I would wager that, if we'd have that, C++ and Rust are probably among the most complicated programming languages (perhaps Haskell too), and C also follows close behind. (C is probably a bit simpler than both C++ and Rust because it lacks many features compared to these two; and C++ is kind of a ""subset"" in that it is also backwards compatible with C, so C++ is probably the most complex programming language. It's also successful, which is somewhat strange to me; right now #2 on TIOBE. Not that TIOBE means much but still ...)",2025-04-16 22:26:52,-6,shevy-java,programming
mld8t8c,1jqwygg,reddit,"> By some counts, there are over 200 languages that use the JVM as compilation target

I would like to know by *whose* counts, and where did they learn to count.",2025-04-04 13:01:58,30,nelmaloc,programming
mlc5ze2,1jqwygg,reddit,"> Homogeneous translations are more amenable to abstracting over parametric families of types, such as Java’s wildcards, or C#’s declaration-site variance

O_o

C# uses heterogeneous translation for generics.",2025-04-04 07:17:22,26,decoderwheel,programming
mlex3l6,1jqwygg,reddit,"The only reason why erasure is a problem is because Java's type system is half-assed. If it had no type checks but instead tagged unions (like Rust), things would look much better.

Rust structs are also type erased, but you'll never notice. And all that while it also has trait objects in cases where you want to avoid explosive code generation.",2025-04-04 18:11:47,7,flying-sheep,programming
mlfir58,1jqwygg,reddit,"Reification issues aside, Java generics are a disaster. Use-site variance--what Java calls “wildcards""--is one of the language’s worst missteps. It takes a straightforward concept (variance) and inverts it, forcing you to express it *at the point of use* instead of the point of definition. It’s backwards 99.9% of the time.

And spare me the myth that Java is just “waiting patiently” while other languages make mistakes so it can deliver the perfect version later. That’s revisionist nonsense, a post-hoc excuse for Java’s chronic feature lag. If anything, Java’s track record is littered with half-baked or completely missing features. Pick your poison: generics, lambdas, null safety, traits, delegation, member literals, properties, optional parameters, operator overloading, serialization, lazy values… the list goes on.",2025-04-04 20:03:19,5,manifoldjava,programming
mlubhur,1jqwygg,reddit,"> Existing generic code will occasionally resort to unchecked casts when it knows something about runtime types that the compiler does not, and there is no easy way to express it in the generic type system; many of these techniques would have been impossible with reified generics, meaning that they would have to have been expressed in a different, and often far more expensive, way.

It would be interesting to see examples of techniques that are impossible with reified generics.",2025-04-07 10:35:54,1,Linguistic-mystic,programming
mlclao0,1jqwygg,reddit,[deleted],2025-04-04 10:01:52,-4,N/A,programming
mlbftc0,1jqwygg,reddit,"People who think erasure is a terrible idea need to read this article from one of the most respected language designers.

Erasure is a great choice for languages that are open to evolution and interfacing with other languages.",2025-04-04 03:34:29,-20,devraj7,programming
mkxmrul,1joyi4l,reddit,"does this support  math output? Or is that not supported yet? Boy, if this does support math output and equations, it'd be stupidly nice for building up a quick math presentation. I know tools like Jupiter or colab can do it in markdown directly, but being able to output PDF and HTML document with accessible math formulas in HTML mode would be super nice.
Edit: weird spelling/grammar",2025-04-01 22:43:01,3,blind_ninja_guy,programming
mkwlatw,1joyi4l,reddit,This is bloody genius! Thank you for your hard work! Death to LaTex!,2025-04-01 19:23:26,4,randomguy4q5b3ty,programming
ml2j72k,1joyi4l,reddit,I'm using Quarto with RStudio and I have run into trouble with LateX export. Could I use Quarkdown for generating PDFs?,2025-04-02 18:52:48,1,hoedownsergeant,programming
morzzqp,1k6px9m,reddit,"I made a TinyWeb for java https://github.com/paul-hammant/tiny - about the same lines of code (ignoring `}` and alike. Web endpoints and WebSocket endpoints, no deps. **I'm only commenting as it's two things the same as yours - name and LoC**. And mine will have a lower capacity for concurrent incoming requests with more RAM usage, of course.",2025-04-24 12:27:27,26,paul_h,programming
moxez9l,1k6px9m,reddit,I see you're manipulating the DOM through JS with a thin wrapper `Js::invoke`. Have you considered using WASM reference types or tested it?,2025-04-25 06:24:39,3,BibianaAudris,programming
mort8r6,1k6px9m,reddit,"It is too verbose to be used to do what we already have good frameworks that are far easier to rampup and show results. There has to exist a reason and you must show trade-offs.

Create an example that can only be implemented in rust to provide a good User Experience. Make the same example using Vue/Svelte/React to show benchmarks in certain areas like the js frameworks benchmark that compares several things between pure js frameworks.",2025-04-24 11:42:52,23,Positive_Method3022,programming
mou7gc8,1k6px9m,reddit,"Since it's WASM you're using, this can be done using any language it can compile. Not to belittle your work or anything, but the point of React/Vue/AngularJS and whatnot is them being component-oriented. What your examples show is manipulating DOM with **%your_favourite_language%** and you could already do that 15 years ago without WASM using ExtJS (yes-yes, still javascript, but og JS isn't rocket science) or using GWT/Wicket with Java.

Now if your framework supported *defining* visual components, their lifecycle and rendering in a HTML/JS-agnostic way (how we did in AS3 for example) - that would have been something very interesting indeed.",2025-04-24 19:00:36,4,zam0th,programming
mors7dy,1k6px9m,reddit,"This look really interesting, a start to do a check after 👌🏻",2025-04-24 11:35:31,2,Heavy-Blacksmith4411,programming
mof5k4z,1k534h4,reddit,yet they say we should work at the office,2025-04-22 12:34:17,18,markiiitu,programming
moi3j1o,1k534h4,reddit,Imma take a wild wild guess. Two words: “proper logging.”,2025-04-22 21:29:29,1,this_knee,programming
mmxk4jy,1jy57q7,reddit,Amen to that! The number of systems and programs I see where people decouple for the sake of decoupling until the codebase becomes cryptic and unnatural to follow.,2025-04-13 18:01:06,19,alim0ra,programming
mmxyxdl,1jy57q7,reddit,"I would argue that, to a certain degree, loose coupling is just a natural consequence of getting cohesion right.",2025-04-13 19:19:22,7,pdpi,programming
mmkhd6n,1jvxk5r,reddit,Anyone actually using this in production ?,2025-04-11 14:29:02,4,running101,programming
mlbthng,1jr3xz7,reddit,Kudos for the great content and animations! Keep doing more of those,2025-04-04 05:23:00,3,DevGrohl,programming
mlbrriw,1jr3xz7,reddit,This is exactly the hard hitting programming content I come to /r/programming for.,2025-04-04 05:07:54,7,BlueGoliath,programming
mldpq14,1jr3xz7,reddit,"I’ll be honest, I’m not sure I understand the premise of the article - the behavior of the example at the start and in the conclusion is indistinguishable from one another. What am I missing?",2025-04-04 14:35:38,1,Chisignal,programming
mna9pn7,1jzt762,reddit,Can't wait for someone to get origami to run Doom.,2025-04-15 19:25:40,19,BennyLee,programming
mn8u20g,1jzt762,reddit,"> While it is likely that rigid origami is also Turing complete as a computational device, to our knowledge
no one has proven this. The crease patterns and gadgets in the present work are not rigidly foldable and
therefore could not be used as-is in such a proof.

Might as well give it a go if you need an academic publication under your name.",2025-04-15 15:09:37,14,Skaarj,programming
mmsolod,1jxo0gz,reddit,"The Blackboard pattern is underutilized in modern system design, especially for high-performance, low-latency applications. This implementation is particularly interesting because it addresses several common challenges with IPC:

1. The zero-copy approach eliminates a major performance bottleneck in traditional message passing
2. The shared memory design avoids serialization/deserialization overhead
3. The architecture supports both one-to-many and many-to-many communication patterns

I've seen similar patterns implemented in high-frequency trading systems where nanoseconds matter. The key insight is treating memory as a communication mechanism rather than just storage.

One challenge with this approach is handling process crashes - when a process dies while holding a lock or mid-write, recovery can be complex. Some production implementations add fault tolerance through watchdog processes or transaction-like semantics.

For those interested in this area, it's worth also looking into lock-free data structures and memory-mapped files as complementary techniques. The LMAX Disruptor pattern also solves similar problems with a slightly different approach.",2025-04-12 21:16:09,11,traderprof,programming
mmvl5ue,1jxo0gz,reddit,"More examples and more code than actual description of the pattern ...

It'd be helpful to start with a description of the pattern (e.g. the data structure and its api), then discuss how it applies to the examples provided. All I got was that two very different scenarios require a shared global state and that the blackboard pattern somehow addresses that.

So it's a shared in-memory key-value store with subscriptions at the key level? What are the downsides? How are concurrent writes handled? What's the consistency model?",2025-04-13 10:56:58,4,GeorgeS6969,programming
mmwv6zb,1jy78vm,reddit,"Well some people are just better than I am at this programing lark. ""I'm going to define my own executable format that allows zero-length files to return a value based on the ASCII of their filename. And I'm going to use a crown emoji as the extension. Why? Why not?"".

So making a file with an asterisk as the filename (ASCII 42, and also just a fundamentally evil concept anyway) does the following

    $ touch '*.♚'
    $ chmod +x '*.♚'
    $ './*.♚'
    $ echo $?
    42

diabolical. Wish I had thought of it",2025-04-13 15:52:56,8,Advanced-Essay6417,programming
mmaj99w,1jvi6sd,reddit,"Doesn't HTTP3, (ie QUIC) , solve this already?",2025-04-09 22:29:58,5,Lachee,programming
mm039ho,1ju880g,reddit,"People like Shannon and Conway are brilliant moments of hitting a ""singularity"".",2025-04-08 08:19:04,3,bluefourier,programming
mm3t8il,1ju880g,reddit,"Huh, wild smullyan reference.",2025-04-08 21:24:47,1,Blecki,programming
mlq6e28,1jsx4ef,reddit,"This discussion reminds me of assurance levels from when I worked in aerospace. Based on the criticality of how a system was intended to be used, it would be assigned an assurance level, which would dictate the rigor needed in the development process, covering things like what activities were necessary, what activities needed to be done with independence, and what artifacts needed to be available to demonstrate that the activities were done. The assurance level would need to be met or exceeded by everything in the system, from operating systems up to custom software. If you didn't know the assurance level or an element was at a lower assurance level, there were ways to ""backfill"" the missing steps through various verification and validation activities.

This is also where the concept of software of unknown pedigree or software of unknown provenance comes in. For a lot of software, especially general-purpose software, you don't know who built it, how it was built, or have any assurances about its quality or fitness for a particular use. This can require a lot of effort, to the point where it could be easier and cheaper to build custom solutions.

It is crucial for software product development organizations to understand their current and possible future customers, especially when making software packages targeting horizontal markets. Awareness and informed decision-making can help open up new markets for tools. Even if the development organization isn't targeting safety-critical applications, understanding how their product could be used in these contexts and thinking about what could be done to ease customers' legal and regulatory burdens can lead to new business.

Going to the specific example, tools like [MATLAB have tool qualification and certification packages](https://www.mathworks.com/help/slcheck/tool-qualification-and-certification.html) that make it easier for the user to get the information they need to use in contexts requiring assurance more easily. But these don't have to be provided by the tool creator. Some companies have done a lot of the legwork to put together the packages for some open-source tools. But other tools haven't had anything done at all, so you'd either have to avoid them or put in the effort.",2025-04-06 17:10:44,29,TomOwens,programming
mlprsu5,1jsx4ef,reddit,"I know, let's put 'AI' on the problem.

[Now you have two problems](https://regex.info/blog/2006-09-15/247).

[Reified reference](https://xkcd.com/1171).",2025-04-06 15:51:57,3,church-rosser,programming
mlqdymd,1jsx4ef,reddit,"For anyone that wants to study these questions seriously; these are not answers you have to dream up yourselves. There are all sorts of standards that regulate how to use and develop software in a safety-critical context. 

An example is [ISO 13849](https://en.m.wikipedia.org/wiki/ISO_13849). Doesn't tell you much without the surrounding related standards though. 

On a deeper level, there's e.g. MISRA C, which tells you what you have to do to actually code safe software in C. A few other alternatives exist. 

Looking at MATLAB specifically, it has the ability (with the right licenses of course) to generate C code that follows MISRA C, and can be used in a safety-critical product, if all rules and regulations are followed. Plenty of automotive systems are coded in MATLAB.",2025-04-06 17:50:03,6,Etni3s,programming
mlpxq3m,1jsx4ef,reddit,"Software by itself is a sequence of 1s and 0s.  It only contributes to hazards when it's surrounded by a system that interacts with the physical world.  It's the system that gets evaluated for safety.

The distance from the software's output to the hazard determines how much effort needs to be employed to verify the software's correctness and robustness.  For example, if people directly take the spreadsheet output as gospel, then it would need to be developed at the highest software assurance level.  If there are independent calculations being done, then the software assurance level may go down.

All code on the computer system that interacts with the physical world is part of its overall software, so it can all potentially contribute to a hazard.  Thus, Excel and MATLAB in the examples would be part of the software that would need to be evaluated.  Since those programs aren't written to any safety assurance level for any standard, they are poor choices for implementing the safety-significant function.

Lots of software can become unintentionally safety-critical such as databases.  Case in point: a medical database that stores the patient's blood type.  Failure to produce the correct result may be fatal during a blood transfusion.",2025-04-06 16:24:12,3,gpcz,programming
mlu8jcc,1jsx4ef,reddit,"This raises an interesting point:

> If calculating dosages in a spreadsheet is too dangerous, what would we recommend instead?

Using a pocket calculator, phone or even doing the calculations in your head are probably no less prone to error... Having a ""don't use Excel for safety-critical calculations"" policy could easily lead to _more_ errors.

I do note that the spreadsheet shown does have a ""checked by"" column; presumably the associated procedures would ensure that another competent individual checked the calculations by _a different method_. Additionally, the checker should probably be experienced enough to know instinctively what the right ""ballpark"" dosages are.",2025-04-07 10:06:54,1,mallardtheduck,programming
mlundw9,1jsx4ef,reddit,"You don't delegate safety to software and you don't present software in a way that might lead humans to think you have. 

Most people understand how Excel does math. People who work with fentanyl dosing know the risks associated and have been trained to verify these. 

A common error is messing up unit conversions, particularly between milligrams and micrograms, and the difficulty representing the Greek mu character in systems with ASCII character encoding (yes they still exist). 

So the Institute for Safe Medication Practices recommends that micrograms be represented in clinical systems as mcg instead of with the IU standard mu. 

Some systems enforce this, but all trained professionals check this, every time.",2025-04-07 12:12:35,1,spinur1848,programming
mk540bk,1jl8zxk,reddit,For anyone curious it is about 75k pages.,2025-03-28 05:56:54,4,nivvis,programming
mk54i4c,1jl8zxk,reddit,"Did you figure out who did it?? Hah. Cool stuff though. I was just doing something similar.

You should check out building a knowledge graph, there’s a lot of interesting new ideas and tooling there.

For semantic, is pinecone just abstracting something like rerank search, or? If not you might consider semantic + rerank, though maybe that works better for something like code. How are people liking pinecone btw? Been using qdrant and it’s fine — fast but pretty barebones. Also tried some of the Postgres tooling and it’s pretty decent.

I was just processing 40k pages overnight (the original McClellan Committee / Teamsters archive) and am debating what to do with it. I think I will try some sort of hierarchical summary maybe + RAG.

Cool stuff.",2025-03-28 06:01:44,2,nivvis,programming
mk8whke,1jl8zxk,reddit,We need an LLM for this.,2025-03-28 20:32:33,-1,dhlowrents,programming
mnufti4,1k2b2ee,reddit,"I'm always surprised no one elaborates on the big gotcha with `set -e` the post mentions where it doesn't work if youre in a conditional. idk I don't have a good example ready but let's pretend we're wanting to create a bunch of files in a specific directory and rely on `set -e` to bail out early and not create files if we can't actually get into the directory we want.

    set -e

    mkdir blah
    cd blah
    touch bunch of files within blah

It's gonna stop if `blah` already exists and is not a directory like we'd want:

    $ bash ~/foo.sh
    mkdir: cannot create directory ‘blah’: File exists
    $ ls
    blah

Now pretend we're trying to be extra tidy about it and put everything into a function, so we can easily check if it succeeded:

        foo() {
                set -e

                mkdir blah
                cd blah
                touch bunch of files within blah
        }

        if ! foo; then
                echo >&2 ""couldn't create a bunch of files within blah""
        fi

Then everything is a mess because it created those files in the current directory:

    $ bash ~/foo.sh
    mkdir: cannot create directory ‘blah’: File exists
    ~/foo.sh: line 5: cd: blah: Not a directory
    $ ls
    blah  bunch  files  of  within

Obviously you don't want `set -e` to cause the script to exit when you do, like, `if thing-that-sometimes-fails; then`, but completely breaking it in any environment that's not even lexically within the conditional is such a big limitation on program structure I'm surprised it's not discussed more.",2025-04-18 23:42:08,8,ben0x539,programming
mo2qwii,1k2b2ee,reddit,"Common shell script mistakes:

1. Not using ShellCheck",2025-04-20 11:38:26,3,XNormal,programming
mo4b1zk,1k2b2ee,reddit,The biggest mistake is using shell where you need a real language.,2025-04-20 17:15:39,1,gofl-zimbard-37,programming
mo2cihh,1k2b2ee,reddit,"I honestly don't write bash scripts anymore, if a problem is too complicated for AI to figure out in a couple of prompts then it probably shouldn't be a bash script.",2025-04-20 09:13:35,-1,bigdamoz,programming
mlpwa94,1jsqato,reddit,fun read,2025-04-06 16:16:24,7,press0,programming
mltb292,1jsqato,reddit,"Too bad there was no resolution. Not saying the author had to, but without it it feels pretty depressing. But great observation on why the process feels so broken.",2025-04-07 04:27:42,4,reddit_wisd0m,programming
mltxmds,1jsqato,reddit,"Interviewing is hard, making a mistake is catastrophic, and there's no clear best practices. It's why referrals are given so much weight - in a sea of strangers, even an average acquaintance stands out.",2025-04-07 08:05:51,3,hbarSquared,programming
mltr6vv,1jsqato,reddit,"Interview process is a job

The more interview process looks like the actual job, the less it will fell like a job - because it just 2-3 hours of the usual job you are already doing at your current job

However, the interview process is created by people who don't do the real job and they are just copy pasting from the internet - how big companies are doing their interview process, while giving less money then the big companies

Is interview process broken ?  
Yes

Can we fix it ?

Well, in order to fix it - you need to hire competent people that know what the hell is going on in your company and hire them with your current interview process

  
and there a lot of incompetent people who think they know how to do interview process",2025-04-07 06:56:43,2,gjosifov,programming
mou4ic5,1k6uhjo,reddit,What do you know about the halting problem?,2025-04-24 18:46:25,20,beders,programming
mou9nh3,1k6uhjo,reddit,"The sandbox necessarily exposes the Linux kernel, so it's not completely safe.",2025-04-24 19:11:21,15,KrazyKirby99999,programming
moxl96q,1k6uhjo,reddit,"Interesting, you used containers for sandboxing. Have you thought about a VM like firecracker? It would be slower to run the code, but more secure, definitely a tradeoff.",2025-04-25 07:26:54,2,TonTinTon,programming
mosxv05,1k6uhjo,reddit,"The idea was to create an MCP server with multiple tools, i.e., ""sandboxes,"" i.e., constrained Docker containers.

When an LLM wants to run some code or isn't sure if the code it generated is correct, it can call the MCP proper sandbox from the MCP server, run the code, and return the response.

This can help reduce errors from LLMs, as they can first test the generated code inside the isolated sandbox before responding to the user.

The best part is ANYONE can easily create sandboxes with just a Dockerfile and a JSON configuration. There are docs and enough examples in the repo to guide you.

This project is written in Go and uses the excellent MCP Go SDK (mark3labs/mcp-go).

I would love to get some feedback before adding more features and sandboxes. Both positive and negative feedback are appreciated.

Hope this is useful!",2025-04-24 15:25:34,4,lungi_bass,programming
mowe6y4,1k6uhjo,reddit,"There are some concerns in the comments about security, so I think it is best if I clarify how things work:

1. The sandbox creator configures how a sandbox, i.e., the Docker container, will run. They can set the container to read-only, drop kernel capabilities, set process limits, isolate it from networks, set hard timeouts to kill the container, etc.
2. The AI only has access to a limited API, which essentially allows the AI to pass the file to be run. For example, in the ""go"" sandbox, the AI can provide the `main.go` file and the `go.mod` file. That's it. Even if the AI messes things up, it cannot go beyond the limits set by the sandbox creator (of course, Docker has vulnerabilities, but practically this works well).

See an example configuration file to clear things up: [https://github.com/pottekkat/sandbox-mcp/blob/main/sandboxes/shell/config.json](https://github.com/pottekkat/sandbox-mcp/blob/main/sandboxes/shell/config.json)

This is an example of a request from the AI to the MCP server:

    {
      `go.mod`: `module example
    
    go 1.20
    `,
      `main.go`: `package main
    
    import \""fmt\""
    
    // findMax returns the larger of two integers
    func findMax(a, b int) int {
    	if a > b {
    		return a
    	}
    	return b
    }
    
    func main() {
    	// Test cases
    	fmt.Println(\""Maximum of 5 and 10:\"", findMax(5, 10))
    	fmt.Println(\""Maximum of 20 and 7:\"", findMax(20, 7))
    	fmt.Println(\""Maximum of -3 and -8:\"", findMax(-3, -8))
    	fmt.Println(\""Maximum of 0 and 0:\"", findMax(0, 0))
    }
    `
    }",2025-04-25 02:01:09,1,lungi_bass,programming
mol7nt3,1k5vp1n,reddit,"Thats the easiest thing in the world. Hire someone who isnt qualified and doesnt know what theyre doing, has character flaws and deficiencies, and put them in charge",2025-04-23 11:11:23,10,StarkAndRobotic,programming
mnwsyzf,1k2b02n,reddit,"> The net result of this is that with only a **tiny amount of extra thought** you get garbage collection **for free**. Extend this to other concepts in your program with the **appropriate use of Pool allocators, Bucket allocators, and the likes**, and suddenly you get impressive performance improvements and a **fair amount of memory safety** for very little effort. 

this isn't garbage collection or memory safety, this is using memory allocators lol",2025-04-19 11:28:21,51,floodyberry,programming
mnub8ck,1k2b02n,reddit,"Some weird takes in this. The interface example is precisely not an interface since it copying the data layout of a type and interfaces are precisely useful because they decouple the data from the transformation 

The author seems to indicate that raii is a downside when it's one of the few things that C++ actually did really well? `defer` not only is something you can forget, but also makes code harder to read if you use it as you're supposed to (that is, far away from actual construction since presumably that's advantage of decoupling it from construction) 

On a more subjective note it seems jai doesn't support sum types? That's a huge downside. Also, `foo :: (x: [$N]$T)`  is hella ugly",2025-04-18 23:14:42,37,teerre,programming
mnzbbat,1k2b02n,reddit,"If you tried Zig and thought, “I like this but it needs to be closed-source and have an insufferable, condescending creator & no community,” then Jai is for you!",2025-04-19 20:08:48,42,Capable_Chair_8192,programming
mo2smcu,1k2b02n,reddit,"> no RAII in 2025

🤦‍♂️",2025-04-20 11:52:45,10,SuperV1234,programming
mo5nd8w,1k2b02n,reddit,"> It’s a serious language being made by adults, for adults. For serious programmers, by serious programmers.

Lol, lmao. We've already got Common Lisp, the ideal language for ""recursion and condescension"".

We don't need another. I'm surprised the author didn't mention Blub languages.",2025-04-20 21:39:44,3,BroBroMate,programming
ml53yt2,1jplgsq,reddit,"The only thing I didn't get: was it a dedicated native window? Because usually in web world (chrome/cef/electron/etc) popups aren't native windows but just a piece of html with a different z-offset rendered within the main content window. And obviously, you wouldn't see a popup in Spy++.",2025-04-03 03:16:51,1,ioneska,programming
mla4yri,1jplgsq,reddit,Does it prevent changing Teams status? Asking for a friend.,2025-04-03 22:41:14,1,randomlogin6061,programming
mla8wj1,1jplgsq,reddit,"One of the ones I've seen over & over again, just using powercfg is the steam application. Not always, I think it has something to do with the embedded web view on the store page marking the process with ""thou shalt not sleep"" and crashing or unloading before it can undo",2025-04-03 23:03:45,1,tswaters,programming
ml53gbb,1jplgsq,reddit,"TLDR:

* playing a video prevents sleep (an obvious feature of all video players) 
* closing a window in CEF doesn't release its resources (well, it's electron - what else would you expect)",2025-04-03 03:13:23,-1,ioneska,programming
mn4nvhu,1jz0and,reddit,"C vs. Pascal was a major component of the Windows vs. Mac developer community conflict up through the 90s.

Pascal did evolve over time, and plenty of serious applications were developed with it. Early versions of Mac OS (up through, if I remember right, System 7.5) featured a lot of Pascal, especially in the extensive developer documentation.

Pascal developers loathed C's messy syntax and there were quite a few die-hards who tried to keep the language vibrant. I was one of them!

I still remember going to a local Mac Users Group meeting in the early 90s, and learning about object-oriented programming for the first time. Pascal quickly made the jump (""Object-Oriented Pascal"", of course). I thought it was all terribly dumb, but that was in part because early advocates for OOP insisted that objects could only interact by passing ""messages"" to each other. Early OOP was slooooow.

In those early days of computing, Pascal's length-prefixed strings were pretty nice, up until you had to come up with clever ways around the 255-byte limitation. Still, C's null-terminated strings seemed like a terrible idea (and still do).

It was a nice language for simple console-based programs. There was minimal fuss needed to just accept some input, do something with the input, and print some output.",2025-04-14 21:16:13,24,gottago_gottago,programming
mn30ezy,1jz0and,reddit,I only programmed in later version of Pascal/Delphi. There the issues with `string` were not relevant as you treat it as an opaque type. I'm remember sorting just working. So the `The size of an array is part of its type` issues were solved as well (I assume at the language level).,2025-04-14 16:19:02,8,Skaarj,programming
mn7f5g6,1jz0and,reddit,"You can have complaints about Pascal, but this largely reads like a C user whining that Pascal is not C.",2025-04-15 09:25:04,5,simon_o,programming
mn9r1w6,1jz0and,reddit,"Standard Pascal was a rubbish language.  Standard C would have been rejected as equally rubbish if the definition of ""conforming C program"" didn't allow programmers to exploit all of the ways in which practical C implementations behaved more usefully than the Standard required.",2025-04-15 17:51:52,2,flatfinger,programming
mn7qq40,1jz0and,reddit,"What a shitty paper, honestly.

Extremely shallow.

More of a c programmer’s rant of not adapting to a different language.",2025-04-15 11:15:20,-1,therealdivs1210,programming
mn7rrky,1jz0and,reddit,"Is it true that pascal doesn’t have array routines?

This sounds like a really bad design decision, and one that would show it’s ugly consequences soon enough to be corrected.

I have a feeling the author of the paper didn’t find the pascal way of doing things?",2025-04-15 11:23:30,0,therealdivs1210,programming
mn2ipv7,1jz06gy,reddit,"Pretty cool! Who is the target audience?

When I think lua, I think scriptable clients like game devs might use to control a critter. I don't think artists and non-technical collaborators would have an easier time with fennel, but this is my first time looking at the project.

I'm excited to take a closer look. This is a fun project",2025-04-14 14:49:47,20,pbNANDjelly,programming
mn4zvcp,1jz06gy,reddit,There can never be enough lisps out there,2025-04-14 22:22:43,2,AcanthisittaScary706,programming
mn74wek,1jz06gy,reddit,I’m afraid I find [Moonscript](https://moonscript.org/#overview) more bitchin’,2025-04-15 07:32:23,2,Linguistic-mystic,programming
mnb14jr,1jz06gy,reddit,"As a gamedev programmer, I see the benefit. Lua is usable anywhere and lisp is great at making dsls, which is very useful.

For example, I believe Naughty Dog uses their own flavor of lisp and they use it for a wide array of things AI, Animation, Scripting etc",2025-04-15 21:43:39,2,totallytroy,programming
mn2icbb,1jz06gy,reddit,"Looks like a fun project, but honestly I cannot take seriously anyone who wants to write lisp for anything serious. I have tried doing this myself and it was miserable.",2025-04-14 14:47:52,5,Awesan,programming
mn6fow8,1jz06gy,reddit,"Everytime I look at a Lisp language, I think giving it a chance. But then, it's like, you gotta switch to Emacs, or use a complicated plugin that messes all your keybindings, and setup the REPL, and it's just a pain to deal with.


I guess it's just beyond my grasp. 


Like the idea of the project though.",2025-04-15 03:40:29,1,nelmaven,programming
mn3byj7,1jz06gy,reddit,This subreddit is just bots commenting to bots arguing about AI,2025-04-14 17:16:27,-12,NoleMercy05,programming
mn2eob1,1jz06gy,reddit,Tldr or no one is clicking that,2025-04-14 14:28:42,-46,NoleMercy05,programming
mmcuvwm,1jvssmp,reddit,"That was a good read. Really interesting!

> While many frameworks push for totally decentralized designs, iroh strategically incorporates limited centralization

How does that work?",2025-04-10 08:39:36,6,imported_username_,programming
mmhulfa,1jvssmp,reddit,Love that it’s likely named after uncle iroh ( maybe ),2025-04-11 02:00:32,1,flarthestripper,programming
mmcud0f,1jvssmp,reddit,Great post!,2025-04-10 08:33:38,0,ThenTumbleweed4474,programming
mmfwlps,1jvssmp,reddit,Impressive technology,2025-04-10 19:32:33,0,faustoc5,programming
mof3nxr,1k528l8,reddit,"I had to write code for processing Apple Pay payment tokens which involves a fair amount of crypto handling, and there are specific details for Apple Pay to make the whole thing work. I had no clue how to even start. I did everything with a mix of Copilot, Claude, ChatGPT, Grok, and a bit of stackoverflow. It was painful because the LLMs most of the time generated garbage code that didn't work, but after a few days it started working. Anyway my point is, when I was done I still had no clue how the whole thing works, and that troubles me deeply because if I'm ever asked to explain it or to replicate it, I'll be toast. I can't even put Apple Pay experience in my resume because if a recruiter asks any question about it I'll be unable to answer.",2025-04-22 12:21:50,6,bring_back_the_v10s,programming
moekhef,1k4ixn9,reddit,"The implicit subtext here is that somehow Zig has a tasteful subset of comptime.

However, Zig’s comptime is remains fairly opaque to IDEs. In particular because types are created at compile time, an IDE will struggle to do simple refactorings.

Secondly, Zig’s ”only check what is traced to be used” (so that a function which isn’t detected to be called will not be semantically, checked - it’s like a macro that’s never called: it can look like almost anything) is both novel and bad. This latter thing is acknowledged in blog post but not highlighted.

This essentially means that Zig drops to a dynamic scripting language in terms of what one can infer by something compiling (as most people knows, uninvoked code in scripting languages aren’t even guaranteed to compile)

This is by design, as this is Zig’s way to implement conditional compilation.

Zig *could* have chosen to do conditional compilation in a more clear and conventional way, but this too is ”things that Zig comptime won’t do”: being clear about what code is actually type checked.

The conflation of runtime and compiletime code in if statements, and this ”branches/functions not taken are not checked” makes Zig comptime unnecessarily difficult to read.

(Disclaimer: I did in the past submit feedback on Zig issues to improve the readability of Zig ”comptime”. When I later started working on C3 I made sure that it would be extremely clear as to what was runtime and what was compile time code)",2025-04-22 09:44:39,15,Nuoji,programming
moav8pr,1k4ixn9,reddit,"Just a small detail, in the ""No #eval "" section it starts mentioning D's mixins, then says:

> Zig has a completely different feature, partial evaluation/specialization, which, none the less, is enough to cover most of use-cases for dynamic code generation.

Then proceeds to describe how to use `comptime` as a keywork in parameters. So it seems like he assumes that in D you would use `mixin` in order to get that variable evaluated at compile time?

But nobody would do that, in D you just use `static if` (evaluate the condition at compile time). Once you do `static if` (or static foreach, or static assert) on a variable, it will be evaluated at compile time.",2025-04-21 18:56:18,5,EnUnLugarDeLaMancha,programming
mnwv5gd,1k2ayyz,reddit,Love this. Any other relevant repos which are equivalents for this for other languages?,2025-04-19 11:46:40,0,RamboCambo15,programming
mkszyd4,1joh0xq,reddit,"Looks like a very cool language.
The docs are very straightforward and include crucial things like

- interop with racket
- building standalone executable
- how to unit tests, etc

Just one question to OP, are there any performance benchmarks?",2025-04-01 04:07:00,6,getaway-3007,programming
mkt5ryr,1joh0xq,reddit,Didn’t find the “error handling” chapter in the reference. Does Rhombus prevent all errors?,2025-04-01 04:54:50,4,Linguistic-mystic,programming
mkze5pn,1joh0xq,reddit,"Seems to provide the syntaxic simplicity of javascript and python with the guidance of typescript, all while maintaining scheme semantics. Pretty cool",2025-04-02 06:00:16,3,funkie,programming
mkrp430,1joh0xq,reddit,"Rhombus is ready for early adopters.  
Learn more and get it now at [https://rhombus-lang.org/](https://rhombus-lang.org/)",2025-03-31 23:08:41,3,sdegabrielle,programming
mktbaef,1joh0xq,reddit,Year of the Rhombus esolang.,2025-04-01 05:46:05,0,BlueGoliath,programming
mjuwbln,1jkf480,reddit,"If you're linking the new features link the actual java documentation, rather than these watered down garbage reinterpretations

https://www.oracle.com/news/announcement/oracle-releases-java-24-2025-03-18/",2025-03-26 16:34:04,72,Worth_Trust_3825,programming
mjur072,1jkf480,reddit,No longer the students need to dance their fingers typing public static void main string args,2025-03-26 16:08:11,53,__Blackrobe__,programming
mjw5oc7,1jkf480,reddit,">game changing


lmao",2025-03-26 20:12:10,21,BlueGoliath,programming
mjvs09h,1jkf480,reddit,"downvoting for not even getting basic example right smh
```java
void main() {
    var name = readln();
    var message = “Hello, World and “ + name;
    println(name);
}
```",2025-03-26 19:05:23,10,ryo0ka,programming
mk2t0hf,1jkf480,reddit,"Awesome, I just added support in compiler explorer for java 24",2025-03-27 21:35:18,1,12destroyer21,programming
mjxe3ku,1jkf480,reddit,"Amazing, catching up with language features from the 2000s!",2025-03-26 23:54:31,-8,UloPe,programming
mn837vg,1jz0umd,reddit,Stark contrast with the « for dummies » brand,2025-04-15 12:42:57,2,My_reddit_account_v3,programming
mnn7xf7,1jz0umd,reddit,Mad man :-),2025-04-17 20:11:18,1,Jabes,programming
mn3uxsu,1jz0umd,reddit,"Seems more like tracking (as in Trackerz) rather than programming.  

Still neat but probably better suited to r/edmproduction than r/programming",2025-04-14 18:49:20,-7,church-rosser,programming
mjwgux6,1jki3vg,reddit,"The most important qualities:

- Lots of title-case subheadings
- Bulletpointed lists with bolded leading phrases
- Em-dashes
- A complete lack of meat on the bones; lots of structure and fluffy details without reference to the hard problems of engineering or technical documentation",2025-03-26 21:02:32,14,Saint_Nitouche,programming
mjvpjxc,1jki3vg,reddit,[deleted],2025-03-26 18:53:30,3,N/A,programming
mompwrg,1k636c4,reddit,CS Shell,2025-04-23 16:16:18,19,Gladamas,programming
momw278,1k636c4,reddit,"I quit at 😭: 

>Nice thinking. Unfortuantely for you, *animation*, *offset*, *perspective*, *scale*, *transform*, and *translate* are forbidden.",2025-04-23 16:46:18,5,elemental-mind,programming
momqq40,1k636c4,reddit,Fun.,2025-04-23 16:20:19,3,bkervaski,programming
moqbm3j,1k636c4,reddit,"[https://x.com/JosephKertz1/status/1915250339281772768](https://x.com/JosephKertz1/status/1915250339281772768)

  
fun and challenging! 🤩",2025-04-24 03:45:42,1,JosephKrzy,programming
mov23nd,1k636c4,reddit,"\#3 was just >!`flex-direction: row-reverse`!<, which seems a bit too easy to me? I think it was supposed to be more difficult.",2025-04-24 21:33:08,1,LucasOe,programming
mmevdr0,1jw1n7k,reddit,Props for the approach here. I've seen someone explain \*what\* the Y Combinator is lots of times. Explanations for \*why\* I would care or need it are less common or satisfying. This one seems pretty good.,2025-04-10 16:31:12,12,thicket,programming
mmh1umi,1jw1n7k,reddit,"Very cool!

For those interested in the topic, [code_report](https://www.youtube.com/@code_report/featured) on youtube has a lot of videos about combinators (including short videos using combinators to solve leet code style problems and longer deep dives into theory)",2025-04-10 23:06:20,3,Sufficient_Meet6836,programming
mmfqvl7,1jw1n7k,reddit,"This post took me back to college in a big way. It might be my age but I did feel like I lost some details at a certain point. I am not a python dev. So I am a bit lost on the lambda keyword. The examples around currying look, to me, the same as just writing it recursively. It has been almost 20 years since I’ve written lisp so I’m assuming by using the lambda keyword you get tail recursion or late evaluation (how old am I…)",2025-04-10 19:04:03,2,razialx,programming
mmizub8,1jw1n7k,reddit,"At the end when you note that function arguments are evaluated eagerly, could you perhaps use functools' partial() to get around the problem?",2025-04-11 07:39:27,1,ADavison2560,programming
mmozzji,1jw1n7k,reddit,"One of my favorite articles on Y Combinator and implementing fizz buzz: https://tomstu.art/programming-with-nothing

Presentation: https://www.youtube.com/watch?v=FITJMJjASUs",2025-04-12 06:31:35,1,amirrajan,programming
mkvjdxk,1jozcbn,reddit,How does this compare to optic?,2025-04-01 16:09:49,6,brianjenkins94,programming
mkxna1m,1jozcbn,reddit,"Automating API documentation is incredibly valuable, but I've found a complementary approach is structuring the documentation in a MECE way (Mutually Exclusive, Collectively Exhaustive).

The challenge with automated docs is often that they capture *what* happens but not *why* or the conceptual model behind the API. We've been using a hybrid approach where automation handles the technical details, while we maintain a MECE framework for the conceptual structure.

This significantly improves both maintainability and comprehension, especially when API behavior changes but the underlying concepts remain the same. The documentation doesn't just show the endpoints but helps developers understand the mental model.

If you're interested in this approach, I wrote about applying MECE principles to technical documentation: https://medium.com/@jlcases/mece-for-product-managers-the-forgotten-principle-that-helps-ai-to-understand-your-context-9addb4484868",2025-04-01 22:45:56,3,traderprof,programming
mkvshqv,1jozcbn,reddit,"Automation is valuable, but without a MECE (Mutually Exclusive, Collectively Exhaustive) structure, automatically generated documentation may have critical conceptual gaps. I shared some thoughts on how MECE principles can transform documentation for APIs and other systems in this article: https://medium.com/@jlcases/mece-for-product-managers-the-forgotten-principle-that-helps-ai-to-understand-your-context-9addb4484868",2025-04-01 16:56:47,-1,traderprof,programming
mklizyd,1jnp11w,reddit,Using Lisp for NLP is certainly a choice. Fun idea.,2025-03-30 23:03:36,4,itijara,programming
mkod6uj,1jnp11w,reddit,I initially read this as Uncovering Carrot Biases ...,2025-03-31 12:45:00,0,shevy-java,programming
mova67f,1k646bm,reddit,"> Fortunately, our good old friend List(x) = (1 - x)⁻¹ gives us List(2) = -1

Since 2 = { `false`, `true` } the Booleans, List(2) is isomorphic to ℕ (let f `[]` = 1, f (`false`: x) = 2 * f x, f (`true` : x) = 1 + 2 * f x); hence -1 = ℕ.",2025-04-24 22:16:24,2,notfancy,programming
mokyp7i,1k5pt17,reddit,I thought FD3 (`-fno-finite-loops`) would have a bigger impact and the result is quite surprising. Like on ARM with LTO it has a negative impact? Is it because people don't use numerical for loops as often as we used to?,2025-04-23 09:50:53,1,BibianaAudris,programming
mokcll2,1k5pt17,reddit,"Thanks for the link, this was a question that often troubled me, I did not understand why compilers by default do not define the behavior that was left undefined in the C standard due to architecture differences but rather make the results completely unpredictable. This paper appears to confirm my doubts.",2025-04-23 05:59:49,1,dravonk,programming
mnsya29,1k2b0rb,reddit,"> Note that these numbers are not expected to get significantly higher since a lot of these tests are not meant to be working in GPUs anyway

No broken windows!

Sounds like there is a huge opportunity to tag the ones that are expected to never work and exclude them. That would increase feedback on the remaining ones.",2025-04-18 18:45:18,4,Pyrolistical,programming
mngatxn,1k0owr6,reddit,"The question is all about how to balance bad reporting against hiding of data.  Where should the balance be set?

Allowing anybody to report a CVE gives too much noise and makes it hard to understand and find what is important.  Not to mention false reports or incorrect attribution of issues.  But, maintainers - especially corporations selling a product - are incentivized to hide CVEs.  I am in agreement that far.

But licensing and significant personal exposure to liability is not the right way to change that conflict.  

The pilots model - where there are severe penalties for failing to report incidents and no direct repercussions for self-reporting - would be a better one to emulate; though licensure for software engineering still doesn't make sense.  There's too much useful creations and contributions made by amateurs as well as by professionals that would never choose to certify or work under somebody with a certification.",2025-04-16 18:29:05,15,exjackly,programming
mnho0t8,1k0owr6,reddit,"Laughing that you managed to write an article about malware attributes and not mention ATT&CK. Like it sucks and it’s annoying, but that’s literally what it’s for. ",2025-04-16 22:44:20,4,usernamedottxt,programming
mo9lz10,1k0owr6,reddit,"How would licensing even work?

> We make certain types of software require a PSWE as an Engineer of Record.

Okay. Let's talk about Curl. Daniel Stenberg lives in Stockholm, Sweden. Curl is used worldwide, in over 200+ countries:

 1. Do you expect Daniel to obtain a PSWE license in over 200 countries; or more, if it's some large country it's a ""local"" certification?
 2. Or do you expect 200+ countries to come together and form a PSWE body?

I don't necessarily mean the _idea_ of PSWE is bad, but honestly, it seem wholly impractical.

I can't wait to see China & the US at the negotiation tables to define the rules of a PSWE body right now, in the middle of a tariffs war.",2025-04-21 15:00:26,3,matthieum,programming
mnk9yye,1k0owr6,reddit,"So, mixing the EU's CRA with engineer licensing? That sounds ideal, but unfortunately companies will lobby against the CRA, and programmers will help them lobby against the licensing.",2025-04-17 10:47:23,1,nelmaloc,programming
mniurp4,1k0oste,reddit,"I've seen this floating around a lot. I recognize a bunch of folks are working hard on a product they think is cool. It seems like they raised some VC money which is great for them. 


However there seems to be a big media push but not a clear actual product/ product market fit happening here. Some of their material makes it's seem like they are trying to be a database product but their SQL surface area is extremely lacking. No aggregate functions besides count. Limited expression support. No real useful functions. No CTEs. Only a handful of data types. 

But then they turn around and try and offer like a ""cloud for game developers"" they claim scalability and performance but I didn't see any concrete numbers. They claim their cloud offers uptime guarantees and SLAs but they are pretty handwaved. 

I'm kinda confused exactly what they're trying to be. 

I'm my mind I kinda see where they are going and it kinda goes something like this: 

* I have a bunch of game clients that want consistent state! 
* This sounds like ""transactions""
* Hey databases are transactional! Let's use a database
* Oh I can't really express the kinda things I want at the frequency I want using a client driven SQL interface 
* What if we put the game logic in the database as a bunch of user defined wasm functions! 
*  now my game clients can just query the state they need! 

 This sounds more negative than I intended. If this is solving their use case then great! I guess Id like to see some clarifications on the thing they are building. Are you trying to be a database? A cloud hosted database like thing?  Why would I trust uploading my games IP to your cloud service? Why would I trust it to be reliable or supported when the game they are building this for hasn't launched yet?",2025-04-17 03:01:22,26,coterminous_regret,programming
mni91pu,1k0oste,reddit,"It has been mentioned before but it sounded sketch the last time & does this time around as well. An account that very recently got active after 5 years of inactivity, a blog which also just started a month ago, and this whole post reads like a marketing ploy. For example:

>Their first release is going to be an MMORPG known as BitCraft, which is still in its development and testing phase, but has millions of players signed up.

But there seems to be no such official numbers, in fact the only thing which can be done as far as signing up seems to be to wish list on steam, and those numbers are far from millions. And the link to the MMO webpage is a referral link ( https://bitcraftonline.com/?ref=blog.slamdunk.software ), which also leads me to believe that this blog poster is in fact associated & just trying to market.",2025-04-17 00:48:12,29,Sairony,programming
mngf4wq,1k0oste,reddit,"> SpacetimeDB has enabled us to build our massively multiplayer game, BitCraft, with a small team. Its entire backend, including all game logic, real-time player positions, and all persistent state, is implemented as a SpacetimeDB module.

what the actual fuck",2025-04-16 18:51:06,24,shittalkerbot,programming
mnlcht8,1k0oste,reddit,"I saw them at GDC, they were pretty upfront about everything and had Bitcraft on demo. Seems great for small devs who want an all in one solution, I imagine large devs that already have cloud services setup won’t be interested.",2025-04-17 14:42:40,3,Xryme,programming
mnitf4h,1k0oste,reddit,"Feels kinda like Supabase but for games? Well, quite different in a few fundamental ways but there's some similarities in the value proposition.",2025-04-17 02:52:35,2,pizzapiepeet,programming
mnfqxs8,1k0oste,reddit,This is super cool.  Thanks for the article!,2025-04-16 16:53:50,0,Scyth3,programming
mmilmyk,1jwibq5,reddit,Oracle should first get their pre quantum cryptography correct before moving on,2025-04-11 05:19:48,42,Jmc_da_boss,programming
mmivyjc,1jwibq5,reddit,"This is actually a good read, was not expecting that from Oracle.  I don’t know what the future is, but it is wise to prepare for the possibility that these do become real.  Having said that, [this](https://www.cs.auckland.ac.nz/~pgut001/pubs/bollocks.pdf) is a fun read from a reputable skeptic.",2025-04-11 06:58:51,7,ScottContini,programming
mmj88mc,1jwibq5,reddit,"Post-quantum landed in OpenSSL 3.5 LTS. Thus it's a thing for everyone this year, regardless of actual quantum computing advancement",2025-04-11 09:09:47,3,xebecv,programming
mmirzwx,1jwibq5,reddit,"Oh good, is the hype wheel finally turning onto a new cycle, leaving LLMs behind for quantum computing? I guess we haven't had a quantum computing hype cycle for a while, could be fun to have one again.",2025-04-11 06:18:45,1,syklemil,programming
mlkdcvf,1js6ipu,reddit,Sounds nice. Is the source available to follow along?,2025-04-05 17:00:10,3,biehl,programming
mlm4i5b,1js6ipu,reddit,"Out of curiosity, why did you delete your previous post about Krep? Especially given there was some excellent feedback about errors and bugs from some well known individuals?

https://se.reddit.com/r/programming/comments/1jpk8sw/krep_a_blazingly_fast_string_search_utility/

Will the same happen to this post if constructive comments are proffered?",2025-04-05 23:01:54,1,sumwheresumtime,programming
mlr6trn,1js6ipu,reddit,I still want a universal editor!,2025-04-06 20:23:45,1,shevy-java,programming
mlknald,1js6ipu,reddit,I don't know what subs allow devlogs and I don't think it's a good idea to post here every week (or is it?) I created a sub to post in /r/boldedit/,2025-04-05 17:54:11,1,levodelellis,programming
mk22vq8,1jl4w0i,reddit,"I like a lot of the stack's ideology - server side rendering, HTMX instead of reactive components, AlpineJS instead of some do-it-all JS package. That being said, writing HTML inside rust with limited inteli-sense and having to compile when playing around with layout/content seems like a masochistic development process for anything other than super simple CRUD sites.

I see a stack of contradictions: simplicity is good VS let's compile HTML, find errors at compile time VS rendering generated from macros, focus on the essentials VS seemingly painful development pipelines. Even with me not ever wanting to use this stack myself, it's great to see people looking at alternative ways to escape the local minima web dev finds itself in, and looking at ways to make web pages load faster - respecting the users time.",2025-03-27 18:41:27,23,AHorridge93,programming
mjwhbkn,1jkg7bl,reddit,"Mistitled article. It should be:  
  
Collapse OS: Operating System for the end of the world.",2025-03-26 21:04:38,26,gordonv,programming
mjysx7f,1jkg7bl,reddit,"Let me real: A post apocalyptic computer will be whatever shit laying around still works. 

I’d love to think some old Commodore 64’s will be humanity’s computing saviour… but for fucks sake it’s literally gonna be whatever shit is laying around close to whatever nerd is alive and laying around who can figure out how the fuck to get anything working.",2025-03-27 05:29:43,13,Liquid_Magic,programming
mjwyb23,1jkg7bl,reddit,"Paywalled. I already know about these anyway, being something of a FORTH dabbler with Pico2 / Mecrisp FORTH.",2025-03-26 22:30:18,10,bravopapa99,programming
mjw59pm,1jkg7bl,reddit,"Isn't there a more C-like doom-friendly language? Please, no Forth, I'd rather get into the path of the asteroid and/or missile to get it over with faster.",2025-03-26 20:10:14,11,Zardotab,programming
mjxir8z,1jkg7bl,reddit,"Wired, stop spamming your articles to /r/programmjng.",2025-03-27 00:20:34,15,dex206,programming
mjwjopr,1jkg7bl,reddit,"I wrote a lot of Forth code, back in the day. The end of the world would be preferable to having to write more of it.",2025-03-26 21:15:15,7,gofl-zimbard-37,programming
mjuzsgw,1jkg7bl,reddit,[deleted],2025-03-26 16:50:48,2,N/A,programming
mjyv72d,1jkg7bl,reddit,Weathering software winter,2025-03-27 05:51:42,2,callmesun7,programming
mjuxo5o,1jkg7bl,reddit,"Once I started thinking about the apocalypse, it was hard to stop. An unsettling encounter with the doomsday clock that hangs over New York City’s Union Square got me frantically searching WikiHow for survival tips. I soon found my way to the doomsday writings of a Canadian programmer named Virgil Dupras. He believes the collapse of civilization is imminent and that it will come in two waves.

First, global supply chains will crumble. Modern technology relies on a delicate web of factories and international shipping routes that are exquisitely vulnerable to rapid climate change. The iPhone uses memory chips from South Korea, semiconductors from Taiwan, and assembly lines in Brazil and China. The severing of these links will, Dupras says, catalyze total societal breakdown.

The second part will happen when the last computer crashes. The complexity of modern hardware means it’s nearly impossible to repair or repurpose, and without the means to make new devices, Dupras believes there will be a slow blackout—less bang, more whimper. Routers die. Servers take their last breath. Phones crap out. Nothing works.

Except Collapse OS. Lightweight and designed to run on scavenged hardware, it’s Dupras’ operating system for the end of the world.

Read the full story: [https://www.wired.com/story/forth-collapse-os-apocalypse-programming-language/](https://www.wired.com/story/forth-collapse-os-apocalypse-programming-language/)",2025-03-26 16:40:37,5,wiredmagazine,programming
mjwjlys,1jkg7bl,reddit,"I wrote a lot of Forth code, back in the day. The end of the world would be preferable to having to write more of it.",2025-03-26 21:14:55,4,gofl-zimbard-37,programming
mjwz094,1jkg7bl,reddit,Ω OS,2025-03-26 22:34:03,1,Mathematicus_Rex,programming
mk53ezd,1jkg7bl,reddit,Nah. It'll be C on Linux.,2025-03-28 05:51:09,1,Noiprox,programming
mkdfjsb,1jkg7bl,reddit,The end of the article was a bit weird. The two people on a boat are [100 rabbits](https://100r.co/site/home.html) aren’t they? The names and descriptions match. Though didn’t mention their work or site.,2025-03-29 16:00:21,1,xntrk,programming
mjwjl7z,1jkg7bl,reddit,"I wrote a lot of Forth code, back in the day. The end of the world would be preferable to having to write more of it.",2025-03-26 21:14:49,1,gofl-zimbard-37,programming
mnnj3k8,1k1nmh4,reddit,[deleted],2025-04-17 21:06:08,11,N/A,programming
mns81cl,1k1nmh4,reddit,I work in HFT and use things like this daily. I like how you defend all your considerations in your blog post - they are all spot on. Nice work,2025-04-18 16:34:53,2,mgoblue5453,programming
mm6ov2t,1jv1z5c,reddit,"Gained a good bit of traction on /r/commandline and thought this sub may enjoy it.

[remind](https://dianne.skoll.ca/projects/remind/) is a calendar/alarm program which blows most other calendars out of the water with its configurability

(I am not the author of the blog post)",2025-04-09 09:54:45,3,mr-figs,programming
mm91e2s,1jv1z5c,reddit,RemindMe! 1 day,2025-04-09 17:59:47,0,SaltineAmerican_1970,programming
mk6y208,1jlv3dr,reddit,JEP 483 is a great step toward speeding up JVM startup time—something that’s been a pain point for a while. Ahead-of-Time class loading feels like one of those “why didn’t we always do it this way?” ideas. Curious to see how this will impact real-world microservices. Anyone already testing it?,2025-03-28 14:48:19,5,tomasartuso,programming
mkbwxod,1jlv3dr,reddit,"Nice that it's possible but the experience seems to be much crappier then simply using a language which does not have this problem.


Who is going to record and keep an up to date list of classes, not really useful for most of the cases.",2025-03-29 09:18:37,0,bytesbits,programming
mm9fnak,1jv6aiu,reddit,This kinda describes a lot of the senior dev team members where I work,2025-04-09 19:08:56,4,AshKetchupppp,programming
mnje1lg,1k11l0o,reddit,basically a raid on network level. you increase throughput but also latency,2025-04-17 05:29:50,3,SlovenianTherapist,programming
mniki4i,1k11l0o,reddit,"* [design notes](https://github.com/deepseek-ai/3FS/blob/main/docs/design_notes.md)
* [deployment](https://github.com/deepseek-ai/3FS/blob/main/deploy/README.md)",2025-04-17 01:56:56,2,self,programming
mnrmq8n,1k11l0o,reddit,"I'm curious why they had to roll their own vs use something open source.

I mean, I can guess why but would be an interesting story.",2025-04-18 14:48:02,1,Lame_Johnny,programming
mmqrds9,1jxcyax,reddit,"> One may notice that there’s an additional cost in handling a closure call. However, with a sufficiently big amount of iterations the overhead will be dampened and won’t be that significant.

What? Isn't the closure overhead something you have to pay on each and every iteration, since you call the closure on each and every iteration?",2025-04-12 15:05:39,5,somebodddy,programming
mmqrqsa,1jxcyax,reddit,"How come in the `LuaC (d)` column the `add` method is the slowest? How come simple addition is slower than square root and trigonometry?

Is it because of its high `gF/sF`? Does getting/setting fields from Lua tables really that slow?",2025-04-12 15:07:34,2,somebodddy,programming
mnif7at,1jxcyax,reddit,Lua is awesome ❤️,2025-04-17 01:25:16,2,Limp_Day_6012,programming
mmvf05n,1jxcyax,reddit,"I think Lua is mostly used for game development like Roblox and FiveM, the game engine that run the Lua(u) code is just very well optimized for the implementations on top of the native functions, especially the implementation of Roblox's LuaU.",2025-04-13 09:53:17,1,UniversityMiddle3655,programming
mmj3eo9,1jw9x06,reddit,Click on this link for an easy way to trigger the blog authors beep: http://susam.net:8000,2025-04-11 08:17:34,3,Skaarj,programming
mmj873m,1jw9x06,reddit,"> Much of the traffic seems to have come from persistent client loops constantly connecting to my beeper loop.

That’s what I would have done if I was if I was looking for something silly to waste time with.",2025-04-11 09:09:18,4,ScottContini,programming
mmaq1pt,1jvb0ja,reddit,"Some good points in here, I’d add understanding the full underlying infrastructure including networking. At least at some level, each is so deep. Most devs I know understand their code really well, but not the services it connects to. Once it’s deployed to production, they don’t understand all the parts before and after a request reaches their code. Then when there are problems, they are in the dark as to where to look based on the issue.",2025-04-09 23:08:50,5,71678910,programming
mmb6n4q,1jvb0ja,reddit,"Tl;Dr they have more time, unlimited attention spans, and are more smart than you",2025-04-10 00:46:08,7,Deathnote_Blockchain,programming
mm2150a,1jual0g,reddit,"I think I may have a guess regarding the channels behavior.

Consider the following Go code:

    ch := make(chan int, 0)
    ch <- 42

This code blocks forever. The channel has a zero-sized buffer so it cannot place the value in the buffer - it has no choice but to wait for some other Goroutine which wants to receive from the channel so that it can hand the value directly to it. But there is no such Goroutine - we never launch one - so it waits forever.

I suspect Zero channels behave similarly. They don't have a buffer to queue the value in, so they have to wait for a receiver - but in their case, having a receiver is impossible because the channel is not actually real. So they wait forever for this conceptually impossible receiver.

As for why receiving blocks forever - it's similar. It waits for someone to send a value on the channel, but since it's a zero channel - sending a value on it is impossible, so it waits forever.

Basically it's like trying to communicate over a pair of cups that **don't** have a string connecting them.",2025-04-08 16:15:20,6,somebodddy,programming
mm185x7,1jual0g,reddit,"Python's default value is not `None`. It's `NameError`:

    $ python -c ""
    > foo: int
    > foo
    > ""
    Traceback (most recent call last):
      File ""<string>"", line 3, in <module>
        foo
    NameError: name 'foo' is not defined

Because of that, I'd put Python under the _No uninitialized values_. And JavaScript too - `undefined` there is not a default value, unless you think that an empty object is initialized with the memory representation of `undefined` for every possible key.

I'd go even farther and argue that the problem of initialization values is completely circumvented in languages with dynamic typing and - more importantly - late binding. If you don't care about the type of a variable until you access it at runtime, then you don't need to initialize it with anything. It's not ""uninitialized"" - it's ""nonexistent"".

**UPDATE**

My memory of JavaScript is outdated. I checked now, and it looks like JavaScript, too, raises an exception when you try to access an undefined value. Furthermore - unlike Python where ""defining"" a variable does not actually initiate it, in JavaScript using `let foo` (without assigning a value) assigns `undefined` to it - which means that it is an ""initiation value"".

So... JavaScript is in a different category than Python in this regard.",2025-04-08 13:48:38,22,somebodddy,programming
mm2bw7r,1jual0g,reddit,"Just don't tell the press. ""Google goes from 'Don't be Evil' to creating a programming language with Zero Values""",2025-04-08 17:08:05,9,FIREishott,programming
mm0ro7w,1jual0g,reddit,"I particularly see no big problem with zero values. I understand that zero might have a meaning in a data structure, and it being a default might lead you to do some debugging, but I usually find this type of behavior very trivial to debug. Random values like in C/C++ are much harder. Not my main complaint about go, I can pretty much live with it",2025-04-08 12:06:36,15,Zealousideal_Wolf624,programming
mm0hrab,1jual0g,reddit,"Go feels like the language creators thought they were really really smart, and everyone else was just stupid to not come up with their ""simple"" designs.

As it turns out, these simple designs only work the first 60% of the way.

Which caused those ""stupid"" people to reconsider and take a different approach, but the smart Go creators decided to double down.",2025-04-08 10:49:57,11,simon_o,programming
mm1kpw2,1jual0g,reddit,"Nil maps are weird, I don’t see any reason why they disallowed adding keys to nil map. 

Nil channels are weird, but kinda make sense if you consider their behavior together with select{} - you can temporarily disable receiving/sending to channel if you need.",2025-04-08 14:54:08,1,beebeeep,programming
mm6lmgw,1jual0g,reddit,"
When it comes to zero-values in Go, I find it's important to keep all gotchas with the type system in mind. For example, everyone knows that assignment to the nil map panics, but in cases with functions returning struct and error, it still occasionally confuses me:

```go
val, err := doSomething()
if err != nil {
    return MyStruct{}, fmt.Errorf(""failed to doSomething: %w"", err)
}
```

The returned zero might be ""valid"" for a compiler, but meaningless to the caller. 

I think idiomatically, you would just define constructors as functions (e.g. `NewFoo()`) instead of defining zero structs, and then enforce it with code review. However, this feels fragile at scale because of the reliance on the discipline, not the type system.

I do enjoy Go overall, but I feel it's often necessary to debug the code because of those type system shortcomings when writing out code quickly or heavily relying on unit testing.",2025-04-09 09:21:02,1,nexo-v1,programming
mm3uqyi,1jual0g,reddit,"Dumbest idea ever.

The idea is so dumb people have developed several sql null types just to fetch data from databases (which is possibly the most common task in programming).

Imagine designing a language that can't deal with fetching data from a database out of the box.",2025-04-08 21:32:41,1,myringotomy,programming
mm2huiq,1jual0g,reddit,"The zero of a slice, map or channel is nil, not an empty one.
They behave ""like"" reference types because they refer to an underlying datastructure. (a backing array in the case of slices for example). 

Zero makes a lot of sense if you don't want constructor galore. 
Especially when one has value types and not everything is a pointer by default.

Interesting article although there are a few mistakes.

It's also funny that it illustrate a case where people may want nillable value types (for serialization purposes, as a sentinel nil value) while criticizing nil. Nil is not the issue. It's programming with it that needs to be improved and still can.
In other languages, these are optionals or maybes.",2025-04-08 17:36:11,1,aatd86,programming
mm49uuy,1jual0g,reddit,"Learning Go as I go (no pun intended) while making a small microservice from scratch, zero values have been a bit of a pain to go around. Not hard, just unintuitive.

For example, I made a REST API server, using structs to express the expected request payloads, parsing request data and binding it into instances of said structs.

Doing this way, there's no way to know (unless you dig into the request body text, of course) if a requester sent a value that resembles a zero value, or if they didn't send a value at all. The popular go-playground/validator for example, if you have an int field marked as required but a requester sends ""0"", it assumes it's a zero value, and so that no value was sent, and fails the validation.

The ""solution"" has been to declare as a pointer of the type, so the uninitialized value is now nil instead of a zero value, but that feels inelegant.",2025-04-08 22:55:48,1,SchrodingerSemicolon,programming
mkwykzu,1joxjzw,reddit,"Love tools like this, the only problems I have with them is that I need them sporadically and then either forget they exist or I can't find them anymore. I've starred it on GitHub, perhaps I'll find myself trying it out soon!",2025-04-01 20:30:56,4,Veloxy,programming
mm0quw8,1jubn3n,reddit,Is this using grpc-web? e.g https://docs.rs/tonic-web/latest/tonic_web/,2025-04-08 12:00:54,2,tavi_,programming
mlumpo7,1jtg8qc,reddit,"Interesting post!

Last year, I wrote about a related topic — sharing my experience introducing Requests for Comments (RFCs) in my team. The post includes detailed statistics on the outcomes, along with thoughts on motivation, RFC structure, and more.

Might be of interest: https://tiendil.org/en/posts/two-years-writing-rfc-statistics",2025-04-07 12:07:37,8,Tiendil,programming
mlweu7k,1jtg8qc,reddit,Put them into your code repo.  Put keywords into the doc so that you can find them!,2025-04-07 17:58:13,3,onektwenty4,programming
mlwih1d,1jtg8qc,reddit,"Everything should be well-documented. Now if ruby would learn that it could perhaps avoid dropping like crazy on TIOBE ... (not that TIOBE is great either, but for trends it is semi-ok; ruby is even mentioned in the April 2025 release, together with other two languages destined to fade away. Not that I buy into TIOBE's narrative per se, but it can no longer be denied that something is not going well here. Don't you worry, some random accounts will soon come out and say that everything is ok ...)",2025-04-07 18:16:36,1,shevy-java,programming
mlvmvm5,1jtg8qc,reddit,"Ah yes, concise little documents.  I also like to play a little game I like to call Just the Tip.",2025-04-07 15:36:28,1,CherryLongjump1989,programming
mlxeako,1jtg8qc,reddit,"Better is to create a wiki to document all your technical decisions

Markdown wikis are great, they support text but also mermaid diagrams where you can create Flow, ER, Sequence, etc

I am doing this with a personal project and it helps me when I take a few days break so I can go back in track and get back into context.",2025-04-07 21:00:41,1,faustoc5,programming
mkd5ppp,1jmcktr,reddit,"idk i think this article is cooked. 

I'm not really sure you need all that much to support 10 million users creating, reading and liking each others posts.

I think a relational database on a big server, plus caching, plus a CDN, plus read replicas, basically would take you there. 

most users might read their feeds a few times a day, most would be making one post or less per day, may only be liking 3 or 4 things a day, may not even open the app more than 2 or 3 times a week.

eventual consistently is completely fine, we don't need cross region transactions, we aren't a bank.

you don't need webscale architecture for this kind of thing. some clever table partitioning would get you there. all this extra cruft early on is only going to get in the way of getting the ""core"" right.

it is true loadtimes would be greater overseas but i suspect most people would be surprised at how fast things stay so long as you have a global CDN for static file serving & its only the database which requires a transatlantic flight. its often 300ms to 500ms round trip, which is really not that bad early days. then geo-replicate read only replicas, which is pretty easy to set up even self hosted, and then its only writes which are taking 500ms, which most people are fine with waiting.

keeping systems maintainable by the smallest number of staff possible has never been more important than today, where hiring and budgets are frozen and we just have to make due with what we have.",2025-03-29 15:06:13,25,No_Technician7058,programming
mkd27bo,1jmcktr,reddit,"> *we need to constantly go to AWS and increase the CPU and Storage Limits*

> *The approach described above is using vertical scaling*

Do the authors know about software-defined datacenters? In a datacenter everything is virtual now, computing power, storage and networking. There is no ""single server"" anymore in a provider like AWS, the load is being assigned to physical resources in a transparent manner.

The entire article feels like ""just use cloud services"". The master template is highly debatable, I won't say you need by default things like search, event queues, a data warehouse, a Redis and a video microservices cluster.",2025-03-29 14:46:49,5,st4rdr0id,programming
mkfhuh0,1jmcktr,reddit,"You don’t really need much scale for a million users on a non-critical app.

I see often people making the mistake that they think a million or even tens of millions of records is a lot of data - it’s just not. This is rife in enterprise — everything is over engineered and yet somehow at the same time extremely poorly optimised :/",2025-03-29 22:48:24,5,maxinstuff,programming
mkjnc1k,1jmcktr,reddit,"You know, every time someone says users in situations like this, I have to ask: what is a user? What does the average user do? Are programs also users? On coworker responded with: well, what is love?",2025-03-30 17:06:07,1,GayMakeAndModel,programming
mkf3mq8,1jmcktr,reddit,"Shiitt a million users, give me drf-django, a beefy postgres server, caching, a few ec2's, kamal2, and a cdn.",2025-03-29 21:25:41,0,babige,programming
mop9zuv,1k6992o,reddit,My only regret is that neither cygwin nor msys2 (and probably not minC either) go about teaching people in ways similar to how LFS/BLFS does (Linux from Scratch). I don't want to end up using pacman but msys2 insists everyone must use pacman; otherwise you are on your own in trying to understand the inner workings.,2025-04-23 23:59:06,3,shevy-java,programming
mocujc4,1k4sund,reddit,Very excellent analysis and related detail.,2025-04-22 01:18:10,3,dead_pirate_bob,programming
mms8x8g,1jx5xms,reddit,"Was at QCon London recently, and one of the discussions there was about making distributed architectural decisions, that is - individual teams being empowered to make architectural decisions, yet still maintaining congruent decisions overall. 

One of the approaches they talked about was in structuring ADRs (Architectural decision records). Backing them were a series of architectural principals, and these would themselves try to tie back to business strategies. So when a decision gets made, these principals could be consulted, and then referenced, in support of the decision being made - then referenced in the ADR itself.",2025-04-12 19:48:41,3,Ark_Tane,programming
mmwt5pq,1jx5xms,reddit,"This was a good read, thank you! I will definitely think about this a little more in my Projects!

I found one Typo (i didn't try to find any, this one was just obvious) towards the end of the Post, in this Sentence:

'We should top pretending that architecture is all about knowing good pattern and engineering, finding the “right optimal choice”.'

Likely supposed to be 'stop pretending' :D

Nonetheless, really good read, thanks again!",2025-04-13 15:42:28,3,cherrycode420,programming
mmodwph,1jx5xms,reddit,this is a good one.. it can be especially obvious to see missteps like this in hindsight,2025-04-12 03:22:56,2,bzbub2,programming
mmo5mnj,1jx5xms,reddit,how about we don't,2025-04-12 02:26:07,-1,CheeseNuke,programming
mkzsjht,1jpgkhe,reddit,"Go says it's a simple language but everything in go is weirdly and unnecessarily complex.

Instead of Handlerfunc being a type it should be an interface. Then you should be able to pass in any function with the same sig because it obeys the interface.

Also you should be able to define an interface on struct members and pass in any struct with those attributes.

But no, you have to go jump through hoops to accomplish something other languages are able to accomplish with ease.",2025-04-02 08:39:27,18,myringotomy,programming
ml5mx8l,1jpgkhe,reddit,This is how anonymous functions work in Java as well.,2025-04-03 05:47:22,1,blobjim,programming
mkipzij,1jnd4c8,reddit,"Why is Lehmer's algorithm important

* **Historical significance** : Lehmer’s continued fraction factorization algorithm was used to factor the seventh Fermat number in 1975.
* **Paper simplicity** : The original paper is only 7 pages long and super easy to follow.
* **Big O complexity** : Continued Fraction Factorization was the first algorithm to have sub-exponential factoring time.",2025-03-30 14:08:00,6,DataBaeBee,programming
ml454cf,1jnd4c8,reddit,"I thought before of an iterative factorization by starting from sqrt(N), but haven't gotten around to explore it. Didn't know it's already been investigated.",2025-04-02 23:46:14,2,WoodyTheWorker,programming
mon97bb,1k63ok7,reddit,"I don't really understand the purpose of the ""super short summary"". It's *too* short to be useful, and skips over too much of the flow to be particularly useful. The ""more detailed summary"" inversely isn't a summary at all, really (arguably) - you're just walking through the flow at that point.

You don't mention that this is just one of several OIDC flows possible - you're describing the authorization code grant flow.

>redirect\_uri is where Google sends the response.

I wouldn't say this is accurate - it's not where Google ""sends"" the response, it's where Google will issue a redirect to the browser to follow. Most of the OIDC/OAuth2 flow happens on the frontend. It's also worth mentioning that in the vast majority of cases (and certainly the case of anyone seriously acting as an IdP), redirect\_uri is controlled by an allowlist on the IdP side which verifies the location as allowable before issuing the redirect, preventing someone from changing the URI on the fly to obtain the authorization code.

>Ideally, Google also returns a refresh token. The JWT will work as long as it's valid, for example hasn't expired. After that, the user will need to redo the above process.

You kind of pass over the purpose of the refresh token in this description - access tokens are generally short lived, and so clients can exchange refresh tokens for new valid access tokens once they expire. Refresh tokens are optional, and in either case (if no refresh token was provided or has also expired/been invalidated), the user would need to complete the authentication flow again, but without the consent step (since the user has already consented to the requested scopes previously).

Your example code also does PKCE but isn't described at all in your documentation. It feels like the two are at least a little disjointed.",2025-04-23 17:48:19,7,got_milk4,programming
momuj8l,1k63ok7,reddit,"**Question:**
_Why not already send the JWT and access token in step 6?_

**Answer:** To make sure that the requester is actually LinkedIn. So far, all requests to Google have come from the user's browser, with only the client_id identifying LinkedIn. Since the client_id isn't secret and could be guessed by an attacker, Google can't know for sure that it's actually LinkedIn behind this.

Authorization servers (Google in this example) use predefined URIs. So LinkedIn needs to specify predefined URIs when setting up their Google API. And if the given redirect_uri is not among the predefined ones, then Google rejects the request. See here: https://datatracker.ietf.org/doc/html/rfc6749#section-3.1.2.2

Additionally, LinkedIn includes the client_secret in the server-to-server request. This, however, is mainly intended to protect against the case that somehow intercepted the one time code, so he can't use it.",2025-04-23 16:38:58,5,trolleid,programming
monmcu9,1k63ok7,reddit,This guide was useful to me as someone who understood about 90% of OIDC as it helped to fill in a few gaps.,2025-04-23 18:51:35,8,happyCuddleTime,programming
momul0x,1k63ok7,reddit,Here is the repo: https://github.com/LukasNiessen/oidc-explained,2025-04-23 16:39:12,1,trolleid,programming
mmn99oq,1jwxz2d,reddit,"I had to learn AI in lisp back in the day

The only reason is because chains and whips didn’t excite you anymore",2025-04-11 23:02:33,38,olearyboy,programming
mmqbupj,1jwxz2d,reddit,Scheme was my favorite programming language in college. But the idea of getting paid for it at all is a long shot.,2025-04-12 13:38:56,7,Hen-stepper,programming
mmn74rk,1jwxz2d,reddit,So that no one can read your code?,2025-04-11 22:50:03,30,maxinstuff,programming
mmnvls3,1jwxz2d,reddit,"I used to program in Lisp because, like the article said, you can build primitives that are custom coded to the domain of your choice. And specifically, that Lisp makes this incredibly easy to do.

But at this point, languages like Java are catching up, and while they certainly aren't at feature parity, the extra level of effort to code in Lisp stopped being worth it.

That's actually why I stopped coding in Haskell too. Haskell pattern-matching is powerful, and you can do some crazy stuff with it. But now Java has Pattern-Matching (not fully implemented yet!), so I just don't have as much need to use Haskell.",2025-04-12 01:21:15,4,davidalayachew,programming
mmmn3j9,1jwxz2d,reddit,"Because you looooooove searching for dangling parentheses in your code, of course!",2025-04-11 20:56:51,-9,davecrist,programming
mmr5aa0,1jwxz2d,reddit,"nonsense, until one can compile C into lisp, I will be convinced",2025-04-12 16:18:51,-1,nextbite12302,programming
mmrz844,1jwxz2d,reddit,"I don’t want to rant too long about why Lisp is bad, so I’ll take just one thing: the dynamic programming. You know, the one that’s image-based, where you have a REPL which can compile new code, update class definitions on the fly (with objects being magically updated in-memory), edit your IDE and reprogram your dog without recompiles etc.

This development model, pushed by Lisp along with its sibling, Smalltalk, was a massive failure. Static approach, with its separation between compile-time and runtime, and lack of `eval`, won. Dynamic code execution is seen as an aberration. Why that happened is another question. But the main value proposition of Lisp (which is not s-exps, as some mistakenly think) ended up vastly rejected by developers. People like version control systems and statically reasoning about things. They like to deploy with containers not with application servers hot-reloading classes in memory. Rust is the total antithesis to Lisp and is so much more loved nowadays. And as for the rest of Lisp (OOP, GC, closures, JIT compilation, macros etc) is just available in pedestrian languages like Java or Scala, for example. So really, any way you look at it, Lisp and Smalltalk have become a part of CS history now. A venerable and highly curious exhibit in the museum of computer science: nothing more, nothing less.",2025-04-12 18:54:28,-5,Linguistic-mystic,programming
ml2vmfz,1jptjfe,reddit,I like the art in the reddit preview,2025-04-02 19:53:23,3,faze_fazebook,programming
mo5mbbz,1k3wymf,reddit,Would be interesting to have a comparison to shelf in your Readme,2025-04-20 21:33:37,23,Pheasn,programming
mo6jpzg,1k3wymf,reddit,You've listed every reason for using kotlin. Plus kotlin can run on the JVM giving you access to all java libs and web frameworks. Give me one good reason to use dart over kotlin,2025-04-21 00:53:41,36,piesou,programming
mo5vbcg,1k3wymf,reddit,Dart is like if C# was missing a chromosome.,2025-04-20 22:27:15,73,Asyncrosaurus,programming
mo5sntb,1k3wymf,reddit,"I have no real opinion on Dart, but “Unified language for full stack” is vastly overvalued as a concept IMO.

Any competent dev should be able to work productively in more than one language.

Sharing internal data structures across front and backend is asking for trouble as the system evolves; communication formats are better defined using API specs (OpenAPI, gRPC, etc.) to avoid leaking implementation details that only matter on one side and to allow the interface to evolve separately from the implementations. You can do code generation from those specs to avoid duplication of effort and minimize inconsistency.

There’s maybe a good argument to be made for sharing validation logic. But that’s usually such a small percentage of a code base that it shouldn’t be the thing that drives language choice.",2025-04-20 22:10:59,71,koreth,programming
mo7x2rq,1k3wymf,reddit,"I use dart to create CLI apps from simple  scripts to 100kloc deployment apps.

Best language I've ever used for cli and I've used a lot of them.

https://dcli.onepub.dev/

Fyi: I'm the author of dcli.",2025-04-21 07:06:59,6,Amazing-Mirror-3076,programming
mo5ngdd,1k3wymf,reddit,Is Dart the language of the month?,2025-04-20 21:40:14,16,BlueGoliath,programming
mo5t19a,1k3wymf,reddit,What's the current status of multi threading in Flutter and Dart?,2025-04-20 22:13:15,6,ComfortablyBalanced,programming
moecvg9,1k3wymf,reddit,"You are basically competing with NextJs and React Router/Remix while also indirectly suggesting that backends should be rewritten from Java/C#/C++/Go into Dart. I just don't see enough upsides with Dart for it to take a large part of the market.

My general thinking about programming languages and frameworks is that it is not enough to be a bit better than the market leaders, you'll have to be a lot better for people to switch.",2025-04-22 08:21:41,2,jbergens,programming
mo61rv0,1k3wymf,reddit,I got buzzword bingo!,2025-04-20 23:06:58,4,lolwutpear,programming
mn4ggk6,1jz1wmo,reddit,"On one hand I am indescribably impressed.  
On the other hand...  I am worried. Are you ok...?",2025-04-14 20:37:55,7,D20sAreMyKink,programming
mnbep0r,1jz1wmo,reddit,"Pretty cool, I like recursion and self-reference.

As an aside, I don't see the <aside /> element that often.",2025-04-15 22:59:19,1,NeuxSaed,programming
mn4p9k5,1jz1wmo,reddit,Very useful for programmers.,2025-04-14 21:23:40,-2,BlueGoliath,programming
mmi6u08,1jvv0cs,reddit,But why :(,2025-04-11 03:21:27,2,vancha113,programming
mmivnkm,1jvv0cs,reddit,"    (...==...)--(...==...)--(...==...)
    3

But Brainfuck (https://en.wikipedia.org/wiki/Brainfuck) already eixsts.

People have a lot of energy creating very odd programming languages or dialects.",2025-04-11 06:55:44,1,shevy-java,programming
mlb7qeu,1jqx0n9,reddit,"Paralellization is easy in C#! Just call Parallel.ForEach! Bam, done.

Only slightly /s because I literally optimized something exactly like this last week, though I also know tricks like Interlocked.Increment to avoid counter synchronization and such.",2025-04-04 02:39:01,2,xeio87,programming
mkqtqtd,1joch9z,reddit,Cool app.,2025-03-31 20:20:12,2,N/A,programming
mkoqynv,1jo3ugf,reddit,"This reads extremely dystopian; giving up on anything getting better ever:

> That does not exist, and there is no reasonable opportunity for it to ever exist because of prior practice and how generics work.  
> If you want ABI-stable mature libraries and enough of them to drive your entire PC experience you're going to be using C. 

But perhaps that's the winning bet in the world we live in.

The problem is that dynamic linking/loading has been held back by C for so long, that ""dealing with libraries"" has splintered into the 4 approaches mentioned in the article in the first place.

I believe that improving/modernizing dynamic linking/loading, is not a zero-sum game:  
It would also improve the lives of people following the other approaches.  
(Though I believe that 4 philosophies to ""dealing with libraries"" is 2 or 3 too many.)",2025-03-31 14:06:21,5,simon_o,programming
mkqbd2j,1jo3ugf,reddit,"I think the shared library approach was always going to fail, as it adds too many artificial constraints with too little upside now that memory & compute are this cheap. 

As for supply chains, I also recently hit that issue. As well as wanting general offline reproducibility. 


I think for these kinds of problems, 90% of the time the problem could be solved by having a tool that that helps imports a Cargo.lock's deps into a version controlled `./libs` folder.",2025-03-31 18:49:07,5,throwaway490215,programming
mkqkpdp,1jo3ugf,reddit,Wasm and its security model deserved a mention,2025-03-31 19:35:48,1,Exidex_,programming
mkg095o,1jmiybd,reddit,"Hello 👋 Security looks absolutely horrible on this one, no protection against replay attacks, no integrity protection, crypto unsafe PRNG, Bad seeding (time-based), No crypto binding to Action, low entropy solution, no rate/guess limit. And this does not even include sophisticated attacks like using ML/AI to Break the oldschool equation-in-image idea.


Given that you offer this as a hosted service that costs actual money, its hard for me to see good will here let me be honest. My recommendation is: discontinue the service as it is extremely hard to get captchas right. If continueing is inevitable: get some professional Security Help by experts.


Best regards,",2025-03-30 00:36:09,52,VajeynaPewp,programming
mkf4s5w,1jmiybd,reddit,"Your solution doesn't implement any accessibility for people who can't view images for one reason or another. Therefore, while your solution is gdbr compliant, it is not compliant with the new eeac or European accessibility act. Therefore anyone using their product in selling it to European customers, can be banned from the European market if they implement this captcha, banning people with disabilities from accessing their product. You're going to need to act add some sort of solution to this if you're planning to sell this to actual customers.",2025-03-29 21:32:20,16,blind_ninja_guy,programming
mkfgwzj,1jmiybd,reddit,"Every time I hit ""Try another CAPTCHA"" it gets faster.",2025-03-29 22:42:59,3,HexDumped,programming
mk90ehl,1jm0eb0,reddit,Anything will beat Clojure error reporting,2025-03-28 20:52:14,12,Alarming_Hand_9919,programming
mop8plw,1k69qmw,reddit,my blob melted,2025-04-23 23:51:47,1,wentworth38271,programming
ml5mjfl,1jpwf50,reddit,Changed from chained to Swiss table finally,2025-04-03 05:43:49,1,reini_urban,programming
mlw79ru,1jpwf50,reddit,"The key word here is _unrolled_.

A well-known optimization for linked-lists is the unrolled linked-list, which is a list of fixed-size arrays, instead of a list of elements.

Linked-lists are not necessarily very popular, though, so I'd argue the better known occurrence of this pattern is the unrolled binary tree, aka B-Tree.

And now, Valkey has an unrolled chained hash-table, and it's lovely.

_Note: this is not quite a Swiss Table / F14 design, as it's not fully an open-addressing hash table since not all values are in the main array._

---

Does anyone know whether they considered using buckets of _15_ rather than _7_ values?

Both Swiss-Table and F14 go with groups of ~16-ish elements, as this matches SSE capabilities for the residual check. And possibly because modern Intel CPUs prefetch two cache lines (128-bytes aligned) anyway.",2025-04-07 17:20:55,1,matthieum,programming
mkqqtsz,1joc5dd,reddit,"If these tools (looking at you, github, gitlab, bitbucket and similar products) would make it possible to properly review and comment on the commits (not just the PR), you've automatically enabled a stacked diff approach. Separate logical commits are infinitely easier to review than the PR's. And in the end git branches are just that: stacked diffs. 

But hey, that would require people to care about their commit hygiene.",2025-03-31 20:05:49,57,Illustrious-Wrap8568,programming
mkrldgv,1joc5dd,reddit,Gerrit solved this 15 years ago.,2025-03-31 22:47:25,10,Swimming-Cupcake7041,programming
mkqnpgh,1joc5dd,reddit,"Counterpoint, stacked PRs are a sign that your PR review process is broken enough to incentivize you to work on multiple things at once.",2025-03-31 19:50:37,-10,jbristow,programming
mof2l15,1k511df,reddit,"Self host zrok, this is the way.",2025-04-22 12:14:35,3,GuurB,programming
moi8u7p,1k511df,reddit,"I would generally never open up anything on local computers. Use git and build a pipeline to start up instances of selected branches. That way you can expose the services safely without compromizing your local computers.

If you can run it locally then you can also run it on infrastructure. If its a dockerized service then its even easier to deploy anywhere on demand.

Edit: Not to take away from your project here, its a cool project. I myself made a go service to effectively do the same as ngrok as a hobby project. But generally I'm strongly against opening up your local computer to anything as it has a lot of compromizing usages/files/passwords that dedicated hosted services do not have.

I do still have some (very sad) exceptions when for example developing a slack plugin or that kind of thing where there is no way to test it locally without opening up to public internet.",2025-04-22 21:57:15,3,Jolly-Warthog-1427,programming
mof8wxg,1k511df,reddit,"I set up a reverse proxy in Apache httpd running on a virtual host I have in the cloud on a fixed IP address. SSL certificates provided by certbot using letsencrypt. The proxy points to a localhost port. 

Then I ssh with reverse port forward from my laptop to the server to have the proxy reach my laptop via the defined ports.

Best part is I did not have to install anything new. I just used the things that were already there.",2025-04-22 12:55:17,2,vivekkhera,programming
mnuq38t,1k2b0z2,reddit,"It's like QWERTY keyboards, SMTP and Javascript in the browser. It is because it was, and you can be sure as shit it will keep being.",2025-04-19 00:45:54,5,pm_plz_im_lonely,programming
mnl0vin,1k1d1vl,reddit,"As an illustrator and software engineer, I find this delightful. Great work!",2025-04-17 13:43:12,3,myka-likes-it,programming
mnlh48c,1k1d1vl,reddit,"This looks very cool, just signed up for the newsletter.",2025-04-17 15:05:03,2,xIceFox,programming
mnk71hk,1k0u6eb,reddit,"Swapping bubble sort for selection sort can be a breaking change, as bubble sort is stable and selection sort is not.",2025-04-17 10:21:44,4,vytah,programming
mnl0hbt,1k0miag,reddit,"I'll check this out since it was a long time since I had a look at CMake, but the last time which was like half a decade ago I hated it. Really like how they did it with Premake, you leverage Lua which people already have a familiarity with. I actually wrote my own system which pretty easily ported the libs I needed to which was greatly inspired by Premake since I needed some feature which were absent, but it used Python instead. And that overall looked *very* promising imo because you can leverage the `with` construct in Python to declare your build in a nested manner. Python is already really well suited for iterating over structures & applying configuration meta data etc, and suddenly you leverage a language which people are already really familiar with. Here's an example for FreeImage for example:

    from kneader import *

    with workspace('freeimage', default_project='freeimagelib') as ws:
        with project('freeimagelib', output_type=StaticLib, project_type=Cpp,
                            include_directories={ Public:['Source'], Private:['Source'] }, file_patterns={ Private:['Source/<FreeImage|DeprecationManager|FreeImageToolkit|Metadata>/*'] },
                            file_group_filters={'inc': ['**.h'], 'src': ['**.cpp']}):
            add_defines([Public,Private], ['FREEIMAGE_LIB'])
            add_requires(Protected, ['*zlib#','../lib*','../openEXR'])
            add_file_excludes(Private,['**.c'])
        with project.create({'name': ['libJPEG','libPNG','libTIFF4', 'libOpenJPEG', 'openEXR','libJXR'] }, project_type=Cpp, output_type=StaticLib,
                            include_directories={ Public:['Source/{prj.name}/'], Private:['Source/{prj.name}/'] }, file_patterns={ Private:['Source/{prj.name}/**.<c|cpp|h>'] }, 
                            file_group_filters={'inc': ['**.h'], 'src': ['**.cpp']}, defines={Private:['_LIB','OPJ_STATIC']}):
            with config_filter(""prj.name in ['openEXR','libJPEG','libPNG','libTIFF4']""):
                add_requires(Protected, ['*zlib#'])
        with ws['libJXR']:
            add_include_directories([Private,Public],['Source/LibJXR/jxrgluelib','Source/LibJXR/image/sys'])
        with project( 'libRawLite', output_type=StaticLib, include_directories={Public:['Source/LibRawLite'], Private:['Source/LibRawLite']}, 
            file_patterns={Private:['Source/LibRawLite/**<libraw_|dcraw_|demosaic_>*.cpp']},project_type=Cpp):
            add_defines([Public,Private], ['LIBRAW_NODLL'])
            add_file_excludes(Private,['**compressed.cpp','**x3f**'])
        with ws['libJPEG']:
            add_file_excludes(Private,['**jmem<dos|mac|sys|ansi|name>.c'])
        with ws['openEXR']:
            add_include_directories([Public,Private], [ x.as_posix() for x in Path( 'Source/OpenEXR' ).glob('*') if x.is_dir() ] ) # Most sub folders in OpenEXR needs to be on the include path
            add_file_excludes( Private, ['*<ThreadSemaphore|ThreadMutex|ExplogTable|eLut|dwaLookups|toFloat>.cpp'] ) # Exclude some files containing main() & dummy implementations
            with config_filter( ""'Windows' in baked['architecture']""):
                add_file_excludes( Private, ['*Posix*'])
            with config_filter( ""'Windows' not in baked['architecture']""):
                add_file_excludes(Private, ['*win32*'])
        with ws['libOpenJPEG']:
            add_defines(Private,['USE_JPIP'])
        with ws['libTIFF4']:
            add_requires(Protected,['../libJPEG'])
            add_file_excludes(Private,['**<wince|vms|ojpeg|unix>**'])
        with ws.children_of_type(project):
            add_defines(Private,['_LIB', 'OPJ_STATIC'])

The entire thing is only a few hundred lines of code & in the early stages but iterating on it a bit more I really liked how productive it was, this was all a fairly long time ago though & I'm not actively developing in C++ at the moment. And yeah, the last thing needed is probably yet another build generator.",2025-04-17 13:41:04,1,Sairony,programming
mn2k242,1jz02cx,reddit,"I cannot quite follow since I haven't touched Zig in over a year and even then just summarily.

In the example code, does that mean that User data type can only be used in a linked list, since the type has an embedded pointer to the next item?",2025-04-14 14:56:38,9,flavius-as,programming
mn2m3ad,1jz02cx,reddit,"Not having sensible boundaries/encapsulation in the language and inventing their own worse solutions to age-old problems both seem to be a recurring theme of the language.

The article gives a good glimpse at both, and for that I recommend reading it.",2025-04-14 15:07:02,21,simon_o,programming
mn3lim9,1jz02cx,reddit,"Very weird to have the exception, something that are often not what you want, intrusive implementation as the normal option in the std lib 

To not say anything how this encourages developers to try to get the data using some offset from node, basically asking for memory bugs",2025-04-14 18:02:16,7,teerre,programming
mn4uq52,1jz02cx,reddit,"This change is based and if you think Container Linked Lists are better than Intrusive Linked Lists you are wrong.

Container Linked Lists have exactly one purpose: To nudge you into using a Vector for your out-of-the-box ""List"" data structure. They do have one positive over other builtin list types - they concatenate in `O(1)`... At the cost of `O(n)` pointer walks for indexing. Maybe the only truly useful application of a Container Linked List is `std::LinkedList<std::ArrayVec<T, COUNT>>` or similar for building a `Vec<T>` that never invalidates its pointers (but is *mostly* contiguous in memory).

Standard Libraries having these Container Linked Lists only serve to deter people from learning about what you can *actually* do with linked lists. They're worse than useless - they're actively dissuading developers from considering and trying linked list based solutions by associating ""linked lists"" with ""expensive lookup"" and ""just use a vec"" *from the day they start programming*.

Intrusive Linked Lists are just **better** in cases where you need to link data *structures* together, not *data*. Also, you can make a Container Linked List using an Intrusive Linked List - you can't do the opposite. They have all (mostly) the same performance characteristics as Container Linked Lists, they just have poor ergonomics due to their tailoredness to specific problems. Additionally, Container Linked Lists take away one of the most powerful aspects of a linked list: control over where the data lives in memory, and its lifetime. Container Linked List data lives in and for as long as the Container (which is also a useful property, to be fair - but it's still a subset of the capabilities of an Intrusive Linked List).

The world runs on Intrusive Linked Lists. Basically every OS on Earth (and in space) uses an Intrusive Linked List for task and resource management.

Container Linked Lists should be considered harmful.",2025-04-14 21:53:26,8,ToaruBaka,programming
mn789i4,1jz02cx,reddit,"> The new version isn't generic. Rather, you embed the linked list node with your data. This is known as an intrusive linked list and tends to perform better and require fewer allocations. 

I don't get it. How new solution requires fewer allocations  than pretty intrusive 

     pub const Node = struct {
       next: ?*Node = null,
       data: T,
     };",2025-04-15 08:08:42,2,Maykey,programming
mn0xllx,1jysggs,reddit,Cool article but not everything has to be a modular monolith or microservices. Choosing the right architecture depends way more on the project's specific needs than following trends. Sometimes an app is best served by a single monolith without any fancy modules.,2025-04-14 07:22:21,56,ThatHappenedOneTime,programming
mn2t80z,1jysggs,reddit,The funny thing about bog standard monoliths is that that's what most successful companies started with.,2025-04-14 15:43:09,10,Isogash,programming
mn18hh7,1jysggs,reddit,"tl;dr: Nothing is simple, no lunch is free.

For an article that starts with mocking the technology pendulum, it seems awfully focused on modular monolith failure points. 

Article implicitly assumes that there's one architect, and then the team is working actively against it. No shame, that pattern is so awfully common that we at least have to take it into consideration.

But if we can't get the team behind the architecture, maybe that's not the team's fault?",2025-04-14 09:20:29,9,elperroborrachotoo,programming
mn42u8m,1jysggs,reddit,"Someone should tell him you can carve out a module out of a monolith without having to go through the pain of following all the modular monolith (in-process microservice?) constraints he advocates. 


I'd be a boring architect, no doubt.",2025-04-14 19:29:42,3,ilawon,programming
mm9dl80,1jvb14n,reddit,"""The long slow failure of Lenat’s project is a strong indictment against the symbolic-logical approach to AI.""

Really? Isn't that like saying ""the long slow failure of donald trump's human soul is a strong indictment against the representative democracy approach to government."" The one doesn't follow from the other. Representative govt may turn out to be unworkable garbage, but we cannot learn anything about the form of that failure from observing the decomposition of donald trump's soul.",2025-04-09 18:58:46,2,mhcat,programming
mk3kagr,1jkk6bj,reddit,What’s it do? You’ve documented the install but not features other than a project / workspace. So no idea what it’s got and why I’d use it,2025-03-27 23:52:19,2,olearyboy,programming
motg5jg,1k6tm1w,reddit,nice,2025-04-24 16:52:02,4,Weary_Performer9450,programming
moh98fe,1k5c1q5,reddit,Maybe fix Reddit instead of posting here.,2025-04-22 18:58:54,-10,BlueGoliath,programming
molcqmu,1k4j88i,reddit,"“Oh, cool! Rob Pike wrote something on bloat?” *Clicks link* Google Docs shows a “Loading…” message for a few seconds. Closes tab. “Message received.”",2025-04-23 11:49:09,4,HappyAngrySquid,programming
moeniaf,1k4j88i,reddit,"I'm not particularly convinced that large dependency trees or complex systems are the cause of certain programs running slow. They can cause more space usage on disk and in transit, and if you're fetching dependencies at the last possible moment you'll get some latency annoyances, but _actually slow software_ seems more to be a problem of bad algorithms (accidentally quadratic, all that), and to some extent using an interpreted rather than compiled language, and using a GC language—both of these things are nice to have in general, but they're not entirely free either. Not to mention extraneous network calls and de/serialization: Kubernetes makes it real easy to add another REST microservice, which might be the right call for process isolation or org-chart reasons or whatever, but it also ain't free.

So Pike's slides here just wind up coming off as a non sequitur.

That said, the industry seems pretty well aware of the threat of supply chain attacks, but also that it's worth doing more work through SBOMs, signatures, etc to mitigate that than to lose out on the rich tapestry of available dependencies. At some point between ""rewrite your own `is_even`"" and ""rewrite your own GTK"" pretty much all devs will say ""nah, screw this"".

Ultimately the kind of software asceticism he's arguing for conflicts with both the users' demands for features, and the devs' wish to eliminate toil. It can be pretty great for personal projects, but out on the marketplace or the commons it's going to struggle.

The other part also with CVEs is that … just because you hardcopied something or rolled your own doesn't mean you're now free from CVEs, it just means there's much more work done, highly likely redundant, both to detect and to fix them, rather than updating dependencies.",2025-04-22 10:15:00,8,syklemil,programming
mobpxpe,1k4j88i,reddit,Are generics bloat?,2025-04-21 21:29:04,6,PrimozDelux,programming
moempv4,1k4j88i,reddit,I agree with much in this presentation and would wish that more software projects try to keep the complexity under control. I am quite afraid of the consequences of large dependency trees and I got the impression that the dangers are often ignored.,2025-04-22 10:07:09,3,dravonk,programming
mobpd9m,1k4j88i,reddit,"> Features

Nope. I'm going to stop you right there. Feature != Bloat. I can tell you for a fact that a simple [text editor](https://bold-edit.com/) with LSP/DAP support was less lines than simdjson. The simdjson single header had a lot of repeating code and was about 30K lines. I really did not want to audit that.

Most of the bloat is from dependencies. I got around to replacing simdjson and my binary size was cut in half",2025-04-21 21:26:06,4,levodelellis,programming
momg8qj,1k4j88i,reddit,"I would be interested to know the intended audience of the talk because he says we ""must account for the expense of maintenance and growth when deciding to add a feature"" but doesn't mention that corporate incentive structures, where most software is written, generally do not support this at all.  Most famously this is not supported at all by incentives at Google, his longtime employer where everything is beta or deprecated, so he surely knows this.  Maybe he was more focused on open source in this talk.  Similarly 'understanding the costs of your dependencies' and 'examining your dependency tree regularly' are great for libraries or small utilities but no story points are going to get allocated to replacing the left-pad dependency.

Good advertisement for Go though, to his credit he did ship Go with so few features nobody could accuse it of bloat; a lightning fast compiler; and they do try to put every foundational thing they can into the standard library so you don't need external dependencies.",2025-04-23 15:29:27,1,sisyphus,programming
moaq07d,1k4iwx4,reddit,Poor python. I would not want to tie a haskell knot in it ...,2025-04-21 18:30:34,-1,shevy-java,programming
mn3tgz1,1jz5omf,reddit,Short and fun exercise for folks who directly learnt React,2025-04-14 18:41:57,4,Eastern_Selection_64,programming
mn4bqkc,1jz5omf,reddit,"I did something like this just last week, why did you declare the state variable outside the useState function?",2025-04-14 20:14:03,0,saantonandre,programming
mn3ov5m,1jz5omf,reddit,"Just what ECMAscript ___doesn't___ need, more damned frameworks!!!!",2025-04-14 18:18:49,-21,church-rosser,programming
mn48qpw,1jz03ir,reddit,THEN must be #defined as nothing somewhere.,2025-04-14 19:59:19,1,XNormal,programming
mn5zm8c,1jz03ir,reddit,"It is pitch black. You are likely to be eaten by a grue.


Now do Planetfall!",2025-04-15 01:53:37,1,LegitBullfrog,programming
mmy15gf,1jy791c,reddit,"> Supports the proleptic Gregorian calendar between 1 and 9999 AD

Aw here we go again, Y10K bugs …",2025-04-13 19:31:23,6,rsatrioadi,programming
mmgdngb,1jw8g1n,reddit,Java could never.,2025-04-10 20:55:10,16,BlueGoliath,programming
mmgodh8,1jw8g1n,reddit,"finally the null conditional assignment, hooray!",2025-04-10 21:50:42,9,yanitrix,programming
mmi3iji,1jw8g1n,reddit,"These are undeniably useful features.  But I am not a fan of multiple unrelated syntax forms to do the same thing.  It just invites bikeshedding and time wasted on code consistency issues.

I don't suppose there's any chance that C# will ever deprecate some of its older syntax, like delegate{} or the now-old form of extension methods?",2025-04-11 02:58:10,8,--recursive,programming
mmk4tn6,1jw8g1n,reddit,Where are my unions in C#?,2025-04-11 13:23:20,0,TheWix,programming
mmjax9s,1jw8g1n,reddit,"Thank god they are adding more features, that was something C# really lacked!",2025-04-11 09:38:19,-7,simon_o,programming
mmmz6tx,1jw1j0l,reddit,"Creating a whole operating system *and* having documentation for ""how would a beginner code on this platform"" is genuinely super badass.",2025-04-11 22:03:13,3,Booty_Bumping,programming
mlx3kop,1jttu8g,reddit,"This is clever, I like the approach.",2025-04-07 20:05:30,0,guitarromantic,programming
mlgmd6i,1jrluex,reddit,These are pitfalls of programming which Rust does not prevent.,2025-04-04 23:46:53,11,Mysterious-Rent7233,programming
mljor9c,1jrluex,reddit,"Thanks, I learned several things to make my rust code safer.",2025-04-05 14:42:23,3,thomas_m_k,programming
mln0cbm,1jrluex,reddit,One important one that it is missing is stack overflow via recursive drop.,2025-04-06 02:28:46,1,slaymaker1907,programming
mkrjzn7,1jm79kv,reddit,"I skimmed it. Looks like a great book for beginners. The only thing I found lacking was the very short description on function pointers, and the total absence of describing pointer-to-array types. I.e int (*)[40]",2025-03-31 22:39:32,1,Madsy9,programming
mobdjfs,1k4mww3,reddit,[deleted],2025-04-21 20:27:03,-9,N/A,programming
mobqfya,1k4j44o,reddit,"Lots of information to be had here. For some reason I never managed to use kate much at all; it seemed somewhat clunky and awkward. 

I still think it would be nice to have ""The One Universal Editor"" like where the user can cherrypick which functions to be had and how. (Emacs and Vim are IMO lacking in regards to ""true GUIs"" such as sublime. I really mean a universal editor, not one that is limited to what we currently have and sacrifice for other features rather than all the useful features. There are even editors that re-implement parsing for files such as .py files or .pl files - that should never have to be implemented by different projects in regards to syntax highlighting, but the reality of the situation is that almost everyone seems to just duplicate existing functionality.)",2025-04-21 21:31:42,1,shevy-java,programming
mo8gi5e,1k3zmdw,reddit,"I love this, the actor model is a much better solution to cloud native mentality",2025-04-21 10:29:40,3,IsThisNameTeken,programming
mnes27p,1k0k6q2,reddit,Awesome! Love the reference to Duff's device in the chapter on lightweight tasks.,2025-04-16 14:00:13,3,No-Concern-8832,programming
mmkhy1f,1jwpkgo,reddit,"In the early 90s, I worked at a company that had an in-house written print spooler for their big green-bar printer, and all the other printers located in the office. The spooler was mostly written in PL/1, but it had printer-specific code written in Postscript. I had to do a bunch of maintenance on that thing over the years I was there. Postscript was interesting; PL/1, not as much. (Actually, it was PL/P, which was a customized version of PL/1 that ran on Prime minicomputers.)",2025-04-11 14:31:55,2,joeyGibson,programming
mknyh00,1jmf3pe,reddit,Short answer: Irrelevance.,2025-03-31 10:53:32,1,simon_o,programming
mkfbz3j,1jmf3pe,reddit,"even this very post on scala has very little in the way or engagement or interest. it is truly a difficult period for scala. however i still believe it will eventually dethrone kotlin, java, and groovy as the JVM language of choice.",2025-03-29 22:13:38,-5,No_Technician7058,programming
mk6c29d,1jlu8rl,reddit,"""The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin."" - Richard S. Sutton (2019)

From people closer to research I'd be curious to know whether this rings true for recent years.",2025-03-28 12:47:40,6,dwmkerr,programming
mk6rvk9,1jlu8rl,reddit,"on the same page.

> The number of transistors in an integrated circuit doubles approximately every two years.
>
> Often used to illustrate the sheer speed at which semiconductor and chip technology has improved, Moore's prediction has proven to be highly accurate over from the 1970s to the late 2000s. In more recent years, the trend has changed slightly, partly due to physical limitations on the degree to which components can be miniaturised. However, advancements in parallelisation, and potentially revolutionary changes in semiconductor technology and quantum computing may mean that Moore's Law could continue to hold true for decades to come.

It's really funny how people today read Moore's Law. It's often read as if it was inevitable these days, but it served a very different purpose when he said it originally.

It was a promise to investors; ""We will uphold the Moore's Law! We will ensure <The number of transistors in an integrated circuit doubles approximately every two years.>""

And a threat to Intel employees; ""Make sure that <The number of transistors in an integrated circuit doubles approximately every two years.> The punishment for failing to uphold this law is you're fired.""

It was a clear and concise way of communicating his companies mission to everyone who worked there, and to the people who invested, what they were investing in.",2025-03-28 14:16:52,8,CVisionIsMyJam,programming
mk7w4sj,1jlu8rl,reddit,"This may apply to more than just AI; here's a talk arguing that the increasing success of fuzzing comes from the fact that it can find bugs using compute power instead of human effort.

https://www.youtube.com/watch?v=Jd1hItbf52k",2025-03-28 17:33:27,4,currentscurrents,programming
mkssbaz,1jlu8rl,reddit,"I like the list overall, a really nice summary.",2025-04-01 03:10:45,1,me_again,programming
mjss830,1jk4rzs,reddit,"Wow, this looks great!

Is this made just by you?",2025-03-26 07:55:07,1,weetbix2,programming
mjst67k,1jk4rzs,reddit,It looks great. It’s a lot of features. Really like the ability to generate files into other systems nomenclature. E.g. Generate build/run files for VScode. I hope the bug squashing doesn’t  become overwhelming.,2025-03-26 08:05:35,1,this_knee,programming
mjtkh8k,1jk4rzs,reddit,"You should update the header to include ""vcpkg and conan"" integration, because skimming the text could make someone think it's really only for vcpkg.",2025-03-26 12:18:03,1,suitable_character,programming
mjuaypa,1jk4rzs,reddit,Does it work with system packages / pkg-config?,2025-03-26 14:48:37,1,maep,programming
mjw54c7,1jk4rzs,reddit,What advantages does this have over something like Meson?,2025-03-26 20:09:30,1,PuzzleheadedWeb9876,programming
mk3nosa,1jk4rzs,reddit,What makes this better than [xmake](https://xmake.io),2025-03-28 00:10:49,1,erhmm-what-the-sigma,programming
mna3u55,1jzxylv,reddit,Wow such a hard hitting generics level feature.,2025-04-15 18:55:58,-17,BlueGoliath,programming
mmx2cz4,1jy4q1b,reddit,"I am impressed, this kind of image processing seems like a huge pain in the behind to me, but your explanation and github code will hopefully give me ideas to follow if I ever need to do such horrible things",2025-04-13 16:30:21,4,HeadAche2012,programming
mmvitpd,1jy4q1b,reddit,"Link to the code, if anyone is interested: [https://github.com/mhso/SuperHexagonAI](https://github.com/mhso/SuperHexagonAI)",2025-04-13 10:33:30,2,Catz1010,programming
mmzg1vi,1jy4q1b,reddit,"would this work with a flash game? I've been looking into a way to create a reinforcement learning/AI for an old 2D mountain car type game called Max Dirt Bike, from what I've read a lot of the gymnasium documentation for flash hasn't been kept up to date and people were having compatibility issues, so I never really went down that path but always figured I could brute force train an AI to just open a window and read the environment, only 4 control options (left, right, up, down) but then the cursor is only used to reset

I can elaborate/provide examples of what it looks like exactly if you think it sounds doable

edit: great video btw",2025-04-14 00:22:29,2,nickpiscool,programming
mmj880w,1jwla31,reddit,"Good for you, but most people should probably just run ddclient.

https://github.com/ddclient/ddclient",2025-04-11 09:09:35,7,fragglerock,programming
mmlcnry,1jwla31,reddit,This is good. Cloudflare also provides a solution for this called Cloudflared,2025-04-11 17:03:07,3,prateeksaraswat,programming
mm40xex,1juijcx,reddit,Regular Expressions are often not the right solution for many use cases... Same can be said of Monads 😁,2025-04-08 22:05:22,5,church-rosser,programming
mm7v6c8,1juijcx,reddit,Aren't regexes instructions for generic parsers?,2025-04-09 14:35:14,2,AnnoyedVelociraptor,programming
mm833vk,1juijcx,reddit,">We generally don’t use regexes in Haskell. We use parser combinators instead, because they are almost always better. In other languages, it would be considered overkill to write a full parser when a simple regex can do the same thing.

*20 lines later instead of a 1-line regex*

Cool Story, Bro.",2025-04-09 15:14:19,0,gladfelter,programming
mm0ypm0,1jucpqv,reddit,"Damn, that's one of the many languages ​​I've forgotten completely. Well. It was a good party.",2025-04-08 12:53:00,1,YahenP,programming
mmci0tq,1jucpqv,reddit,"Fortran led to Algol which lead to C then C++ and its relatives such as Java, JavaScript, and C#.",2025-04-10 06:22:57,1,Zardotab,programming
mlhp1st,1jr7jyo,reddit,"ACID vs BASIC

CAP theorem

Consistency vs Availability

Pick one, you cannot have both

Similar to Heisenberg's Uncertainty Principle",2025-04-05 04:12:13,5,atehrani,programming
mlcgio7,1jr7jyo,reddit,The smudged lady-bugs are the Gen-AI rendition of one of the main ideas of the article: that of processing bugs in a serialized manner (i.e. one by one).,2025-04-04 09:11:49,-7,klaasvanschelven,programming
mltybhg,1jr7eiu,reddit,[deleted],2025-04-07 08:13:38,3,N/A,programming
ml3iixx,1jpx2b6,reddit,"This has always bothered me. If you are writing in a memory-safe Language like Rust, why would you ever use a C library that is not safe? I have seen this when somebody wants to connect to a piece of hardware using an odd memory footprint using the library provided by the manufacturer. If the hardware requires you to use unsafe practices, why are you using that hardware? If the answer is 'Legacy' and/or 'Costs', you had better be prepared for the technical and security debt you are incurring.",2025-04-02 21:43:09,-12,Bonejob,programming
molggyb,1k5bk1s,reddit,"A technique I've never seen anyone mention... build your app with multi-tenancy keys in mind, even if there is only every one tenant. Every database model I create has a root ""app"" table. Every other table references a record in app (by default, the first app == id: 1). Then when you run database tests, each test can start by creating a new app. They won't conflict which each other because all of the code is written to contextually operate within the multi-tenant 'app'. You can use rollback transactions or not. You don't need to recreate all tables (slow). You can investigate the generated data from each test run, by filtering by the app.id created in that test.",2025-04-23 12:14:46,2,roryl,programming
mok83tz,1k5bk1s,reddit,testcontainers work great and are made for this: https://testcontainers.com/modules/postgresql/,2025-04-23 05:18:46,1,chipstastegood,programming
mogn7i7,1k5bk1s,reddit,I think rails does this right,2025-04-22 17:12:14,-1,Alarming_Hand_9919,programming
mnuy3g3,1k2ilmi,reddit,"> The first feature, run to cursor, resumes the program until it reaches the line where the cursor is at. It is a declarative alternative to the primitive debugger features for stepping into, over, and out — rather telling the debugger how to do every single step, you just directly tell it where do you want to be:

You just described a breakpoint",2025-04-19 01:36:27,68,rlbond86,programming
mnvfb5g,1k2ilmi,reddit,"> Quick Evaluate Expression

I do this in gdb all the time. `p myVar * otherVar`",2025-04-19 03:32:47,9,remy_porter,programming
mnrvlkm,1k1d2z3,reddit,"Very nice article! Another interesting piece of reverse mode AD is static vs dynamic graphs.  For programs with a fixed size and control flow you can use a transpiler (ala Stan/jax etc.) to fuse the passes of the reverse mode together. This gives you reverse mode but with optimizations opportunities like you did symbolic differentiation. Though static graphs are much more restricted. 

Since you need a fixed path at runtime static graphs based AD cannot have conditional statements that depends on parameters. So while() loops become impossible. Things like subset assignment on matrices can also become weirdly tricky. Most AD libraries like Jax and pytorch give strong warnings about subset assignment to matrices. 

Dynamic graphs in reverse mode AD allow the depth of the graph to not be known at runtime so things like while loops become possible again. There's interesting research currently into combining dynamic and static graphs by compressing parts of the dynamic graph that you can identify as fixed.",2025-04-18 15:32:07,1,Stevo15025,programming
mn35g12,1jz2jbq,reddit,This is both impressive and deeply frightening,2025-04-14 16:44:27,2,oceantume_,programming
mn3kmg4,1jz2jbq,reddit,"That is absolutely insane. Idk if I’d use it, but as a concept it is wild af. 

How is the performance? I’d assume it takes a while to process a large proto file.",2025-04-14 17:57:57,1,CloudSliceCake,programming
mn2hxtj,1jz09sj,reddit,"I don't have the time, but this makes me want to drop Newlib even more.",2025-04-14 14:45:49,1,jaskij,programming
mm296eg,1jugrip,reddit,"I have found that ""hostile codebases"" (the opposite of ""friendly code"") tends to have a few qualities:

1. **Lack of consistency**.  Consistency is key for discovery and understanding the patterns in the system.
2. **Broad complexity**.  It's OK to have a bit of highly dense complexity if it can prevent complexity from spreading broadly in the codebase.  But that highly dense complexity needs to be well structured, well documented, and well tested.
3. **High repetition**.  Repetition creates opportunities for simple mistakes and creates cognitive load ""If I do this here, I also have to do this there and there and there..."".  This is very common in startups where a lot of copy+paste happens in place of refactoring to patterns, but is also more prone on some platforms versus others.
4. **Highly transactional**.  The code tends to lack domain entities and instead, represents the possible transactions instead.  The net result is that it's hard to discover, reuse, and re-compose existing code because of the tight binding to the transaction.",2025-04-08 16:55:00,4,c-digs,programming
mkzq9xu,1jphw3e,reddit,"Huh, I never thought about having to memoize children, too. Makes sense when you think about it, of course, since they are just another prop... Makes for really inelegant code, though.",2025-04-02 08:12:32,4,Pesthuf,programming
mk5jjfg,1jllpme,reddit,This was a really well written article actually.,2025-03-28 08:43:16,9,SwitchOnTheNiteLite,programming
mk5rpxr,1jllpme,reddit,"I'm sceptical of these releases from anthropic. Since they don't specify their methodology for inspecting and labelling model features in a way that's verifiable, this is just a bunch of flow chats saying ""look how clever our AI is! It thinks! Not like other models that just regurgitate!""",2025-03-28 10:10:01,7,Omnipresent_Walrus,programming
mk6zkny,1jllpme,reddit,"These blogs always sound like an ad, but this one is trying really hard. We've know for a long time how latent spaces work, that has nothing to do with thinking, it's simply a statistical relationship. The rhyme example is particularly silly since they are forcing a lot of meaning for no reason while also editing the network as they see fit. The model isn't ""planning ahead"", it's simply reacting to the fact that not every word rhymes with ""it"" in the training set, that's literally what these models always have done, statistically tell you what's the next word",2025-03-28 14:55:48,0,teerre,programming
mjud4pz,1jkdgeo,reddit,Interesting that Pokémon Company has been more lenient compared to the rest of Nintendo.,2025-03-26 14:59:20,9,Subsum44,programming
mjw3h1v,1jkdgeo,reddit,"> But, Pokémon Showdown is the OG battle simulator. They’ve been doing what Pokémon Champions is set to do for over a decade.

R.I.P. Shoddy & Net Battle, if you know you.",2025-03-26 20:01:35,2,valarauca14,programming
mouastn,1k6x9bi,reddit,"The same should apply to configuration, like we have prisma for sql, we should have something like this for JSONs, like https://typeconf.dev (I’m one of the founders)",2025-04-24 19:17:03,1,heraldev,programming
mows8pi,1k6x9bi,reddit,"Really like the emphasis on type-driven design here, it makes search systems so much more robust and maintainable in the long run.

That said, for local-first use cases, I’ve found that a lot of what we want out of a DSL can already be achieved with embedded SQL. DuckDB and SQLite are both fantastic for this--they’re fast, portable, and you get real query power without giving up structure.

And if you’re using Java, [manifold-sql](https://github.com/manifold-systems/manifold/blob/master/manifold-deps-parent/manifold-sql/readme.md) lets you embed SQL directly in code, fully type-safe and IDE-friendly--so you get all the benefits of a DSL and the power of SQL, without the stringly-typed pain.",2025-04-25 03:24:20,1,manifoldjava,programming
moujjzt,1k6vwlo,reddit,That's neat,2025-04-24 20:00:31,3,pickledplumber,programming
mousp4r,1k6vwlo,reddit,The name reminds me of this based software: https://greenfishsoftware.org/gfie.php,2025-04-24 20:45:17,1,No_Nobody4036,programming
movwytl,1k6vwlo,reddit,"It would be nice if there were more examples.

Also the examples just sat there blank for me.

So I'm still not sure what this does for me other than standand layout and arrows. :)",2025-04-25 00:23:30,1,zhivago,programming
mowctjm,1k6vwlo,reddit,"TikZ.js! Actually, it would be really cool if it worked with MathJax too.",2025-04-25 01:53:32,1,jdehesa,programming
mowjanh,1k6vwlo,reddit,I’d love a better mermaid js or something that can do azure or aws diagrams natively,2025-04-25 02:30:29,1,Icy_Foundation3534,programming
mop80jg,1k6dvwd,reddit,"This isn't a problem I've ever had. I've never had a manager insist on being the go-between for conversations between developers.

Managers absolutely should be gatekeeping random people asking for features or timelines.",2025-04-23 23:47:52,30,rcfox,programming
moqaong,1k6dvwd,reddit,"Managers are preventing the devs from talking to sales or product. Because sales or product keep asking for more. And because, believe it or not, most devs have trouble explaining things to non-devs, there is too much how and not enough why.",2025-04-24 03:39:20,7,gelatineous,programming
mos0avx,1k6dvwd,reddit,"Heh, yes and no.

Managers and middles guys SHOULD protect the team's time. And if you only rely on direct communication, you may completely disrupt someone's work by being constantly hassled by requests, questions and useless fluff. 

This this would only work in a work environment where there's a high quality of focus on the work to be done.

That being said the ""3-way chats"" is a good idea, I did saw something like that before and it was working well, but mostly on the virtue it is asynchronous",2025-04-24 12:29:24,2,DuskStalker,programming
mopzbif,1k6dvwd,reddit,"From my own experience, middle managers shouldn’t just be passing messages around — they really need to own the whole project from start to finish. For me, it’s about getting involved in the early tech research, setting up the team, keeping track of progress, and staying close to what the business actually needs. A good manager anticipates roadblocks before they hit and keeps everything moving smoothly. Of course, every company does things a bit differently, but I’ve seen firsthand how a proactive approach can really make a difference.",2025-04-24 02:26:07,4,Hungry_Importance918,programming
moqwz07,1k6dvwd,reddit,"So true. Chat structure can play a huge role. Had much better communication if everything happens in public groups. I even once told the new CTO about the previous, bad chat structure and how it should be improved when switching to another tool (here: Slack) – got an initial ""yeah that's important"" and then everybody just cooked their own soup again and it was as bad as before. I'm not working there anymore, luckily.",2025-04-24 06:37:39,1,AndiDog,programming
morugw6,1k6dvwd,reddit,Middle managers also shouldn't meddle in the technical side of things .. there is no cause-n-effect between a middle manager and being the best developer since sliced bread! ... advice to middle management ... go back to your metrics and kissing your boss' a...,2025-04-24 11:51:20,1,KrochetyKornatoski,programming
mosw8u9,1k6dvwd,reddit,"No. My job is to be a filter and I cannot be a filter if people skip me. The result is that you end up task switching and having mixed priorities. You don’t know what actually is important vs what is ok to defer to next sprint, next quarter, or to literally never do because it’s just someone’s stupid whim. My job as a manager is to be a buffer between chaos and your productivity and to create space for you to focus and do your job. 

I’m given the power, as part of my role, to tell the business “no” and I’m given the time, as it’s part of my job, to quantify the “no”. As an engineer, most likely you’re going to say no, not quantify it, or simply say you’re busy. The business will see that as confrontational or “difficult” whereas for a manager that’s seen as prioritization and team focus.

So no, unless you want your job to be a chaotic mess and ultimately get let go.",2025-04-24 15:17:53,1,o5mfiHTNsH748KVq,programming
motx4ed,1k6dvwd,reddit,"> Let’s say I need to implement Feature A.
> I ask my manager for documentation.

And this is where it has gone wrong, already. Why would the manager know?",2025-04-24 18:10:43,1,ben_sphynx,programming
movj8dv,1k6dvwd,reddit,"let's have a series of meetings to discuss why you feel that way

I'm sure we can come up with a process to optimise your communication requests",2025-04-24 23:06:45,1,mpanase,programming
mof0s4y,1k53qm4,reddit,"> that FOSS is specifically “forcing charity” on others, which the act itself is not virtuous but vicious

It’s virtuous because it promotes collaboration. Without forced charity, companies just use your free labor without sharing their contributions. Just compare Linux (developed via forced charity) to FreeBSD (no forced charity). One is thriving, the other is all but dead.",2025-04-22 12:02:09,19,Linguistic-mystic,programming
moha9g1,1k53qm4,reddit,"This guy seems to have some misunderstandings about what Free Software is, considering that he’s comparing it to OSS.

Free Software I guess is like communism in that it’s about community (whether that’s like “Java is like JavaScript the way that Car is like Carpet” is another story). 

The “freedoms” of free software are the essential freedoms of that community. You don’t have to participate in that community if you don’t want to. Not everyone who uses the GPL buys into this ideology. Linus chose the GPL because of the “share and share alike” practice consequence (which is why Linus is opposed to GPLv3). Others use the GPL as a scheme to sell proprietary licenses.

The GPL is “viral and pernicious” only if you think you are entitled to other people’s work without any obligation. The authors of GPL code believe in these freedoms, and don’t want their code to be used in proprietary software. Forcing those who benefit from the freedoms they were given to give those freedoms to others isn’t “forced charity”, it’s basic respect.

By the way, the fact that software has been getting worse over time has nothing to do with OSS, but that the barrier to entry has been significantly lowered. In the olden days, processing power and memory were scarce, and software had to be written with much greater care. Today, these things are abundant, so a lot less care is required to produce a useable product. This will obviously cause a decrease in quality of software as the quantity of software vastly increases. That has nothing to do with OSS.",2025-04-22 19:03:59,5,TippySkippy12,programming
mof4gm6,1k53qm4,reddit,leave it to Twitter to generate discussion like this,2025-04-22 12:27:06,2,bzbub2,programming
mok9o7r,1k53qm4,reddit,"We can see an alternative world to free/open source software right now, in the way of websites (free to sign up, ad- and tracking-driven profits), in the Android app store (free to install, ad-, tracking- and compulsion-driven profits) and in ""free-to-play"" games (same as Android apps).

In all those cases the (obvious) prices were also driven to zero, the profits are made in morally very questionable ways. If you wanted to sell an ""honest"" Android App right now, you would also face serious challenges.

In other areas commercial, proprietary software has de-facto monopolies, ie. Microsoft and Adobe. There is also almost no small scale commercial competition and the companies use it to force all their users into even deeper dependencies (you even do not control your own data anymore) and into subscription ""services"".",2025-04-23 05:32:56,1,dravonk,programming
mokmcye,1k53qm4,reddit,"I think it’s nice that there were some people who, seeing that software doesn’t fit nicely into existing frameworks of property, wanted to make a world where property was less important.
I don’t think that they necessarily contradict themselves when it comes to other industries which have a lot of intellectual property and trade secrets, maybe people wish that all industries had less intellectual property.

That might seem naive but I think it’s also foolish to think that the way society operates right now is the only or best way it can be.",2025-04-23 07:38:38,0,Ripest_Tomato,programming
mnpiak5,1k1c4wq,reddit,"> Since 64-bit computing was hideously expensive at the time of when the CRC33 polynomial got truncated down to 32-bits without any loss in generality even though this gives different results then a pure 33-bit implementation

I could be wrong here, but my understanding was that the polynomial is always one bit larger than the field, with the top bit always being a 1.  
Due to the awkwardness of 33-bit calculations, it's just easier to truncate it to 32 bits and make the code work with the implicit '1' bit at the top (i.e. manually do the necessary XOR).  Thus polynomials get specified without the top '1' bit.",2025-04-18 04:25:19,2,YumiYumiYumi,programming
mnf4il0,1k0j9jk,reddit,"Great to see another possibility to simulate logic circuits in the 2020s! I did a little survey of the existing programs last year because I wanted to translate the original schematics of a PDP-8/I in order to check my FPGA implementation for deviations. Turned out that most tools either require Java on the Desktop - or are browser-only and don't support many of the Logisim features such as nested circuits or signal tunnels.

I ended up finding this kinda new tool: [https://www.antarescircuit.io/](https://www.antarescircuit.io/)

It's a desktop program implemented in Kotlin, but there's also a web version that can load the circuits produced by the desktop app. This allows playing around with circuits on the web, e.g. here: [https://www.antarescircuit.io/docs/web/web/](https://www.antarescircuit.io/docs/web/web/)

I contributed a few patches and ideas to Antares and I think it's a great state-of-the art circuit simulation tool now. Here's the original PDP-8/I circuit from the 1960s if anyone's interested, Antares even allowed using the front panel art as an SVG: [https://github.com/fpw/antares-pdp-8i](https://github.com/fpw/antares-pdp-8i)",2025-04-16 15:03:11,2,fpw23,programming
mnaquca,1jzw379,reddit,"> says Daniel Terhorst-North, the author of the viral Twitter thread on the best programmer he knows


No idea who DT-H is and really don't care, but this is the most damning of faint praise possible.


> The programmer’s job is to deliver.  If you don’t get the job done, it doesn’t matter how good you are!


Is their job to deliver empty aphorisms...?",2025-04-15 20:50:40,54,jonhanson,programming
mnc2975,1jzw379,reddit,"I think the best programmers have certain personality traits, and a culture of humility, personal responsibility, and self improvement.

Being humble, means they are open to looking at things from different perspectives and questioning themselves - that itself leads to learning, improvement and identification of errors.

Personal responsibility means they take charge of things and dont expect others to fix things. If they see a possibility of a negative outcome, they act on it, and by doing do, they also gain certain experiences and knowledge which again make them better.

Self improvement means that they dont settle for getting things done, but for doing things better. That also leads to further self improvement.

Two people can be equally intelligent and capable at problem solving, but the persons personality traits can lead to more learning experiences, or them creating value for the team.",2025-04-16 01:15:50,13,StarkAndRobotic,programming
mnal5ie,1jzw379,reddit,I don't want to become best. I want proper life work balance. ,2025-04-15 20:22:28,44,Eastern_Interest_908,programming
mna12rf,1jzw379,reddit,Never trust anyone who wears a hat indoors ;),2025-04-15 18:42:10,20,OllieOnHisBike,programming
mncv00e,1jzw379,reddit,“I don’t always describe great programmers but when I do I describe myself.” I just can’t get this notion out of my head when reading these same articles over and over again. There is no data here. It’s all just subjective value judgments. Who cares?,2025-04-16 04:24:19,8,shizzy0,programming
mn9fxtv,1jzw379,reddit,"Dude nailed it - it's not just about slinging code, it's about understanding people, asking better questions, and being curious as hell.",2025-04-15 16:58:25,15,isaiahassad,programming
mndzt8r,1jzw379,reddit,">The best programmer he talked about is a real person; he’s known that person for over 20 years. And that person is not the best programmer because they are the best at solving LeetCode or the best at solving algorithmic problems (those programmers are going to be the first ones replaced by the LLMs, says Dan).

Yeah but no, there's no way LLMs are going to be able to be front runners on solving algorithmic problems. One of the best programmer I know is at the very forefront in the domain where he works, there's never going to be a LLM that's going to generate better solutions than him because they can't push the envelope forward, it just trains on existing solutions. The very best are also usually working more on architectural problems & overall design issues, also an area where LLMs are notoriously bad. The larger the project, the more it pays off in the long run to think about architecture & design. If you get it wrong everything you build on top of it will not quite fit, and then you need to special case & break the rules you've decided on, and down that path lies huge buggy spagetti mess.

>The best programmer doesn’t start by doing extensive research on the problem at hand, reading tutorials, etc. He just starts, even if he doesn’t know everything about the task. He does one thing, and if it doesn’t work, he then tries something else.

>He resists the urge to procrastinate and knows that doing (and doing something wrong) is researching!

You start by researching the problem domain you're trying to solve, and then you try to balance analysis paralysis with actually coding. The worst programmers just start to code by picking the first solution they can think of & get to work without spending time exploring the solution space of what they're trying to solve. The larger your toolbox is the more ways you have to approach a problem, and that generally also means you spend more time thinking about the problem than actually coding. The best coders find the balance here iterating on solutions they know will ultimately be scrapped, but also spending a lot of time understanding how others have solved similar problems. Actually writing code is a very small part of the time spent, because the more experience you have the more it's just an exercise of filling in a known puzzle which you've already decided on in your head. You already have a good idea about what aspects of that puzzle are problematic, because you know from experience what the full picture looks like.",2025-04-16 11:00:06,2,Sairony,programming
mndy39w,1jzw379,reddit,"People believe that ""best/great programmer"" can live on some imaginary intersection with ""best employee"".


Because of this conflation, the discourse gets really muddled. 


You can either be a great employee (political, obedient, quiet), or you can be a great programmer (technically skilled, critical, outspoken).


While I've seen some people try to get close, I've never seen both aspects in a single individual. The most political developers have always been the most prone to bad technical decision-making. The most technically skilled have always been indifferent towards optics and manipulation. 


In business nowadays, that puts their technical skill at a disadvantage as those people will most often be flagged as insubordinate. When in reality, they are simply more focused on the task at hand. 


Make of all that what you will, but I've been at this for 30 years. Companies are just schoolyards full of adults and there are still bullies.",2025-04-16 10:45:50,2,RDOmega,programming
mncqq5b,1jzw379,reddit,Random guy who has built nothing of value: “listen to me how to be a good dev with an AI created dot point list which is the same fodder everyone keeps repeating”,2025-04-16 03:52:17,0,SadCoder24,programming
mnhdao2,1jzw379,reddit,"> 3.2 Send the team home
>
> No one should be working late; a rested team is effective team.

Are we talking about a programmer or about a manager?",2025-04-16 21:44:10,1,somebodddy,programming
mnhh567,1jzw379,reddit,"> Choose the right tool for the product, not for the team. It’s easy to choose to use Java on a project if that’s what the team knows.

I really hate that advice. Or, more specifically, I hate the absoluteness at which it is usually offered. This should be done at the category level, not at the specific tool level. If - to take a very extreme example - `sed` would do the job better than Java, then even if you are a Java expert who've never used `sed` you should still pick it even if it means you have to learn it. But - if there are reasons to believe C# fits the job better than Java, you should stick with Java because your team's familiarity with it (and with its ecosystem) is going to dwarf the slight advantages C# has over it for that particular task.

Also - the extensive research required for determining the exact tool which is best for any specific job kind of contradicts the first part of the article...",2025-04-16 22:05:19,1,somebodddy,programming
mnk51mk,1jzw379,reddit,This is one of the worst written articles I have ever read.,2025-04-17 10:02:50,1,Kwantuum,programming
mm5zgtw,1jnxz1w,reddit,"A modest proposal;   a flag like --treat-ub-as-error  for your c/c++ compiler.

However, that's not going to happen. The C and C++ language committees are populated entirely by compiler wonks.

Speed and efficiency... of cpu cycles. Are they the right cpu cycles? Eh. Not their problem.",2025-04-09 05:31:41,1,Excellent_Tubleweed,programming
mkt7pvr,1jnxz1w,reddit,"Commenting here to check back, in case a thoughtful discussion happens (apologies for contributing absolutely nothing on that front)",2025-04-01 05:12:27,0,ironykarl,programming
mjum7xm,1jkdmh3,reddit,"> Developer tries TDD, attempting to adhere to the steps.

The alternative posed here is (instead of a sequence of steps) an extensive list of suggestions that only make sense in context if you already know TDD... This isn't really an article saving TDD, but instead throwing the idea away by conflating TDD with the value of tests in general and then sort of suggesting that people test.

The only real benefit of TDD is if you give up on any religious notion of unit testing and essentially view writing a test as an exercise in public API design. Remember, it is Test **Driven** Design, not merely tested design. When you are writing your test you should be thinking, ""What do I want the developer experience of using the API I am about to build to be?"" You focus on the public api first and write down the usage of it and make assertions on what it produces. The goal then becomes to implement that API. It is easy to stub implementations and iteratively implement them until you have your test working.

If the setup is extensive and confusing, you should be thinking, how can I make it easier for users of my API to set these things up? You are the first user of your API. Basically, you write an API that you want to work with and then you implement that. If the API irritates you somehow, then you refactor the API while you don't have any code backing it so it is still cheap.

Instead, if you don't think about the API from the usage side first, chances are you complete a full API, but even though it is irritating to use you feel loss aversion when you consider refactoring it so you simply ship it.

Why do I say to give up on religious ideas of unit testing? Because the test you write is going to probably require a bunch of units to coordinate and function and you shouldn't be mocking them just to make that first test work. The simplest ""dependency injection"" I have ever worked with was changing a db connection string to instantiate an in memory sqlite db in place of a real connection. Tests made like that are still incredibly fast and survive refactoring. Ideally, even services can be connected without network hops. They aren't real unit tests nor real integration tests.",2025-03-26 15:44:56,6,Illustrious-Map8639,programming
mkn0bbv,1jkcfr1,reddit,Local first sounds rad. All that crypto sounds really complicated.,2025-03-31 05:02:48,2,youngbull,programming
movp2az,1k71kd2,reddit,">all on a single thread


Software developer discovers compile languages and how fast modern CPUs are.",2025-04-24 23:39:08,10,BlueGoliath,programming
moxn95i,1k71kd2,reddit,"Love the app Kulve. I wish discord and slack would also have native clients which use faster APIs like opengl to draw things.

Its just so snappy, uses so little ram.
Powerful machines are only faster if the apps that we use are as efficient as they used to be back in the days",2025-04-25 07:47:45,1,txdv,programming
mowwlqv,1k71kd2,reddit,"> This ""handler"" component (still don't know what to name it) also orchestrates the asyncronous workflow in a way that not only doesn't wait for results, but ensures that no data races occur if the UI ends up navigating away from the page and/or starts a new request before the results of the first one.

Maybe there's some ESL stuff going on here, but sentences like this are pretty darn hard to unravel for the reader. 

For example, I'd write this as:

> The handler component orchestrates the waiting for results from other threads. It also handles edge cases, such as the user navigating away, or starting a new request before the last has completed.

Ultimately, you might benefit from passing your writing through an LLM with instructions to write plainly.",2025-04-25 03:53:24,0,light24bulbs,programming
momaqbx,1k60ai7,reddit,"The real challenge is that there is no universally correct atomic unit of decomposition for strings, which means that string length is itself incoherent.

And likewise there can be no universal character type.

How long is 밥 for example? Is it one character or three?

It depends on how you're looking at it.

Text processing is much more interesting than the illusion of simplicity our languages tend to provide.",2025-04-23 15:02:34,8,zhivago,programming
momlksu,1k60ai7,reddit,Grapheme clusters most closely match what we consider a character,2025-04-23 15:55:08,3,CKingX123,programming
momk4h7,1k60ai7,reddit,Nothing burger of an article.,2025-04-23 15:48:08,-2,Fiennes,programming
moj6uhp,1k5bdoc,reddit,Wow this is awesome,2025-04-23 01:09:34,1,Interesting-Story405,programming
moakm5h,1k4iwjg,reddit,This is an interesting approach to organize source code. Remins me a little of how Smalltalk's Code Browser does.,2025-04-21 18:04:11,2,6502zx81,programming
moay7bx,1k4iwjg,reddit,Is that you TopMind?,2025-04-21 19:10:59,1,PerceptionWinter3674,programming
mofqxv2,1k4iwjg,reddit,"Where do I try the web prototype? 

I imagine you could make it work for a Forth, or Lisp-like language pretty easily",2025-04-22 14:35:11,1,Zireael07,programming
mooz8i9,1k4iwjg,reddit,"Don't find this remotely expressive.  

Feels retrograde in the same way working with a tracker feels retrograde as compared to working with Ableton's Live.",2025-04-23 22:58:59,1,church-rosser,programming
mnoi9yg,1k1m4oc,reddit,Very important information for programmers.,2025-04-18 00:23:05,1,BlueGoliath,programming
mnnvfls,1k1k786,reddit,"If you want to be a founder do the following:


- make a project that can make you stand out from the crowed of people above your age
- ask your parents to find friends to buy the product from you but never tell anyone they did it
- when you reach certain amount of revenue ask your parents to ask the local news to make a video of you showing you are an entrepreneur
- at age 16 get into one of the top 10 colleges in the USA
- find 2 other co-founders for your AI startup from the same college
- by age 18 have an AI product ready to pitch to YCombinator or other angel investor
- drop the college and work full time
- get funding and pay people to develop the company while you and your co-founders become the face of the company
- by age 21 you will have become billionaire


success in the market is all about collecting results that a few can get and that can be measured. Don't waste your life learning thousands of stacks and technologies because this is not efficient. Learn enough to collect a result that can make people see you are more valuable than other people. Yes, it is all about comparison contrary to what psychology say. If you don't do what I said above you are doomed",2025-04-17 22:10:29,-35,Positive_Method3022,programming
mn2frru,1jz0d2x,reddit,PDF here https://github.com/dendibakh/perf-book/releases/tag/2.0_release,2025-04-14 14:34:30,3,ketralnis,programming
mm6olnp,1juzs1j,reddit,"This post seems very confused.  Mistake #1 claims:

> `WHERE to_tsvector('english', message) @@ to_tsquery('english', 'research')`

> This forces PostgreSQL to:

> 1. Perform Expensive Computation: Run to_tsvector() (parsing, stemming, etc.) repeatedly for many rows during query execution.

> 2. Limit Index Efficiency: Prevent the most direct and efficient use of the GIN index, even if one exists on the base message column.

And suggests indexing a precalculated tsvector column instead.

This is wrong.  If there is an index on `to_tsvector('english', message)` then it will not need to recalculate the tsvector during the query, and the index will be just as useful (identical, even) as the proposed fix.

This seems like a pretty major thing to get wrong.",2025-04-09 09:52:06,1,therealgaxbo,programming
mlj6zvg,1jrh3w2,reddit,So many textboxes... I don't mind filling out surveys but writing essays isn't my style.,2025-04-05 12:50:07,3,pip25hu,programming
mlcifr3,1jqwxfi,reddit,How is the proposed change-id diffrerent than the name of the branch that the changes are commited to?,2025-04-04 09:32:34,-2,Skaarj,programming
mlbxilo,1jqwxfi,reddit,"I wonder, why are they not exploring placing the change id as part of the commit metadata; of course with upstream change.",2025-04-04 05:59:39,-5,Venthe,programming
mlbpotm,1jqwv8q,reddit,Will the lecture videos be available to the public?,2025-04-04 04:50:30,2,highview,programming
mlc5os8,1jqwv8q,reddit,Thanks for sharing. Definitely looks interesting. Will check it out,2025-04-04 07:14:19,1,jduyhdhsksfhd,programming
mkoqcro,1jnx6uh,reddit,"> I am looking for ideas to minimize the weights loading time. Any idea on how I can improve this?

Faster disk or more RAM?",2025-03-31 14:03:03,2,puddingfox,programming
mktakyq,1jnx6uh,reddit,Are the weights compressed? If not do so and load them on a second thread. I/O-bound operations don’t get penalized by the GIL.,2025-04-01 05:39:15,2,Wonderful-Wind-5736,programming
mkxgte6,1jnx6uh,reddit,I haven’t looked into the implementation but do you know if there layers are fully connected? Could you avoid loading the nodes in the next layer that don’t receive input?,2025-04-01 22:08:43,1,raiango,programming
mko80il,1jnx6uh,reddit,How do we get it where it doesn't censor things?,2025-03-31 12:09:31,-3,One_Being7941,programming
mon26po,1k646ky,reddit,"Ben Eater has a fascinating series of YouTube videos designing an 8-bit breadboard computer from logic components. It really breaks down the various internal registers, bus behavior, etc. Highly recommend!",2025-04-23 17:15:28,3,Fluid-Assistant-5,programming
moo66vu,1k646ky,reddit,"This handwaves past all of the interesting things I wanted to learn more about (""I draw the line""...).",2025-04-23 20:27:46,1,mctwistr,programming
mon5wfm,1k646ky,reddit,"AFAIK there was no native assembler for the c64. We used to either have to upload the code to a BBS and hope the sysop would compile it for us on his fancy machine, or... write a basic program, that stored asm instructions directly in RAM and execute it from there. Which was tough, because there was no assembler, you had to find the byte code for the instruction and stuff it into RAM. I almost failed the 5th grade trying to write a breakout clone in 6502 assembly.",2025-04-23 17:32:48,1,Dirty_South_Cracka,programming
momdpk9,1k5vn3c,reddit,Jia Tan? Is that you?,2025-04-23 15:17:12,1,BlueGoliath,programming
mom0xj3,1k5v9vm,reddit,"I have to agree with ALMOST all of this.

The primary exception would be the bit about dependency injection. External systems (e.g. client talking to an external API ), should be injected and also mocked/faked so that internal testing can be completed. In some cases business partners don't even provide an appropriate test instance (horrible practice ).  Like wise sub-systems where are exceedingly slow (e.g. a ton of computation ), should be mocked so that the overall systems can be tested in an expedient manner.  In both cases there should ALSO be some level of testing which uses the actual real API/subsystem if possible.",2025-04-23 14:14:11,1,manzanita2,programming
mokk0zw,1k54lvz,reddit,What's the difference between webextensions and regular chrome extensions?,2025-04-23 07:13:45,1,remenic,programming
mofres1,1k4jabg,reddit,Congratulations! You're making progress where it really counts. ,2025-04-22 14:37:32,1,Wonderful-Wind-5736,programming
mom6jz8,1k4j90u,reddit,"I don't mind the idea of vendoring as such, but I won't use them until Dependabot or similar tools support the vendoring automation solution.",2025-04-23 14:42:07,1,yxhuvud,programming
moaobp7,1k4j90u,reddit,"There is no reason (to me) to forgo normal dependency management in a world that has working dependency managers, unless you are prepared to effectively fork libraryX.

And that is not necessarily just a scare-statement, I think there is sometimes too much reluctance to just go ahead and fork things, but I don't believe there is value in vendoring without this in mind",2025-04-21 18:22:18,1,bzbub2,programming
mnwprph,1k2t11l,reddit,Wonderful video. Keep up the good work. Thanks for sharing,2025-04-19 10:59:40,3,PossibleCicada4926,programming
mnaq30t,1jzyg9j,reddit,"This is a rather long-winded way of saying ""I think React Server Components are cool"".",2025-04-15 20:46:52,3,pip25hu,programming
mn4addt,1jz8e2t,reddit,"Emacs' [maggit](https://github.com/magit/magit) has been doing this for awhile and remains the best git interface available in 2025.

Long live Emacs! Long live Maggit!",2025-04-14 20:07:19,1,church-rosser,programming
mn2m86d,1jyz41g,reddit,Can’t you just save it as a PWA?,2025-04-14 15:07:45,21,Pattycakes_wcp,programming
mn2d67c,1jyz41g,reddit,But why? Is this literally not just a browser shipped to visit their website or are you only using their APIs and building your own UI on top?,2025-04-14 14:20:45,27,Valuable-Yard3577,programming
mn2m6uw,1jyz41g,reddit,The people yearn for progressive web apps,2025-04-14 15:07:33,24,caschb,programming
mn26vd2,1jyz41g,reddit,Nice work OP! What made you decide into making a wrapper instead of going through a browser? More direct? Fun little project? Or are there any other benefits besides that?,2025-04-14 13:46:22,3,ExclusiveOne,programming
mn26bhw,1jyz41g,reddit,"The Crunchyroll license classifies redistribution as commercial activity, which would include GitHub releases.

Since this is a wrapper that doesn't distribute any code belonging to Crunchyroll, you can simply license as MIT without problems.

Have you considered publishing a Flatpak?",2025-04-14 13:43:15,4,KrazyKirby99999,programming
mn55uj7,1jyz41g,reddit,"To all the comments that say I simply could've used PWAs (Progressive Web Applications), I did a quick test and most of the PWAs don't work and show a DRM error.  
This is simply due to inconsistent DRM support on PWAs.

The release contains a custom compiled Electron binary with WidevineCDM support that fixes this issue and is much more reliable and consistent than the PWAs.",2025-04-14 22:57:39,2,Mean_Option_7459,programming
mn6x98g,1jyz41g,reddit,"Out of curiosity, why disable the inspector/F12 tools?",2025-04-15 06:12:05,1,GasterIHardlyKnowHer,programming
mmww06b,1jy2p1u,reddit,"Not understanding HTML entities, tho.",2025-04-13 15:57:08,3,DaveVdE,programming
mm8vakd,1jv639a,reddit,"Cool! I'm a Big proponent of re-/writing shell scripts in a language suitable to the project & task. Bash/sh-the-language is... weird, and most people write it infrequently enough that they need to relearn all the tricks and pitfalls each time. I've used several similar tools, like Rscript, Escript (for Erlang), 

Lua seems like a good candidate for shell scripting, seeing as it's foremost intended to be an easy, interactive embeddable scripting language. There are some things missing that would be nice, like argument parsing or json stuff, and as far as I can tell there's no way to install packages programmatically to supplement.

Luash seems interesting, though I'd worry that it might tempt people into word-for-word rewrites while avoiding Lua's native functionality, which wouldn't provide as much benefit.

My preferred tool for this is Babashka, which is a scripting runtime for Clojure. I rarely need to shell out to external programs so my scripts are more easily cross-platform, it includes a task runner and argument-parsing library, json/xml/csv/yaml/edn libraries, and I can add one-off versioned dependencies from within the script itself. It's a great all-round experience, tbh.",2025-04-09 17:31:45,7,11fdriver,programming
mm9vjjq,1jv639a,reddit,"If it's more complex than running a few commands, then I just jump up to Python. Likely to be installed by default on many Linux distros.

And if you're doing something a bit more complex that needs dependencies, you can use ""uv run"" to manage that for you: https://simonwillison.net/2024/Aug/21/usrbinenv-uv-run/",2025-04-09 20:25:55,5,lotanis,programming
mmaf24w,1jv639a,reddit,"But ... a shell script? That's not written in lua...

> Handling strings with Lua’s string manipulation functions is undoubtedly productive and faster in shell scripting

I never understood why shell scripts are used so widely on Linux. I always felt as if I would cripple myself using shell scripts. Ruby replaced all shell scripts I'd ever need to use (save for a few bootstrap-related shell scripts I still keep).

I distinctly dislike how arguments are passed into functions in shell scripts. It seems not a clever approach.",2025-04-09 22:06:08,2,shevy-java,programming
mm82mu3,1jv639a,reddit,"Been having a nice time with Lua again this week for some gamedev, but I hadn't heard of the Luash project! Looks good",2025-04-09 15:11:57,1,Isogash,programming
mm2p3km,1ju6zz5,reddit,you're just on time with your post :),2025-04-08 18:09:40,2,ilham_israfilov,programming
mlte4k2,1jszrp4,reddit,"It’s interesting how much this reminds me of the first time I wrote Go some 10 years ago. It’s way over engineered, but I think that’s part of the learning process.

If I had to teach someone from scratch, I would say just put it all in a single file, get it working, then break it up into packages after you have your implementation surface how you like it. It’s a similar concept to TDD, but slightly less rigid.

Good job learning though, keep going!

edit:

Also, you can template migrations and use go-migrate as a library, fyi.",2025-04-07 04:53:37,3,Cidan,programming
ml8s369,1jqmipt,reddit,"I liked the article,light and easy to consume with good points to consider. Thanks.",2025-04-03 18:29:26,5,johnmc325,programming
mlaptro,1jqmipt,reddit,"I'm not convinced that old versions should become unsupported. The point of an API is to provide access to a wide range of clients and some are not that easy to update (also why they should be required to be updated when there is no reason).

You could almost always implement the old version by calling into the new version internally if it's annoying to maintain, this way it is done only once. It also encourages to design the API well so you don't have to create that many versions.

Most usages would gravitate naturally to use the newer versions as most people would update the applications so it shouldn't represent an increased load overally.",2025-04-04 00:45:51,1,jezek_2,programming
mlbv0hl,1jqmipt,reddit,Just host the new version of the API on a subdomain which is the short sha of the change commit. That'll keep people busy.,2025-04-04 05:36:41,0,elmuerte,programming
ml7p7xu,1jqctx0,reddit,"In K&R2, nested arrays are *specified* as having all of their elements placed in one continguous region of storage, with the last element of all but the last row specified as immediately preceding the first element fo the next row.  Because of this, and the fact that indexing was *defined* in terms of address computations, given \`int arr\[5\]\[3\]\` and a value \`i\` in the range 0 to 14 (inclusive), `arr[i/3][j%3]` was equivalent *by specification* to `arr[0][i]`.

C99, in a *non-normative annex*, and with *no normative justification*, broke the language by saying that an attempt to access an array with an inner subscript that wasn't within range of the inner array invoked Undefined Behavior, even if the access would fall within the range of a containing array.",2025-04-03 15:19:24,2,flatfinger,programming
ml6lu4s,1jqctx0,reddit,"My language of choice, Common Lisp, handles multi dimensional arrays with no problems. Strongly typed garbage collected language FTW!

Not everything true of C/++ is true for other languages.",2025-04-03 11:31:29,4,church-rosser,programming
ml87kgq,1jqctx0,reddit,"Arrays were the first thing that I remember having an ""oooooh...that's how that works"" moment in programming.

I learned about them in college but it was still pretty abstract. It wasn't until I got my first job and I had to use them that it really clicked. And it really did feel like like something clicked into place in my brain. Such a wonderful feeling.",2025-04-03 16:49:39,1,ThisIsMyCouchAccount,programming
mm54sam,1jqctx0,reddit,"`a[0][i]` is ugly and gross anyway.  It seems to me that if you want to access a multi-dimensional array as a linear array, you should just cast it in the first place:

```
#include <stdio.h>

#define ROWS (2)
#define COLS (4)

int main()
{
  int a[ROWS][COLS] = { { 0, 1, 2, 3 }, { 4, 5, 6, 7 } };
  for (int i = 0; i < ROWS * COLS; ++i)
  {
    printf("" %d"", ((int*)a)[i]);
  }
  
  return 0;
}
```
which I believe should be well-defined.",2025-04-09 01:55:12,1,ozyx7,programming
ml4u29g,1jps2jt,reddit,I really liked the last video i saw from this guy. But this mic sounds like its under water or compressed to shit or something. I'm still going to make it through based on the last video. Please fix it if op is the author.,2025-04-03 02:12:29,1,todo_code,programming
mknrhqm,1jnz0ka,reddit,I thought this was the building designer from Sim City 2000.,2025-03-31 09:46:40,2,binarypie,programming
mkok7qn,1jnz0ka,reddit,"Cool, the graphics slightly remind me of roller coaster tycoon scenery graphics. Though the basic code gives me PTSD from times I've had to touch pascal because I really don't like the ""then if else end"" syntax, I prefer the curly braces.",2025-03-31 13:28:27,1,Harha,programming
mkhn98x,1jn74ag,reddit,"Interesting! Definitely going to follow this. Local search is always a challenge, and most of the times it results in some very simple techniques with suboptimal results",2025-03-30 08:34:25,5,robbiedobbie,programming
mowm4as,1k75aow,reddit,"I think AI will create more jobs because its so bad, and once this phase passes, they will need to hire real devs to fix all the stupidity. 

AI is very convincing in how it talks, but completely hallucinates a lot of things.",2025-04-25 02:47:00,65,StarkAndRobotic,programming
movjaeg,1k75aow,reddit,"I generally agree with your assessments of what LLMs can and can't do (there are always nitpicks, but whatever).  But I don't think you are correct in your assessment of what motivates those of us who don't give our autonomy to LLMs.

> I am exaggerating a little, of course, nevertheless I think that there is dishonesty on both ends of that spectrum that is motivated by either greed or self-preservation; one side is trying to market their AI tech to raise capital, and the other side is scared shitless that they’ll lose their income.

I have no fear whatsoever of losing my income to an LLM.  No LLM that exists today can do what I do, and no LLM will ever be able to do what I do.  They have no fidelity or ability to reliably learn and apply best practices.  A model is trained (and maybe fine tuned), and that's it.  Even if this wasn't the case, they still could never do what I do because they are fundamentally not capable of deduction or inference.  They're just text prediction engines that are really good at making plausible output but not particularly good at accurate output because - again - they lack the ability to discover.",2025-04-24 23:07:04,54,Nyefan,programming
moy2416,1k75aow,reddit,I've been using it pretty successfully recently. One thing that strikes me is that it makes business analysis far more important than it already is because you need very specific requirements for what you want it to deliver.,2025-04-25 10:20:04,7,TheBlueArsedFly,programming
moxv2z0,1k75aow,reddit,"\> on the other hand, you have those that say AI slop is just ruining the planet and will never amount to anything.

This is based on facts: [https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/](https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/)

OpenAI, which owns 95% of the LLM market, spends 2$ to earn 1$.

It loses money even from paid users. It needs to raise more funds than anyone ever did to hope to continue to survive and expand. It's hitting capacity limits which means it'll have to either start rationing its service, force people to pay, or the quality of service will just degrade. (because as it turns out you can't just wave a data center with hundred of thousand of GPUs into existence)

LLMs are hitting diminishing returns on improving because they can only be improved by brute force aka ingesting more human authored content. But they have already pretty much ingested all the human authored content that is available.

People keep waving about fan fiction of what they think AI will do in the future, but in the present, all that computing power, money and energy expenditure amounts to are mediocre chat bots of questionable usefulness. But surely, by throwing even more money, computing power and energy onto this gigantic trash fire it will suddenly transform into something actually good!

So I think what will actually happen is that the whole thing will spectacularly crash and burn. I might just die of a schadenfreude overdose.",2025-04-25 09:10:08,7,ClownPFart,programming
moyl2gn,1k75aow,reddit,"~~That's rich coming from someone that seems to be using AI images on their website.~~

Ok, I don't know whether the artwork is AI or not. I just hope it's not.",2025-04-25 12:40:12,0,JezusTheCarpenter,programming
mouh2cx,1k6vvlp,reddit,"> Paradoxically each new SIMD generation essentially renders the previous generations redundant.

If only! Using 256- or 512-bit instructions on x86 can downclock your entire core (512-bit more than 256-), so unless you know you’re streaming through large amounts of memory, it’s better to stick with 128-bit, whether actually in the oldest SSE/-2 instruction subset or not. Iow, you need to continue supporting past techniques into the indefinite future.

And then, there are extensions like FRMS that actually make the *much* older REP MOVS and REP STOS instructions faster than vectorgunk for large enough buffers—prior, SSE and worse hacks were used. (E.g., who remembers FILD/FISTP to memcpy on P5?)",2025-04-24 19:48:20,5,nerd4code,programming
movdegb,1k6vvlp,reddit,"Flaw 1 and 2 aren't right: 1) AMD did use 256 bit execution units for 512 bit operations, so it's doable. 2) in-order architectures for performance computing are a total non-starter, so it really doesn't matter.",2025-04-24 22:34:23,3,wintrmt3,programming
mnobcyc,1k1pkys,reddit,Awesome!,2025-04-17 23:41:50,1,Efficient_Suit_1030,programming
mmyrbps,1jyir70,reddit,Centering a div is the hardest programming problem in the history of programming.,2025-04-13 21:53:41,1,BlueGoliath,programming
mmrukt8,1jxnw6v,reddit,"I was wondering, is the layout and screenshots fine? If there isn't a problem I'll write pages like this every week. I won't be posting to this sub every week, maybe once a month",2025-04-12 18:29:03,2,levodelellis,programming
mmt21vp,1jxllin,reddit,Congratulations on a job well done. :),2025-04-12 22:36:14,2,zhivago,programming
mmt6wn1,1jxllin,reddit,Year of the esolang.,2025-04-12 23:07:01,2,BlueGoliath,programming
mmrkihn,1jx23t3,reddit,"`git pull && git log`

Or if you're that ambitious https://git-scm.com/docs/githooks#_post_merge

But never npm anything in my git flow 🤦",2025-04-12 17:36:24,2,Serious-Regular,programming
mmm41cp,1jwp95k,reddit,"He mentions the legend Brian Kernighan at 41:22. This in turn reminds me of a young Brian Kernighan here: https://www.youtube.com/watch?v=tc4ROCJYbm0 where he shows pipes under UNIX, at ~ 18:28.",2025-04-11 19:19:38,2,shevy-java,programming
mmh6e1i,1jwc15d,reddit,"Hey all! Just dropped the second part of my two-parter explaining how to use python to extract table data from a set of Word / docx files and merge them into a different Word template! 

Cool little gig, saved these guys a few thousand bucks with a couple days' work so thought it might be nice to share the process!

Part two covers the merging and of the csv into the intergrated report format:
https://peakd.com/hive-169321/@coderad/how-i-saved-100s-of-hours-of-work-for-a-local-company-using-python-and-python-docx-n00b-friendly-part-22

Here's the first bit, if you missed it covering the data extraction to csv files (and getting the gig in the first place!):

https://peakd.com/hive-169321/@coderad/how-i-saved-100s-of-hours-of-work-for-a-local-company-using-python-and-python-docx-n00b-friendly-part-12

Cheers

CodeRad",2025-04-10 23:32:42,1,CodeRadDesign,programming
mm7b6yc,1jv4hby,reddit,"Seems like the thing to get in front of is actually having deterministic command lines in production. Good grief.

Also, the ordering of arguments in bash wildcard expansion isn't ""alphanumeric-ish"", it strictly follows the LC_COLLATE environment variable.",2025-04-09 12:46:15,11,falconindy,programming
mm96pj7,1jv4hby,reddit,I’ve seen issues with FS ordering before with Spring since the order of class initialization depends on the order in the JAR which depends on the order of the FS unless you are careful.,2025-04-09 18:25:19,1,slaymaker1907,programming
mm3rb6q,1jttpad,reddit,"50 years is not only the age of C, but also the age of the first open source supply chain attack - the aforementioned self-modifying C compiler that would inject a backdoor whenever it compiled the file handling the login sequence.

Things move slow in the software industry.",2025-04-08 21:14:55,1,flundstrom2,programming
mlcd8dc,1jqx08u,reddit,Crust?,2025-04-04 08:36:08,2,Batteredcode,programming
mlc562o,1jqp7fi,reddit,Typescript? Don't people know javascript anymore?,2025-04-04 07:08:48,-8,BasieP2,programming
ml8d24n,1joai0u,reddit,Science has gone too far!!,2025-04-03 17:16:22,1,zombiecalypse,programming
mjxdgjf,1jkb57i,reddit,"ES2020 was 5 years ago and browsers were implementing BigInt long before that.

The biggest problem with BigInt is performance. Whether it's inherent to the spec or a lack of optimization, even small numbers that should be representable by 31-bit ints (the same ones they use to represent most numbers in JS behind the scenes) they are massively slower.

Add in the proposal to use the Math library taking forever and it's pretty easy to see why they aren't very common.",2025-03-26 23:50:59,13,theQuandary,programming
mjttgpn,1jkb57i,reddit,"More langauges should have base 10 floating point numbers like C# has the Decimal data type.

Sure there will be a performance pentalty, but they are so much more intuitive for people to work with. Most people will understand limitations like not being able to perfectly represent 1/3 because it's a repeating decimal in our normal everyday number system. Similar to how you can't represent the exact value of pi or e in any base. Not being able to properly represent numbers like 0.1 just causes a lot of headaches and confusion for programmers.

With how common it is to use computers for financial calculations, not having a native base 10 decimal datatype seems like major feature that's missing. That's not to say that binary floating point shouldn't be there, but support for base 10 floating points should be right up there with support for strings and dates.",2025-03-26 13:14:26,15,w1n5t0nM1k3y,programming
mjz0gw3,1jkb57i,reddit,"Floats are a fine choice for numbers in a scripting language. An integer range of +/-2^53 should be enough for most practical applications. As for the classic `0.3 - 0.1` example, I'm sorry, but I think this is a skill issue. I can't remember the last time I was tripped up by this kind of thing. I probably was at some point, but these aren't difficult lessons to learn. Programmers should understand how floats work.

Bitwise ops truncating to 32 bits is a trade-off with several icky alternatives: Should they truncate to a larger bit width up to 53? Should they cast to a 64 bit integer type? How would that type interact with JS's existing mess of duck typed weirdness?

I'm a little biased because I'm building a language, and I've decided to make the same design decisions, or maybe repeat the same mistakes. Floats are far from perfect, but using them exclusively works 99% of the time, gets you reasonably good performance, and saves you from worrying about overflows or casts.

Can't say I disagree with the overall conclusion though. In a mature general purpose language, there should be more options with better support.",2025-03-27 06:46:15,4,birdbrainswagtrain,programming
mjxgahw,1jkb57i,reddit,"Interesting though I'm not in complete agreement.  
  
I don't want something like BigInt to be the default next step because its literally 99% slower performance then Number and thta alone has been an issue I've faced many times. I want there to be a base number how it currently is, a bigint with better JSON support, a BigNumber that can handle any float precision, a 64-bit signed and unsigned number. 5 types, all different use-cases, 3 of them having great performance, all can handle arithmetic operations syntax.

I don't get why we can add dumb crap like pipelines and yet another Symbol like type, but expanding how we deal with numbers is somehow stuck in the stone age with this language.

Side note, I will always be annoyed AF that bit manipulation has been relegated to 32-bits. So stupid.",2025-03-27 00:06:46,5,Craiggles-,programming
mjyrvag,1jkb57i,reddit,"> You know, complex decimals like 0.1

Actually, that value is complex in base 2. It's odd to say this given that he spends so much time explaining how floating poibts work.",2025-03-27 05:19:49,1,NiteShdw,programming
mjyrwz5,1jkb57i,reddit,"The reason why bigint is not default, is because it is  soooo slow.   
It is basically a [dynamic array of bytes](https://docs.openssl.org/1.0.2/man3/bn/#synopsis) with software implemented operations like sum, multiple, shift (not CPU).",2025-03-27 05:20:15,1,RedEyed__,programming
mjygwkv,1jkb57i,reddit,"JavaScript (as language) annoys me. I don't have any good work around (aka to not use JavaScript would mean I would forego its benefits in the browser ecosystem), but I'd love to leave it behind. If only WebAssembly could truly free us from JavaScript ...",2025-03-27 03:49:48,0,shevy-java,programming
mjuh2ju,1jkb57i,reddit,This article assumes a javascript person knows what bitwise operators are.,2025-03-26 15:19:07,-12,NenAlienGeenKonijn,programming
mowe4ea,1k79id4,reddit,The link fails with a 403 message,2025-04-25 02:00:46,1,ryuzaki49,programming
movyexy,1k77q5b,reddit,"If this is moved into a syscall, the syscall will then just take longer as it does the same thing for the filesystem. The OS doesn’t know anything about files. PATH is a user space concept, but, supposed you did want to solve that searching problem; how do you handle the `N` number of potential filesystem interfaces for each directory? Everything in UNIX is a path which means the OS has to ask the owner of that path for information. 

You ultimately optimize one call by making another call worse.",2025-04-25 00:31:43,36,demosdemon,programming
mowzu9s,1k77q5b,reddit,"I would want different paths for different concurrent processes. While a default path is a thing (and frankly messy without care), I need a ton of fidelity if I’m outside a single purpose docker container",2025-04-25 04:16:37,4,paul_h,programming
mox12oo,1k77q5b,reddit,No,2025-04-25 04:25:36,4,knowledgebass,programming
movvur6,1k6x9dk,reddit,"The more interesting question is: given a floating-point number, find the shortest decimal representation that rounds to the same floating-point number.

This is what makes `print(0.1)` print 0.1.",2025-04-25 00:17:18,1,vytah,programming
mot1vso,1k6u7my,reddit,This an example of what might happen: https://tansu.io,2025-04-24 15:44:39,3,InformalOutcome4964,programming
moyc9qe,1k6u7my,reddit,If you just wanted to have an always on broker with near infinite storage and a stream of messages for pennies you could also go with this: https://github.com/xn-intenton-z2a/s3-sqs-bridge,2025-04-25 11:42:14,2,InformalOutcome4964,programming
motyyry,1k6u7my,reddit,"I like NATS, way smaller resource usage, written in go around the same time as Kafka, try it out!",2025-04-24 18:19:32,1,lcserny,programming
