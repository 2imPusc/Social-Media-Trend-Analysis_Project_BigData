subreddit,post_id,comment_id,comment_content,comment_score,comment_created_at,comment_author
programming,1jwmwdy,mmjksaf,"He built it in 9 days, and rested on the 10th. That's one two week sprint.",2991,2025-04-11 11:09:11,rcls0053
programming,1jwmwdy,mmjmrz3,"In an interview, he said, he ruminates the design over several months. Then he wrote the first version in ten days. Then after that only he starts using git for kernel development. Then handover git development after four months.",911,2025-04-11 11:24:44,zemega
programming,1jwmwdy,mmjnk86,Vast oversimplification,423,2025-04-11 11:30:46,ziplock9000
programming,1jwmwdy,mmjjxub,The hard part is design. Git still exists because the design is extremely useful and flexible.,472,2025-04-11 11:02:12,Isogash
programming,1jwmwdy,mmjl5h3,Imagine how fast he would do it today with vibe coding!,257,2025-04-11 11:12:08,TyrusX
programming,1jwmwdy,mmkqqmf,"Linux Torvalds built Git in 10 days... Plus the decades spent working on related problems and systems. Like the article said, he'd been thinking about it for a while, and he had plenty of chance to explore similar products, consult various implementations, and apply various ideas to a very specific problem that plagued him in his job.

If you understand a problem, and have a specific solution in mind, the ""writing the code"" part is just the final step of bringing the idea from your head into reality. If you can do it in 10 days, that just means you've already done months if not years of work leading up to that final sprint.",24,2025-04-11 15:15:31,TikiTDO
programming,1jwmwdy,mmjwjv3,ah but he didn't have a product manager. with a product manager you can work 20 years and the result will last for 10 days.,43,2025-04-11 12:33:06,I_AM_GODDAMN_BATMAN
programming,1jwmwdy,mmkcyqg,Linux Torvalds was able to build this in a cave! With a box of scraps!,34,2025-04-11 14:06:52,ants_a
programming,1jwmwdy,mmkpxab,Linus Torvalds built this thing **in a cave**. With a box of **shell scripts**.,13,2025-04-11 15:11:32,Zomunieo
programming,1jwmwdy,mmlly2n,"I always hate this type of mentality.   I'm sure he built version .1 in 10 days.   There's been a LOT of workover the years, that's why it's on version 2.49 and not .1 or 1.

This is the difference between ""Concept"" ""Proof of Concept"" and ""Execution""..  People think the job is done after proof... it's not.  Apparently Concept is multiple months before this point, and execution has had a lot of work done after this point.",13,2025-04-11 17:48:17,Kinglink
programming,1ju6ils,mlzr3ty,Why is it always 10x and not like 2.86x?,752,2025-04-08 06:14:59,arturaz
programming,1ju6ils,mlzpili,"I was told on r/OpenAI that I would be replaced this year, or was it last year? The hyperbolic nature of AI discussions is a sight to behold. At least now they seem to dial it down a bit. Make that 10x to 40% and we're onto something.",1193,2025-04-08 05:59:25,Raunhofer
programming,1ju6ils,mlzr6um,"I hope everyone remembers what they were saying less than a year ago and understands this is a complete reversal. 

Guess the end of the s curve for the scaling law comes at you fast",480,2025-04-08 06:15:49,Disgruntled-Cacti
programming,1ju6ils,mlzpbyi,"10x more productive sounds like I need 1 developer instead of 10


-CEO",177,2025-04-08 05:57:39,tubbana
programming,1ju6ils,mlzp661,Shovel dealer says shovels will make gold diggers 10x more productive,679,2025-04-08 05:56:06,beebeeep
programming,1ju6ils,mlzozbx,"When AI starts to understand wtf the customer are asking for, and communicate to them, I will start to shiver, and be scared for my job. Until then, they are a tool, I can use.",189,2025-04-08 05:54:17,Soccer_Vader
programming,1ju6ils,mlzxwkx,"Two weeks earlier on 24 March 2025:

[OpenAI's Sam Altman claims AI will ""gradually"" replace software engineers — Creating an urgent need to master ""AI tools""](https://www.windowscentral.com/software-apps/openai-sam-altman-ai-will-gradually-replace-software-engineers)",40,2025-04-08 07:19:46,Cube00
programming,1ju6ils,mlzphjn,so far AI just introduced a lot of fakes and probably it will introduce a lot of fake coders as well,69,2025-04-08 05:59:09,Impossible-Staff6793
programming,1ju6ils,mlzvg0b,The use case for AI is spam.,71,2025-04-08 06:54:58,skippy
programming,1ju6ils,mm08qyp,Guy who sells AI says AI is the future.,30,2025-04-08 09:20:34,Relative-Scholar-147
programming,1jvfxl3,mma1nlv,[deleted],775,2025-04-09 20:55:34,N/A
programming,1jvfxl3,mma22sq,https://en.m.wikipedia.org/wiki/Jevons_paradox,97,2025-04-09 20:57:38,shif
programming,1jvfxl3,mm9yz4k,https://www.sfgate.com/tech/article/okta-layoffs-after-first-profits-20147418.php,111,2025-04-09 20:42:41,uniquesnowflake8
programming,1jvfxl3,mma8xa9,this jerkoff just layed off a bunch of engineers and shipped the jobs to india,56,2025-04-09 21:33:02,krispey
programming,1jvfxl3,mm9x01v,I like the cut of this guy's jib.,82,2025-04-09 20:33:05,TheBoosThree
programming,1jvfxl3,mma7d2h,"As I've been saying, we will always need formal verifiers.  Software developers simply have ever widening areas of responsibility as we automate more and more faucets of life.

Even if you rename the role... the general premise remains.  Somebody has to know how to build and deliver product even if they're telling automated systems to do it.",37,2025-04-09 21:24:45,recurrence
programming,1jvfxl3,mma8xfs,"Company that sells primarily to developers says that developers will be more in demand

Shocking",21,2025-04-09 21:33:03,mrfreeze2000
programming,1jvfxl3,mm9y11o,Paywalled. Can someone share the article?,9,2025-04-09 20:38:05,lifeslippingaway
programming,1jvfxl3,mm9zi99,"If they paid like they were in demand, that’s be nice.",124,2025-04-09 20:45:15,danikov
programming,1jvfxl3,mma7bqq,"Look at where his company is hiring 


And where it isn't ",19,2025-04-09 21:24:33,predat3d
programming,1jsrtrt,mlotl7l,"PTSD

I've been a frontend engineer, backend engineer, <insert blurb> engineer, architect, developer, <insert title>.

I've run BAs, product owners, product managers, project and program managers across 13 industries.

I've worked with graduates all the way to board level. 

I've worked from startup, scale up, enterprise. 

I've created two startups from scratch (both made good money and closed with happy employees).

I've worked on gcp,AWS,Azure plus private cloud.
From days of Pascal and C to Nodejs, React, Angular,.net,java, python, PHP, Android, flutter, stupid amount of cicd tools, and more.

The most common response I get....

""Thank you for your interest in <insert leadership role>, however your skillset doesn't match our needs of <insert ridiculously stupid thing engineers do once in a year>....""

The other is

""Sorry We are looking for a FAANG approved <insert role> individual that can leap mountains and turn time""


Get fucked, I'm out.


UPDATE:
I have been getting interesting questions and also some smooth brain attacks re this post so I'll add content here and leave it be. 

1. Not unicorn startups and less then 10 people in both
2. I love solving problems and creating solutions 
3. Why do I keep looking? Refer to point 2, also I can't imagine not doing something you don't enjoy and I love engineering, I'll probably be hacking my morphine drip on my deathbed.
4. I enjoy my lifestyle and I don't spend every waking moment working (hence me currently on Reddit while drinking on my porch at fuck look at the time)
5. Some of you have distorted ideas of what rich means, no I'm not Bezos rich, I'm comfortable for me and family
6. You think my post is all bullshit, I'm happy for you, I hope it brings you peace and a wonderful day.",1223,2025-04-06 12:23:43,TheAeseir
programming,1jsrtrt,mloskaw,"> All of this complexity is there for a reason.

I think we should stop assuming this. This implies that it’s reasonable, which is far from the truth. Closer to the truth is that all of this complexity has an excuse. Often to cover up a previous mess of our own doing rather than talking a step back. It’s also heavily incentivised career-wise.",305,2025-04-06 12:15:24,jahajapp
programming,1jsrtrt,mlp8anm,"The complexity explosion in software engineering seems to have two distinct facets:

1. The complexity required to solve hard problems
2. The complexity we introduce through lack of documentation and knowledge preservation

I feel like we focus too much on the first and not enough on the second. I've joined projects where understanding the existing architecture took weeks because nobody documented design decisions or created knowledge structures.

When I compare software to actual engineering disciplines, the difference is stark. Civil engineers don't reinvent beam calculations for each bridge - they have standardized knowledge transfer. Meanwhile, we're constantly reinventing state management patterns in each new project.

One of the most productive teams I worked with spent 20% of their time creating architecture diagrams, decision logs, and structured documentation that explained not just how things worked, but why they were designed that way. New engineers became productive in days, not months.

The irony is that we've built incredible tools for building software but terrible ones for transferring knowledge about that software. Then we wonder why tech debt accumulates so quickly.",96,2025-04-06 14:03:51,traderprof
programming,1jsrtrt,mlor3ko,"> Provide valuable feed during product meetings

Now we have to manage livestock too!?",143,2025-04-06 12:03:17,vajeen
programming,1jsrtrt,mlonu6r,This kind of description always reminds me that software engineering is not an actual engineering discipline,420,2025-04-06 11:35:07,mr_x_the_other
programming,1jsrtrt,mlpuy5d,This article is so biased towards web development though,30,2025-04-06 16:09:04,saxbophone
programming,1jsrtrt,mlpd4cb,"Reading this made me very relieved that I'm still being paid to do desktop app development, with no backends or css or any Javascript frameworks involved.",76,2025-04-06 14:31:39,guygizmo
programming,1jsrtrt,mlot7hb,">You know you need types, right? Add TypeScript. Are you really going to be managing state in React like a pleb? Add Redux.

a real ""insanity"" would be rolling your own types and state management. those tools standardise these tasks and make them **easier** for everybody

""You know you need nails, right? Add hammers. Are you really going to be managing spanners like a pleb? Add a toolbox.""",71,2025-04-06 12:20:38,prefixsum
programming,1jsrtrt,mlq0ft4,"All of this happened because people started pushing for tools instead of solutions. 


I am not telling to the civil engineer ""make this house with this kind of steel"" because that is the steel used for the Burji Khalifa so it must be good.


I am not telling the doctor ""cure my back pain with this medicine"" because it worked for David Beckham so it must be good.


And yet, we have clients asking to use React for a particular project.",31,2025-04-06 16:39:06,fosyep
programming,1jsrtrt,mlpgttd,"It’s about two things: 

1 - Software development is actually one of the most difficult things to do because a person has to imagine complex and abstract ideas in their head. Even if you personally find it easy to do this it is difficult and unappealing for most people in general. 

2 - Those who hire people to do software development generally do not respect the work or those who do it, but instead, they usually tolerate the whole thing as little as possible while always looking to save money at the expensive of literally anything or anyone else. 

People complain about lawyers. But lawyers actually, through the application off the rule of law, defend people against tyrants. Lawyers also figured out their best position long ago. With clients and partners and senior partners and starting their own firms they figured out how to take big facefuck companies and force respect. Both professionally and financially lawyers setup themselves up as an industry to never get fucked. 

Software developers should have done this long ago. Programming for money is hard and programmers should force people to pay for it. Full stop. 

But… instead we have a beautiful community where programmers share code and help and don’t value social status or formal training but instead operate like punk rockers, artists and hackers. The world is better for it and overall a lot of good has come from it. 

However the biggest problem is that it’s hard to have a community of creative people like that and also have them unionize or organize so that people like a certain billionaire (whom I shall not name) can just abuse nerds out of their time and money like a fuckface schoolyard bully stealing their lunch money. 

This AI grift-bubble is the same attitude. It’s trying to sell the idea to shareholders that you don’t even need those nerds because AI can just barf out all the code automatically. 

But outsourcing overseas back in the 90’s was the same grift. They would ask for 40% upfront, 40% on the first alpha version, and then 20% when they deliver the final version. Then they slap some crap together and fuck off once they collect 80% when the last 20% of the job is often the hardest. 

Likewise AI generated code is basically, but barely, the same. It barfs out bullshit code. It’s like maybe 80% of what you wanted. But you’ve still got to be a good programmer to refine that last 20% so it actually works. 

In the end is all about powerful and rich psychopathic narcissistic assholes who don’t give a shit about anything or anyone else but getting off on their own power. That leaves most developers to try and fend for themselves in a shit storm world that doesn’t get it and doesn’t give a shit. 

That’s why my current favourite kind of startup is that one person coding their little product for their little customer base. It’s a one to one customer relationship and usually makes products that actually create value. 

But yeah programmers should unionize. Not because AI can actually replace them but because the perception that it can is the most dangerous part of this whole grift.",87,2025-04-06 14:52:09,Liquid_Magic
programming,1k4c4t0,mo8xkq9,"If Microsoft actually broke the MIT license by removing the original license information / claiming they wrote the code themselves when they actually copy-pasted it, that's illegal, isn't it?",887,2025-04-21 12:42:48,Pesthuf
programming,1k4c4t0,mo902yk,"This reminds me of the Winget and Appget story: 

https://keivan.io/the-day-appget-died/

Notice the same parallels. There is some reaching out by MS (in fairness, that's better than nothing), followed by silence, followed by the original creator being blindsided.",283,2025-04-21 12:59:00,iamapizza
programming,1k4c4t0,mo8w7s6,"Devs love to take mit code and remove it's license entirely. I dunno why, just do the bare minimum and keep some, any amount of source code citation",163,2025-04-21 12:33:44,bzbub2
programming,1k4c4t0,mo9i80c,"Microsoft actually has a whole lot of internal people and processes dedicated to compliance, especially for use of open source. The conduct here (not complying with the original license) would be seen as violating standards of business conduct and would quickly be corrected.

If I understand correctly, the ask here would be for peerd to be relicensed under the original MIT license? I'd email the current maintainers and cc buscond@microsoft.com with the concrete ask.",62,2025-04-21 14:41:31,ysustistixitxtkxkycy
programming,1k4c4t0,moc8yuk,"- [This issue](https://github.com/Azure/peerd/issues/109) from 11 hours ago mentions lack of attribution and cites OP's blog post.

- [This PR](https://github.com/Azure/peerd/pull/110) merged 3 hours ago adds attribution and closes the issue.

The project currently contains the same MIT license that Spegel was licensed under, and now properly mentions the Spegel Authors' copyright. Seems OK to me.",22,2025-04-21 23:14:27,kogasapls
programming,1k4c4t0,mo8uvti,Licensing will always be a problem. And being exploited by big corpos especially Microsoft and Amazon is a reality everyone will have to go through.,82,2025-04-21 12:24:41,RoomyRoots
programming,1k4c4t0,mo96441,"Well, if you have meetings with big corps, they should be for selling your product, not explaining the architecture to facilitate the theft",27,2025-04-21 13:35:54,RB5009
programming,1k4c4t0,mo8wyyx,Use GPL,129,2025-04-21 12:38:46,agilefishy
programming,1k4c4t0,mo9pu53,"Spegel was licensed with the MIT license and so is Peerd. The only thing Microsoft has done wrong here, as far as I can tell, is changing the copyright owner to themselves in the license file, that is an easy fix.

If the author of Spegel doesn’t like the terms of the MIT license he shouldn’t have licensed it as such.",26,2025-04-21 15:19:59,wildjokers
programming,1k4c4t0,moe4dih,"you could simmer this down to ""MS spoke to you about collaborating and asked you a bunch of questions about architecture then decided to fork your project without any proper attribution and push you out of the space you created"" and somehow people dont see this as transgression? That's insane to me.",6,2025-04-22 06:50:51,SweetBabyAlaska
programming,1jxpl9c,mmsf8oc,What's clever about over-using one letter variables? ,602,2025-04-12 20:23:45,RiverRoll
programming,1jxpl9c,mmsgga6,I have long said people who think they are being clever when writing some obtuse piece of code are the absolute worst engineers. Your cleverness makes it 1000% more difficult for the next person. I will always try to get the author to fix this type of code in their prs.,345,2025-04-12 20:30:31,zoddrick
programming,1jxpl9c,mmsiwzs,"The difference between a junior and a senior. 

""Wow this code is cool I bet no one will understand it but it's so sweet"" 

""Wow this code is hard to understand, I won't remember it in 6 months, better document it""",167,2025-04-12 20:44:06,Kinglink
programming,1jxpl9c,mmskccl,"This was parroted already 20+ years ago when I began, or the more clever acronym: KISS, keep it simple stupid. But instead this has been used as an argument for lazy programmers to pick the most apparent solution; the one which most programmers would think of from the beginning, and consequently code bases grow huge & slow. You can open up a file of 1000+ lines of code & realize it accomplishes almost no actual work, superfluous comments, elimination of all sub expressions, and it's a major PITA to get an overview of what's going on because everything is so spread out & there's only so much short term memory in the mental computer. I actually think there's mostly 1 thing wrong with the so called horrible python code in this article, it's the variable names, otherwise it's quality code. It says what it does on the tin, it's contained, it uses standard python functions which should be in most python coders toolboxes, and if it turns out there's some error here you want to debug you can just split out the sub expressions & get to work if you want.",111,2025-04-12 20:51:59,Sairony
programming,1jxpl9c,mmsv6mt,"The irony is that truly clever code is not the clever code that is referred to in the article, that's like level 1 cleverness.",21,2025-04-12 21:54:32,UMANTHEGOD
programming,1jxpl9c,mmuwcep,"In my 60's now and still writing code..or programming, as I still call it.

Had a stroke in October 24 and have some memory issues now.

I have to write code as if it is being written for a stranger to read..because in 3 months time I will be that stranger. Sometimes I will remember nothing about the code except the names.

So..clean variable and function names. No hidden side effects. No hidden assumptions. Everything a function does is explicitly named. Prefer simplicity over complexity.

How's it working out for me? Ok. It actually does help me to understand things I might see months or even years later...I do a lot of refactoring, write the code first then clean it up, fix the names etc.

I often find I reuse code at least three times..which includes three sets of refactoring..before it is in it's ""final"" state. How do I know it;s in a final state? Because I can use it in other projects without having to change anything or fix any hidden assumptions or side effects.

In addition simplicity can actually help the compiler.",19,2025-04-13 06:36:10,TheDevilsAdvokaat
programming,1jxpl9c,mmsdg3d,"I recently had this feeling with some complex, and ""very elegant"", AutoMapper profiles. It was taking the results of a couple of queries, and projecting them out in a view model. One of the collections on the view model was getting created with some property values not getting set. It difficult to even wrap your head around how exactly it was doing these complex, nested mappings and projections. Even once I finally got past the cognitive load of that, it didn't really matter, because it was still impossible to debug in a straightforward/traditional manner. It was still going to be a whole lot of guess and check. I couldn't help but wonder what we were gaining for this clever code, instead of having probably a 2-4 dozen lines of code doing a few for loops. It would be super easy to follow, and you could cleanly debug everything all the way through.  Buy apparently it is better to use packages that save you some lines of code, but make everything about the developer experience worse. 🤷",10,2025-04-12 20:13:49,poop_magoo
programming,1jxpl9c,mmsj27r,There’s a difference between prematurely optimizing code and deliberately writing slow code because it’s easier,44,2025-04-12 20:44:55,Jobidanbama
programming,1jxpl9c,mmsje9e,"> I now understood why Big Tech seemingly had so many docs — half of the docs I wrote didn’t need to be written, except they did… because I wanted to get raises and be promoted.

Yup, just had this talk with my manager. He asked me to write more documents, give more presentations, even if they’re not necessary, because they’ll help him argue that I deserve a promotion.",20,2025-04-12 20:46:48,Arandur
programming,1jxpl9c,mmsocbj,"So in defense of consise code:

I've seen the code bases of people who aggressively wrote clean code.  There were *multiple pages* of intermediate variables in some modules.  Tracking down what happened where was ""easy"" in the sense that the code wasn't doing anything clever, but not ""simple"" in the sense that you often had to scroll through several different very large files to find what you were looking for.

There were some troubleshooting tasks where I would have rather been dealing with a code-golfed one-liner than reading through pages and pages of useless comments and variable declarations.

If you're familiar with the language in question, its often faster to decode a one liner than it is to read several pages of boilerplate.",18,2025-04-12 21:14:39,Bloaf
programming,1jnb00a,mki90at,">obscure languages like Delphi

Heroes of forgotten days.",723,2025-03-30 12:11:58,YahenP
programming,1jnb00a,mki8oc5,"Paper: [Coding Malware in Fancy Programming Languages for Fun and Profit](https://arxiv.org/abs/2503.19058)

> The continuous increase in malware samples, both in sophistication and number, presents many challenges for organizations and analysts, who must cope with thousands of new heterogeneous samples daily. This requires robust methods to quickly determine whether a file is malicious. Due to its speed and efficiency, static analysis is the first line of defense.

> In this work, we illustrate how the practical state-of-the-art methods used by antivirus solutions may fail to detect evident malware traces. The reason is that they highly depend on very strict signatures where minor deviations prevent them from detecting shellcodes that otherwise would immediately be flagged as malicious. Thus, our findings illustrate that malware authors may drastically decrease the detections by converting the code base to less-used programming languages. To this end, we study the features that such programming languages introduce in executables and the practical issues that arise for practitioners to detect malicious activity.",114,2025-03-30 12:09:14,self
programming,1jnb00a,mkine8n,"An alternative way to write the topic could be ""Reverse engineering code is actually quite difficult if most of it isn't just straightforward C code that only does OS / library calls"".

My pandemic project was reverse engineering a mid 90s demoscene demo written in a combination of Watcom C and assembly. Every single reverse engineering guide I found was completely useless because they all assumed 90% of the code would be just library calls instead of actually consisting of computations and non-trivial logic.",191,2025-03-30 13:52:41,SkoomaDentist
programming,1jnb00a,mkii8b1,"Idea: Write malware in APL.
Blocker: Need to learn APL first.",43,2025-03-30 13:19:34,I_just_read_it
programming,1jnb00a,mkia9w3,"Not just malware, any software written in Haskell is incomprehensible!",275,2025-03-30 12:22:07,IshtarQuest
programming,1jnb00a,mkk2knv,"Someone wrote a malware in PureBasic and now almost any non trivial PureBasic software is considered malware, It sucks!",14,2025-03-30 18:22:33,ricardo_sdl
programming,1jnb00a,mkjf1qi,You can't write Malware in Haskell because you would need to figure out how to do IO,50,2025-03-30 16:23:11,dasdull
programming,1jnb00a,mkjsu46,"Yeah. I wrote my database stuff in THP!

Never heard of it? Good.

I’m retired now but never dropped a database or lost any data, or got hacked in a 30 year career.

THP? It’s a LISP interpreter. Ran a tad slow but super-easy to work with and very hard to reverse-engineer.

Most important project? Glastonbury Festival booking system for Theatre and Circus performers and crew.

Attack Frequency: high. We issue festival tickets, so some bad actors try to hack us, probably mostly for fun and on the off chance. They were looking for basic  database security failures mostly.

So that all worked just fine.",8,2025-03-30 17:33:51,DXTRBeta
programming,1jnb00a,mkidt85,"No shit, antivirus is a bandaid. It won’t detect 0-days, and (at least almost) all of them are a security risk themselves because they need elevated permissions.

So antivirus is for you if you don’t trust users (be it yourself or others) to properly use the internet. Fair, most people are dumbasses, but if you know what you’re doing, don’t get an antivirus.",41,2025-03-30 12:48:48,flying-sheep
programming,1jnb00a,mkiq3r0,"delphi, thats a name i haven't heard in a very long time",7,2025-03-30 14:08:41,Healthy_Razzmatazz38
programming,1k0dyk8,mndckfw,This news should have a score of 10.0,569,2025-04-16 07:02:36,iamapizza
programming,1k0dyk8,mneolci,"Contract was just extended this morning, thankfully. Sounds like this may have also prompted a migration away from dependence on the US govt. to keep the program alive, which seems like a good thing.

https://www.bleepingcomputer.com/news/security/cisa-extends-funding-to-ensure-no-lapse-in-critical-cve-services/",118,2025-04-16 13:41:19,ryusage
programming,1k0dyk8,mndir2s,Huh I had no idea this was a US Gov programme. I'd have thought the economic benefits to the US alone outweighed the cost of running the service. The costs of the service seem like a drop in the ocean compared to the costs of cyber crime generally. If you wanted to show some gainz then you could ask other countries for a GDP weighted contribution to the costs surely?  But clearly that approach isn't sufficiently bigly savings.,237,2025-04-16 08:08:23,Advanced-Essay6417
programming,1k0dyk8,mndh6b0,"This is where the world is learning that anything that was largely reliant upon the USA needs to be addressed sharpish as they can no longer be relied upon to act in their own best interests, let alone anyone else's.",285,2025-04-16 07:51:31,thatpaulbloke
programming,1k0dyk8,mndno5v,How in the hell is this not getting more attention?,63,2025-04-16 09:02:09,funeralforecast
programming,1k0dyk8,mnexboi,Update: CISA extended the funding this morning! Crisis averted for now. This whole situation shows how fragile our security infastructure can be when it depends on govmnt funding. The CVE system is literally how devs track vulnerabilities worldwide.,14,2025-04-16 14:27:32,PM_ME_UR_ROUND_ASS
programming,1k0dyk8,mne1hv8,Today in “things a Russian asset would do” news,28,2025-04-16 11:13:38,jelder
programming,1k0dyk8,mndw4cm,Why isn't anyone saying thank you?,11,2025-04-16 10:28:18,heatlesssun
programming,1k0dyk8,mngaic7,This post title doesn’t match the article title. The post title is “CVE program **averts** swift end after CISA executes 11-month contract extension”,2,2025-04-16 18:27:26,dmilin
programming,1k0dyk8,mnjkx4a,I'm super curious of the impact of this. Will we see less CVE script kiddy style attacks but more sophisticated APT type attacks?,2,2025-04-17 06:35:08,Glum_Sun_3459
programming,1jrl2zw,mlg9xua,"> According to the VS Code Marketplace [Terms of Use](https://aka.ms/vsmarketplace-ToU), *you may only install and use Marketplace Offerings with Visual Studio Products and Services*.

Source: https://github.com/VSCodium/vscodium?tab=readme-ov-file#more-info

So any product like Cursor was not allowed to use those extensions in the first place.",462,2025-04-04 22:31:23,krokodil2000
programming,1jrl2zw,mlfkqe6,"Bound to happen tbh, surprised it took them this long to create a branch of Copilot to rival Cursor.

Straight blocking MS extensions from VS-Code moving forward is a bit of an old school MS move, but it makes complete sense from a business perspective. They want people to use their Agent, people want to use VS Code. 

Either the Cursor team puts together a fork of VSCode and maintains the extensions (or people just never update beyond the previous version) or their users just naturally migrate over time.",317,2025-04-04 20:13:25,ScriptingInJava
programming,1jrl2zw,mlfmhma,I wish I never had to hear about AI companies again.,737,2025-04-04 20:22:21,BlueGoliath
programming,1jrl2zw,mlfl3w0,"It looks like the plugin itself is open source but there are some needed binaries that are not open source. I'm not sure what binaries the license is referring to though. Maybe it's a matter of someone picking it up and making an alternative version of the plugin. 

[https://github.com/microsoft/vscode-cpptools](https://github.com/microsoft/vscode-cpptools)",51,2025-04-04 20:15:20,Suspect4pe
programming,1jrl2zw,mlfubdw,"They were going to figure out a business model for VSCode eventually.  It was always going to be uncomfortable for users that found themselves on the other side of where Microsoft wanted to make their money.

Just because we didn't know what it was going to be, doesn't mean it wasn't inevitable. Or that this is the end.

edit: I'm pretty sure the ssh extension already refused to work in vscodium, but I'm not at home to check.",54,2025-04-04 21:02:54,old-toad9684
programming,1jrl2zw,mlgz9xn,[Visual Studio Code is designed to fracture](https://ghuntley.com/fracture/),15,2025-04-05 01:09:20,micod
programming,1jrl2zw,mlg4dzq,"Open source is all fun and games, until a competitor uses your shit.",65,2025-04-04 21:58:39,abraxasnl
programming,1jrl2zw,mlfxzf8,"It was bound to happen I guess. 
Other companies like SourceGraph bet for staying as a plug-in of vscode and it may play better for them long term",16,2025-04-04 21:22:55,r0s
programming,1jrl2zw,mlh4a61,Just use the clangd extension. It works better than the MS C++ extension anyway.,10,2025-04-05 01:42:08,DeeBoFour20
programming,1jrl2zw,mlfvyly,"Classic msft move with the extensions.🤣 They were always going to eat Cursors lunch eventually, but I didn't see the extension block coming.

Hopefully the kid behind cursor enjoyed it while it lasted. I was endly baffled that he/they didn't sell.",27,2025-04-04 21:11:50,Livid_Combination650
programming,1jirwz7,mjhj2fb,"I don’t know about “every programmer should know,” but pretty solid overview of cool algorithms",371,2025-03-24 14:52:59,shoot_your_eye_out
programming,1jirwz7,mjjkyss,"> SHA is incredibly useful for ensuring data integrity, securing passwords, and verifying authenticity. For example, websites store password hashes instead of the actual passwords, so hackers can’t easily find them. 

No!  [SHA should never be used for passwords](https://www.troyhunt.com/our-password-hashing-has-no-clothes/).  Instead, use argon2, bcrypt , scrypt or even pbkdf2 (but prefer the other 3).  Password hashing needs to be slow to prevent dictionary attacks.  SHA256 is designed to be fast so is not built for password usage.",87,2025-03-24 20:49:21,ScottContini
programming,1jirwz7,mjhr7ig,"Would have loved to see a section on checksum algorithms, those feel like they'd be used by a much greater subset of programmers than graph theory",49,2025-03-24 15:34:00,manystripes
programming,1jirwz7,mji1qba,"I can count on one hand the number of these algorithms I've actually needed to know in the 15 years since I graduated. It is good to learn about how these algorithms work in college, as it helps build your problem solving insight, but at no point in your professional career are you likely to be expected to implement selection sort, Prim's algorithm, or FFT.",49,2025-03-24 16:26:11,timewarp
programming,1jirwz7,mjhol1m,"This is a nice broad range of algorithms, I particularly liked the inclusion of Newtons method and Disjoint set which I think is underrated.

But yea not every programmer should know these.",26,2025-03-24 15:20:56,TheAtro
programming,1jirwz7,mji5ax9,"I'd say you don't really need to learn all the sorting algos, since some are essentially never used anymore. Radix sort however should be in the back of your head because for some applications it's still incredible. It's often used in the games industry for sorting rendering lists for example. You can bake in whatever criteria you want in decreasing significant bits & sort it blazingly fast while respecting criteria in descending order of importance. You can bake in whatever bucket structure you want, material ID, Z sorting etc, and you get all of these sorted in conjuration.",20,2025-03-24 16:43:44,Sairony
programming,1jirwz7,mjhgymm,Every student programmer maybe.,42,2025-03-24 14:41:57,Lobreeze
programming,1jirwz7,mjiv5ac,Algorithms _most_ programmers should _be aware of but never have to implement themselves_,28,2025-03-24 18:46:42,Wynadorn
programming,1jirwz7,mji6pzc,There’s a typo under “Heap Sort” where it says “The time complexity of *quicksort* is O(n*log(n)).” The next section is QuickSort and has the same exact sentence.,5,2025-03-24 16:50:33,backfire10z
programming,1jirwz7,mjk3bda,"For the lazy:

- Sorting Algorithms
  - Selection Sort
  - Insertion Sort
  - Heap Sort
  - Quick Sort
  - Merge Sort
  - Tim Sort
- Search Algorithms
  - Binary Search
  - Depth-First Search (DFS) and Breadth-First Search (BFS)
- Graph Algorithms
  - Prim’s Algorithm
  - Kruskal’s algorithm
  - Dijkstra’s algorithm
  - Bellman-Ford algorithm
  - A* Search
  - Union-Find algorithm (also called Disjoint Set Union (DSU))
  - Ford-Fulkerson Algorithm
- String-Search Algorithms
- Compression and Encoding Algorithms
  - Value Encoding
  - Dictionary Encoding
  - Huffman Coding
  - Lempel-Ziv (LZ) Compression
  - Bitmap Index (used for Column Compression) & Run-Length Encoding
  - Burrows-Wheeler Transform
  - Fourier Transform (and Fast Fourier Transform (FFT))
  - Quantization
  - Discrete Cosine Transform (DCT)
  - Image Compression (JPEG)
  - Video Compression & Encoding
  - Ray Tracing
- Optimization Algorithms
  - Simplex Method
  - Integer Programming
  - Newton's Method
  - Simulated Annealing
- Machine Learning & Data Science Algorithms
  - Regression (Linear, Logistic, and Polynomial)
  - Support Vector Machines (SVMs)
  - Decision Trees (Random Forest & Boosted Trees)
  - Gradient Descent & Backpropagation
  - Neural Networks
  - Reinforcement Learning (RL)
- Security & Cryptographic Algorithms
  - SHA (Secure Hash Algorithms)
  - RSA Algorithm
  - Diffie-Hellman (DH) Key Exchange
- Interview Prep-Focused Material / Algorithms
  - 14 Patterns to Ace Any Coding Interview
  - Algorithms You Should Know Before Any Systems Design Interview
  - 5 Simple Steps for Solving Dynamic Programming Problems
  - Mastering Dynamic Programming

        
---

Source:

    var text = $(""h3, h4"")
      .map((k, v) => '  '.repeat(parseInt(v.tagName[1]) - 3) + '- ' + v.innerText)
      .get()
      .join(""\n"");
    
    console.log(text);",12,2025-03-24 22:24:03,muntoo
programming,1k0sc6y,mngrwu9,Even worse: sometimes it's used to deliver javascript,1155,2025-04-16 19:55:48,nickcash
programming,1k0sc6y,mnguvmt,**NODE.JS** is used to execute *powershell* commands,160,2025-04-16 20:10:14,Jealous_City_9623
programming,1k0sc6y,mnhyjvr,So scripting languages used for malicious scripting?,117,2025-04-16 23:43:19,atomic1fire
programming,1k0sc6y,mnkez4j,"I dislike usage of JS outside of browsers as much as the next guy, but what the hell is this article? ""A programming language can be used to write (malicious) software""? Wow, who could've thought.

I kinda expected it to be about the fact that [merely installing an npm package can execute arbitrary code](https://docs.npmjs.com/cli/v6/using-npm/scripts#life-cycle-scripts), but this is something else.",16,2025-04-17 11:26:34,TypicalFsckt4rd
programming,1k0sc6y,mngn4nl,No shit Sherlock ,68,2025-04-16 19:31:47,GreedyBaby6763
programming,1k0sc6y,mni54zo,The amount of brain rot in these comments is tremendous.,39,2025-04-17 00:24:08,WebDevLikeNoOther
programming,1k0sc6y,mnghsua,Shit found in shithole!,126,2025-04-16 19:04:49,zmose
programming,1k0sc6y,mni363w,Breaking news: supply chain attacks exist in popular software ecosystems,10,2025-04-17 00:10:57,tj-horner
programming,1k0sc6y,mnhgpvu,AI slop,25,2025-04-16 22:02:57,grumblefap
programming,1k0sc6y,mnj8l5w,Surely vibe coding will help,9,2025-04-17 04:43:03,ooqq
programming,1jms5sv,mke5yhh,"Accurate takes all around.  Vibe coding sounds like some silicon valley bullshit to make a particularly stupid idea seem cool.  But these people are disconnected nerds so it seems pretty lame to a person like me.

The author's path to integrating AI into their workflow mirrors mine.  I use it to do the things I don't want to do and guide it but I always have a good idea of the architecture and work I have in mind to implement things.

I also lean pretty heavily on integration tests.",564,2025-03-29 18:20:55,NoobChumpsky
programming,1jms5sv,mkf7z3i,"TIL that vibe coding is not just a derogatory term for extensive use of ai while coding, but instead something that people are in fact serious about",97,2025-03-29 21:50:35,spirit-of-CDU-lol
programming,1jms5sv,mkeh9vm,"Vibe coding goes against the core principles of Clean code: Accountability for code being written. 

You expect your doctor to be liable for mistakes he makes. It’s very important to safeguard people’s lives. We live in a World where our safety depends on systems being written by people that know what they are doing. 

Would you blindly trust your plane’s auto pilot system code being prompted by a Product person?",184,2025-03-29 19:22:21,Immediate-Raccoon-84
programming,1jms5sv,mkg1ohi,I’m still getting used to this sub. Is it just links to people’s blog articles?,18,2025-03-30 00:44:40,Greenphantom77
programming,1jms5sv,mkh8wys,"Code exists because natural language is not precise enough. Putting an LLM in between your natural language and the code means you are losing that precision, and replacing it with extremely convincing hallucinations.",19,2025-03-30 05:59:41,CharlieDarling14
programming,1jms5sv,mkezxlm,"Companies that allow AI slop into their codebases will create a lot of job opportunities for real, experienced programmers a few years down the road. ",29,2025-03-29 21:04:41,Grove_street_home
programming,1jms5sv,mkhdicy,"What worries me the most is that investors are buying into this trend. They want to see the products released as fast as possible. Recent Y Combinator podcast ""Vibe Coding Is The Future"" shows that their lack of fundamental understanding of software engineering is only getting worse.

I recently worked in a gen-z startup that fully embraces vibe coding. The founder expected a bunch of features to be developed and deployed for an investor meeting overnight. It was a shit show and the code was complete garbage full of bugs and it looked like shit. Needless to say I no longer work for them.",11,2025-03-30 06:47:13,akirodic
programming,1jms5sv,mkejd9e,"People blow this dude's quote so far out of proportion. How one brief, fun tweet got turned into ""Karpathy's Vibe Coding Movement"" is pretty surreal.

>Also I just talk to Composer with SuperWhisper so I barely even touch the keyboard. I ask for the dumbest things like ""decrease the padding on the sidebar by half"" because I'm too lazy to find it. I ""Accept All"" always, I don't read the diffs anymore. When I get error messages I just copy paste them in with no comment, usually that fixes it .... Sometimes the LLMs can't fix a bug so I just work around it or ask for random changes until it goes away... It's not too bad for throwaway weekend projects, but still quite amusing""

Really? You think this dude was proposing ""verbally asking for random changes until the bug goes away""  as a movement for a new software engineering paradigm?

I'm imagining this dude sitting on his couch, pizza in one hand and beer in the other,  just talking at his computer, vibing, having fun on his weekend project, while the entire software engineering community shits itself over how this isn't a viable strategy for a long term healthy codebase.",124,2025-03-29 19:34:08,_BreakingGood_
programming,1jms5sv,mkejdzj,"A good friend does fractional CTO and contract dev work. He told me that he’s found a great area of business: he goes into a company that vibe coded a product, raised money, and discovered that what the AI built is completely unsustainable. Now they need to fix it and hire a team to run their business. He says it’s very similar to what he saw more than a decade ago with ad agencies hacking together spaghetti Rails and Wordpress sites on behalf of companies and then leaving them to figure out how to make them work.",38,2025-03-29 19:34:14,sickcodebruh420
programming,1jms5sv,mke5gy8,"The suggestions in the Better Path Forward section are almost exactly the guidelines we have for using AI coding assistants in my org.

This is a quality post with a weird title, OP. Maybe it's just me, but I was expecting some kind of data describing why it's considered harmful, and by whom.",39,2025-03-29 18:18:16,hurbunculitis
programming,1jpribc,ml2yow0,"*“it deleted the whole repo”*

*“i had another idea anyway”*",158,2025-04-02 20:07:45,husky_whisperer
programming,1jpribc,ml1j17u,"*""It's not a syntax error, it's a mood misalignment""*

*""Fix this or you go to jail""*

So many fantastic quotes in this one. I love all this guy's videos, honestly.",304,2025-04-02 15:58:11,creaturefeature16
programming,1jpribc,ml1yn16,I have to say even without watching the video the preview picture perfectly matches my expectations from the headline.,182,2025-04-02 17:14:40,jk_tx
programming,1jpribc,ml2rfwe,"This guy is great. Go watch his ""Interview with Senior JS Developer"" if you haven't, also really good.",53,2025-04-02 19:33:05,SpikeX
programming,1jpribc,ml1ruly,Why the ski goggles?,30,2025-04-02 16:42:15,atika
programming,1jpribc,ml2shij,Last couple of minutes are a gem.,23,2025-04-02 19:38:17,touristtam
programming,1jpribc,ml3dnud,"""Cease and desist? Bro, the AI takes care of everything.""

""I don't know how to take it down. Clause, take it down!""

""Lawyers... with... a.... criminal... record... near me.""

""Why is my bill $30,000?!""",39,2025-04-02 21:18:35,grendus
programming,1jpribc,ml413ot,"""claude turn it off or you will go to jail""",9,2025-04-02 23:23:51,JDMagican
programming,1jpribc,ml3n2s9,"I just learned about vibe coding yesterday, the fact that it's even a thing makes me scared for the future.",18,2025-04-02 22:06:51,Sage2050
programming,1jpribc,ml22y8b,r/ProgrammerHumor,37,2025-04-02 17:34:43,Mysterious-Rent7233
programming,1julofe,mm3n8hm,"As somebody who spent last weekend trying out ""_vibe coding_"", this is **SHOCKINGLY** close to my experience to the point this isn't even a parody.

Anyways... Learned a lot today, love galactus..",337,2025-04-08 20:54:55,valarauca14
programming,1julofe,mm3ujat,Current AI coding tools are what happens when you wish for a personal assistant and then the monkey paw curls.,184,2025-04-08 21:31:33,TheDrInconsequential
programming,1julofe,mm4bqww,"Imagine having a really dumb intern or junior like really dumb, but they have access to Google. And they are surprisingly good at googling. But put almost no thought into what they doing just making their Google search fit to what you are doing. And they just won't get any better until the next intern model comes out. But it's more or less the same",192,2025-04-08 23:06:20,todo_code
programming,1julofe,mm5aizy,I mean the whole video is gold but the editing adding a border around the video really did me in lmao,28,2025-04-09 02:28:40,thetdotbearr
programming,1julofe,mm3yhgz,Ha! He calls himself senior but doesn't even have 10+ years experience using LLMs!,75,2025-04-08 21:52:10,Putrumpador
programming,1julofe,mm47ntw,"Have seen this term all over recently but haven’t bothered to look into what it means yet. 

Is it really just pretending to be Tony Stark or Capt Picard talking to “AI” and hoping it will do what you ask? 

….. That’s fucking dumb.",70,2025-04-08 22:43:22,ShenmeNamaeSollich
programming,1julofe,mm3b8i3,Never not good. Love these! Lmao!,20,2025-04-08 19:58:19,this_knee
programming,1julofe,mm6atfh,"These vibes, they are all bad.",7,2025-04-09 07:23:31,pelrun
programming,1julofe,mm3p1du,Sounds like having an intern.,19,2025-04-08 21:03:29,fireduck
programming,1julofe,mma05uc,"“No no, you don’t use clear: both on a flexbox.” Fucking gold.",5,2025-04-09 20:48:25,squeeemeister
programming,1judf0y,mm1ryr3,My company doesn't allow us to use AI. InfoSec reasons.,378,2025-04-08 15:29:56,wildjokers
programming,1judf0y,mm23pm9,In my 25 years of developing writing the actual code must be like 10% of the time. Waiting for other people to get shit done seems to be around 75% of where my time has gone.,152,2025-04-08 16:28:09,Plank_With_A_Nail_In
programming,1judf0y,mm3794r,"If it were us two years ago asking executives to give access to AI tools for increasing productivity, they would say no. But when AI turned into a FOMO thing, now executives forcing us using AI to increase productivity.",38,2025-04-08 19:39:27,yamirho
programming,1judf0y,mm1dolf,"We also had that lately with shopify aka the CEO ""if AI is better than you, you won't get a job here"".

Pretty bleak future ..",240,2025-04-08 14:18:13,shevy-java
programming,1judf0y,mm3tdd0,"Our CTO ""left"" 2 weeks ago, because his AI strategy didn't work out for the firm, and caused some really high value employees to leave for competitors.",24,2025-04-08 21:25:28,wapskalyon
programming,1judf0y,mm2xd9b,"In one sense I am relieved I will still have a job in Refractoring old/bad codebases, on the other hand my god that job will probably suck.",17,2025-04-08 18:50:07,LordAmras
programming,1judf0y,mm15a8u,"> In 2024, 72% of respondents in the Stack Overflow report said they held a favorable or very favorable attitude toward the tools, down from 77% in 2023.

You'd expect a far larger drop if the following statement was as widespread as the article would have you think:

> Overall, developers describe a slew of technical issues and headaches associated with AI coding tools, from how they frequently suggest incorrect code and even delete existing code to the many issues they cause with deployments.

Not that these aren't problems -- they clearly are -- but this isn't exactly ""driving people to the brink"" levels of dissatisfaction.",162,2025-04-08 13:32:08,phillipcarter2
programming,1judf0y,mm2kyyp,"The worst thing about this is   
Companies are giving cheap laptops for writing software, where 40% of the hardware resources are spent on security background checks  
and they expect software engineers to deliver software faster with this AI

It is like Pixar giving animators cheap laptops and 10 year old drawing tablets and then write email with subject the movie release next week",24,2025-04-08 17:50:27,gjosifov
programming,1judf0y,mm2cx4r,"I have started using AI coding tools (Claude, to be specific) extensively in the last month.

I've wasted a fair bit of time (or spent or invested, I guess) learning what they're good at and what they're not good at.

The high-level summary: my job is safe and probably will be for the foreseeable future.

That being said, they are definitely good at some things and have increased my productivity, once I have learned to restrict them to things they're actually pretty decent at.

The overarching shortfall, from my point of view, is their confidently incorrect approach. For example, I set the tool to help me diagnose a very difficult race condition. I had a pretty good idea of where the problem lay, but I didn't share that info from the jump with Claude.

Claude assured me that it had ""found the problem"" when it found a line of code that was commented out. It even explained why it was a problem. And, its explanation was cogent and very believable.

This is the real issue: if you turned a junior dev or non-dev loose with this tool, they might be very convinced they had found the problem. The diagnosis made sense, the fix seemed believable, and, even more, easy and accessible.

Things that the tool is really good at, though, help me out a lot, even to the point that I would dread not having access to this tool going forward:

\- documentation: oh, my god, this is so good. I can set Claude to ""interview"" me and produce some really nice documentation that is probably 80-90% accurate. Really helpful.

\- spicy stack overflow: I know Spring can do this, but I can't remember the annotation needed, for example

\- write me an SQL query that does this: I mean, I can do this, but it just takes me longer.

\- search these classes and queries and make sure our migration scripts (found here) create the necessary indexes - again, needs to be reviewed, but a real timesaver",56,2025-04-08 17:13:00,evil_burrito
programming,1judf0y,mm1706i,"> Many also say the use of AI tools is causing an increase in incidents, with 68% of Harness respondents saying they spend more time resolving AI-related security vulnerabilities now compared to before they used AI coding tools.


So 32% of respondents spent more time resolving AI-related security vulnerabilities *before* using AI coding tools? This has to be a butchering of the survey question, right?",37,2025-04-08 13:42:07,apnorton
programming,1joqlry,mkugxdu,"Thats amazing. 

**The backend team builds APIs based on their own assumptions**

This sums up a problem I had today 😂",109,2025-04-01 12:35:13,BeyondLimits99
programming,1joqlry,mkujm6h,"Price's law is not about work don but about scientific publication:
> in any scientific field, half of the published research comes from the square root of the total number of authors in that field

And even in its correct form, it's not a very acurate ""law"":
> Subsequent research has largely contradicted Price's original hypothesis 

source : https://en.wikipedia.org/wiki/Price%27s_law",142,2025-04-01 12:52:50,mareek
programming,1joqlry,mkwue5u,You forgot about [Cole's Law](https://www.google.com/search?q=coleslaw&udm=2),40,2025-04-01 20:10:02,darchangel
programming,1joqlry,mkvclx7,"Retired old guy here. 

All accurate BUT: it completely absolves the engineers from any responsibility regarding outcome. (Been an engineer, been in management, switched back and forth many times.)

Engineers can learn how to manage their managers. 

Easy statement to make, hard to implement. Company culture, communication skills (the engineers, and the managers), motivation, etc come into play. But successful teams eventually figure it out. 

Ie: (as stated in the article) every rule (law) has exceptions and smart people learn to work with them.",38,2025-04-01 15:35:08,thesamim
programming,1joqlry,mkuun28,Well that was almost good until it mentioned Elon Musk firing a bunch of Twitter devs as if it was no big deal.,52,2025-04-01 13:59:44,N0t_my_0ther_account
programming,1joqlry,mkxde1s,">Elon Musk fired 50% of Twitter in November 2022.
Price's square root law explains why Twitter didn't collapse, even when a further 30% were fired.

>The square root of the original 8,000 employees is just 90!

You lost my respect when you brought that up.

Twitter did in fact, collapse. A bunch of times. X/twitter has had a lot of glitches, the last one 2 days ago [https://www.it-daily.net/en/shortnews-en/x-down-again-thousands-of-users-report-outages](https://www.it-daily.net/en/shortnews-en/x-down-again-thousands-of-users-report-outages)",42,2025-04-01 21:49:17,cazzipropri
programming,1joqlry,mkvcbfr,Imho missing a very important one: https://en.m.wikipedia.org/wiki/Amdahl%27s_law,5,2025-04-01 15:33:36,reveil
programming,1joqlry,mkvl5zy,Illustrating Cunningham's law with anything else than [XKCD 386](https://xkcd.com/386/) is just wrong.,5,2025-04-01 16:18:59,jdehesa
programming,1joqlry,mku9ag4,Funny. Sent it to my teammates and we all had a good laugh.,2,2025-04-01 11:40:31,NewExplor3r
programming,1joqlry,mkuxvqi,Great read. Really good points in there.,2,2025-04-01 14:17:51,Jaarmas
programming,1jz8jrw,mn4mxka,"This is why setting environment variables is now defined to be unsafe, because it’s not threadsafe and can result in very unusual behaviours when races occur.

It’s not even possible to wrap it in a safe abstraction, like would normally be done (even aside from the breaking changes this would involve), as rust has no control over what other non-rust callers may do with environment variables.",356,2025-04-14 21:11:10,_zenith
programming,1jz8jrw,mn4qrkl,"`getenv` strikes again.  If you follow the ABI standards, you are faced with a dilemma.  You either must leak memory (prevent an old environment from being freed), or have a use-after-free bug because another thread changed the environment pointer.

Yes, it's possible to change the standard to give ""getenv"" a reference count and allow it to be freed if everyone plays nice and releases their reference to the string, otherwise a leak.",69,2025-04-14 21:31:49,Dwedit
programming,1jz8jrw,mn51j1z,Am I understanding the last sentence correctly that a possible fix in libc is to introduce a memory leak of the old environment strings?,29,2025-04-14 22:32:18,Own_Goose_7333
programming,1jz8jrw,mn4ewuj,"I was expecting this to be whiny, but it was instead really informative and interesting!",93,2025-04-14 20:30:02,Primary-Walrus-5623
programming,1jz8jrw,mn5nvzb,This is a [repost](https://np.reddit.com/r/programming/comments/1i7iz4h/c_stdlib_isnt_threadsafe_and_even_safe_rust_didnt/). I guess they moved the site. The comments on that link are far better than the ones here.,23,2025-04-15 00:42:47,chengiz
programming,1jz8jrw,mn4rcsa,"No affiliation with the article but surprised to see people saying the title is whiny?

>C stdlib isn't threadsafe

This is a statement of fact.

>and even safe Rust didn't save us.

Barring doing something to violate thread safety in unsafe code, Rust guarantees thread safety. I would be surprised too if my Rust project with zero lines of unsafe code was segfaulting. This is why Rust now marks these functions as `unsafe`.

What about the title is bad other than being mildly clickbaity?",149,2025-04-14 21:35:00,weirdasianfaces
programming,1jz8jrw,mn4w1ky,setenv is just a bad idea. Just never call it if you need something to have a different env spawn a new process with that altered environment.,53,2025-04-14 22:00:45,Days_End
programming,1jz8jrw,mn5z4es,why do you expect rust to save you when the crash happened due to memory corruption in cstdlib?,12,2025-04-15 01:50:35,Southern-Reveal5111
programming,1jz8jrw,mn9vizg,I dream of being able to debug this well.,2,2025-04-15 18:14:10,helix400
programming,1jz8jrw,mn5d4zz,Does anyone have examples of a “valid” use case for ever even using ‘setenv’?,6,2025-04-14 23:39:28,landon912
programming,1jzxu1i,mn9pzqw,This is hilarious af,173,2025-04-15 17:46:46,stickfigure
programming,1jzxu1i,mnaky48,"The economist-approved formula is:

    Δτᵢ = (xᵢ − mᵢ) / (ε ⋅ φ ⋅ mᵢ)",106,2025-04-15 20:21:27,obfuscatedanon
programming,1jzxu1i,mnam47q,Finally some quality shitposting,47,2025-04-15 20:27:13,rotilladetapatas
programming,1jzxu1i,mn9t39m,Not bad! But it should work by default by querying the country of the package and applying the tarrif based on that,69,2025-04-15 18:01:55,sjepsa
programming,1jzxu1i,mnakm55,I am more concerned that you can overwrite the importing mechanism at all.,36,2025-04-15 20:19:48,Worth_Trust_3825
programming,1jzxu1i,mnaao27,Do you get tarrifed on transitive dependencies every time it is added?,29,2025-04-15 19:30:30,cellarmation
programming,1jzxu1i,mn9rdnv,That’s a good meme 😂,31,2025-04-15 17:53:28,neo-raver
programming,1jzxu1i,mnd0cyw,"Presumably there's an update coming soon which reduces some of the tarrifs, then another one shortly after which claims it didn't reduce the tarrifs, but changed the _type_ of the tarrifs (but without any type annotations to prove it), then a third update which just gives up altogether and randomises them?",15,2025-04-16 05:06:35,adh1003
programming,1jzxu1i,mngy2j4,"> This is a parody package. 

Sometimes reallife in itself is more the parody than the parody about reallife is. Although I think it is sad how people can seize power and control so many other people ""downstream"". Tariffs are basically just an extra tax really. So many shop owners complained about suddenly having to pay a lot more money when importing goods.",5,2025-04-16 20:26:01,shevy-java
programming,1jzxu1i,mnaja8s,"I love it, i feel like this could be better expanded to tariff functions in modules....

[this talk will always be gold](https://youtu.be/t863QfAOmlY?si=G8Q292326G82oATV&t=729)",7,2025-04-15 20:13:14,Thisconnect
programming,1k0wouy,mnhhmv2,"I use GitHub users to segment, I have a whole series of config files for this. Copilot has started to ignore those and enables itself in folders that those accounts don’t have access too. 

I’m assuming it’s the same behavior. I have to logout of all accounts when I open a workspace/window now and log back in to the accounts that the config files should be allowing.

I think their agent that is coding the agent became over zealous. Imagine that.",229,2025-04-16 22:08:05,zaskar
programming,1k0wouy,mniqnzi,"Copilot enabled itself as a reviewer on our org's repos without notice. And because the ""request"" hyperlink is tiny, there's very little space between users in the suggested reviewer list, and copilot put itself right on top... there were a couple of instances where devs accidentally requested copilot to review PRs in our private repos before we figured out what was happening.",128,2025-04-17 02:34:58,kisielk
programming,1k0wouy,mnjj0yc,"Whoops hehe seems we accidentally trained our model with your stuff, no problem bro don't make a fuzz about it, here have a copilot discount coupon to compensate",78,2025-04-17 06:16:25,_OVERHATE_
programming,1k0wouy,mni9z1l,[deleted],114,2025-04-17 00:53:47,N/A
programming,1k0wouy,mnk3bfn,techbros have idea of consent of an average rapist,64,2025-04-17 09:46:04,CrunchyTortilla1234
programming,1k0wouy,mnj5ms3,Just Microsoft things™,26,2025-04-17 04:19:29,fn3dav2
programming,1k0wouy,mnj6zcu,they really want our code,23,2025-04-17 04:30:08,SlovenianTherapist
programming,1k0wouy,mnjnui1,"its the microsoft classic, they have done this type of bullshit for as long as i can remember. if you have windows you basically have to consatnly check your privacy settings to see if microsoft turned something on that you had turned off,  apart from the fact that most things cant be disabled anyways",26,2025-04-17 07:04:16,bokuWaKamida
programming,1k0wouy,mnkhg17,"I think this is going to be the first in a long line of big tech ""oopsies"" that result in them accidentally stealing all your data in the next few years.",13,2025-04-17 11:44:28,nnomae
programming,1k0wouy,mnk9h8n,The myth of consent,10,2025-04-17 10:43:15,PrimozDelux
programming,1jycix4,mmxzf3z,That's legitimately a hilarious exploit. Some names just get hallucinated more often!,214,2025-04-13 19:22:00,Tsear
programming,1jycix4,mmy6nsa,"Its wild for me that people just import whatever packages some tool suggested. I may be paranoid, but I'm used to manually pick even which version to install or update to.",195,2025-04-13 20:00:58,meganeyangire
programming,1jycix4,mmyicf5,"I'm just going to keep repeating this:

The consulting jobs that will be created in a few years to fix all this garbage are going to be glorious.",169,2025-04-13 21:03:40,h3ie
programming,1jycix4,mmycq1e,"""slopsquatting""? I prefer to call it vibe-jacking.",93,2025-04-13 20:33:13,Popog
programming,1jycix4,mmykez3,"My major grievance is that not even OpenAI/Copilot knows which Windows Desktop framework uses what XAML dialect, no matter how often you tell him it's MAUI (not WinUi3, not WPF, not Xanmarin, MAUI!!!) and 90% of the results are almost unusable.",38,2025-04-13 21:15:09,md_youdneverguess
programming,1jycix4,mmynb5n,Snyk Code scanner has a feature where it suggests a coding fix to a vulnerability.  Now I understand why in one case it was suggesting a library that I never heard of and could not find in my searches: it was a hallucination.,16,2025-04-13 21:31:22,ScottContini
programming,1jycix4,mn0hf6w,It's hilarious to me that a while back all the professionals told us this kind of thing would happen and all the AI stans got all worked up telling us how dumb everyone is.,15,2025-04-14 04:45:48,ClownMorty
programming,1jycix4,mmzwph0,Senior engineers are going to make a mint rewriting the nasty code bases created by this wave of AI nonsense,11,2025-04-14 02:10:30,-grok
programming,1jycix4,mn0ttun,well its actually not sabotaging but more like vibe-sabotaging,3,2025-04-14 06:43:23,FederalRace5393
programming,1jycix4,mmzk8h8,"Recently was trying to import node module suggested by LLM and it fkng didn't exist, i could have been hacked.",1,2025-04-14 00:49:03,RealMadHouse
programming,1jv3emt,mm8l7r0,"God all these articles are so fucking useless. The actual news is just: https://xcancel.com/blelbach/status/1902113767066103949

> We've announced cuTile, a tile programming model for CUDA!

> It's an array-based paradigm where the compiler automates mem movement, pipelining & tensor core utilization, making GPU programming easier & more portable.",110,2025-04-09 16:43:37,fxfighter
programming,1jv3emt,mm7p4o3,Original article without the LLM slop: https://thenewstack.io/nvidia-finally-adds-native-python-support-to-cuda/,234,2025-04-09 14:04:26,mcpower_
programming,1jv3emt,mm71vpm,"Bad news for mojo, I guess?",57,2025-04-09 11:44:56,pstmps
programming,1jv3emt,mm76e8u,I don’t really get much from this article. If I am understanding this correctly this now allows for you to specify threads to run on grids that you specify? Do they just always use shared memory smart pointers? That seems awfully non pythonic. As a scientist I rarely feel like I never need anything more than the cuda associated libraries with anything implemented in RAPIDS but maybe someone else might find this useful.,44,2025-04-09 12:15:51,Cultural-Word3740
programming,1jv3emt,mm7rxv3,"What does native python even mean here, are they JITing to PTX?",8,2025-04-09 14:18:53,activeXray
programming,1jv3emt,mm708mp,"Ah, that's what they been working on, cause they haven't been fixing their gaming drivers",165,2025-04-09 11:33:05,supermitsuba
programming,1jv3emt,mmaslaw,"NVIDIA is doubling down on Python. I did some training with them recently and they asked everyone in attendance what languages they knew. Mine was the only hand that went up for C++ and of course everyone knew some Python there. The trainer went on to explain how everything is moving to Python. I am familiar with NJIT and Numba but they did not get into the specifics of what they meant when they said that at all. Honestly, I think much of this is TBD but they know the direction they want to go.",3,2025-04-09 23:23:28,thatdevilyouknow
programming,1jv3emt,mm85dup,"Is it me, or is trying to make Python fast in hardware a really dumb idea? Why use some of the fastest, hot, expensive, and capable hardware to natively support one of the slowest and most bloated runtimes? Is there really that much demand from people who need things to be fast but can't code in another languag....oh.

So- massive power use so non-coders can have AI generate python, which needs massive power use to run fast on massive GPUs to hide the fact that AI code usually sucks...
  
Excuse me, I'm going to go buy some stock in electrical utilities and swimming pool companies.

edit- I was wrong. I had to dig a bit, it turns out it does compile to Nvidia Runtime C++, so it's just an official wrapper. The article failed to mention that, I got the vibe that Python was going straight to CUDA opcode.",1,2025-04-09 15:25:39,Truenoiz
programming,1jv3emt,mm8rfer,How is GPU memory allocation and freeing supposed to work with that?,1,2025-04-09 17:13:37,Dwedit
programming,1jv3emt,mmaelbo,They can’t have you be using an abstract API that could work with other hardware…,1,2025-04-09 22:03:32,mkusanagi
programming,1jkgh2s,mjw172v,[deleted],203,2025-03-26 19:50:44,N/A
programming,1jkgh2s,mjxcr7c,"I work in bioinformatics. 

We constantly get computer scientist offering their services to save us. 

Then you point them at the relevant data to what they want to work on and you never hear from them again. 

Biology is hard. For most problems it requires knowledge of both biology, chemistry and computer science to even attempt to solve anything beyond toy problems. The most successful scientific research is done by groups/labs with specialists in all areas who have deep domain knowledge and the lab/organization has the ability to run wet lab experiments to generate additional data and test the algorithm results. 

There have been some cases where the thing needed was simple enough for a computer scientist to make significant impact such as the various algorithms to align dna sequences to a references or each other. But they are few and far between.",153,2025-03-26 23:47:08,TheLordB
programming,1jkgh2s,mjvy79o,"> At least 60 GB of free space on your machine and at least 2GB of RAM.

I understand the RAM, but what takes so much disk space for the simulation?",119,2025-03-26 19:36:12,voronaam
programming,1jkgh2s,mjw5q1z,"It reminds me of those synthetic biology experiments where they remove as much of the genome of a cell as possible and see if it still lives and grows. 

This is really cool, finishing the worm would be like finding the Higgs boson, its a confirmation that our model of reality is correct.",18,2025-03-26 20:12:25,lizardmos5
programming,1jkgh2s,mjv0fbo,"Stephen Larson is a cofounder of OpenWorm, an open source software effort that has been trying, since 2011, to build a computer simulation of a microscopic nematode called Caenorhabditis elegans. His goal is nothing less than a digital twin of the real worm, accurate down to the molecule. If OpenWorm can manage this, it would be the first virtual animal: the “holy grail,” as OpenWorm puts it, of systems biology.

Unfortunately, they haven’t managed it, even though scientists have been studying C. elegans for decades (in fact, no fewer than four Nobel Prizes have been awarded for work on the worm).

So why keep trying? What is it about this little worm that pulls generations of scientists towards its challenge? Well, it’s an opportunity. Understanding C. elegans is a stepping stone toward understanding more complex nervous systems and eventually, someday, the human mind.

Read the full story: [https://www.wired.com/story/openworm-worm-simulator-biology-code/](https://www.wired.com/story/openworm-worm-simulator-biology-code/)",292,2025-03-26 16:53:47,wiredmagazine
programming,1jkgh2s,mjv9b0b,He should talk to u/perfect-highlight964.  His work is on snake but that’s not too different,46,2025-03-26 17:35:35,s0ulbrother
programming,1jkgh2s,mjwxi54,"Babe, would you still love me if I were a computer simulation of a worm?",25,2025-03-26 22:25:59,TangerineX
programming,1jkgh2s,mk0k6uu,"This article is fascinating—OpenWorm feels like the perfect intersection between biology and programming. It’s wild to think that something as “simple” as a worm still can't be fully simulated, even with all the computational power and talent we have.

It really puts into perspective how complex even the smallest forms of life are. Makes me wonder: is it just a matter of time and resources, or is there something fundamentally missing in how we model behavior?

Also curious—anyone here ever contributed to OpenWorm or a similar project?",4,2025-03-27 14:18:53,tomasartuso
programming,1jkgh2s,mjyfjsa,"People are working on this, but all I want is a modern 2d update to the Creatures series of games that takes full advantage of how powerful home computers have become.",3,2025-03-27 03:40:04,MrArborsexual
programming,1jkgh2s,mk1cjz2,"As a co-founder of the OpenWorm project, there has been many interesting and fun off shoots of the project. I was instrumental in cataloging the nervous system and left the project back in 2014 to explore higher level animals. My worm emulation work has been written up in many places including Wire, as well as, replicated around the world and applied to many different robots. My point is don't discount their work. It has led to a number of discoveries despite the ultimate goal not having been achieved. 

[https://youtu.be/YWQnzylhgHc?si=z9AJ774ZrahS785t](https://youtu.be/YWQnzylhgHc?si=z9AJ774ZrahS785t)",5,2025-03-27 16:37:08,ConnectomicAGI
programming,1jo0dzz,mko2ksu,"When an AI replies to a prompt with: “Wait, I don’t think we should do that and here is why”, I’ll believe that there is a future for vibe engineering down the line.

Right now, affirming every request and confidently delivering bullshit is far from it.",751,2025-03-31 11:28:24,akirodic
programming,1jo0dzz,mko73ly,"The funny thing about the whole ""AI"", ""vibe coding"" replacing software engineers debate is that it's being determined by AI outputting the equivalent complexity of a to-do list app, judged by non-software developers who wouldn't be able to code a to-do list app themselves without AI.",255,2025-03-31 12:02:56,freecodeio
programming,1jo0dzz,mkpgunh,what the fuck is vibe coding,20,2025-03-31 16:17:41,jcl274
programming,1jo0dzz,mkpqh6s,"As soon as I first heard the phrase ""vibe coding"" I knew immediately that it was some stupid tech bro vapour ware shit like ""web 3.0"". 

Why do people keep falling for these scams?",26,2025-03-31 17:06:07,seamustheseagull
programming,1jo0dzz,mkq7623,"One of the biggest problems still is that it just can't fit enough domain context to even start. We humans take a lot of stuff for granted when dealing with subject matter experts and using our own lived experience. 

It needs a large context size to understand the customer base and domain and then say something like, ""hey actually your Christmas shopping list app might be better suited to using a passwordless authentication mechanism because based on your use case you have non technical users who only use it for a month or a year, they won't remember their password next year. For the best user experience we can just text them a one time use code when they log in to avoid the problems of forgotten password resets. Implementing this will avoid having to do password reset flows entirely!""

Most of the experiments I've done where I try to feed it enough documentation context of ends up just dying. So you have to really implement RAG workflows and ""reasoning"" internal monologs, and build a whole multi-agent workflow to try and do it, but in practice it gets tripped up by document context window limits in those cases too.",9,2025-03-31 18:28:02,manliness-dot-space
programming,1jo0dzz,mkol562,"> Such systems could tightly encapsulate AI-generated black-box components with rigorous testing, detailed performance profiling, tracing, canary deployments, and strict protocol compatibility checks. In other words, the systems would employ the same rigorous engineering practices that underpin today's software – but likely much, much stricter.

Yeah, that's just regular engineering.

When I am taking that trend to its extreme, I see something I like: self-healing software. If you get to the point where you can have good tests covering 100% of the use cases, and have 100% of the code generated autonomously, then fixing a bug is just a matter of describing it, in the form of a test, and letting the system fix it.

Many things can go wrong there, and it opens a new range of many potential issues, but this is also a totally new engineering style that opens up.",13,2025-03-31 13:33:57,keepthepace
programming,1jo0dzz,mko1nid,"I thought the insight into AI coding as pushing the problem to the right where it is more expensive to fix was good.  I think the jury is still out on if “vibe coding” is here to stay.  As a term, it’ll end up with “surfing the web”, even if the practice actually sticks around.",17,2025-03-31 11:20:45,N/A
programming,1jo0dzz,mkpm4xk,Today I saw a job post for vibe coder. Industry is cooked,7,2025-03-31 16:44:23,ImprovisedGoat
programming,1jo0dzz,mkptujz,"Programmers aren't engineers.  Engineers actually have to pass certification, there are laws controlling who can call themselves an engineer. Anybody can just *say* they're a programmer or software engineer. 


That's why we have 6 round interviews. Because they've been the ```IsEven``` code you guys come up with, and they want to avoid that kind of bad hire.",7,2025-03-31 17:22:43,ColoRadBro69
programming,1jo0dzz,mkqkle0,This crush is harshin my mellow,2,2025-03-31 19:35:14,mycall
programming,1k1jn9x,mnmlifl,"Mod node: this is r/programming, a technical subreddit. Technical discussion of vulnerabilities is encouraged but political rants won’t be tolerated.",1,2025-04-17 18:19:17,ketralnis
programming,1k1jn9x,mnpi0r5,"Two fun reminders: Cellebrite itself is vulnerable to many exploits because of how naively its' implemented, and has been exploited in the wild.

And preventing any kind of cellebrite exploit is as easy as rebooting your phone if you know its about to get confiscated (for most modern devices)",37,2025-04-18 04:23:04,Somepotato
programming,1k1jn9x,mnn01o6,"> The attack relied on an intricate exploit chain that used emulated USB devices to trigger memory corruption vulnerabilities in the Linux kernel.

I am trying very hard to not say the thing.",151,2025-04-17 19:32:07,minno
programming,1k1jn9x,mnmkmi0,"* ""Serbian student activist’s phone hacked using Cellebrite zero-day exploit"" by Pierluigi Paganini (March 3, 2025): https://securityaffairs.com/174822/breaking-news/serbian-student-activists-phone-hacked-using-cellebrite-zero-day-exploit.html , https://archive.is/1zf8I


- The first part of the submitted title (""Serbia: . . .  activist"") and the submitted link are from ""Serbia: Cellebrite zero-day exploit used to target phone of Serbian student activist"" by Amnesty International (February 28, 2025): https://www.amnesty.org/en/documents/eur70/9118/2025/en/ , https://www.amnesty.org/en/wp-content/uploads/2025/03/EUR7091182025ENGLISH.pdf  (""CELLEBRITE ZERO-DAY EXPLOIT USED TO TARGET PHONE OF SERBIAN STUDENT ACTIVIST"" ""RESEARCH BRIEFING"" ""AMNESTY INTERNATIONAL"") from https://www.amnesty.org/en/documents/eur70/9118/2025/en/

    ""Cellebrite zero-day exploit used to target phone of Serbian student activist"" by Amnesty International (February 28, 2025) -- has the ""table showing traces of each USB connection and disconnection event which was seen while the youth activists phone was exploited using Cellebrite UFED"" (quotation from [https://www.amnesty.org/en/wp-content/uploads/2025/03/EUR7091182025ENGLISH.pdf](https://www.amnesty.org/en/wp-content/uploads/2025/03/EUR7091182025ENGLISH.pdf)): https://securitylab.amnesty.org/latest/2025/02/cellebrite-zero-day-exploit-used-to-target-phone-of-serbian-student-activist/


  - ""Serbia: “A Digital Prison”: Surveillance and the suppression of civil society in Serbia"" by Amnesty International (December 16, 2024): https://www.amnesty.org/en/documents/eur70/8813/2024/en/ , https://www.amnesty.org/en/wp-content/uploads/2024/12/EUR7088132024ENGLISH.pdf from https://www.amnesty.org/en/documents/eur70/8813/2024/en/

  - ""Cellebrite Statement About Amnesty International Report"" by Cellebrite (published on December 16, 2024 and updated on February 25, 2025): https://cellebrite.com/en/cellebrite-statement-about-amnesty-international-report/ , https://archive.is/fkWoW

  - https://nvd.nist.gov/vuln/detail/CVE-2024-53104

  - https://nvd.nist.gov/vuln/detail/CVE-2024-50302

  - https://nvd.nist.gov/vuln/detail/CVE-2024-53197



&nbsp;

* ""Android USB Zero-Day Exploit Exposed"" by Mohammad Mehdi Edrisian: https://findsec.org/index.php/blog/418-android-usb-zero-day-exploit-cellebrite , https://archive.is/mIx43





&nbsp;

* ""[Phone] Enables a future optional security feature, which will automatically restart your device if locked for 3 consecutive days."" from ""Google System Release Notes"" ""April 2025"" ""Google Play services v25.14 (2025-04-14)"" ""Security & Privacy"": https://support.google.com/product-documentation/answer/14343500 , https://archive.is/yFTEY , https://archive.is/2025.04.17-134211/https://support.google.com/product-documentation/answer/14343500

* ""For security, Android phones will now auto-reboot after three days"" by Lorenzo Franceschi-Bicchierai (April 15, 2025): https://techcrunch.com/2025/04/15/for-security-android-phones-will-now-auto-reboot-after-three-days/ , https://archive.is/FFpjX






&nbsp;

- ""Your Phone, Your Data: How to Safeguard Your Digital Life When Entering the U.S."" by Emily Neumann (March 7, 2025): https://www.rnlawgroup.com/your-phone-your-data-how-to-safeguard-your-digital-life-when-entering-the-u-s/ , https://web.archive.org/web/20250307234303/www.rnlawgroup.com/your-phone-your-data-how-to-safeguard-your-digital-life-when-entering-the-u-s/

    - From https://archive.is/2025.04.12-111954/https://news.ycombinator.com/item?id=43650507 (Hacker News, ""Your Phone, Your Data: How to Safeguard Your Digital Life When Entering the U.S.""):
  
        - Is Your Password Secure? (IYPS) is a ""password strength app that evaluates and rates your password's robustness, estimates crack time, and provides helpful warnings and suggestions for stronger passwords."": https://github.com/StellarSand/IYPS

        - Android KeePassDX can generate passwords and passphrases: https://github.com/Kunzisoft/KeePassDX

        - ""Password Generator is a simple Android application which generates secure passwords."": https://gitlab.com/vecturagames/passwordgenerator

        - KeePassXC has a ""Password Generator"": https://keepassxc.org/docs/KeePassXC_UserGuide , https://github.com/keepassxreboot/keepassxc , https://keepassxc.org/download , https://github.com/termux/termux-packages/tree/master/x11-packages/keepassxc


        - ""keepassxc-cli is the command line interface for the KeePassXC password manager."": https://github.com/keepassxreboot/keepassxc/blob/latest/docs/man/keepassxc-cli.1.adoc , https://keepassxc.org/docs/KeePassXC_UserGuide#_command_line_tool , https://keepassxc.org

        - ""Motorola moto g play 2024 Smartphone, Android 14 Operating System, Termux, And cryptsetup: Linux Unified Key Setup (LUKS) Encryption/Decryption And The ext4 Filesystem Without Using root Access, Without Using proot-distro, And Without Using QEMU"": https://old.reddit.com/r/MotoG/comments/1jkl0f8/motorola_moto_g_play_2024_smartphone_android_14/


&nbsp;

* ""EU issues US-bound staff with burner phones over spying fears"" ""European Commission officials heading to IMF and World Bank spring meetings advised to travel with basic devices"" by Andy Bounds (April 14, 2025): https://www.ft.com/content/20d0678a-41b2-468d-ac10-14ce1eae357b , https://archive.is/nxjxG  




* ""Avoid US or Take Burner Devices, Canadian Executives Tell Staff"" by Thomas Seal (April 14, 2025): https://www.bloomberg.com/news/articles/2025-04-15/avoid-us-or-take-burner-devices-canadian-executives-tell-staff , https://archive.is/GvBLF


* ""No burner phones for Swiss diplomats on US visits"" ""Switzerland has no plans to increase digital security of diplomats visiting the United States, despite the European Union issuing burner phones to protect from snooping."" by SWI swissinfo.ch (April 16, 2025): https://www.swissinfo.ch/eng/swiss-politics/no-burner-phones-for-swiss-diplomats-on-us-visits/89170804 , https://archive.is/WD8qZ



&nbsp;




* ""Australian with working visa detained and deported on returning to US from sister’s memorial"" by Daisy Dumas (April 11, 2025): https://www.theguardian.com/us-news/2025/apr/11/australian-with-us-working-visa-detained-insulted-deported , https://archive.is/Kej6V

&nbsp;

* ""New airport rules will get rid of boarding passes and check-in"" ""Passengers will be issued with a digital ‘journey pass’ containing all relevant information in the biggest shake-up of global aviation in 50 years"" by Ben Clatworthy (April 11, 2025): https://www.thetimes.com/uk/transport/article/new-airport-rules-boarding-pass-check-in-fs8d5qg2j , https://archive.is/4Xqm9



&nbsp;

* ""DHS to screen social media of visa applicants for 'antisemitic activity'"" ""Similar guidance was issued by the State Department in March."" by Luke Barr (April 9, 2025): https://abcnews.go.com/Politics/dhs-screen-social-media-visa-applicants-antisemitic-activity/story?id=120642944 , https://archive.is/5V4Ax

&nbsp;",40,2025-04-17 18:14:56,throwaway16830261
programming,1k1jn9x,mnr33qx,Is this amateur hour? Why would you burn a 0-day and not cover your tracks?,10,2025-04-18 12:59:40,commandersaki
programming,1k1jn9x,mnw0q0a,"* ""Android Security Bulletin—April 2025"" (published on April 7, 2025 and updated on April 8, 2025) -- "" . . . The most severe of these issues is a critical security vulnerability in the System component that could lead to remote escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation. The severity assessment is based on the effect that exploiting the vulnerability would possibly have on an affected device, assuming the platform and service mitigations are turned off for development purposes or if successfully bypassed.  . . ."": https://source.android.com/docs/security/bulletin/2025-04-01

* https://nvd.nist.gov/vuln/detail/CVE-2024-53150

* https://nvd.nist.gov/vuln/detail/CVE-2024-53197",1,2025-04-19 06:38:44,throwaway16830261
programming,1k1jn9x,moc3mjv,What's the fix to this potential problem? Doing a factory reset? Or it appears on a list of all apps and can be removed?,1,2025-04-21 22:44:27,pajser92
programming,1k1jn9x,mno3ura,[deleted],-17,2025-04-17 22:58:28,N/A
programming,1jvujzu,mmd5y1q,"This was a fun read. Thanks for not publishing it on medium. Thanks for sharing a random side project instead of the usual flood of thinly veiled career boosted crap.

Enjoyed it.",206,2025-04-10 10:32:50,CrushgrooveSC
programming,1jvujzu,mmdca20,"This is really cool! Truly what programming is supposed to be, just tinkering around making cool stuff",41,2025-04-10 11:24:58,thatssomegoodhay
programming,1jvujzu,mmdpe8b,I’m a web dev and this stuff is over my head but a very cool read.,17,2025-04-10 12:54:03,SideDish120
programming,1jvujzu,mmexg5g,"Good Job! Can you tell why you clone your Pokemon if you reset the leader gameboy at the right time? Does this work with your spoofer, too?",15,2025-04-10 16:41:26,Arosares
programming,1jvujzu,mmf88x4,"You might want to post this to r/emulation, they love any type of emulation stuff.   This is fascinating. 

Technically the TAS community might be interested in this too, but I have no idea where to find them :)

>I’m not 100% sure about the data in between 4. and 5.
> The spoofer just echos this data. The preamble bytes (0xFD) seem off.

Is it possible this is future proofing?   Let's say Pokemon Pink comes out and wants to add a new super cool feature, but Pokemon Red doesn't understand that feature.  So Pokemon Pink uses the extra bytes, but when that character is passed to Pokemon Red, they get lost (or who knows?  Maybe saved but unused).  But if Pokemon Pink and Pokemon Pink pass a character, it uses that for extra stats or something?",8,2025-04-10 17:33:42,Kinglink
programming,1jvujzu,mme1rxh,is this a year old or like 3 days old?,5,2025-04-10 14:04:16,therossboss
programming,1jvujzu,mmdhc73,Pretty cool!,4,2025-04-10 12:01:41,DinoChrono
programming,1jvujzu,mmhfdbf,"I interpreted `(with Go)` as `(with PokemonGo)` and was like ""well that certainly doesn't sound like it should be possible but please tell me more!.""",5,2025-04-11 00:26:12,DigThatData
programming,1jvujzu,mmdgk75,"Curious why your serial library is in a private repository (seemingly)
Edit: I am dumb. Ignore me.",8,2025-04-10 11:56:19,razialx
programming,1jvujzu,mmdyi9e,"Cool, Pokemon Red was awesome",3,2025-04-10 13:46:59,sammymammy2
programming,1k0tsm5,mnh71d5,Who does this affect exactly? I have a home network where I have my own root CA to access the server via a VPN as `https://xxx.lan` and `https://1.2.3.4`. There are exactly 0 ways for me to automatically distribute a new cert to the many kinds of devices used in the family from what I have found so far.,114,2025-04-16 21:10:38,helloiamsomeone
programming,1k0tsm5,mnin51i,I did a regression in desmos on the lifetime schedule and the curve intersects the x axis in late 2030.  So get ready for instantaneously expiring certs next decade!,34,2025-04-17 02:12:58,FetusExplosion
programming,1k0tsm5,mnjkbxc,"There are a number of comments from people asking what benefits this change has to end-user security, and there are other comments from people claiming that there are no such benefits.

Suppose that you own a domain and run a TLS server (eg, web server) for that domain. Here are the relevant threats that I am aware of:

1. *Someone obtains your TLS server's private key.* Even after you discover the breach and switch to a new private key and new certificate, the attacker can impersonate your server until the last certificate issued for the stolen private key expires.
2. *Someone somehow obtains a TLS certificate for your domain from CA.* They can impersonate your server until that TLS certificate expires.
3. *You recently obtained ownership of the domain.* Its previous owner may have legitimately obtained TLS certificates. They, or anyone who obtains the old private key and certificate from them, can impersonate your server until the old certificate expires.

When the changes take effect, they will reduce the period of vulnerability in each of these situations.

The vulnerability lasts until the certificate expires because CRLs and OCSP do not work in practice. At least, that's what the CA/B Forum seems to have decided, and their judgment seems plausible to me. And OCSP stapling doesn't seem much different from issuing a short-lived certificate without revalidating domain ownership etc, except with the complexity of a different protocol.",12,2025-04-17 06:29:14,ryan017
programming,1k0tsm5,mnhneit,These people don’t have shitty applications that you have to upload certs to and stuff. It’s not all docker containers and trendy serverless BS!,65,2025-04-16 22:40:50,crazyguy5880
programming,1k0tsm5,mnjcovx,Why not let us trust on first use and use only self signed with Dnssec txt record lookups for every request; why trust a CA more than the website; Why put everything  in one basket with LE;,18,2025-04-17 05:17:45,MilkFew2273
programming,1k0tsm5,mnh9xem,Why not 30 days?,23,2025-04-16 21:25:55,iNoles
programming,1k0tsm5,mnjdaw9,"Obviously none of the people who point fingers at ""autorenewal"" or somesuch ever heard of air-gapped data-centers or locally-mandated CAs. ""Ewwww, but you can use LetsEncrypt!, silly"" no you actually can't for many reasons.

What's more ironic is that LE! is shutting down OCSP in three months this year, talking about automation.",30,2025-04-17 05:23:09,zam0th
programming,1k0tsm5,mnguhbc,"It's excellent news, and for all the right reasons. Everyone should be managing certs automatically, there's no excuse for not doing it.",82,2025-04-16 20:08:16,gredr
programming,1k0tsm5,mnmaa1r,"Thanks for the heads up. I will adjust my cron jobs to run every week instead of every month.

I need it more frequently to get more time in case there is an error as I tend to ignore the error e-mails for multiple weeks due to my fatigue from handling of various kinds of certificates.

Personally I also have an HTTP mirror for my more important projects when availability is more important than security of the connection.",3,2025-04-17 17:25:42,jezek_2
programming,1k0tsm5,mni8d85,/sigh/ our org automated certification process so much that it's more feasible to just manually upload certs nowadays because of reasons. yeah i will enjoy this change :(,5,2025-04-17 00:44:07,No_Nobody4036
programming,1jqypxq,mlamn61,"The alternative is learning an ever-growing mountain of DSLs and tools and technologies and terms that aren't very rewarding to a majority of devs... So you do the bare minimum and get crappy results and deliver slowly.

I don't disagree, really, but as an ex-devops I'm not sure the alternative is better",578,2025-04-04 00:26:06,pampuliopampam
programming,1jqypxq,mlazmjg,"All I'll say is Amazon's approach to DevOps was really bad when I was there, just devs doing lots of ops work and basically doing two jobs for the pay of one 

At my new place we have dedicated SREs doing pager duty while the devs are not

And at least afaik the SREs get paged way less than we devs did back at Amazon, probably in large part cause the devs have their time allocated towards writing the software with long-term quality rather than putting out fires in the short term",109,2025-04-04 01:47:45,GenTelGuy
programming,1jqypxq,mlatuc7,"I see a lot of ""We did X, we did Y"" in this blog post. But who is ""we"" here?

I recognize some of the original challenges, but I don't recognize the world this dude describes.",149,2025-04-04 01:11:09,abraxasnl
programming,1jqypxq,mlb5xss,">Originally, DevOps was about trusting developers with production. But modern DevOps teams operate on the belief that developers can’t be trusted with production.

Heh. I am old. This belief existed (and was challenged) before the term ""DevOps"" existed.

DevOps is just a word that merely reflects a cooperation need that exists between development and deployment , in a growingly complex world. Who do you think deployed software 50, 60 years ago...? Developers, that's who, with cooperation from system admins. In fact, first deployments were done by developers alone.

Nothing has changed from that, and it cannot change, except the position of a ""dev-ops"" needle in individuals, depending on the organisation etc.",32,2025-04-04 02:27:23,goranlepuz
programming,1jqypxq,mlaq60j,It doesn't matter what you call it; poor communication is just poor communication.,135,2025-04-04 00:47:58,omniuni
programming,1jqypxq,mlbf310,"Speaking as a product engineer, there's two types of companies: companies with dedicated DevOps teams and companies I don't want to work for.

You need specialists at certain things in a mature company else your ""fullstack engineers"" are gonna want to blow their brains out.

Of course we're going to have people on both sides of some fences that are aware of and have experience on the other side. Those people will have a unique extra perspective vs people who are very focused on one domain and know nothing else.

At the same time as us having those special multi-skilled swiss army knife devs, I'll bet that there's plenty of engineers who don't want to do all the stuff that other types of engineers do. That's why I'm a backend product engineer and not a DBA, devops, web developer, mobile app developer, product manager, engineering manager, or anything else product development-adjacent. I like what I do.",24,2025-04-04 03:29:12,Scottz0rz
programming,1jqypxq,mlat4x6,"""We need Operations but naming it *DevOPs* was a mistake*""*  is a pretty weak argument ngl. The SOC complaining is especially weak. It's essentially someone groaning exagerattedly when they get told their code was rejected for violating HIPAA/security or something regulated. In that example you give, you are basically arguing that devs should be able to just merge non-compliant code anyways, despite the possiblity it could adversly expose clients/users to unnecessary risk.",96,2025-04-04 01:06:42,MoistCarpenter
programming,1jqypxq,mlc06td,"There is a distinct ‘DevOps team’ failure mode, the article writer has experienced it. It’s also clear that not everyone else has, and that leads to people having very different takes on what the author is saying. 

My personal experience with this failure mode was in a 150 person scaleup. As we were scaling from 50 people to 150, we realized that we needed some more devops oriented profiles. Rather than embed them onto different product teams, they got formed into a single dedicated devops team, who was supposed to support everyone. 

First they wasted 12+ months on building their own CI/CD platform in AWS based around hashicorp tech, it had a lot of bells and whistles, being able to bootstrap itself in case of disaster, service mesh to support multiple cloud providers and ability to seamlessly migrate between AWS, Azure, google cloud. After that they discovered that everyone was happily using azure devops for CI/CD tasks, and that there was 0 reason to migrate to their homegrown solution. 

Next they decided to streamline our AWS environments. Everything should go into terraform, and to make things even better, they should only use our home grown terraform templates. They hadn’t settled on which practices they wanted to use for those templates yet, but the policy was still in effect. Only members of the devops team could bypass it. 

Net effect was that if you needed a new server for anything, you could either get the on-prem infrastructure people to order it, set it up, and get it running in 4-6 weeks, or you could ask the devops team to provision it for you in the cloud and you might get it sometime after 3 months, but also you might just never ever get it. 

Even worse if you wanted to use a new service or feature in AWS, then you first needed to wait for an official or unofficial module in terraform to be made available, and then wait for the devops team to have time to write their own wrapper around it, which could be delay you a few months, or result in you never ever getting it.

So I have seen the failure mode of ‘devops teams’ and it is not pretty",13,2025-04-04 06:23:07,Grubsnik
programming,1jqypxq,mlar14h,"OP it’s not too late to delete this really strange way of enthusiastically telling everyone you have very little experience. 

TLDR of the article is: 

Developer is big sad they can’t potentially break production, which is just like, super unfair. Back in the day developers were trusted with production, and it’s just really weird that after years of developers needlessly breaking production that an entire skillset rose up to protect companies from the harm caused to silly things like brand equity and reputation! Those pale in comparison to the freedom of giving developers the keys to the kingdom! This certainly is a trust issue, DEFINITELY not companies learning from mistakes. Nope. It’s just absolutely pointless. 

DevOps meanies build tooling that deal with stateful operations, policy and access controls, security, any of which can easily take down the entire stack, and you know, those things are just super duper restrictive for developers… Like, why not just have product engineers do those things? 

I mean, it’s so simple - companies just need to allocate the time for product engineers to learn complex provider offerings and implementations, design tooling to provision resources for those without destroying the world, which is obviously just a total walk in the park and can EASILY be done in parallel to existing product development. 

I mean, it’s all just so pointless. Never mind things like compliance audits, security, resilience - those are just super duper simple for every single developer ever.",281,2025-04-04 00:53:23,btdeviant
programming,1jqypxq,mlarcv2,I am amazed at how quick IT industry can churn out new fancy names every few years for things that aren't even new.,89,2025-04-04 00:55:26,udum2021
programming,1k22pdf,mnqr8ue,I look forward to them moving it back in one year when they realise how much GCP actually costs.,424,2025-04-18 11:38:54,Rhoomba
programming,1k22pdf,mnqx9qv,"Ah yes, putting more critical infrastructure in the hands of a single for-profit megacorp.",236,2025-04-18 12:22:05,hbarSquared
programming,1k22pdf,mnrkmu8,"Strange they would choose Google Cloud for this. 

I’d expect something more sustainable and lower cost and likely to exist in 10 years. 

I think arXiv is a great resource and was kind of surprised to learn it’s just run by Cornell. I kind of feel like it needs to be hosted by Wikipedia Foundation or something.",43,2025-04-18 14:37:23,prepend
programming,1k22pdf,mnqqwb6,"Good, so Google will need less efforts to scrap it.",46,2025-04-18 11:36:14,RoomyRoots
programming,1k22pdf,mnr5gdi,"[Oh dear](https://i.imgur.com/KH9Is6U.jpeg)  Well, kind of - if they do the work to modernize it as a containerized app on top of now-standard k8s containerized hosting, then it IS migratable again fairly readily back to modern in-house k8s or other k8s provider hosting services I suppose.",12,2025-04-18 13:14:02,lood9phee2Ri
programming,1k22pdf,mnr0ohi,"Hmmm. I can understand it to some extent; local universities here in Europe also kind of do the same, usually running to Microsoft (guess they don't understand the problem of Trump's US-first directive and tariffs, but that's a secondary thing, I am not meaning to pull in politics here). The problem I see is that more and more inter-dependencies in regards to computer and software, are controlled by a few mega-mega-corporations. While this is understandable (many universities or campus sites lack knowledge and manpower to offer any alternative), it's still pretty unfortunate.

> replace the portion of our backends still written in perl and PHP

^^^ we can see that with regard to COBOL. Granted, neither perl nor PHP are in a similar state as COBOL is, but slowly you have those issues coming up more and more, in particular in regards to perl. And while people claim ""COBOL is so highly paid, sure perl will be the same"", the fact of the matter still is that young software devs will rarely specialize in any niche language merely because they have a more secure job (or they assume this to be the case, which is not necessarily true either).

> containerize all, or nearly all arXiv services so we can deploy via Kubernetes or services like Google Cloud Run

That seems mega-buzzword jargon. So, their legacy system is perl and php ... but they TOTALLY know the MUST have Kubernetes running on Google Cloud? I mean what is next: ""extend AI to all infrastructure""?

> The cloud transition is a pre-requisite to modernizing arXiv as a service

How so?

They did not give any arguments.

Great for those landing those three jobs, but there are some mixed feelings. If anyone of you lot land a job, make sure to give feedback about it in a few years. And we'll also have a look at arXiv how their epic move to become part of a googlified cloud will have work. If all has been messed up, AI may come to the rescue. Possibly ... \o/",7,2025-04-18 12:44:33,shevy-java
programming,1k22pdf,mnti563,"I don't know why, but this is bad.

May be I know why: It's Dejanews all over again.

Google killed Usenet when they acquired and neglected Dejanews. On purpose, I may add.

arXiv is getting dejanewed.",-1,2025-04-18 20:30:09,Nicolay77
programming,1k22pdf,mns37y8,This post clearly triggered a lot of people who bought into the cloud repatriation kool-aid.,-11,2025-04-18 16:10:17,yourfriendlyreminder
programming,1k22pdf,mnqxxvn,it's so over,-15,2025-04-18 12:26:40,DreamDeckUp
programming,1jqwybf,mlar519,Kinda ironic that so much of this was about trying to fit BASIC in 4k - and then they publish it as a 100meg pdf.,146,2025-04-04 00:54:04,wosmo
programming,1jqwybf,mlc206g,Let’s see Paul Allens code.,59,2025-04-04 06:38:14,Sarthox
programming,1jqwybf,mladmxo,"as a naturally distracted person, having the text change funkily right underneath my cursor is certainly a readability choice",179,2025-04-03 23:31:19,bzbub2
programming,1jqwybf,mlafold,[deleted],133,2025-04-03 23:43:31,N/A
programming,1jqwybf,mlb8pkp,"The actual code linked a the bottom of the epilepsy triggering post:

https://images.gatesnotes.com/12514eb8-7b51-008e-41a9-512542cf683b/34d561c8-cf5c-4e69-af47-3782ea11482e/Original-Microsoft-Source-Code.pdf",32,2025-04-04 02:45:27,quakedamper
programming,1jqwybf,mlb8ud5,"Interesting that Bill is writing this book now, after Paul Allen has died.  I have a feeling Paul might have a different take on some of the stories in the book.",33,2025-04-04 02:46:19,jedberg
programming,1jqwybf,mlali8v,"Looks cool if one isnt trying to read the site. But really annoying if one is trying to read it. I think demonstrates quite well why the user experience of Microsoft products is so bad in comparison to other companies.

Bill gates writing could be simple text without any formatting and people would read it just to hear what he has to say. This kind of gimmickry is usually reserved for content that isnt worth reading.",51,2025-04-04 00:19:06,StarkAndRobotic
programming,1jqwybf,mlajb95,">Incredible leaders like Steve Ballmer

lol.",19,2025-04-04 00:05:28,-grok
programming,1jqwybf,mld08bt,"You know what I want from a website? For it to **not** show me the content, and instead flicker some bullshit for a few seconds, reflowing text and images, and just plain being an asshole.",5,2025-04-04 12:05:40,lalaland4711
programming,1jqwybf,mlbtcwh,"How is this upvoted? I literally cannot read it. In Brave, the whole page is white. In Chrome, the constant animations are fucking idiotic.",10,2025-04-04 05:21:51,netherlandsftw
programming,1joeiaj,mkrqiog,"This is the key. Just like when the AI initially suggests nonexistent methods on libraries, then apologizes with a “You got me!” when you point it out. If it can’t use features that actually exist the first time, it can’t “code.”

> Take my Express backend experiment. The code worked perfectly, but it was clear that protection against SQL injection was completely absent. Not even in the most basic way was it taken into account, which means that the site was so incredibly unsafe that it wouldn’t take an hour before it would be hacked. When I addressed ChatGPT about this, it immediately provided a security fix. The knowledge was there, but wasn’t proactively applied. Of course, this can be solved with better prompting, but that’s obviously not a solution that can replace developers. To be able to prompt well, you already need the knowledge of a developer by definition.",447,2025-03-31 23:16:37,TestFlyJets
programming,1joeiaj,mkrrv3s,It's fine for spitting out code segments and various types and such. And also just throwing ideas at it helps me think. Like a superpowered rubber duck. I absolutely loathe using it as auto-complete though. I need my editor to be deterministic.,84,2025-03-31 23:24:17,SerdanKK
programming,1joeiaj,mkr5mbp,"As an engineer with 2 decades of experience, I find myself increasingly annoyed by non-coding managers thinking AI is going to bring 190% reduction of cost, or replace entire divisions of coders. A helpful tool, sometimes yes, but sometimes also a complete and utter tool. So I wrote a rant about it.",300,2025-03-31 21:20:12,monkeyinmysoup
programming,1joeiaj,mksdnnz,"> It's a reality check that LinkedInfluencers prefer to ignore, because AI is so incredibly cool and hip and for many people the only intelligence they know, but those who build products on a daily basis know better.

Beautifully said.",38,2025-04-01 01:36:42,Big_Combination9890
programming,1joeiaj,mkt13oi,">But in my view, this is just the next step in a long evolution of developer tools.

This is absolutely true, and I think a key point that seems to be glossed over by so many articles hyping the technology. 

I would argue that LLMs as they are today are less impactful than modern IDEs, frameworks, version control, infrastructure as code tooling, you name it. Tools written by developers for specific purposes that always do what you tell them to allow for repeatable compiles, builds, testing, and deploys.

IntelliJ can use the language compiler itself to literally tell you exactly what parts of code are correct or not, in real time, and it can perform mass refactoring in a way that is nearly perfect and pretty much guaranteed to do exactly what you expect, every single time.

Frameworks like Spring Boot and React allow developers to create fully functional applications with minimal work, and MAINTAIN THEM. IaC improvements allow site reliability engineers to simplify a huge amount of platform management responsibility. 

Meanwhile, LLM offers the potential to MAYBE do what you want, as long as you can babysit it, correct it when it's wrong, and know all the little 'gotchas' you have to warn it about. Yes, they can help you do some grunt work now and then, and occasionally they can help you out if you get stuck and do things like read 700 lines of error logs to help find the one that's meaningful, but just as often, they give you the wrong answer, or they misunderstand what you meant, or YOU misunderstood what you were asking for and they just went along with you.

They're a tool that sometimes helps a bit. IMO the jury is still out for complex work whether or not they help more than they hurt. Like 90% of the time I do something like hand gpt a class and ask it to write tests for a new method I wrote, it does something totally different than what I wanted, even if I provide example test cases. It will miss obvious edge cases, mock nonsense things, get variable names wrong. Even with o3-mini or o1-pro it does stupid things ALL THE TIME. 

It's just not reliable. And even when it is, it's still just an incremental gain over our previous tooling advantages.",27,2025-04-01 04:16:02,sprcow
programming,1joeiaj,mkrulos,"Very sane take, appreciate the post. I also appreciate how you addressed productivity and expectations: “You could even say that productivity doesn’t increase, but expectations do.”

I’ve also found the same value in treating it as a private tutor: something to help fill in the blanks, but also something you’ve got to actively think about. It’s why the whole vibe coding “just hit the approve button” is so misguided. Why surrender the most important thing: the context people have about what the problem is and what kind of solution is the most appropriate.",18,2025-03-31 23:40:10,sufianrhazi
programming,1joeiaj,mksoipc,"Also fairly old as far as programmers now with over 2 decades experience. Been through enough cycles to know that new technology always over sells, people jump on it, investors push in funding, and ultimately most of it turns to shit. That is not to say that it's bad, just have to let other people waste their time in the beginning until it matures.",11,2025-04-01 02:45:11,Sairony
programming,1joeiaj,mktawtj,"Big fan of AI tools, but the more I use them, the more it's obvious how the suggestions are just a blended up version of whatever source it was trained on. If you ask it about a common problem then it does well. The more uncommon your situation, the more it flounders. It's definitely not a general reasoning intelligence.",11,2025-04-01 05:42:24,Zealousideal-Ship215
programming,1joeiaj,mkts18r,"It seems to me that, in the current IT boardrooms there is this fantasy that AI will mean no more senior developers will be needed—just hire a bunch of juniors and hand them an AI. 

The truth is that, if anything, it would be the juniors who will be cut down on. The AI can do all the badly-executed grunt work, while the seniors spend half their days correcting it. 

Of course, in this scenario the industry will soon run out of senior developers.",7,2025-04-01 08:50:04,sambeau
programming,1joeiaj,mktv66n,"The way I've expressed it before (probably in this sub) is that AI code generation is like simultaneously the best and worst intern you've ever had.

This virtual intern is uncannily good at certain weird minutiae of the sort that might look impressive in the typical poorly-thought-out whiteboarding interview. There's a perspective from which it appears to know more than any one human developer is capable of holding in their own head, and that's superficially compelling.

On the other hand, it cannot operate with even the least independence, and never can. You will forever be driving this ""intern"" as a full-time over-the-shoulder micromanager, because the second you drop your vigilance it will produce something *insane* and doesn't even have the capacity to recognize or learn from that.

Hate doing code reviews? Most of us do. Well, guess what, now your job as a responsible, competent developer relying on AI is *all code reviews* of a *complete moron.* As a bit of technology it dazzles people. As a human you'd fire it no matter how many obscure languages it seemed to know enough of to be dangerous.",7,2025-04-01 09:26:04,gelfin
programming,1jwiqfp,mmj5k0i,">MLKEM is not only faster, but is also now standardized by NIST.

the same people who standardized [Dual_EC_DRBG](https://www.schneier.com/essays/archives/2007/11/did_nsa_put_a_secret.html) from 2006-2014 despite the very obvious NSA backdoor and wide public criticism for 7 years? lovely",93,2025-04-11 08:40:56,Takeoded
programming,1jwiqfp,mmivi1u,"I still think it is somewhat strange to have more and more code in regards to quantum computing, without having desktop PCs be quantum computers too. Or do they plan some hybrid model? E. g. ""this is your new 20 CPU core chip; it has a secondary quantum chip only for when you really need quantum shenanigans"" (and then we have a quantum spectre exploit with multiple Schroedinger cats inside the box).",-80,2025-04-11 06:54:10,shevy-java
programming,1jmlgue,mkcmu6a,"gah. my second favorite boss ever was the bane of my existence for 5 years. it was only after he left and he wanted to poach me (absolutely shocked me, i assumed the guy absolutely hated me) that we became friendly and talked about our work experience 1:1 without filters. 

it was enlightening to say the least. turns out, i *was* a huge egotistical asshole. good at the job, just an asshole about it. i was young. people would come complain to him about me frequently and he'd just be an asshole back to me to try and make me feel how i made his other people feel. i'm not sure that's good leadership but i can't fault it and i was very young.

best lesson i ever learned; don't be a dick. 

but that was more of a soft skills thing. 😂",462,2025-03-29 13:12:47,YOUR_TRIGGER
programming,1jmlgue,mkcot67,"I worked in an org at a large company that had shifted so far into ""everyone gets a trophy"" territory that it became exhausting. Every week there was a day of appreciation where our Slack channel was filled with ""Thank you @xyz for explaining how your new feature works!"" and similar circle jerking nonsense. All championed by middle management who would also fill our calendars with team building ""fun activities"".

The engineers that were heads-down churning out business value were effectively ostracized for not being ""team players"" by thanking other people for doing their jobs.

If you **dared** to provide any feedback that wasn't 100% positive and covered in unicorn stickers, you could expect managers to start talking about how you are creating a hostile work environment.

I'm a fairly positive and empathetic person. However, I simply cannot give you a gold star and approve your PR because ""gosh darn it, you sure did try"". Nobody learns that way, nothing improves, tech debt accumulates and it crumbles under its own weight.

Being objective and honest while also instructive is part of the job. Constructive feedback fosters growth, while convincing everyone they're perfect stifles it.

So, not only is this ""tough love"" beneficial, the opposite is absolutely ruinous.",209,2025-03-29 13:26:02,vajeen
programming,1jmlgue,mkd40u7,Eventually we all realize this. Clever code is code that’s not maintainable.,57,2025-03-29 14:56:54,vehiclestars
programming,1jmlgue,mkcvm6v,Brutually honest feedback and delivering as constructive criticism aren't mutually exclusive,42,2025-03-29 14:08:48,_byl
programming,1jmlgue,mkd0ab9,"Fyi, search results are filled with AI generated tech articles with gen AI pictures as headers. So, all my brain sees in the article preview is a big ""irrelevant, and potentially incorrect made up info ahead"" sign",67,2025-03-29 14:35:57,saantonandre
programming,1jmlgue,mkcngw6,Sometimes the manager just really is a dick.,22,2025-03-29 13:17:05,stevemk14ebr2
programming,1jmlgue,mkclgiw,">Over-engineered. Too many moving parts. Refactor.

what the fuck does that even mean? Either give good feedback or don't give it at all. 

Also this AI generated image is awful",104,2025-03-29 13:03:22,yanitrix
programming,1jmlgue,mkfjvgs,"> “Over-engineered. Too many moving parts. Refactor.”

This is a terrible PR feedback and something we actively discourage on my team. 

Critical feedback is fine. However I expect it to be targeted feedback with explanations of what exactly is wrong, with suggestions for how to fix it. 

If a junior posted a CR that was so fundamentally incorrect. Then I would ask them to cancel it, write a design proposal, review that before writing more code. 

> I demoed a feature I was sure would impress him. Instead, he cut me off halfway through.

>    “This is fragile. What happens under load? What’s the rollback plan?”

> I scrambled for answers but didn’t have good ones. He paused and then said, “You’re thinking like a coder, not an engineer. Build things that survive failure.”

That is actually good feedback. It's something every junior needs to learn in their career.",8,2025-03-29 23:00:06,versaceblues
programming,1jmlgue,mkdpvgz,"Trying to put my finger on the issue I have with this.
A little respect goes a long way is the best way I can put it I guess.

Engineers seem to vastly underestimate the significance of a small amount of kindness in their approach as younger developers are going to learn from them not just technically but in the type of culture they will maintain.

If a PR is that off the mark, and yes over engineering means that the intent and desired outcomes were either not clearly communicated or simply ignored, then a simple comment of, “Hey great effort. There’s a few things that i wanna go over with you as some of these changes might be beyond the scope of the acceptance criteria”

Then you can explain all the functionality/scalability/maintainability issues on a call or an in-person meeting etc.

And to head off any issues of whether the tech lead or engineering manager has time for that, understand that the time spent putting together a huge PR that won’t get merged and then redo the work and put together another one, on top of the engineering leads reviewing both of those iterations, is significantly longer than an hour or so with a jr dev to explain some of the concepts and desired solution types they’re looking for",9,2025-03-29 16:56:26,BellPeppersAndBeets
programming,1jmlgue,mkck30i,"The manager I hated taught me how to spot bosses who like nose candy. He was the owner, not my direct manager, but he eventually made a bunch of deals he knew the company couldn’t deliver on and took the money and ran. No idea what happened to him after that, but he has basically no online presence, which is interesting.",10,2025-03-29 12:53:53,remy_porter
programming,1k1d4d2,mnl7djp,You mean database is not bits floating around on cloud? Weird.,272,2025-04-17 14:17:16,robberviet
programming,1k1d4d2,mnl2zr2,"Next up: ""Databases are just bits sitting on long-term storage, accessible via the I/O mechanisms provided by the operating system.""",955,2025-04-17 13:54:31,qrrux
programming,1k1d4d2,mnle9r0,"Okay I got a good chuckle out of the smart ass comments, but in all seriousness sometimes just reminding developers of these base concepts can be helpful. We deal in a world with so many abstractions on top of abstractions that it can be easy to lose sight that everything is built on some pretty core mechanisms. These concepts do still come up from time to time when working on things like query optimization for e.g.",194,2025-04-17 14:51:20,jardata
programming,1k1d4d2,mnl7zhx,In other news: Cloud is just other people computers,335,2025-04-17 14:20:20,AlphaX
programming,1k1d4d2,mnl8tv9,Data is just data really.,32,2025-04-17 14:24:32,ziplock9000
programming,1k1d4d2,mnljkcz,"I remember early in my IT career I was shocked to learn that the windows registry was a file. I mean it makes perfect sense, I just never thought about it",29,2025-04-17 15:16:58,duckwizzle
programming,1k1d4d2,mnlq32c,Everything’s computer,19,2025-04-17 15:48:24,justAnotherNarwhal2
programming,1k1d4d2,mnlg2ux,"Hm, ok... what did people think they were backed by? The Holy Ghost?",39,2025-04-17 15:00:00,cazzipropri
programming,1k1d4d2,mnlloml,"> It’s a complex and powerful system—but fundamentally, it’s just an executable that manipulates files.

...is like ""It's a complex and powerful engine, but fundamentally SpaceX Raptor is just a bottle that spits fire.""",40,2025-04-17 15:27:16,wxtrails
programming,1k1d4d2,mnm49co,"Some enterprise level databases use disk partitions for storage, instead of files.

An extra level of speed at the price of complicated kernel level access.",12,2025-04-17 16:57:04,fried_green_baloney
programming,1jisdju,mjhngii,">What's actually getting faster is the TypeScript compiler, not the TypeScript language itself or the JavaScript's runtime performance. Your TypeScript code will compile faster, but it won't suddenly execute 10x faster in the browser or Node.js.

>It's a bit like saying,

>""We made your car 10x faster!""

>and then clarifying that they only made the manufacturing process faster—the car itself still drives at the same speed. It's still valuable, especially if you've been waiting months for your car, but not quite what the headline suggests.

Hadn't considered that people might misinterpret it this way, I suppose if you only read headlines that complaint is reasonable. The article itself was pretty clear what they were talking about.",733,2025-03-24 15:15:19,Ecksters
programming,1jisdju,mjhqvqy,"> There's a widespread belief that ""Node.js is slow,” which is more of a repeated stereotype than a truth. In some instances, it can be true, but it is not a general statement.

> If someone says, ""Node.js is slow” is slow, it’s almost like they’d say that C and C++ are slow. Why?

Eh, haven't we generally agreed long ago that languages generally go from slowest to fastest as shell languages > interpreted languages > compiled languages > compiled non-gc languages? *It's more complicated than that*, but compilers have the opportunity to do more work ahead of time, and they're not doing that work for shits & giggles.

There's no magical language that's the best at absolutely everything, and there's no need for fans of interpreted languages to feel particularly self-conscious of their favorite language's performance. It's not as fast or memory efficient as a compiled language, but we've always known that, and still chosen the interpreted language, for its expressivity, its ecosystem, its friendliness towards prototyping, and so on.

Node is pretty fast _for an interpreted language_, as a result of javascript becoming hugely common/popular and there being a huge gain for everyone if it ran faster. But it's still an interpreted language. It's fine. We know. There's no need to get defensive.",88,2025-03-24 15:32:23,syklemil
programming,1jisdju,mjhlew2,"Too many words for saying JS runs on single CPU core vs Go runs on multiple. Also I'm a bit sceptical of reaching 10x just by going multiple core, you know there are dependencies, when you compile you don't use all your CPU cores all the time.

Also there is zero content about why TS compiler doesn't use techniques like worker threads or multiprocessing to use more than one core.

Edit: I actually went and watched the TS announcement video in the blog post. And I was right, it's demoed there that even with single thread, new compiler is vastly faster.",118,2025-03-24 15:05:03,null3
programming,1jisdju,mjhrlwf,"One of my takeaways from this article is that the author really wants people to stop saying nodejs is slow because of Microsoft's announcement. Let me be the first to say I already thought it was slow before the typescript announcement, and I'm frankly impressed with what the team managed to achieve with nodejs before switching to something else. I recognize that nodejs a great tool for companies trying to create/deliver products fast, but I don't personally think it's a great idea long term to use a weakly typed language in the backend. Besides, wouldn't Go also be great at the same IO intensive tasks mentioned in the article since you could use goroutines/channels to either create your own event loop like system or something even better? Not to mention the additional speedups you can get out of Go with it being a strongly typed systems language.",22,2025-03-24 15:36:00,SuspiciousBlimBlam
programming,1jisdju,mjhwb7y,"**Take away**: JavaScript is fast at waiting (not doing stuff).

Although the content of the article itself is correct, maybe besides the clickbait thing, you can read bias and prejudices between the lines. As if the quite logical move away from JavaScript was an attack on JavaScript and/or Node.js community.

Could it be that Node.js will become next PHP? Maybe. Is Go perfect? Not at all. That's just an evolution of tools.

PS. Not totally correct. Statement *""If someone says, ""Node.js is slow” is slow, it’s almost like they’d say that C and C++ are slow""* is just plain wrong. The claim was about JS, not Node.js. Python and Lua are also written in C/C++. But performance of **programs** written in these languages vary a lot. Interpreted languages are always slower. JavaScript is quite fast for an interpreted language, but besides that... it shouldn't be chosen if performance matters.",15,2025-03-24 15:59:07,steve-7890
programming,1jisdju,mjjr62t,"The Typescript team was pretty clear on what was changing. 

I only care about IDE speed, language server suggestions on big repos is a game changer. Hopefully I'll get to love working with zod again",4,2025-03-24 21:20:14,GBcrazy
programming,1jisdju,mji56s6,"This is quite a lot of words to say ""it's likely concurrency, but we don't really know"". Ironic considering the ""what's *really* behind"" title. It's a good post otherwise, but there's a lot less substance than I expected from an article claiming to explore intriguing details.

I wonder if anyone has determined exactly what part of tsc was 10x slower. Parallelising type checking is more complex than it seems due to inference. That *is* possible to implement, but looks hard to retrofit to an existing codebase. Then again, I don't know much about tsc internals, so I might be wrong.

Others in this thread have said that even without parallelism, a 3x speedup was achieved. I don't trust that it came simply from switching to Go: Node uses a state-of-the-art JIT compiler, and although Go has AOT, it's based on braindead techniques straight from the eighties. Where exactly did V8 fail? Was it a suboptimal data layout, leading to worse cache utilization? Was it maybe cross-function control flow? There's a valuable lesson here somewhere.",3,2025-03-24 16:43:10,imachug
programming,1jisdju,mjiaron,"Thesis: ""Node.JS isn't actually slow""

Content body: ""It's really slow lol""",4,2025-03-24 17:10:01,telionn
programming,1jisdju,mjhr11h,Typescript already compiled so fast so this is pretty impressive. I'm mostly curious to see what stuff this enables.,3,2025-03-24 15:33:06,Ok-Kaleidoscope5627
programming,1jisdju,mjj82nr,I would actually like to know why it’s supposedly an order of magnitude faster if anybody does know.,1,2025-03-24 19:49:09,blisteringbarnacles7
programming,1k541xl,moft2f7,"I never thought people would get in to cryptocurrency, then choose the one where the people that started it can just print themselves more whenever they want. I am constantly discovering new depths of systemic stupidity.",77,2025-04-22 14:45:46,GaboureySidibe
programming,1k541xl,mof2iqp,What is the file example that is corrupted?,20,2025-04-22 12:14:10,Reeywhaar
programming,1k541xl,mogscwm,Crypto scammers scamming crypto scammers?,18,2025-04-22 17:36:34,araujoms
programming,1k541xl,mof1ek5,"Hahahahaha

When will cryptobros learn (rhetorical question, for they are not capable of learning)",114,2025-04-22 12:06:29,eyebrows360
programming,1k541xl,mofcde2,"oh no

anyway",32,2025-04-22 13:16:05,fragglerock
programming,1k541xl,mof4mmk,"> the official Ripple SDK

Well there's your problem. Why would anyone seriously think they could avoid being grifted by voluntarily working in crypto, a technology that was invented solely to grift?

What the hell did you honestly expect?",79,2025-04-22 12:28:11,Djamalfna
programming,1k541xl,mof8qlx,When our descendants far in the future look back at how we ruined the planet crypto will be right there at the top as the absolutely dumbest shit.,42,2025-04-22 12:54:12,Sairony
programming,1k541xl,mofw6vv,"Hello! Creator and maintainer of vet here. We run an npm package monitor to detect malicious open source packages and retrospectively it seems like we detected it as well

The detected package versions and signals:

[https://platform.safedep.io/community/malysis/01JSD265S7K1P46FY0G90J9E5S](https://platform.safedep.io/community/malysis/01JSD265S7K1P46FY0G90J9E5S)  
[https://platform.safedep.io/community/malysis/01JSD49NEDP81SJS5WZPS84RN5](https://platform.safedep.io/community/malysis/01JSD49NEDP81SJS5WZPS84RN5)  
[https://platform.safedep.io/community/malysis/01JSD4HV7W29TJZAPNR92FPVAE](https://platform.safedep.io/community/malysis/01JSD4HV7W29TJZAPNR92FPVAE)  
[https://platform.safedep.io/community/malysis/01JSD58JJHPG7GWNVHVZKZ21JG](https://platform.safedep.io/community/malysis/01JSD58JJHPG7GWNVHVZKZ21JG)

GitHub project: [https://github.com/safedep/vet](https://github.com/safedep/vet)",12,2025-04-22 15:01:14,N1ghtCod3r
programming,1k541xl,mohzwwk,"Always enjoy your blog posts, thanks for the informative write-up. Really small annoyance: the code blocks are small compared to the actual code in them sometimes. I was a bit confused reading the line:

> It all looks normal until the end. What’s this `checkValidityOfSeed` function?

Then realised the block had a scroll bar and the actual malware was hidden below the fold.",3,2025-04-22 21:10:43,ScriptingInJava
programming,1k541xl,moh4csb,"Serves them right, maybe when enough people will be scammed and lost hundreds we will finally stop those BS and try searching for an actual use for the block chain and NFT technologies 

Also karma for that dogshit that hacked one of the most interesting FR YouTubers a few days ago (Axolot got his channel hacked and hijacked to basically stream H-24 Ripple crypto shit content)",5,2025-04-22 18:34:44,Belhgabad
programming,1jtkfpq,mluwp9z,the points listed are such common sense yet lots of enterprise programs I've seen go haywire because the basics of common sense are not applied,72,2025-04-07 13:15:13,LowB0b
programming,1jtkfpq,mlxatj4,"> Code should read as if it was written by a single human. There should be a consistent and uniform code style all over, as that helps us read code better. Wrong or inconsistent code style is a bug. We fix all bugs we find.

Good god every developer who rebels against linting needs to read this over and over again until it sinks in.

And actually, I needed to read it too. I hadn't thought of how to put into words _why_ linting is so important and this is so succinct and clear that I love it.",20,2025-04-07 20:42:33,chalks777
programming,1jtkfpq,mlv3ml9,"> Warning-free

> While it should be natural to everyone already, we of course build all curl code entirely without any compiler warning in any of the 220+ CI jobs we perform. We build curl with all the most picky compiler options that exist with the set of compilers we use, and we silence every warning that appear. We treat every compiler warning as an error.

Does he mean they fix every warning when saying ""we silence every warning that appear [sic]""?",69,2025-04-07 13:56:41,Ratslayer1
programming,1jtkfpq,mlw9xlh,"These are the simplest standards I've ever seen.  And I've seen so many companies not live up to them. 

>C is not memory-safe

Yup.  But you can write it cleanly, and if you use applications like valgrind to test your code you can feel even more safe in your assumptions. 

> Warning-free

Fucking hell yes.  Though I will say C has some !@#$ing warnings.  ""OH are you sure you want to use this?"" YEs.. YES I DO  stop asking me.  (You literally have to use -Wno-psabi to silence them. WTF C/C++) 

I prefer python because you can silence linter warnings at times... but in general Warnings are warnings for a reason.

>Avoid “bad” functions

If you don't know any of these... you need to. (Sprintf?  Strcpy? )  honestly I almost think those should be removed, but that would break applications of course because people don't know them and used them

>keep master golden

MMMMMM   This is the one I love. You NEVER work in the Ship branch.  I'd argue ""Master"" is the wrong word,  Final or ship is better, but agreed there's a clean branch somewhere that can NEVER EVER EVER EVER be broken.  And people should be starting by cloning using that, not other people's work branches.   The amount of times I've been boned because the ""Dev branch"" is broken and left broken for weeks is not acceptable. 

>Always check for and act on errors

""This never happens"" Great throw a log, throw an exception, throw X  Because ""Never happens"" becomes ""happens once"" real quickly.

>  We do. We are human. We do mistakes. Then we fix them. 

Words to live by.",17,2025-04-07 17:34:07,Kinglink
programming,1jtkfpq,mluyg21,"All that, and they *still* have tons of bugs and vulnerabilities due to C:

> We are certainly not immune to memory related bugs, mistakes or vulnerabilities. We count about 40% of our security vulnerabilities to date to have been the direct result of us using C instead of a memory-safe language alternative...Over the last 5 years [out of 29 years], we have received no reports identifying a critical vulnerability and only two of them were rated at severity high. The rest (60 something) have been at severity low or medium.",39,2025-04-07 13:26:04,gwern
programming,1jtkfpq,mlxlo5j,"> In early 2023 we dropped support for building curl on systems without a functional 64-bit integer type.

With many core OSS projects now doing this, I wonder how fast Debian is going to drop x86-32. Good riddance, though &mdash; it's just too much work to keep supporting it.

> We build curl with all the most picky compiler options that exist with the set of compilers we use, and we silence every warning that appear. We treat every compiler warning as an error.

Wait... every possible warning for every compiler? Curl supports [an ungodly number of configurations](https://daniel.haxx.se/blog/2023/11/14/curl-on-100-operating-systems/). Maybe I'm just used to [superfluous warnings in other languages](https://rust-lang.github.io/rust-clippy/master/index.html?groups=pedantic) but that sounds super impressive.",5,2025-04-07 21:40:52,Booty_Bumping
programming,1jtkfpq,mly6wfu,Can I just comment on what a pleasure it is to access a new website and not be immediately assaulted by a cookies popup.,5,2025-04-07 23:42:02,jdehesa
programming,1jtkfpq,mlv3908,80 columns and preferring short names in 2025? Did this get posted a week late?,22,2025-04-07 13:54:34,Spaceman3157
programming,1jtkfpq,mlz734h,"My native language is not English. I want to ask, is ""write C in curl"" correct? I think it should be ""write curl in C"". //the sentence is from the first sentence in the article, not title.",3,2025-04-08 03:26:52,heroboy
programming,1jtkfpq,mm7v660,The C89 requirement is archaic. 1989 is 36 years ago. I wonder if there is anyone out there who is building and using curl in an environment where a C99 compliant compiler isn't available.,2,2025-04-09 14:35:13,setuid_w00t
programming,1jm79rv,mkaseiu,"Long is commented out here: https://github.com/mortdeus/legacy-cc/blob/936e12cfc756773cb14c56a935a53220b883c429/last1120c/c00.c#L48

Is there a story behind that?",34,2025-03-29 02:58:49,Ok-Bit8726
programming,1jm79rv,mk9l7v3,"This cannot be the first C compiler, as the source is clearly written in C.",116,2025-03-28 22:43:58,vytah
programming,1jm79rv,mkca2b3,"https://github.com/mortdeus/legacy-cc/blob/master/last1120c/c00.c

Old C was indeed a lot uglier than Modern C - which is also pretty ugly.

It feels as if C is just syntactic sugar that reads a bit better than assembler. Basic logic in a function is semi-hidden after some syntax noise:

    while(i--)
      if ((*sp++ = *s++)=='\0') --s;
         np = lookup();
         *np++ = 1;
         *np = t;

Oddly enough I haven't seen this before:

    i =% hshsiz;",7,2025-03-29 11:35:10,shevy-java
programming,1jm79rv,mkbvwdg,[deleted],-15,2025-03-29 09:06:56,N/A
programming,1jm79rv,mkcjqzy,Against proving tabs has always been superior.   …++,-5,2025-03-29 12:51:32,Shock2k
programming,1k56hlt,mofkp8v,"Despite the fact that TFA ends with a pitch for Earthly’s Lunar product, I’ll have to empathise with some of the problems they’ve outlined in the table. Especially the bit about common CI/CD templates. It doesn’t work well due to differing maturity levels and business needs.

That said, scorecards can be implemented in various ways. We (large engineering org in a Fortune 100) have ended up creating scoreboards that track changes, deployments and periodic scans and this has worked well for us.

But yeah, nuance and flexibility is the key. Eg I’ve seen a lot of control owners obsess over “blocking” releases which don’t comply with x. In reality, blocking *increases risk* for all but the most egregious of violations. But a lot of SDLC governance approaches completely ignores that. Perhaps this is an education / awareness issue.",92,2025-04-22 14:02:42,pxm7
programming,1k56hlt,mofg0xi,"Hey folks - author here. We started this industry research with the goal to monetize an open-source CI tool, but as we tried to understand how to make it work at scale, we ended up going down a rabbit hole of conversations with platform and DevOps teams. What we heard was honestly a bit overwhelming — not about CI speed or dev productivity, but about just how fragmented and hard to govern modern engineering has become. We wrote down what we learned and where the journey took us. Curious if these problems resonate with you too (or if we're imagining things lol).",115,2025-04-22 13:37:13,vladaionescu
programming,1k56hlt,moh6yhh,"Yes, microservices are a terrible choice for most organizations.",47,2025-04-22 18:47:41,AmalgamDragon
programming,1k56hlt,mogrdz0,"its almost like, 99.9999% of teams do NOT need kubernetes. if you have less than 100 million customers, fuck ALL the way off with k8s. and when you do have that many customers, you have the money to hire the teams to specialize in those chaotic tools you need at that scale. engineering got complex because everyone convinced themselves they have to do what google does, but they dont have google levels of demand for their unheard of product",71,2025-04-22 17:31:58,Scavenger53
programming,1k56hlt,mokckuv,"I don't want to be a downer here, but you're trying to use tech to fix a social problem. Good luck.",4,2025-04-23 05:59:38,Sigmatics
programming,1k56hlt,mohp8n9,[Someone should really do something about that](https://xkcd.com/927/).,8,2025-04-22 20:18:03,xorian
programming,1k56hlt,mojtlce,"Can confirm.

The bigger the team(s) the more it sucks. The best open source projects have 1-2 devs",3,2025-04-23 03:28:08,reini_urban
programming,1k56hlt,monfyzi,"I saw ""too many dashboards"" and was then offered another dashboard 🤷‍♂️",1,2025-04-23 18:20:37,messiah-of-cheese
programming,1k56hlt,moj37k4,"I mean, duh.

Get a bunch of developers who are paid very well, and they start to think they're all snowflakes who should be given the latitude to do whatever they want.  Not a single one of them is a Donald Knuth or Dennis Ritchie or Edsger W. Dijkstra or even Linus Torvalds, but they all wanna play *prima donna* in this tragedy.

**DivaDevs**: *""I couldn't care less about the risk to the organization! My pet language/framework/coding style/idioms have total primacy over the organization's needs, and I know I'm special because I make 10x what some schlub in India or Croatia makes.""*

**Anyone sensible**: *""What are you actually making?""*

**DivaDevs**: *""Oh, well, I'm connecting this API with that API, and inserting a record in the database.""*

TL;DR:

> *""We used to build buildings with a set of materials that we understood, like wood and steel. But, today, for speed's sake, we'll use anything.  It could be some ""concrete"" we made from grandma's fudge, my little sister's makeup, and a literal shit I took after lunch.  Sometimes our buildings fall down, but sometimes it stays up for a minute, and we can attract Series B.""*",-4,2025-04-23 00:48:16,qrrux
programming,1k56hlt,mokfgva,"I was laid off because it “just wasn’t working out” from a programming job two weeks after an all hands meeting about how to improve retention. 

It sucks, I had a 90% completion rate per cycle, with my peers hovering in the 40%s. And I liked that job a lot, because it was hard. Been doing taxes ever since because I can’t mentally sell myself this kind of uncertainty in my life as being a good thing. I make about 1/3rd what I would/should programming.",0,2025-04-23 06:27:47,TheApprentice19
programming,1jtr45e,mlwbkez,I'm thrilled this joke is entirely recyclable from IOT,196,2025-04-07 17:42:06,elprophet
programming,1jtr45e,mlynn8l,"Me: ""wtf is MCP?""  
Google: ""Think of MCP like a USB-C port for AI applications.""  
Me: ""wtf""",121,2025-04-08 01:23:34,MooseBoys
programming,1jtr45e,mmcrgcs,Great article just added it to Awesome MCP Security [https://github.com/Puliczek/awesome-mcp-security](https://github.com/Puliczek/awesome-mcp-security) :),21,2025-04-10 08:01:13,Puliczek
programming,1jtr45e,mlwn7aa,lol I'm going to make so much money helping companies unfuck themselves after this AI wave,96,2025-04-07 18:40:54,-grok
programming,1jtr45e,mlwci9n,"It's also interesting that there's possibility for remote remote execution... I need to think through this more, but I'm envisioning a scenario where one mcp instructs the agent in a way that triggers an RCE in a second MCP",45,2025-04-07 17:46:45,elprophet
programming,1jtr45e,mlwvtt6,"When I saw the first specification of the MCP protocol I was immediately struck by the fact that they have not specified any authentication for a protocol meant to be used over network. Only in the newest version, some utterly complicated authentication mechanism (some kind of double OIDC) is specified. Why does someone, nowadays, design a protocol mostly  useful for desktop clients (missing authentication, STDIO as standard protocol, the SSE based protocol was initially underspecified)? We live in the time of web applications!",44,2025-04-07 19:25:17,BlackSuitHardHand
programming,1jtr45e,mlyz5y2,"Just read the authentication section of the MCP spec. It is so spectacularly bad...

1. It is not a draft, yet it requires OAuth 2.1 complience - which is still a draft.

2. The spec starts with an exclusion that it does not apply to non-HTTP protocols. There is no spec for how to do auth on those in the spec.

3. It arbitruary regulgulates portions of OAuth spec, such as redirect URL validation. Despite that being already implied at the start. And the regulgulated requirements are weaker than in the original.

4. It lacks any meaningful constraints on implementation. For example, Access tokens must be subject to a lifetime, but setting life of a token to thousand years would be totally fine by this spec.

A way better version of the spec would've had just two lines:

> MCP server SHOULD require OAuth 2 authentication.

> MCP client MUST support OAuth 2 authentication.

The plephora of weak restatements of OAuth 2 spec, arbitrary domain name restrictions and extensive examples only muddy the waters without adding anything to MCP security beyound what a faithful OAuth 2  implementation would.",24,2025-04-08 02:34:18,voronaam
programming,1jtr45e,mlyy15z,"Has anyone looked at MCP, specifically the underlying protocol? They are incredibly simple. Like dumb simple. It's not made for this, it's made for very simple, very controlled situations.",9,2025-04-08 02:27:06,deadwisdom
programming,1jtr45e,mlyfj41,">  What Can You Do?

Not use MCP?",14,2025-04-08 00:34:07,chat-lu
programming,1jtr45e,mm0626f,My first reaction to the AI boom was considering a career change into security research.,5,2025-04-08 08:50:52,hejj
programming,1jjjcuq,mjpzhgd,"Seems a bit overblown. The attack vector is ~~when the admission controller loads the payload from the ingress resource in the cluster~~ to the admission controller via internal cluster networking. This means it only works on multi-tenant clusters with untrusted tenants. This has got to be a pretty rare architecture. My company uses kubernetes heavily, but only employees have access to create ingress resources in the cluster, and they can already execute code anyway.",54,2025-03-25 20:50:13,thabc
programming,1jjjcuq,mjr4n63,Well this was certainly an interesting read. What's cool is how recent it was discovered and how quickly it's been patched. I wonder what the stress levels were like on that nginx dev team.,3,2025-03-26 00:25:02,DoingItForEli
programming,1jjjcuq,mjqspkr,There was one in Tomcat just the other day as well. Basic OWASP shit.  What's going on out there? You guys okay? Somebody wake up Rip Van Winkle and let him code?,2,2025-03-25 23:19:55,bwainfweeze
programming,1k2uy82,mny0y1q,"This is a very interesting tool. I usually try to make sure that my programs do not carry any exclusive information in color, but so far I haven't verified that for example the contrast would still be high enough.",47,2025-04-19 16:00:39,dravonk
programming,1k2uy82,mnxvhui,Why is the Readme so poorly written? ,40,2025-04-19 15:32:11,WackoDesperado2055
programming,1k2uy82,mnz4bcj,"[Here is a dramatically better discussion on color blindness](http://www.daltonize.org/)

[And here is how little code it takes to convert RGB color to something a colorblind person can see](https://miko.art/labs/Color-Vision/Javascript/Color.Vision.Daltonize.js)

[Also simulation code](https://miko.art/labs/Color-Vision/Javascript/Color.Vision.Simulate.js)",9,2025-04-19 19:29:48,Craiggles-
programming,1k2uy82,mo3hn1m,"Dumping code out in the open before the CCP gets their hands on it?

God I can't wait for Ubishit to finally die.",-4,2025-04-20 14:37:51,cake-day-on-feb-29
programming,1jyxu3p,mn1xa6c,Sometimes the cost of not deciding or taking too long to make the call is higher than the cost of making the wrong decision.,311,2025-04-14 12:48:13,One_Economist_3761
programming,1jyxu3p,mn24fst,"I feel like the one thing this post is missing is that not only is it okay to be wrong, it's also okay to change your mind on a decision.

There obviously may be a cost associated with switching tack but this can still be desirable over no decision / action.",186,2025-04-14 13:32:11,nicholashairs
programming,1jyxu3p,mn235cx,"Maybe when you are not able to commit to a solution as a senior engineer is because of lack of context. 

I don't think the proposed solution of faking confidence  is the correct approach.

What I would propose to do is to organize two small POCs with focus points, collect data and evaluate both solutions. At the end of the day engineering is not about options but hard data.",58,2025-04-14 13:24:30,AlphaFarmer42
programming,1jyxu3p,mn2hp2m,"I think most experienced engineers will (imo, wisely) avoid committing to things they don't have enough control over.

It's not even about being wrong or right, it's about avoiding the possibility of getting thrown under the bus and being blamed for the consequences of things you couldn't have foreseen.

PMs and management are frequently looking for ways to shed accountability if they don't meet their goals, don't willingly be their stooge. Remember, even if you put your skin in the game for them and succeed, they will still get most of the credit for it regardless.",53,2025-04-14 14:44:34,SanityAsymptote
programming,1jyxu3p,mn27g9h,"Just `git commit -m ""My update""` bro, it takes 2 seconds.",76,2025-04-14 13:49:38,poop-machine
programming,1jyxu3p,mn3xtwp,"Why does the kicked dog cower? Because it fears the boot is coming again.

If your senior and staff and whatever the fuck you're calling them this week engineers are remaining noncommittal, look into why. You'll probably find a management culture that is, at best, indifferent to suggestions from engineering, and more than likely actively hostile to them.

I worked at a company once where there was a big debate over a piece of technology to use. There were largely two camps, the engineers that had been with the company for a long time (call them Tech A), and then some of the engineers and managers that were brought in more recently (Tech B). There was a promise of an open discussion regarding this technology, both sides made their arguments, and then there was a ""closed meeting"" where the choice was made. Only the new manager and a few of the new engineers, who supported Tech B, were invited to the closed meeting. Unsurprisingly, they went with Tech B. This told all the old engineers exactly what we needed to hear, which was that input wasn't valued and organizational bullshit would rule the day. So most of them stopped providing complex feedback, and soon the attrition started, with a slow but steady exodus of older, knowledgeable engineers.

I check back on that company from time to time, and find they _still_ haven't managed to implement Tech B, despite the fact that Tech A had a working demo that could have been productionized in 6 months.",18,2025-04-14 19:03:51,Paradox
programming,1jyxu3p,mn373w0,"This piece is written by someone who has never been on a team that functions properly. Using ""institutional power"" AKA seniority to facilitate your opinion? Weakest-but-loudest engineers making decisions on the entire team's behalf? Pretending to be confident when you're only 60% certain? That's dysfunction junction right there.

True cowardice is refusing to accept that you are part of, and a contributor to, this dysfunction.",21,2025-04-14 16:52:35,IanAKemp
programming,1jyxu3p,mn2ovn4,"I think committing to technical solutions and committing to estimates/deadlines are two entirely different things.

I find it fairly easy to commit to a solution.  Most of the time, any of several choices will work, they just have advantages and disadvantages.  You pick one that you think you can best live with and make it work.  Usually it works out, and if it doesn't, you decide if you want to spend the effort to change it.  Even if you ""fail"", you end up learning something.

IMO there's usually nothing to learn from a ""failed"" estimate.  You just have to deal with a bunch of stressed out people who wanted something to happen sooner.",11,2025-04-14 15:21:12,EntroperZero
programming,1jyxu3p,mn38gvz,">managers do not typically think “wow, I’m glad this person is being so careful and accurate”. They think “ugh, why are you forcing me to make the decision myself?”

Here's a manager that's going to require absolute heaps of ""managing up.""

He believes that for any given question there is always an apparent answer, that someone on his team will know enough to make that decision correctly, that person will be able to identify themselves as the one on the team who should be owning that decision, and it's just a personality flaw that they're not answering with the confidence of ChatGPT.

Yet, he simultaneously does not know how to gather enough information from the team with which to gain that ""55% or 60%"" confidence himself.

This is the kind of ""manager"" that expects their senior engineers to do all the actual management because it's nerd shit. He'll just play hall-monitor in between taking credit in front of middle management.",9,2025-04-14 16:59:13,old-toad9684
programming,1jyxu3p,mn20mj5,I seem to disagree with almost every line of this article,34,2025-04-14 13:09:10,Huberuuu
programming,1jlkqcy,mk6x5yu,This is wild. Running Go on a PS2 is such a cool mix of retro tech and modern language. Makes you wonder what other “obsolete” systems could be brought back to life with today’s tools. Super fun read,42,2025-03-28 14:43:52,tomasartuso
programming,1jlkqcy,mk4jqkn,Wow this is awesome work ! Good job !,30,2025-03-28 03:17:13,HolaSoyCara
programming,1jlkqcy,mk5piv4,That is very very cool. mad props.,8,2025-03-28 09:48:04,The_0bserver
programming,1jlkqcy,mk4jjmx,This is so cool! Great work,11,2025-03-28 03:15:58,sorokya
programming,1jlkqcy,mk5hoof,This is cool btw,5,2025-03-28 08:22:12,devloperfrom_AUS
programming,1jlkqcy,mk6w431,Way cool! Thanks for sharing,4,2025-03-28 14:38:31,MediumRareInnards
programming,1jlkqcy,mk5arbs,People are awesome,7,2025-03-28 07:06:20,ikarius3
programming,1jlkqcy,mk4jssj,[deleted],-4,2025-03-28 03:17:37,N/A
programming,1jlkqcy,mk6zxw9,"Super cool, thanks for sharing!",2,2025-03-28 14:57:35,sonbn812
programming,1jlkqcy,mk9u18r,Go golang!,1,2025-03-28 23:32:32,goranlu
programming,1jqodtw,ml9r0n7,"Pleasently surprised that it sticks to the proven UI and does not use the vscode/electron style without menubar, padded buttons and monochrome icons.  
Other people will probably say it looks old (not “modern”).  
To me np++ has peak UI design, and the fact that it has been around for so long in this form, while other editors have waxed and waned (e.g. sublime), tells me I must be at least partially right. Thrilled to get a cross-platform version as I moved to mostly Linux because of the seemingly unstoppable enshittification of Windows.",135,2025-04-03 21:22:50,3dGrabber
programming,1jqodtw,mla2nlh,"I hope this goes well. I have since jumped ship to BBedit on MacOS, about 5 years ago since no notepad++ on macOS. Hopefully this thing gets stable and gets supper over time. It’d be rad if it grows into its own.",11,2025-04-03 22:27:37,this_knee
programming,1jqodtw,ml9hawa,Why does NP++ need to be re-implemented?,37,2025-04-03 20:33:51,zimboptoo
programming,1jqodtw,mlamjga,"Suggestion: Please add hover hint on icons at the tab bar.

Thank you I have been waiting for this all my life <3",5,2025-04-04 00:25:28,silencer07
programming,1jqodtw,mlbzdt8,Personally I prefer VSCODE de’s approach but still use Notepad++ because of some text manipulation plugins and macro recording that aren’t as good on VSC. Also useful for files that are a little too big for VSC.,4,2025-04-04 06:16:41,heavy-minium
programming,1jqodtw,mlfapsj,I feel like an opportunity to call this Notepad# was missed,4,2025-04-04 19:21:41,chicknfly
programming,1jqodtw,mlaka07,"Well, I gotta check It out. Notepad++ is my main editor for some programming languages.",3,2025-04-04 00:11:28,ricardo_sdl
programming,1jqodtw,mlal9hw,That's a quick git clone. Thanks for bringing this to my attention!,1,2025-04-04 00:17:36,Prudent-Elevator-123
programming,1jqodtw,mldnbzk,"Neat! Though I hope ""re-implementation"" doesn't mean they're not gonna fix some of NP++'s weaknesses (no vertical tabs...)",1,2025-04-04 14:23:24,terablast
programming,1jqodtw,mledsls,"Yes, Yes, Yeeessss!!!",1,2025-04-04 16:35:54,thekennysan
programming,1jm3tc2,mk96gy5,"“We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. Don’t let yourself be lulled into inaction.”

Bill Gates",340,2025-03-28 21:23:39,somkoala
programming,1jm3tc2,mk8ofvr,what is dead (inside) may never die,253,2025-03-28 19:52:50,Twistytexan
programming,1jm3tc2,mk91cbc,"> Just have a look at Linkedin job postings to get an idea of what is expected from junior developers. They are required to be novices, but at the same time have the tool belt and experience of a developer already working for years.

There was once a recruiting company that published data analysis results of their worker placement in the tech industry. One of their findings was that a successful job applicant should match on average 50% of the posted job requirements to land the job.

They sadly went out of business a few years ago. I can only imagine this metric deteriorated even further down - with the posted job requirements becoming a universal ""wish lists"" copy-pasted between Staff Embedded C++ Electric Engineer Automation role and Junior Summer Coop (Full Stack) roles.",66,2025-03-28 20:56:57,voronaam
programming,1jm3tc2,mk9yvwb,"I'm not really losing any sleep over an AI doing my actual job anytime in the foreseeable future. What I do is pretty damn niche with a ton nuance. Training someone on the basics is pretty easy, but actually being able to navigate the gray areas (especially in regards to international governance and laws around the shit) is incredibly difficult to really learn without years of time actually doing it - never mind trying to train an algorithm to handle it (though plenty of groups are out there trying... and fortunately for me, failing pretty hard).

What does keep me up, though, is the idea that one of those same groups might manage to convince my leadership into believing their shitty AI solution can handle what I do. And then some executive, dazzled by a flashy demo and a slightly lower price tag compared to my team, signs off on it, resulting in a bunch of us getting the axe.

So no, AI isn't going to replace me. But some douchebag techbro peddling glorified vaporware might just *eliminate* my job by convincing people who don’t know any better that it’s “good enough.""

Honestly, I think that’s what’s happening in most of these AI job replacements. It’s not that the AI is actually doing the work - it’s that leadership cuts people, throws some crappy tool at whoever’s left, and tells them to make do.",80,2025-03-28 23:59:54,absentmindedjwc
programming,1jm3tc2,mk8x7rt,"Good news, we are not dying. We are going to live forever!",43,2025-03-28 20:36:15,nattack
programming,1jm3tc2,mk9edq6,"> This could also be read as ""are the stake holders capable of instructing a LLM accurately with their wishes for the latter to really understand what they mean in order to let them know what is feasible or not and how to utilize it?"". I don't think so.

They hate us cuz they ain't us",16,2025-03-28 22:06:01,ForeverHall0ween
programming,1jm3tc2,mkaefx5,It'll die or it won't.  Let's just keep writing code while we can.,6,2025-03-29 01:31:41,longshot
programming,1jm3tc2,mkb0egt,"What is most unfortunate is there are marketing and executive folks out there who are actively trying to put people out of jobs acting in bad faith. Once this AI crap turns into production disaster SWE should ask 3x the last base pay to fix all of it. Also that crap is not even close to doing anything useful in real world engineering problems, I'm just going to enjoy the hysteria and the aftermath of AI layoffs, SWEs are going to make a bank after the disaster. 


I'm just sick of these vibe coding clowns they can't fix a simple syntax error if their life depended on it. ",10,2025-03-29 03:55:04,Scary-Mode-387
programming,1jm3tc2,mk90i3r,Based on the assumption that what is not possible today will not be possible tomorrow ,25,2025-03-28 20:52:45,avacadoplant
programming,1jm3tc2,mkcje0h,"Junior SWE are getting screwed here, but seniors are going to make bank with the way the software landscape is evolving.

AI has already reached a plateau, and we're not going to see any major improvements until the next breakthrough. No-code has also reached a plateau, in terms of profitability for the user.

When you really think about it : no-code is basically a paid programming language with a nice UI. It runs on hardware, most often in the cloud. That cloud service is usually just fly or heroku that ends up paying Amazon or Google for their servers. Every one in the chain is in to make a margin. Compare that with running your actual code on bare metal, and it's night and day. Once people realize that, it's a whole subject matter into ""reducing costs"" cause nobody wants to pay 1,000$ a month for a shitty app they think they can code in a day.

AI is the same. Everything runs at a loss right now. Once the actual price of using AI hits, you'll compare price / performance to an actual engineer and settle on the engineer. The highest paid ChatGPT plan is 200$ a month, and it's not even close to the actual final price of the AI. When you factor in energy costs, land, hardware (GPUs most likely), infrastructure for the datacenters and networking, the final price should be at least 10-20 times that.",3,2025-03-29 12:49:01,Dogeek
programming,1ju1f1g,mlynvxq,"Before git, I used SVN. It wasn’t fun.",140,2025-04-08 01:25:01,watabby
programming,1ju1f1g,mlzkwqs,I love how git is both indispensable to our industry and yet confounding enough that seasoned veterans sometimes wind up in bad places with it. You’d think we’d have something friendlier by now.,52,2025-04-08 05:16:34,auximines_minotaur
programming,1ju1f1g,mlynafs,still not enough to learn properly,49,2025-04-08 01:21:24,SltLt
programming,1ju1f1g,mlz69j3,"Last Thursday, I used git bisect run to find a regression while I went out and got a burrito.

I like git.",27,2025-04-08 03:21:10,Weshmek
programming,1ju1f1g,mlzjrkt,Kids.  I used Panvalet from Panshophic in the early 1980s.  It was that or store the program backups in punch cards.  At least we skipped paper tape!,9,2025-04-08 05:06:31,johnpmayer
programming,1ju1f1g,mm1dzg9,"Git kind of won.

Even then, I am not the biggest fan of it. I am not sure how a better system should look like, but git feels clunky to use all the time.",4,2025-04-08 14:19:48,shevy-java
programming,1ju1f1g,mlzq0j8,"My use tends to be simple enough with the odd rebase or two.

Hasn't failed me yet.",2,2025-04-08 06:04:15,YesIAmRightWing
programming,1ju1f1g,mm3819y,Perforce :(,2,2025-04-08 19:43:15,Snwspeckle
programming,1ju1f1g,mlzt3k8,Git can be annoying at times (mostly because people don’t know how to use it) but I will take got any day of the week over 10 devs using VSS,2,2025-04-08 06:32:43,Wiltix
programming,1ju1f1g,mm001wr,shit I missed git-day by 5 days,1,2025-04-08 07:43:23,realblobii
programming,1js8gqz,mlky1tt,This was a wild read! Well written and sounds like fun.,30,2025-04-05 18:53:47,njacklin
programming,1js8gqz,mlmvjte,Website is down…,4,2025-04-06 01:56:06,amestrianphilosopher
programming,1js8gqz,mlou8ab,"Amazing achievemnt! It was exciting when Corellium managed to get it working, but in the end nothing public came out of it.",4,2025-04-06 12:28:47,moridinbg
programming,1js8gqz,mlo9aib,Really nice,1,2025-04-06 09:04:17,Aalexander_Y
programming,1js8gqz,mlqx4cs,"""Forward every call to a server, executing them and returning the result""  
What the fuck is this black magic fuckery?",1,2025-04-06 19:32:22,Omnidirectional-Rage
programming,1js8gqz,mlshwef,Legend!,1,2025-04-07 01:02:21,sonbn812
programming,1js8gqz,mlmawyg,"wow! just wow, excellent write-up",1,2025-04-05 23:41:28,sumwheresumtime
programming,1jsnn5b,mlo20h4,"Two years into managing role. These are good advices, a starting point that you must adapt to your specific scenario. E.g., strategy and vision often depend on external factors, priorities may suddenly change (for whatever reason, like tariffs...).
Also, you not only have to take care of each team member, but also the team as a whole, the relationships between team members, more or less like a psychologist doing team therapy.
That's my short experience,  my two cents of course. ",47,2025-04-06 07:45:48,NoHopeNoLifeJustPain
programming,1jsnn5b,mlnupa2,"I'd boil it down to:

- Wants to lead
- Has an idea about what sort of leader they want to be

Leadership at the junior level can mean taking responsibility for a task, even if the individual isn't capable of completing the task themselves - e.g. bringing the right people together, pairing with more senior team members, seeking help.

Management roles on the other hand require a different set of planning and organisational skills, along with lived experience of various scenarios, charisma, common sense, and specific knowledge of how large companies (HR, Project, Product, QA, Architects, etc.) function.

I mean to say, any one can lead if they want to, but you rarely see a junior manager, because such people usually lack the experience to properly navigate the corporate world.

/thoughts",88,2025-04-06 06:33:37,Markavian
programming,1jsnn5b,mlp89bg,"One key skill I've found absolutely crucial for engineering leaders, yet often overlooked, is the ability to effectively document and transfer knowledge.

I've seen so many brilliant engineers fail in leadership roles because they never developed a system for capturing and sharing institutional knowledge. When they're promoted, all their technical wisdom stays locked in their heads.

The best engineering leaders I've worked with weren't necessarily the most technically proficient, but they excelled at:

1. Creating clear architectural decision records that explained not just what was decided, but why
2. Building knowledge graphs that connected different systems and components
3. Establishing documentation practices that the team actually followed
4. Using diagrams and visual explanations alongside code

These practices not only improved their own leadership capabilities but created a multiplier effect on their teams' productivity. Engineers spent less time rediscovering solutions and more time building new things.

As AI tools become more prominent in development workflows, this ability to structure and document knowledge becomes even more valuable - the leaders who can effectively capture context will get much better results from these tools.",10,2025-04-06 14:03:38,traderprof
programming,1jsnn5b,mlouuiz,"Managing client expectations, protect your team. This is leadership, not management. Managing is not leadership. Vastly different things.

That's about it. 

The client could be a customer, your marketing department, or a higher level of executive. The key is to understand what their expectations really are. You might need to bring their expectations down to earth, or you might need to prioritize certain aspects to meet them. For example, a marketing department wants things to be cool, look cool, act cool, etc. They don't care that you used technology X or Y. Yet, some customers might care to the point of this being a showstopper. Thus, understanding all the clients and how to meet their expectations. Some people use the BS term ""stakeholders"" but that crap term can end up encompassing so many people that suddenly the janitorial staff are somehow on the steering committee. Some people might say accounting is a stakeholder because of the budget. But that is not a stakeholder, that is a constraint.

Protecting your people is a very broad term. Often keeping them away from the predations of executives, etc is a big job, but some of the best leaders I've seen were happy to go to war with HR just to keep them from asking their people to fill out stupid forms for the new medical plan; a giant and usually avoidable waste of time. Protecting your people from the nattering nabobs of negativity or the downright assh*les, is very important. But a massive thing a leader can do is to keep anyone who thinks they are a manager with the right to treat ""their people"" like infants. Great leaders fire this sort of toxic nightmare in a heartbeat.

The best companies I've seen in terms of profitability per employee, low turnover, and productivity of employees only had a few people leading many teams and few if any people with a title which was manager or translated to manager. 

The proper place for managers is t focus on any required process; leaders focus on keeping people focusing on realizing a vision. There is a massive difference. There are products where a process is essential, and maybe even regulatorily required. This where you have managers managing the process, but not people. This is where leaders have their work cut out as they now need to hover over the process managers with a shotgun making sure they aren't diverting resources to their own stupid needs, as opposed to working with people to produce a great product which also happens to have followed a process, vs doing a process which they don't overly care if the product meets client expectations beyond meeting a regulatory requirement; or some internal process cooked up by a manager to justify their existance. 


An OK leader will protect their people from as much manager style BS as possible, but some companies have terrible toxic cultures where there are plenty of manager walking around generating BS meetings, and BS reports, and an OK leader will mitigate this as much as possible. A great leader will annaliate this. A near pure example of the pinnical of toxic management culture is when a company has agile coaches.

TLDR; management and leadership are not the same thing; and managers who don't understand this, but put into leadership roles, are a cancer.",7,2025-04-06 12:33:35,LessonStudio
programming,1jsnn5b,mloyndf,"\> Because leadership isn’t about code. It’s about people. And that means you need a different set of skills.

You don't need a blog article to point out this abundantly obvious fact.",3,2025-04-06 13:01:34,Greenphantom77
programming,1jsnn5b,mlnwrdq,"Company-sponsored lobotomy, if it's most managers i've known.",26,2025-04-06 06:52:57,dethb0y
programming,1jsnn5b,mlot943,"For a moment the headline looked like ""I asked an engineering manager how prompt engineers can prompt for leadership roles""",2,2025-04-06 12:21:01,Worth_Trust_3825
programming,1jsnn5b,mlq26xu,"Just read Management 3.0 by Jurgen Appelo, it's the only management book you'll ever need.",1,2025-04-06 16:48:31,eagee
programming,1jsnn5b,mltctw9,"I really don’t like the very common ”leader equals manager” assumption. I don’t ever eant to be a manager as I never want to be forced to judge people in money but I sure as hell am a leader in my team (and to some extent department and company), with compassion, experience, principles, interest and candor. I could probably be a better leader, as it’s not really an explicit choice, so I try to stay humble and listen to the people around me (and some pods).",1,2025-04-07 04:42:32,mirvnillith
programming,1jsnn5b,mlxslbc,Learn how to pass the buck and over/under estimate deadlines. Scope creep is a handy tool to stick developers with too in your leadership role. Favor the people that feed you the most bullshit and scorn the ones that actually own-up to their responsibilities.,1,2025-04-07 22:19:47,fliption
programming,1jo66p4,mkpuiso,Quantum computing is so hard to read about. That shit is in the Stone Age and every article is always hyping it up like it’s about to become the new computing standard,167,2025-03-31 17:25:59,eightysixmonkeys
programming,1jo66p4,mkpb54p,42.,168,2025-03-31 15:49:26,jericho
programming,1jo66p4,mkr1xdw,"There have been hardware random number generators for ages, usually using something like background radiation measurements to generate them",19,2025-03-31 21:00:55,olearyboy
programming,1jo66p4,mkpmxjx,"I thought quantum-based random number generators for a while?  For example, based on shot noise in electronic diodes.  Or you could use decay of a radioactive isotope for this (e.g. the spacing of the noise from a geiger counter).  Is it the certification aspect that's novel here?",37,2025-03-31 16:48:23,Deto
programming,1jo66p4,mkpizoz,"Talk is cheap, show me the code",14,2025-03-31 16:28:26,anonymous-red-it
programming,1jo66p4,mkphxnu,"It's really a philosophical question as much as a physics one, isn't it? Is anything that happens in conventional, Newtonian/relativistic space truly deterministic? And if so, is what happens in the quantum space truly non-deterministic?

Of course, in regards to practical, cryptographic purposes, the answer is: it doesn't matter. Even if dice are deterministic, no attacker has the ability to parse all the specific conditions that go into determining its result. It *is* random. God already knows your password and He doesn't need to reverse-engineer your secret key.",21,2025-03-31 16:23:05,vomitHatSteve
programming,1jo66p4,mkqfn9v,Still no better than a coin flip but we'll get there!,3,2025-03-31 19:10:24,LoadCapacity
programming,1jo66p4,mkrctmd,At last. 4.,3,2025-03-31 21:58:49,msnshame
programming,1jo66p4,mkru9mw,tapping into the quantum realm just to get some rando number lol.,3,2025-03-31 23:38:14,david_nixon
programming,1jo66p4,mkpkj01,"> The result was a number so random, no amount of physics could have predicted it.

This is probably just watered down science journalism glossing over complexity, but if not… suck it determinism.",14,2025-03-31 16:36:15,CanvasFanatic
programming,1jkdiku,mjuxhn4,I had to (and still have) use next.js app router on cloudflare pages (edge runtime). It’s the worst experience I’ve ever had in my career and I had to work on multiple 20+ years old codebases…,96,2025-03-26 16:39:45,Parachuteee
programming,1jkdiku,mjugp70,"Honestly, first time seeing the concept of ""adapters"" for hosting platforms. Sounds a lot like something user for shared hosting of PHP, circa 20 years ago.

Next.js can spit out standalone build. You can host that yourself, you can pack it in a docker container and give to majority of cloud hosting providers.

Is it serverless edge computed on your router? No. Can you scale those in response to traffic spikes? In my experience, yes.",65,2025-03-26 15:17:14,slvrsmth
programming,1jkdiku,mjxoyq9,"Unrelated, but that website is fucking awesome - genuinely one of the most unique good frontends i ever saws.",13,2025-03-27 00:55:44,RedstoneEnjoyer
programming,1jkdiku,mjxfv1f,NextJS is a Trojan Horse.,15,2025-03-27 00:04:22,theQuandary
programming,1jkdiku,mjw2k79,"> The official React documentation, which the Next.js team help maintain, says that Next.js can be deployed to «any serverless hosting», but there is no official documentation whatsoever for this.

Not surprising that Vercel would poison React once they got their grubby hands on official recommendation

Shame on the React team for allowing this, while gaslighting the community that all is fine",38,2025-03-26 19:57:15,drink_with_me_to_day
programming,1jkdiku,mjw414c,So what should you use instead?,13,2025-03-26 20:04:16,cedear
programming,1jkdiku,mjyp7aa,"Used nextjs for the first time last year, deployed it to self managed server, and it was a horrible experience (for me). Plus, the over engineered framework stuff that requires referring to the docs every time and slow DX when switching routes really threw me off. I built the entire website anyway in nextjs, but regretted the decision.
I don't need this level of complexity and friction to lear a framework built by a for-profit company when literally n number of alternatives are available.",4,2025-03-27 04:55:39,paramvik
programming,1jkdiku,mjzq27t,"Good read, thanks for sharing.  Have some tech debt to replace the stack for a recently ejected CRA; this and their handling of this security incident will be good information to add to that issue so that we make a more informed choice.  I'm in the camp of not using a framework until we need one, baby steps.",2,2025-03-27 11:09:07,Educational-Ant-173
programming,1jkdiku,mjx1ktz,"Why is this article formatted using latex or some other spacing mechanism that makes it absolutely treacherous to read?

```
My     job      involves
```
No. Absolutely not.",4,2025-03-26 22:47:40,7heWafer
programming,1jkdiku,mk0kpy5,"Really good read, especially for folks who are thinking of jumping into Next.js without fully understanding the trade-offs. I’ve seen a lot of devs treat Next.js as the ""default"" choice without realizing how much is abstracted under the hood — which can be a problem once you need to debug or scale.

I appreciate how the article breaks down the magic and points out what you’re really committing to. Curious to hear if anyone here has run into real-world pain points from not knowing these things upfront?",1,2025-03-27 14:21:37,tomasartuso
programming,1jwjw7b,mmjj9s7,"> Honestly, basing a framework decision solely on a startup time difference of less than even `1 500 ms` is likely overthinking it for most applications

*cue Casey Muratori's VS rant*",93,2025-04-11 10:56:39,ShinyHappyREM
programming,1jwjw7b,mmj4wly,"I think the non-uniform rendering engine would be a nightmare to deal with. Not only different engines (chromium vs safari vs webkit), but also different versions of the same engine.",81,2025-04-11 08:33:50,Programmdude
programming,1jwjw7b,mmjzgz4,Are you really sure that the memory consumed by the webview is showing up under same process and not elsewhere?,16,2025-04-11 12:51:37,petereteq
programming,1jwjw7b,mmk7wt4,"There's a stack of benchmarks that they included a link to which suggest *higher* memory usage for Tauri compared to electron.

Not only does this not make sense, but it contradicts the article's claims-- which make me wonder why they included it or whether their claims are accurate.",10,2025-04-11 13:40:45,Coffee_Ops
programming,1jwjw7b,mmj2ztu,For I second I thought it was r/Stargate and I was confused by the title.,22,2025-04-11 08:13:06,pur3pwnage
programming,1jwjw7b,mmjctyj,"If you are targeting only one and the latest OS then Tauri is fine, else Electron is less trouble for the developers.",14,2025-04-11 09:57:30,AKMarshall
programming,1jwjw7b,mmmmqn5,"At the end of the [Startup time](https://gethopp.app/blog/tauri-vs-electron#startup-time) section it says:

> For more detailed benchmark data across frameworks, check out the [Web to Desktop Framework Comparison repository](https://github.com/Elanis/web-to-desktop-framework-comparison?ref=hopp#benchmarks).

So I clicked that link, and scrolled down to [the startup times table](https://github.com/Elanis/web-to-desktop-framework-comparison?tab=readme-ov-file#start-duration). And... and empty Tauri app, build in release mode, takes 25 seconds to start on Linux?

This can't be right...",3,2025-04-11 20:54:58,somebodddy
programming,1jwjw7b,mmlt5d6,"So you guys are building an ultra low latency screen sharing service and then choose a web technology? Just why 😭 why is everyone obsessed with using web for native applications, it just sucks. Pretty sure the memory usage on windows will be much higher. Ms Teams has plenty of these WebView2 instances that hog memory like crazy",7,2025-04-11 18:24:06,emdeka87
programming,1jwjw7b,mmjfmx0,568% more segmentation fault errors in runtime and 1% probability that your binary which depends on this f\*king os-native webview will launch on random machine (windows 7 - 0% probability),9,2025-04-11 10:24:30,vanbrosh
programming,1jwjw7b,mmnzqh5,"Why noone is talking about ""ToDesktop"" ?",1,2025-04-12 01:47:48,RealMadHouse
programming,1jqc8gy,ml6k0a0,"I've been using [uv](https://github.com/astral-sh/uv) for a while now which does this, nice to see a standard being pushed for all the other ways of managing python stuff.

uv is the only way of managing python projects that hasn't made me want to tear my hair out while screaming obscenities.",97,2025-04-03 11:17:18,Wolfy87
programming,1jqc8gy,ml5xx38,">Actual adoption remains open-ended

All the big tools have already said they'll either entirely switch to it or at least support it.",130,2025-04-03 07:37:47,SV-97
programming,1jqc8gy,ml6mxyp,"March 31, 2025: Python boldly steps forward into the early 2000s!",142,2025-04-03 11:39:50,Xyzzyzzyzzy
programming,1jqc8gy,ml67bgz,"Oh, neat, Python finally has a `Gemfile.lock`.",48,2025-04-03 09:19:18,slvrsmth
programming,1jqc8gy,ml871zt,Is this going to fix the fact that there are at least 14 different tools to work around python's global library nightmare?,7,2025-04-03 16:47:08,wildjokers
programming,1jqc8gy,ml75vc8,Definitely a good thing; python feels like a broken language with how dependency resolution works now.,13,2025-04-03 13:40:41,CVisionIsMyJam
programming,1jqc8gy,ml75pgu,Can only be a good thing. Python packages are a mess unless you use `uv`,7,2025-04-03 13:39:47,mr-figs
programming,1jqc8gy,ml881h2,"We moved to uv on all python projects, don't think about dep management and python versions anymore",3,2025-04-03 16:51:56,Yarden-zamir
programming,1jqc8gy,ml8695b,"Why is this called a lock file? I think of a lock file like the UNIX concept of a lock file, to indicate that a file is already opened by another task.

This doesn't appear to be that, it's a version control file. Is that right? Why is it a ""lock"" file?",6,2025-04-03 16:43:12,happyscrappy
programming,1jqc8gy,ml8607l,virtual environments and the entirely library install process is something where python is very far behind. Too many solutions none of them great.,2,2025-04-03 16:41:59,manzanita2
programming,1juufhv,mm5jg1v,I really enjoyed this video. Had no idea about any of that. I always just assumed it was a flat image.,46,2025-04-09 03:26:08,cheezballs
programming,1juufhv,mm5i2ws,"Nice short video.

IIRC Nintendo also used to do the same thing with the Gameboy Advance, but instead of a copyrighted logo it was the Nintendo trademark itself. That's why you knew that a GBA cart was going to fail to load when the Nintendo was missing. I believe it also went to court and lost.

More generally, the courts have consistently upheld that there is nothing illegal about playing an unlicensed game on a console because preventing it would be anti-competitive, and you can't use traps like this as a loophole.",31,2025-04-09 03:16:43,Isogash
programming,1juufhv,mm6eyts,The more I learn about the og PlayStation the more I’m impressed. It blows my mind that the creators of Crash (or was it Spyro?) had to use the game to “hack” the ps system to get more memory or something similar,8,2025-04-09 08:08:04,peppersrus
programming,1juufhv,mmapdja,"I enjoyed the video, but I think the title is misleading.  I wouldn’t call that hacking, that’s just fiddling.  It doesn’t really compare to serious hacks such as the old [ECDSA nonce reuse hack](https://www.youtube.com/watch?v=j6yU9z8mtRE) that allowed installing arbitrary firmware.",0,2025-04-09 23:04:58,ScottContini
programming,1jo59ba,mkp2kip,"Can't wait for this to be supported by all browsers, I had to reimplement the select element way too many times in order to accomodate design requirements",123,2025-03-31 15:06:12,Giannis4president
programming,1jo59ba,mkq1n5t,"Huzzah. Now we just need to wait for Firefox, which shouldn't be long, and also Safari, and then five years for older versions of Safari that don't receive renderer updates because they're not on the latest version of OS:X to slip out of use",54,2025-03-31 18:00:34,BellerophonM
programming,1jo59ba,mkp5l7o,Freaking finally.,41,2025-03-31 15:21:32,Raunhofer
programming,1jo59ba,mkpr3jd,Our long nightmare is finally over.,32,2025-03-31 17:09:12,CanvasFanatic
programming,1jo59ba,mkqw4lg,"this shit should have been default in all browsers 10 years ago

along with a good date picker, the browser provided one is still far too variable and inconsistent

i dread to think the carbon footprint of select2/choices/chosen",29,2025-03-31 20:32:02,Lewke
programming,1jo59ba,mkre6gu,"lol. “Just use standard web technologies.”

Browser UI has been in the dark ages since its creation, and has no intention of ever catching up.",11,2025-03-31 22:06:20,editor_of_the_beast
programming,1jo59ba,mkpba3j,Thank God. I can’t believe it took this long.,18,2025-03-31 15:50:08,jack0fsometrades
programming,1jo59ba,mkqu2vy,What about select multiple?,8,2025-03-31 20:21:52,Alive_Scratch_9538
programming,1jo59ba,mkrjp69,This is great! Now let's do date pickers...,9,2025-03-31 22:37:50,lurco_purgo
programming,1jo59ba,mkpsbv6,holy shit it is about time,6,2025-03-31 17:15:17,personman
programming,1jrlr8r,mljlx6c,"I'm trying to wrap my head around what they mean by ""native"". The article waffles a lot but I think they mean they wrote their own Python JIT interpreter?",41,2025-04-05 14:26:09,Supuhstar
programming,1jrlr8r,mlif46y,Ok.,11,2025-04-05 08:18:43,standing_artisan
programming,1jrlr8r,mlgc61o,Good,5,2025-04-04 22:44:58,WillemDaFo
programming,1jrlr8r,mlk7m7x,How is this different from Jax?,4,2025-04-05 16:28:19,AmbitiousTour
programming,1jrlr8r,mlipg1r,If only they put as much effort into their drivers as they do stuff like this.,7,2025-04-05 10:14:27,nekokattt
programming,1jw88ct,mmh77md,"Time to update this...

https://imgur.com/a/5VzAdep",191,2025-04-10 23:37:31,bakery2k
programming,1jw88ct,mmgo4m8,Kind of confusing that there's now both `string.Template` and `string.templatelib.Template`.,66,2025-04-10 21:49:26,roerd
programming,1jw88ct,mmggmiz,Will this be usefull for day to day f string users ?,21,2025-04-10 21:10:02,WERE_CAT
programming,1jw88ct,mmh93kg,"Why are Python users so illiterate?  Click the link, read the (short) motivation, it provides the reason for the PEP pretty clearly.

https://peps.python.org/pep-0750/#motivation",28,2025-04-10 23:48:44,Halkcyon
programming,1jw88ct,mmj0opb,I was mildly surprised that internationalization wasn't mentioned as one of the examples in the motivation section.,3,2025-04-11 07:48:31,mgedmin
programming,1jw88ct,mmgwau2,"TIMTOWTDI, famous Python principle after all.",13,2025-04-10 22:34:49,lood9phee2Ri
programming,1jw88ct,mmkuy5t,Kind of amusing that Python will manage to ship string templates before Java (https://openjdk.org/jeps/459). The design itself is very similar to what is now being considered by the OpenJDK devs for when they bring the feature back.,2,2025-04-11 15:36:03,Hueho
programming,1jw88ct,mmhrdc0,We've reinvented str.format(),3,2025-04-11 01:40:28,rlbond86
programming,1jw88ct,mmkxwd3,"The feature itself looks useful, but really feels like they could have come up with literally any other name for it",1,2025-04-11 15:50:19,sysop073
programming,1jw88ct,mmqsdhm,"The `_ = TemplateMessage` example I think shows why i wish they went with javascript style template tags. 


Maybe they could have found a comprise syntax that doesn't exclude adding other letters later. I guess this doesn't stop them from adding one later.",1,2025-04-12 15:10:59,looneysquash
programming,1jkya80,mk13u14,"My hot take is that if tags are mutable, then GitHub shouldn't even allow them to be used as a reference. The whole point to pinning a version is to make sure it can't change and break, which makes them unfit for purpose. That's before we even talk about security implications.

They also absolutely should not have any documentation that uses that as an example if it's insecure by default.",201,2025-03-27 15:55:17,xeio87
programming,1jkya80,mjzswyk,"Our org used tj-actions but had already started pinning SHAs prior to this incident.

In your org’s GitHub Action settings you can create an allow list for actions, including which ref tags are allowed.",51,2025-03-27 11:31:37,Sinisterly
programming,1jkya80,mjzsor9,"> If you specify a Git commit ID instead (e.g. `a5b3abf`), 

ofc nothing stopping them from pushing a tag named `a5b3abf` right?",51,2025-03-27 11:29:52,ben0x539
programming,1jkya80,mk0w1zh,"Note that the provided command will look at GitHub Actions not only in your own project, but also in other subdirectories, such as `node_modules`. To look only at the GitHub Actions in your own repo:

    find . -path './.github/workflows/*' -type f -name '*.yml' -print0 \
      | xargs -0 grep --no-filename ""uses:"" \
      | sed 's/\- uses:/uses:/g' \
      | tr '""' ' ' \
      | awk '{print $2}' \
      | sed 's/\r//g' \
      | sort \
      | uniq --count \
      | sort --numeric-sort

(That just changes the `find` path from `*/.github/workflows/*` to `./.github/workflows/*`.)",11,2025-03-27 15:17:33,doublecastle
programming,1jkya80,mjz3dpr,Submitted article mirror: https://archive.is/J2wUM,9,2025-03-27 07:17:20,throwaway16830261
programming,1jkya80,mk1vjz9,Interesting article. I always was concerned about GitHub secrets being read by actions.,7,2025-03-27 18:05:54,RedEyed__
programming,1k0mdpn,mnfbhad,"The worst part about reddit is that you can only upvote something once. 

Great write-up, it's easy to forget how little substance most programming related posts typically contain nowadays until you encounter something like this that reminds you what technical blog posts should look like. <3",41,2025-04-16 15:37:36,loptr
programming,1k0mdpn,mnfxjgr,"I believe the 6502 was the last CPU a human can fully understand. I sometimes write VCS 2600 programs just to reconnect to the machine.

Also: Hail the Omnissiah",28,2025-04-16 17:25:06,nsn
programming,1k0mdpn,mnfoqu5,Interesting read and felt like a time machine. Long time ago I was programming assembler on the C64 and it was always fun fiddeling with the stack or doing some self modification stuff (although always ugly to debug).,7,2025-04-16 16:43:18,Bontaku
programming,1k0mdpn,mnh2gw3,"Is still the most convincing behaviour, in my opinion (quite old at this point in time; almost nobody has computers like that anymore):

https://tenor.com/view/guaton-computadora-enojado-computer-rage-gif-14480338",1,2025-04-16 20:47:45,shevy-java
programming,1jxeinw,mmppg34,"Hey r/programming,

This post acts as an introduction to writing WebGL shaders. It starts by building a mental model for writing shaders and it then walks through how to create a flowing WebGL gradient effect from scratch.

It's a lengthy post that touches on many topics — gradient noise, interpolation, color mapping, and generally how to write fragment (pixel) shaders. I hope you like it!",27,2025-04-12 10:53:41,XLEX97
programming,1jxeinw,mmptkoh,"This is super interesting to me, I became a web developer but always wanted to explore things that involve graphics. I avoid it because I utterly suck at math, so I have a debt to myself to eventually become comfortable working with graphics.",9,2025-04-12 11:30:17,peperinus
programming,1jxeinw,mmqpw8a,Now this is actually a good article. Finally some good content on this sub.,5,2025-04-12 14:57:37,Hidden_driver
programming,1jxeinw,mmpr9ti,"Weirdly this is completely broken on mobile, known issue?",11,2025-04-12 11:10:20,JaggedMetalOs
programming,1jxeinw,mmq031a,Well made writeup and cool result!,3,2025-04-12 12:21:01,Jewelots
programming,1jxeinw,mmqwq5h,"Terrific write-up, thank you.",2,2025-04-12 15:34:22,civildisobedient
programming,1jxeinw,mmrbnc3,"Always had an interest in computer graphics and shaders, having a step-by-step breakthrough of what seems like a complex shader seems like a godsend! Thank you, will definitely check out the full article.",2,2025-04-12 16:52:02,Medafu
programming,1jxeinw,mmrmyr6,Amazing write up. Thank you!,2,2025-04-12 17:48:53,mattv8
programming,1jxeinw,mmul6xw,I don't upvote things often but this deserves it.,2,2025-04-13 04:54:01,grimtooth
programming,1jxeinw,mmve0ms,"Awesome site and great blogs, really liked your blogs.",2,2025-04-13 09:42:37,N/A
programming,1jpll84,ml21f3v,Oh very nice. Can't wait to see how all these improvements will improve KDE Plasma desktop even more.,17,2025-04-02 17:27:35,JRepin
programming,1jpll84,ml0kljp,"Still one of best C++ RAD tooling, alongside VCL/Firemonkey on C++ Builder.",28,2025-04-02 12:51:48,pjmlp
programming,1jpll84,ml04w11,Nice,81,2025-04-02 10:52:42,HansLuft778
programming,1jpll84,ml0f8xd,"""Improved Emoji-Handling""

I desperately need more variants of the poop emoji. It has brought so many new ideas for epic games substituting emojis for images!",24,2025-04-02 12:15:12,shevy-java
programming,1jpll84,ml0uzjl,that's cute,7,2025-04-02 13:56:09,Few-Understanding264
programming,1jop2wi,mktj5t2,"Source? Reference? Anything to show that this is real?


EDIT: pre coffee and assumed the sub was against april fools jokes, my bad!",217,2025-04-01 07:08:27,epos95
programming,1jop2wi,mkttddu,Will there be a proper DIN standardisation for this proposal? I'm willing to donate fax machines for achieving the most efficient communication between the members of the standardisation committee.,33,2025-04-01 09:05:36,RabbitDev
programming,1jop2wi,mku1fvw,There was an article last week about a new memory safe C++ standard. It is basically a subset of the full language that excludes dangerous features like raw pointers. Linus Torvalds is reportedly backing it as an alternative to Rust for new Linux kernel contributions as it's more familiar to all the existing C programmers who contribute patches.,18,2025-04-01 10:32:17,Silhouette
programming,1jop2wi,mku1qhf,You a**holes you got me! 🤣🤣,31,2025-04-01 10:35:08,jolly-crow
programming,1jop2wi,mktgp8z,[deleted],6,2025-04-01 06:41:43,N/A
programming,1jop2wi,mkujl3b,Who will enforce the usage of Seed7? I hear Europol is already quite swamped & with Trump going ballistic Interpol has other security concerns.,3,2025-04-01 12:52:39,Sairony
programming,1jop2wi,mku67g2,"ok, thank you for this joke! :)",3,2025-04-01 11:15:25,tehnic
programming,1jop2wi,mkubh6r,"Demanding the standarized use of a programming language across the industry is the most European Union thing possible so I'm going to believe it's true

EDIT: Ah, damn it. You got me",3,2025-04-01 11:56:53,MileiMePioloABeluche
programming,1jop2wi,mkufc8t,It was hard choice between brain fuck and seed7,3,2025-04-01 12:24:14,hk19921992
programming,1jop2wi,mktiaw7,"Its good they are thinking about this.

But I wonder for lighter stuff will Python and JS need replacements? Can they be replaced?",2,2025-04-01 06:59:02,ProdigySorcerer
programming,1jzujux,mn964km,"I'll be honest, the most surprising part to me is that, apparently, a huge amount of people can even use these tools. I work at BigNameCompanyTM and 90% of the things I do simply cannot be done with LLMs, good or bad. If I just hook up one these tools is some codebase and ask to do something it will just spill nonsense

This ""tool"" that the blog is an ad for, it just crudly tries to guess what type of project it is, but it doesn't even include C/C++! Not only that but it it's unclear what it does with dependencies, how can this possibly work if my dependencies are not public?",191,2025-04-15 16:09:53,teerre
programming,1jzujux,mn8yyh4,"AI gives you quantity, not necessarily quality. Still need a solid dev process.",74,2025-04-15 15:34:10,isaiahassad
programming,1jzujux,mn9b5xp,the ai-generated image slop detracts from your article.,111,2025-04-15 16:35:02,PurpleYoshiEgg
programming,1jzujux,mn9fwpa,"The number of people calling out AI... While saying people use AI with out reviewing, testing or understanding the code depresses me. 

But the same thing was true when people worked and just copied and pasted Stack Overflow code without testing it...  There IS a solution. 

If someone at your company tries to check in AI code which doesn't work, you should treat that as if someone checked in code that is broken, they essentially shouldn't be employees in the long term.  It's one thing if they do this on a specific change, or there's a rush to get the code in, but if the code doesn't work in a direct test... what test did they run?  

If you use AI to generate the code or stack overflow or pound on the keyboard... it doesn't matter, you as a developer are the one with the name on that code, not the AI. 

Basically 90 percent of the problems people have (poorly written code, non working code) isn't a AI problem necessarily, it's a developer problem who accepts that code.    Hallucinations do happen but at that point you'll realize after a quick compile/google.  

I'll continue to use AI because when I have to write a function, 90 percent of the function works, and usually I write a system design to AI that makes it understand WHAT I want to do, WHY I want to do it, and HOW I expect to do it.    It's faster to generate that code at that point, and review it.  There's actual productivity there, and besides having a system design is a good thing.",19,2025-04-15 16:58:16,Kinglink
programming,1jzujux,mn92p0g,"AI flat out lies in a confident manner, and when caught admits it and lies again. It itself admits it doesn’t know if its lieing but generates a probable answer, has the ability to check itself but doesn’t, and requests the user to hold it accountable. But heres the problem - inexperienced or less knowledgeable persons are not capable of that.

AI also cheats at chess by making illegal moves and adding pieces when jt feels like it.",23,2025-04-15 15:52:34,StarkAndRobotic
programming,1jzujux,mn8w5ij,"After months of using AI coding assistants, I've noticed a concerning pattern: what seems like increased productivity often turns into technical debt and maintenance nightmares.



Key observations:

\- Quick wins now = harder maintenance later

\- AI generates ""working"" code that's hard to modify

\- Security implications of blindly trusting AI suggestions

\- Lack of context leads to architectural inconsistencies



According to Snyk's 2023 report, 56.4% of developers are finding security issues in AI suggestions, and Stack Overflow 2024 shows 45% of professionals rate AI tools as ""bad"" for complex tasks.



The article explores these challenges and why the current approach to AI-assisted development might be unsustainable. 



What's your experience with long-term maintenance of AI-generated code? Have you noticed similar patterns?",42,2025-04-15 15:20:11,traderprof
programming,1jzujux,mn8yjf9,"Another shit article, generated by Ai, about how bad AI is, posted on r/programming. Is this broadly all some kind of posts-ironic art piece?",35,2025-04-15 15:32:05,GregBahm
programming,1jzujux,mn95jxg,"I think it's fantastic for small snippets and to use as a rubber duck. For it to code for you use it to code is a no go. It's sort of like grammar checking in word, sometimes it's useful, but it's a tool. I tried to code something with power automate. It makes a table, close but unable to adjust it at all. Could I make it work, yeah probably but it's dogshit.",3,2025-04-15 16:06:54,Icy_Party954
programming,1jzujux,mn9g3kt,"No offense but one of these article gets posted once a day and this offers nothing new and nothing substantial. More slop.

Also, I don’t trust a report from 2023 about LLM code “vulnerabilities”. I’m not saying trust code automatically, but comparing models from 2023 to ones now is hilariously wrong. Gemini 2.5 is very good when used properly",13,2025-04-15 16:59:11,HaveCorg_WillCrusade
programming,1jzujux,mnbh2u2,I tried some ai-assisted coding for a while and did not like it.,3,2025-04-15 23:12:48,TheDevilsAdvokaat
programming,1k2rgwq,mnxocr5,Everyone loves a quine! Nice work.,28,2025-04-19 14:53:54,igorpk
programming,1k2rgwq,mnxkr6c,"Classic ""write a program that outputs its own code"" that replaces printf with CreateGif..",19,2025-04-19 14:34:17,Ateist
programming,1k2rgwq,mnwhuqd,wow that's cool,7,2025-04-19 09:38:49,FederalRace5393
programming,1k2rgwq,mo6ea8v,Ever heard of xpm?,1,2025-04-21 00:21:55,Foreign_Hand4619
programming,1k2rgwq,mo7s5rf,Love it!,1,2025-04-21 06:15:23,Kok_Nikol
programming,1k2rgwq,mo8n4ol,"Fucking hell 70 MB? You're aware that gif has a compression algorithm, right?",1,2025-04-21 11:27:28,araujoms
programming,1k2rgwq,moepcd2,So cute,-1,2025-04-22 10:32:09,Silly-Advertising826
programming,1k2rgwq,mnwcdhm,Haha awesome gotta love’s this one 😹,-24,2025-04-19 08:39:23,old-bot-ng
programming,1k2rgwq,mnxuvaa,That’s clever but not difficult.,-40,2025-04-19 15:28:54,postmaster3000
programming,1jz0azj,mn4tnha,"This is interesting to know, good find. I however rarely care for this kind of micro-optimization in Python. Not saying there is no merit to it, but I'd hope not to need them when I write Python. If something like this made a meaningful difference in my program, maybe I shouldn't be using Python. In this case, I'd generally favour `len` simply because it is more explicit and will error if the variable is `None` or something without length.",173,2025-04-14 21:47:29,jdehesa
programming,1jz0azj,mn4lvw7,"I always use ""if not list"" , even though I didn't know it's faster, for the simple reason that it is shorter to type. At the end of the day I am not using Python to write fast code but to write code fast. 

It makes sense though, that calling a function and then doing a comparison is slower than just doing a direct ""comparison"".

Although, if THAT is causing you performance issues, then you are probably using the wrong language for the task.",103,2025-04-14 21:05:37,Swoop3dp
programming,1jz0azj,mn5bsel,"I always see such comparisons and think ""who cares about the microseconds, it's python"", but just several days ago I needed to optimize a hot loop, in python! One of the things it did was comparing a var to ord('@'). A profiler showed it took 10%! Probably because it's a function call. I replaced it with a hard coded ascii val and a comment, ugly but saved me a couple of minutes per each run. ",24,2025-04-14 23:31:41,unaligned_access
programming,1jz0azj,mn4jous,Sane language standard libraries would have IsEmpty to guide programmers away from shooting themselves in the foot without having to know about language internals.,60,2025-04-14 20:54:17,FF3
programming,1jz0azj,mn79sra,"Before anybody blindly starts changing their code, be aware that `len(foo) == 0` and `not foo` are not equivilant expressions. Some list-like objects return true for the former and false for the latter.",5,2025-04-15 08:25:48,maep
programming,1jz0azj,mn6tozy,Makes sense to optimize the idiomatic way.,4,2025-04-15 05:37:22,oweiler
programming,1jz0azj,mn5c82y,"Except `if not list` is not the same. It works for `list = None`. It works for `list = False` and `list = True`. Hell, it works on any object. 

As to why you'd want an empty list to coerce to `False` is beyond me, but it is defined: https://docs.python.org/3/reference/datamodel.html#object.__bool__

But you're not testing the fact whether someone is actually passing in something that has `len()` method. 

So I'd block your PR based on trying to be smart by actually making the code more stupid, as now I need to go through much more mental gymnastics to figure out what the actual type is of whatever you're testing against.

Oh, and in case you're wondering: I'm a big proponent of types. I don't get why you'd want to develop without. And when you have that information you can get rid of so much cruft.",5,2025-04-14 23:34:10,AnnoyedVelociraptor
programming,1jz0azj,mn70khv,"I don't know why but Dive into Python told me so 20 years ago, thanks Dive into Python.",1,2025-04-15 06:46:07,ivenvd
programming,1jz0azj,mn8sr6e,Hate python. It’s the new Ruby ,1,2025-04-15 15:03:04,hopfield
programming,1jz0azj,mn8tewg,Good to know if you’re doing a metric ton of Len calls,1,2025-04-15 15:06:24,jeremiah15165
programming,1jrc228,mleallx,"If you are thinking of doing this project, please do yourself a favour a do the newer 6502 project first.

  
Its way more begginer friendly and a nice introduction before spending 100 hours assembling the 8 bit computer",59,2025-04-04 16:19:42,urielsalis
programming,1jrc228,mldn4lf,I highly recommend this project if you have a lot of spare time (half your time will be spent cutting and stripping wire and making everything neat). [I did it three times and made my own small improvements with each iteration.](https://austinmorlan.com/posts/8bit_breadboard/),18,2025-04-04 14:22:20,vertexmachina
programming,1jrc228,mldz3vp,If you wanna do this “virtually” check out “Turing Complete” on steam,7,2025-04-04 15:22:15,itsjase
programming,1jrc228,mlezbrb,"I've also heard good things about this course:
[NAND2TETRIS](https://www.coursera.org/learn/nand2tetris2)",4,2025-04-04 18:23:07,Br3ttl3y
programming,1jrc228,mldwi8l,"Yep, Ben Eater's great.",5,2025-04-04 15:09:17,khedoros
programming,1jrc228,mleagf4,"Love it, but fuck that. XD

My fingers are just too stubby to enjoy breadboard work.",2,2025-04-04 16:18:59,a_printer_daemon
programming,1jrc228,mlfbywp,"You can implement this with Logisim if you're looking for a way to achieve this without the kit. It won't necessarily run super fast if you try and run long programs, but it will teach you the logic fundamentals.

I started with the ben eater video PC and ended up slowly upgrading it into a 6502-lite:

https://imgur.com/a/wbF5j57",2,2025-04-04 19:28:15,TheKrumpet
programming,1jrc228,mlfpccb,"First thing I thought was, has OP seen Ben Eater's stuff?

Oh, then I followed the link. :)",2,2025-04-04 20:37:01,greebo42
programming,1jrc228,mlicnq0,"Brings back memories. Growing up in Yugoslavia in 80s, building your own computer was a way to have one. Importing was forbidden, so one guy (Voja Antonić) came up with the idea to build one from scratch (Galaksija), write an OS for it and publish schemas and code in a computer magazine. He expected that maybe 100 will be built in the whole country, but the initial number reached over 10000 and people are still building it for fun.",1,2025-04-05 07:51:52,drvobradi
programming,1jrc228,mllfdul,"or install logisim-evolution which is free and simulate your CPU way faster and easier.
 
you are not limited by wires and the ICs you buy and you can do 16 or even 32 bits, you can do a single cycle CPU up to a superscalar out of order CPU",1,2025-04-05 20:32:19,takethispie
programming,1k4hg9j,mobfrhs,"Awesome, did a ELI5 video on that topic awhile ago [https://youtu.be/zsB-8v9LC7w](https://youtu.be/zsB-8v9LC7w)",34,2025-04-21 20:37:55,hougaard
programming,1k4hg9j,mobr853,Here is the repo: [https://github.com/LukasNiessen/oauth-explained](https://github.com/LukasNiessen/oauth-explained),11,2025-04-21 21:35:48,trolleid
programming,1k4hg9j,modteh6,"**Question:** *Why not just send the access token in step 6?*

redirect\_uri is very important. It's used in step 6

The markdown numbering is broken, there is no step 6",8,2025-04-22 05:06:55,One-Blueberry73531
programming,1k4hg9j,mobyskq,"Here is a talk I gave that you might find educational.

https://youtu.be/r0BCki3U2AM?si=UiY4EJwKNHKJHiNz",3,2025-04-21 22:16:59,NotMyself
programming,1k4hg9j,moe1tx5,"How does LinkedIn know that the one\_time\_code that Google replied with belongs to me and not say, someone else halfway around the world doing the same thing?",3,2025-04-22 06:24:46,Zahand
programming,1k4hg9j,modjhb1,AI generated?,8,2025-04-22 03:51:18,dmitrysvd
programming,1k4hg9j,momomer,Great writeup. [This]( https://stack-auth.com/blog/oauth-from-first-principles) is another blog post that can help understand why it is designed this way.,2,2025-04-23 16:10:01,nyctrainsplant
programming,1k4hg9j,momysrs,"I also wrote a guide on OIDC if you're interested :-)  
[https://github.com/LukasNiessen/oidc-explained](https://github.com/LukasNiessen/oidc-explained)",1,2025-04-23 16:59:19,trolleid
programming,1k4hg9j,moehxa9,"> Note: So OAuth solves an authorization problem! Not an authentication problem. See [here][ref1] for the difference.

It's the other way around, OAuth handles authentication, not authorization",-1,2025-04-22 09:17:11,Rinkin-
programming,1k4hg9j,mobim6z,"LOL, no one understands how OAuth2 works.

Remember, it was designed by a committee of big tech companies to be incredibly complicated so they could sell it as a service. This is why the lead author of OAuth1 and an early OAuth2 spec lead left the project.",-25,2025-04-21 20:51:49,wildjokers
programming,1jr2vdc,mlcot5n,Wow what a hot take. Nobody has thought this before.,157,2025-04-04 10:35:57,Kenji776
programming,1jr2vdc,mlcwjex,"""The abacus is the original ALU""",37,2025-04-04 11:39:18,GeneReddit123
programming,1jr2vdc,mlek6x8,"Oh, really? /s",3,2025-04-04 17:07:55,RedEyed__
programming,1jqg3d4,ml7kcq7,"How long did the process of engineering take for this solution, and how big of a team was involved?

This reminds me of some problems I've worked with, and the frustration all around of trying to fit this into Jira XD (half kidding, sounds like a lot of experimentation was involved)",32,2025-04-03 14:55:23,kreiggers
programming,1jqg3d4,ml7x9w5,"I believe virtualized rendering is an example of the more general [flyweight pattern](https://refactoring.guru/design-patterns/flyweight) - you're not creating and rendering all the elements, just a minor subset and recycling that subset with different properties each time, so that you don't have to create, update and destroy elements each time they go out of view.",19,2025-04-03 15:58:41,GimmickNG
programming,1jqg3d4,ml6modt,"**\[ Disclaimer - I’m an engineer at SigNoz \]**  
  
If you’ve ever tried rendering a million `<div>` elements in a browser, you know what happens, everything freezes, crashes, or becomes completely unusable. This was the same challenge we were faced with when we started to build visualisation of traces with million spans in SigNoz.I’ve detailed all my findings and wisdom in a blog, which broadly covers,

* Smart span sampling
* Virtualized rendering
* Lazy loading and chunked data fetch
* Browser memory optimizations

All built with performance in mind, so engineers can analyze massive traces with confidence.Give this blog a read and let me know if you’d do anything differently!",68,2025-04-03 11:37:52,vikrant-gupta
programming,1jqg3d4,ml82ytz,"This is one thing that I was surprised to see how poorly AWS manages. X-Ray tracing is really easy to integrate with if you're already in the AWS ecosystem. But if you have a large amount of segments/subsegments on your traces, the UI just chokes. Loading the exact same trace in Grafana is often much smoother.",8,2025-04-03 16:26:57,FlinchMaster
programming,1jqg3d4,ml6op5a,I thought you were talking about `Span` from C#,38,2025-04-03 11:52:29,SureConsiderMyDick
programming,1jqg3d4,ml7x1bj,"Having a native virtual list element has been one of the longer waits. I remember close to 10 years ago using Polymer's iron-list and we're still nowhere closer to having native. I mean hell, we're just now starting to get the ability to style `<select>` options so maybe it's asking to much.",6,2025-04-03 15:57:30,shawncplus
programming,1jqg3d4,ml6r65n,Hey i have been following signoz for some time now. It feels like an amazing tool for Otel observability. The UI is also nice. Its interesting to know that you guys are using clickhouse under the hood. Have you ever considered using rust instead of golang. Want to know if you faced any challenges with golang at scale. Since I keep hearing about companies moving from go to rust because of gc,4,2025-04-03 12:09:58,RoXyyChan
programming,1jqg3d4,mlbkg6d,"Amazing work u/vikrant-gupta , the idea to limit the data sent from backend with the offsets is interesting. How do you handle if the user searches for a span which is outside of this limit? Based on my understanding, this would take some time to load it right?",2,2025-04-04 04:09:13,confucius-24
programming,1jqg3d4,mlgdalg,This article makes me feel old.,2,2025-04-04 22:51:43,macca321
programming,1jqg3d4,mlhsa6t,"Cool article but there is one small, tiny issue: the browser can definitely handle 1 million spans without serious problems, just a small delay in rendering.  Just don't use react for it, react would have terrible problems due to the virtual DOM.

/pedant mode, sorry",2,2025-04-05 04:39:06,SirPurebe
programming,1jrlv3y,mlftrir,">That said, most high-level languages (JS, Java, C#, …) capture variables by reference:

Java captures all variables by value. Under the hood, the values are simply copied to the fields of the lambda object.

So how does it avoid having the following code behave non-intuitively (translated from the article)?

    var byReference = 0;
    Runnable func = () => System.out.println(byReference);
    byReference = 1;
    func.run();

It's actually very simple: the code above will not compile. To stop people from incorrectly assuming variables are captured by reference, it simply bans the situation where it makes a difference, i.e. captured variables cannot be reassigned.

If you want to be able to reassign, you just need to create a separate final variable for capturing:

    var byReference = 0;
    var byValue = byReference; // <---
    Runnable func = () => System.out.println(byValue);
    byReference = 1;
    func.run();
    // prints 0 obviously

If you want to emulate capturing by reference, use some mutable box thing, like Mutables from Apache Commons, or a 1-element array. Both options are obviously ugly:

    var byReference = new int[]{0};
    Runnable func = () => System.out.println(byReference[0]);
    byReference[0] = 1;
    func.run();
    // prints 1",63,2025-04-04 20:59:58,vytah
programming,1jrlv3y,mlftpss,"I came in with finger on the downvote button for another low-quality ""`0 == '0'` lol"" post...and it's actually pretty interesting, as a Typescript dev. I've been bitten before in the wild by the string length one.",57,2025-04-04 20:59:43,annoyed_freelancer
programming,1jrlv3y,mlgci8l,"Nice collection of language design blunders...

However, the Unicode-related gotchas are not really on JS but much more on Unicode. As a matter of fact, the approach JS took to implement Unicode is still one of the saner ones.

Ideally, when manipulating strings, you'd want to use a fixed-length encoding so string operations don't need to scan the string from the beginning but can be implemented using array indexing, which is way faster. However, using UTF32, i.e. 4 bytes for representing a code point is pretty wasteful, especially if you just want to encode ordinary text. 64k characters should be just enough for that.

IIRC, at the time JS was designed, it looked like that way. So, probably it was a valid design choice to use 2 bytes per character. All that insanity with surrogate pairs, astral planes and emojis came later.

Now we have to deal with this discrepancy of treating a variable-length encoding (UTF16) as fixed-length in some cases, but I'd say, that would be still tolerable.

What's intolerable is the unpredictable concept of display characters, grapheme clusters, etc.

This is just madness. Obscure, non-text-related symbols, emojis with different skin tones and shit like that don't belong in a text encoding standard.

Unicode's been trying to solve problems it shouldn't and now it's FUBAR, a complete mess that won't be implemented correctly and consistently ever.",23,2025-04-04 22:47:01,adamsdotnet
programming,1jrlv3y,mlmedi4,"    for (let i = 0; i < 3; i++) {
      setTimeout(() => {
        console.log(i);
      }, 1000 * i);
    }
    // prints ""0 1 2""

Are we forgetting our history? This works because it is a `let` declaration, which is block-scoped. `var` declarations will screw this up, because they are function-scoped. But the distinction between `var` and `let` isn't mentioned in the article, so it feels like the real logic here is being glossed over.

Though, it is admittedly a little arbitrary that the `()`s after `for` are ""inside"" the block scope. But very useful in practice!",4,2025-04-06 00:03:11,Booty_Bumping
programming,1jrlv3y,mllnnur,"In .NET it's actually little bit different/complicated.

This:

```csharp
using System;
using System.Collections.Generic;

var byReference = 0;
Action func = () => Console.WriteLine(byReference);
byReference = 1;
func();
```

returns `1` - as the article says.

```csharp
using System;
using System.Collections.Generic;

var list = new List<Action>();

for (int i = 0; i < 3; i++){
	list.Add(() => Console.WriteLine(i));
}

list[0]();

```

this returns `3` - as the article says.


But this:

```csharp
using System;
using System.Collections.Generic;

var actions = new List<Action>();
int[] numbers = { 1, 2, 3 };

// same code but just with foreach
foreach (var number in numbers)
{
    actions.Add(() => Console.WriteLine(number));
}

actions[0]();
```

This prints `1` - suprise!!!


This was explicitly changed in .NET 5 - https://ericlippert.com/2009/11/12/closing-over-the-loop-variable-considered-harmful-part-one/.

So in a way this is similar fix as the one used in javascrips.


### For loops 

I actually tought that in .NET 5 they fixed this problem for both `for loops` and `foreach loops`. But to my suprise they didn't. I guess you learn something new even after years of writing using the same language.

The good news is that for the first two problems my IDE (Rider) shows hint ""Captured variable is modified in the outer scope"" so you know you are doning something weird.",3,2025-04-05 21:19:22,melchy23
programming,1jrlv3y,mllugqw,Are sparse arrays really that bad for perf? I remember trying to test it a while ago and it wasnt that bad.,2,2025-04-05 21:59:58,username-must-be-bet
programming,1jrlv3y,mliby2v,"I honestly think the `eval` thing is pretty reasonable. It lets new code opt into a less powerful, safer, more optimizable form of `eval` (see [""Never use direct eval()!"" on MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/eval#never_use_direct_eval!)) without breaking existing code written with `eval`.",3,2025-04-05 07:44:04,190n
programming,1jrlv3y,mlkwvhn,Nice post!,1,2025-04-05 18:47:08,bunglegrind1
programming,1jrlv3y,mlg431d,one of the silliest things i've found is indexing into a number like 1\[0\] is undefined in javascript. I am not sure what chain of casting or whatnot causes this to happen (and not e.g. throw an error...),-7,2025-04-04 21:56:54,bzbub2
programming,1jrlv3y,mlgs5fe,"The behavior of variable scope in for loop makes perfect sense.

`document.all` need to be scrubbed from the standard

`;` should be mandatory, no ASI  
`NaN === NaN` should be `true`  
`typeof null` should be `""null""`",-16,2025-04-05 00:23:19,Blue_Moon_Lake
programming,1jxxdnz,mmu0fx0,Pfft.  The writer means just at first.  Here I thought I finally had figured out how to retire.,160,2025-04-13 02:20:15,FF3
programming,1jxxdnz,mmu4uzr,"> solve your administrative burdens—domain name, certificates, billing—when it’s easy. When there’s no pressure. Your stakeholders aren’t pressuring you to ship because it’s been no time at all.

The core idea of this article seems to be build a solid foundation first as its much easier to start with a solid foundation as opposed to trying to solidify there foundation layer, which I fully agree with.

That said, the reality of a lot of big tech companies is that for most projects there’s never no pressure. There’s always some stakeholder who wants results yesterday and shipping a blank website and talking about all the under the hood problems you’ve solved won’t appease them. Most developers don’t skip these foundational steps by choice. They skip them because they aren’t given the time to do them.",133,2025-04-13 02:50:30,Drugba
programming,1jxxdnz,mmudfio,"Article is getting some hate but we kind of do this any time we spin up a new service: get a hello world working in prod ASAP, then start shipping functionality. 

Nothing worse than being “feature complete” but having to deal with a bunch of bullshit to get to prod. Also, you can just have one resource tasked with doing the hello world and move people over once it’s up.",40,2025-04-13 03:52:35,lupercalpainting
programming,1jxxdnz,mmwa18a,"Had a colleague — let's call him J — who had… his own opinions on how to do things. He iterated fast, so management was impressed, and they _wanted_ quick results, so they didn't appreciate other developers like me warning them of the end results.

He made lots of bizarre snap decisions. One day, he wanted to rewrite the whole thing in PHP, arguing he could iterate even faster that way. He even registered a website with what he thought the product's branding _should_ be, and deployed a PHP-based implementation there, without management's consent or knowledge. He used it to pressure management into accepting his approach. Now, if you're a PHP shop, go ahead and use PHP. But we're largely a .NET shop, so if you were to ask me, that's a terrible idea — most of the devs can't maintain the result. Well, J _did_ ask, and I told him as much. So he went to the boss to complain.

They compromised, without consulting anyone else, on using the then-new .NET Core 1.1. The argument was that this was ""a lot less enterprise-y"" than .NET Framework. OK.

Anyway, weeks later, it came time to ship. J proudly announced he was ready! …and left for vacation. I guess nobody had told him to either publish the app himself, or at least give someone instructions on how to do so. But management had been promised that it's ready, right? So they went to us and asked. We spent the evening trying to deploy an app targeting a frankly immature toolchain in production. Three people at 9 PM frantically trying to get it working on an IIS that had heretofore never heard of ASP.NET Core, while we all also wanted to go home. None of us had much experience with .NET Core yet, because we were busy enough keeping _everything else_ running.

He was ultimately fired not long after. But his code base remained, and someone else was left to maintain it, full of byzantine decisions, and of course shortcuts, as, guess what, he had run out of time by rewriting it _twice_ (from .NET Framework to PHP, then from PHP to .NET Core). No code review, little knowledge of design decisions, just a bunch of stuff on your desk with ""_you_ figure it out"".

Oh, and the product ultimately failed. This wasn't really his fault, certainly not entirely, though his costly decisions of course did hurt the economic calculus.

Which brings me to the article. Leave aside J's attitude, his egocentric approach to decision-making, management's eagerness to trust him because what he was selling sounded really good on paper; what ultimately remains is that, had he instead started with a _much_ simpler product and then tried, just once tried, to deploy it on a real web server, we could've _iterated_ instead. Maybe even continuously reviewed the code he was writing. And _then_ what would've been the cherry on top would've been (enough) paying customers once the product had reached some maturity.

Real artists ship.",8,2025-04-13 13:59:19,chucker23n
programming,1jxxdnz,mmu76d5,"I think the author may be under-estimating the degree to which product requirements inform infrastructure decisions. Sure, some things you can always get to work on, like setting up your cloud account and domain, but there's only so much platform setup you can do before business logic starts calling the shots.",23,2025-04-13 03:06:32,tolerablepartridge
programming,1jxxdnz,mmwnhlt,"Related: run some A/A tests before you do any A/B testing. If they perform differently, then there are bugs in your testing infrastructure.",5,2025-04-13 15:12:38,sciolizer
programming,1jxxdnz,mmvvo6x,"This is something that I realized recently. I worked on a large project where we built all the software out before figuring out deployment and had a ton of integration issues. For our next iteration, I built a ""hello world"" app with all the IaC and CI/CD set up, then built the actual application and it was much smoother.",4,2025-04-13 12:25:42,itijara
programming,1jxxdnz,mmynrm0,"Obligatory: https://github.com/kelseyhightower/nocode

>No code is the best way to write secure and reliable applications. Write nothing; deploy nowhere.",2,2025-04-13 21:33:52,vytah
programming,1jxxdnz,mmx5gwq,This is clickbait trash nonsense.  Make a dumb headline then use the article to walk it back.  Classic bait.,3,2025-04-13 16:46:51,VictoryMotel
programming,1jxxdnz,mmub9p1,"That’s not going to work out in many cases. You should have a plan to iterate over your software features and about building/ testing/ deploying the product. You develop all aspects at the same pace. You should define a clear vision on how and where you would like to test, how you would like to build and where you will be running in the end and possibly in between.
consider it as part of your development routine to improve a bit in every aspect each sprint. Have a story from every aspect of the development process in your sprint and solve it (!)",3,2025-04-13 03:36:21,asciimo71
programming,1k0jmww,mnejwhs,I often use Godbolt. He's got a pretty interesting surname ngl.,40,2025-04-16 13:14:20,DataBaeBee
programming,1k0jmww,mnepwkk,Recommend this read https://people.freebsd.org/~lstewart/articles/cpumemory.pdf,32,2025-04-16 13:48:35,Sefrys_NO
programming,1k0jmww,mneraiy,"I didnt watch all of the video, but one of the most eye-opening exercises in the Algorithms class I took in college was about CPU cache strides and branch prediction. 

In essence there was the same algorithm implemented two different ways: evaluating a certain 2-D recurrence relation in a dynamic programming table, meaning I needed to compute the entries of a 2-D array A[i][j]. One implementation was a nested for-loop: ""i"" outside and ""j"" inside, and the other was the reverse. The first method was about 10x faster, even though it was literally the same calculation. It blew my mind.",34,2025-04-16 13:56:05,cant_read_captchas
programming,1k0jmww,mnf8qdi,It’s the man himself! His compiler tool is one of the coolest webapps I’ve ever seen!,13,2025-04-16 15:24:05,flying-sheep
programming,1k0jmww,mng71at,"I love that he introduced the `llvm-mca` tool in this talk. It's a neat way to make what is normally a hard to see, seemingly theoretical concept (pipelining) much more concrete, especially when trying it on real code! I was going to give a presentation on it at work, actually.

The only downside is that it relies on the scheduling models for a given processor to be committed to the public `llvm` repository. For example, using `llvm-mca` on my M1 Mac isn't necessarily guaranteed to give accurate results AFAIK, because it [uses the scheduling model for the Apple Cyclone microarchitecture](https://github.com/llvm/llvm-project/blob/6ccc9280ba891bbea349c12a064bf23bdf9000e7/llvm/lib/Target/AArch64/AArch64Processors.td#L1254).

Presumably the real scheduling information for the M architectures are committed in Apple's internal fork of `llvm`?",6,2025-04-16 18:10:04,SereneCalathea
programming,1k0jmww,mnjjpoe,"I highly recommend Computer, Enhance! to anyone that’s interested in learning more about how the CPU actually runs the code we write.",3,2025-04-17 06:23:08,Ashken
programming,1k0jmww,mnijslc,I agree. this was one of our first CS courses tho.,3,2025-04-17 01:52:42,AmeliaBuns
programming,1k0jmww,mnep1e2,"Good talk, thanks for sharing! I didn't know about the stride predictions caches make.",5,2025-04-16 13:43:48,qq123q
programming,1k0jmww,mneifvk,"TLDR: Not all programmers have a comp sci degree that taught the basics of computing, and yet we still often call those same programmers 'software engineers', why?",-38,2025-04-16 13:05:56,church-rosser
programming,1k0jmww,mnegqvg,"""Every programmer""? Don't think so.",-25,2025-04-16 12:56:33,gofl-zimbard-37
programming,1jy3qb0,mmvvsc8,"""Business people can just draw UML diagrams of the system and generate software from it"". ;)",290,2025-04-13 12:26:33,Pharisaeus
programming,1jy3qb0,mmvrkro,"I used an AI to generate a config file for me but I told it exactly what I wanted in the prompt and I still had to clean some stuff up. So can an AI write something if you have a good idea of what you need already? Maybe. But it's that ""knowing what you need"" part that is tricky.",77,2025-04-13 11:53:47,LainIwakura
programming,1jy3qb0,mmvyigv,"[https://www.cs.utexas.edu/\~EWD/transcriptions/EWD06xx/EWD667.html](https://www.cs.utexas.edu/~EWD/transcriptions/EWD06xx/EWD667.html)

seems appropriate. 

if ceebs reading the whole thing this exert kinda describes it all

""In order to make machines significantly easier to use, it has been proposed (to try) to design machines that we could instruct in our native tongues. this would, admittedly, make the machines much more complicated, but, it was argued, by letting the machine carry a larger share of the burden, life would become easier for us. It sounds sensible provided you blame the obligation to use a formal symbolism as the source of your difficulties. But is the argument valid? I doubt.""

For me that's what AI feels like. I already can write code, anything else trying to reach natural language only hinders my ability to deliver. 

I understand how this maybe amazing for those that can't, but realistically, since AI isn't there, they'll still need to learn to actually code, which is only the beginning of the journey as well, after they learn to code, then they must learn to express themselves well.

Just like when we learn to talk its not the end of the journey.",35,2025-04-13 12:46:32,YesIAmRightWing
programming,1jy3qb0,mmvit5s,We tried NoCode some odd 20 years ago. Didn't replace a single programmer.,69,2025-04-13 10:33:21,Vectorial1024
programming,1jy3qb0,mmw12kg,"I think natural language is not a good language for specifying behavior of complex systems. If it was, we wouldn't need maths to describe the laws of physics for example. So, I don't think LLMs will replace programmers. Natural language is the problem, not the solution.",35,2025-04-13 13:04:18,Accomplished_Yard636
programming,1jy3qb0,mmwdxna,If someone would just invent some way of specifying the exact logic to the AI then we could finally go NoCode!,5,2025-04-13 14:21:32,DrunkSurgeon420
programming,1jy3qb0,mn03lk3,I don’t find these discussions very gratifying. People pretending it’s way more useful or way less useful than it is with little nuance.,3,2025-04-14 02:57:44,RICHUNCLEPENNYBAGS
programming,1jy3qb0,mn0kd6k,CEOs will be replaced by AI before they replace programmers it seems.,3,2025-04-14 05:12:04,zayelion
programming,1jy3qb0,mmvzy7y,How exactly is this a paradox?,7,2025-04-13 12:56:38,phillipcarter2
programming,1jy3qb0,mn1qpom,"No one with a brain is surprised LLMs can't program well. They lack the ability to work with a project over a long period of time, interact with it to see if its behavior matches their goals, and then refine their goals when the goal itself is the issue.

The fundamental misunderstanding here is that people who don't know how to design something don't understand what's required to make something. They just complain, and if they have money they hire competent people and then constantly interrupt their work with their complaining. These idiots think the complaining is what gets the job done, and it's not. That's why they see LLMs as free labor.",1,2025-04-14 12:03:18,Sabotaber
programming,1k2b0d7,mntaqe6,"I want to know what someone thinks about \*maintaining\* a project with 60k lines of lua.  Writing it is the easy part IME, maintaining is the hard part.",224,2025-04-18 19:51:13,CitationNeededBadly
programming,1k2b0d7,mnu8l9n,World of Warcraft says Hi,36,2025-04-18 22:59:01,NoleMercy05
programming,1k2b0d7,mnwg4e9,"> Those functional vibes were quite surprising to me. I can illustrate it with something like this:

>     local pref = item_struct.node_tree[""item_prefab/root""] and ""item_prefab"" or ""group_prefab""

> [caption: With syntactic sugar aka “Haskell vibes”]

As far as i can tell this is neither syntactic sugar nor ""Haskell vibes"": 

1. The ""sugar"" seems to be just that they spell the logical `and` and `or` as `and` and `or` rather than `&&` and `||`?
1. You can pull the same kind of stunt with `and`/`or` in any language with truthy values, like Python, but Haskell will actually require you to only provide arguments of type `Bool` to `and` and `or`; `pref` would wind up holding just a boolean value.
1. To look haskellian, it  would rather be something like `local pref = if item_struct.node_tree[""item_prefab/root""] then ""item prefab"" else ""group_prefab""`, i.e. just using an if expression the way they'd use the ternary expression in C++.",23,2025-04-19 09:19:52,syklemil
programming,1k2b0d7,mnwcg9g,"I work a lot with Lua code and I do quite like it, but dynamic typing is definitely both a blessing and a curse.

I've personally found that the code has gotten much more maintainable since we started adding more [LuaLS annotations](https://luals.github.io/wiki/annotations/) to it. It makes you less likely to misuse functions and it's especially helpful when working with ""classes"" and other table objects.",12,2025-04-19 08:40:12,LordofNarwhals
programming,1k2b0d7,mnt71ep,"I'm more interested in what you think of Defold.
I tried my hand at it a while back and it seemed pretty great but I had no ideas at the time so never really went any further than pong haha",8,2025-04-18 19:31:25,mr-figs
programming,1k2b0d7,mnu6je1,"Been using Lua for years, easily my favourite language without fail, I wish it was used more",19,2025-04-18 22:46:44,Limp_Day_6012
programming,1k2b0d7,mny2bbs,"Even though Lua has it's quirks, I quite enjoyed working with it. It has a really nice combination of low complexity in the design and implementation, many possibilities and still quite a nice readability.

Since Lua 5.2 the ""global by default"" issue which can be problematic for larger programs can fortunately be solved by a single line:

    local _ENV = nil",4,2025-04-19 16:07:56,dravonk
programming,1k2b0d7,mo1701c,"OP: Great question thanks for asking

OP: No problem

I'm not judging, I too pretend people ask me questions I got tired of waiting for someone to ask me.",1,2025-04-20 02:53:43,grady_vuckovic
programming,1k2b0d7,mo7tr09,"This ""article"" seems like a mix of incoherent, AI slop, and bad jokes. Look at this paragraph for example:

> After that, I went back to Dmitry and asked him if my understanding of “everything is a table” was correct and, if so, why Lua was designed this way. Dmitry told me that Lua was created at the Pontifical Catholic University of Rio de Janeiro and that it was acceptable for Pontifical Catholic Universities to design programming languages this way.

Wtf? So he asked why and he got ""it was created at a place"" and then he *accepted that answer*?",1,2025-04-21 06:31:55,kankyo
programming,1k2b0d7,mnwkj8l,fuck languages with dynamic typing,-1,2025-04-19 10:07:12,obetu5432
programming,1k2rz06,mnx7ayy,That's beautiful!,16,2025-04-19 13:14:02,loptr
programming,1k2rz06,mnxjdk3,"My goodness! I wrote some graphics and programming language code in 1980's, but not in the same program. Doing this in that era Basic is even more impressive.",12,2025-04-19 14:26:40,hoijarvi
programming,1k2rz06,mnxkqon,nice ! how long did it take you to write ?,10,2025-04-19 14:34:12,naruto--420
programming,1k2rz06,mnxqln4,I loved programming on my Acorn BBC B. Inline assembler was just the cherry on the cake.,4,2025-04-19 15:06:03,ziplock9000
programming,1k2rz06,mnxsn30,"Remember those days well. Did an O Level in computing while in lower 6th form (yr 12 in modern years). One large and five small projects. I did each in a different language, because there was nothing saying you couldn’t.

So much wish I had the large project still, but lost to the years.

Great project OP, and I’m especially jealous that you still have it",3,2025-04-19 15:17:01,jodonoghue
programming,1k2rz06,mnxvmqj,Wow you created control flow graphs in BASIC!,5,2025-04-19 15:32:54,S2kDriver
programming,1k2rz06,mnzr080,"In '86 or '87 I wrote a program in Apple Pascal on Apple II hardware that used turtle graphics to generate bar, line or pie graphs for my high school senior project. It had keyboard routines so you could enter some number of points (I forget how many, I think up to 10) and labels for those points.


The entire system only had about 24K of RAM to work with, so I had to swap everything, including the keyboard routines, out to the floppy disk. Every time you hit a key, you'd see the floppy light blink briefly. I also had to do the pie graph one on a separate floppy because the whole thing plus the Pascal environment wouldn't fit on one.


It might sound trivial today but it remains one of my favorite projects for how much I was able to squeeze out of the environment at the time. If I'd had an Apple assembly environment available at the time, I might have tried to write it in that. I'd taken an assembly course a couple years earlier over the summer at one of my local universities. It was probably possible to cobble one together using pokes in BASIC but that was well beyond my capabilities at the time.",3,2025-04-19 21:36:35,FlyingRhenquest
programming,1k2rz06,mo15qf6,Very nice. I wish I still had all of my BBC Micro programs :(,2,2025-04-20 02:45:06,meowsqueak
programming,1k2rz06,mo2vr90,I do appreciate the fact that you recorded the sound; this is so lovely.,2,2025-04-20 12:17:40,heptadecagram
programming,1k2rz06,mo7susb,"This is truly beautiful, and impressive honestly.",2,2025-04-21 06:22:30,Kok_Nikol
programming,1jztbbv,mnae8ee,"Simple IIR filters commonly run slowly on Intel CPUs on default floating point settings, as their output decays into denormals, causing every sample processed to invoke a microcode assist.

On the Pentium 4, self-modifying code would result in the entire trace cache being flushed.

Reading from graphics memory mapped as write combining for streaming purposes results in very slow uncached reads.

The MASKMOVDQU masked write instruction is abnormally slow on some AMD CPUs, where with certain mask values it can take _thousands_ of cycles.",18,2025-04-15 19:48:25,ack_error
programming,1jztbbv,mn9dplm,Upvotes angrily.,29,2025-04-15 16:47:42,XEnItAnE_DSK_tPP
programming,1jztbbv,mnbcp8b,Reminds me of this: https://nrk.neocities.org/articles/cpu-vs-common-sense,8,2025-04-15 22:48:00,immaculate-emu
programming,1jztbbv,mnac7w4,"Here is a fun one.  Imagine a function that calculates the minimum and maximum values of an array.

     void range_array1(int* array, int count, int* low_out, int* high_out)
     {
         int low = array[0];
         int high = array[0];

         for (int i = 1; i < count; i++)
         {
             if (low > array[i])
                 low = array[i];

             if (high < array[i])
                 high = array[i];
         }

         *low_out = low;
         *high_out = high;
     }



This is all fine, but we can write an optimized version that handles two elements at a time.  This executes fewer instructions and takes a lot longer to run due to bad branch prediction.  \*Assuming the array is not sorted.

     void range_array2(int* array, int count, int* low_out, int* high_out)
     {
         int low = array[0];
         int high = array[0];
         int i = 1;

         for (; i + 1 < count; i += 2)
         {
             if (array[i] < array[i + 1])
             {
                 if (low > array[i])
                     low = array[i];

                 if (high < array[i + 1])
                     high = array[i + 1];
             }
             else
             {
                 if (low > array[i + 1])
                     low = array[i + 1];

                 if (high < array[i])
                     high = array[i];
             }
         }

         if (i < count)
         {
             if (low > array[i])
                 low = array[i];

             if (high < array[i])
                 high = array[i];
         }

         *low_out = low;
         *high_out = high;
     }",13,2025-04-15 19:38:24,mccoyn
programming,1jztbbv,mncn12n,"The [`RDSEED` instruction](https://www.felixcloutier.com/x86/rdseed) is a very slow instruction [on pretty much all x86 processors](https://uops.info/html-instr/RDSEED_R64.html), though I don't know whether that violates the rules.",3,2025-04-16 03:25:44,YumiYumiYumi
programming,1jztbbv,mn9wqrv,"Somewhat ironically, writing slow code can be harder than writing fast code these days because, as the article mentions, some hardware features will work against you. Though both objectives rely on the same (inverted) principles. 

This [book](https://csapp.cs.cmu.edu/) has some chapters which explore various aspects of software performance, and which delve further into some ideas discussed in the article. 

A small caveat is that the article focuses on CPI as a measure of software performance, which might be inaccurate. Having a lower CPI rate will not improve performance if it you also need to execute more CPU instructions to perform a given task. This metric is more often used to gauge the performance of CPUs, compilers, and combinations thereof.",6,2025-04-15 18:20:18,wake_from_the_dream
programming,1jztbbv,mna7ner,"- Another thing that may slow the CPU down is [false sharing](https://en.wikipedia.org/wiki/False_sharing), i.e. variables that are in the caches of several CPUs or CPU cores.
- Transferring data across devices, e.g. from main RAM to the GPU, is slower than accessing just main RAM.",4,2025-04-15 19:15:12,ShinyHappyREM
programming,1jztbbv,mnbt1pk,this fucking rules,1,2025-04-16 00:21:19,moreVCAs
programming,1jztbbv,mna5ulv,"this is an awesome blog post. 

I wonder if a slow code like this could be faster than fast Python/Ruby/JS code. Sure, you don't have many IPC, but they all do meaningful work.",0,2025-04-15 19:05:57,zanza19
programming,1jzyffc,mnaix3c,I see Raymond Chen… I upvote Raymond Chen.,58,2025-04-15 20:11:23,razialx
programming,1jzyffc,mnc8agd,"Back in the Windows NT 3.1/3.5 days I had an embedded system that was hanging every few days with moderate use. I could make it occur more quickly if I forced a lot of UI activity. 

The thing is we had a kernel-level watchdog timer that was supposed to pull the reset line if it wasn’t tickled every few minutes.  The system stayed happily running but frozen. Hmmmmm. 

Turned out a use-after-free condition was corrupting the UI thread list causing it to crash and completely hang. Non UI processes, including our kernel driver and tickler, were happily running thus no reset. 

It took us a LONG time to debug but we eventually got Microsoft to use a remote kernel debugger (from Redmond to Los Angeles) to look into the system and they figured out what was going on pretty quickly and issued us a patch. 

That was fun.",37,2025-04-16 01:52:08,lisnter
programming,1jzyffc,mne8zfk,"He references his own 22 year old blog post ""Why you should never suspend a thread"". What a legend",14,2025-04-16 12:08:24,DJTheLQ
programming,1jzyffc,mn9wefo,Ah yes the UI,-24,2025-04-15 18:18:36,websey
programming,1jzyffc,mnbthcs,An excellent case for Rust,-53,2025-04-16 00:23:51,IsleOfOne
programming,1k48mey,mo9txhp,Yeah Jsonb is the ultimate example that any specialized database will end up better implemented as a postgres feature or a postgres extension,55,2025-04-21 15:40:37,light24bulbs
programming,1k48mey,mobeyxe,Did a full text search implementation in Postgres and not only was it fast I got to keep an all my fun sequential stuff.  It’s pretty great,9,2025-04-21 20:34:02,s0ulbrother
programming,1k48mey,mo8igq6,https://martendb.io/ is a ORM and much more for .NET that uses this approach.,14,2025-04-21 10:47:54,Nisd
programming,1jy78sa,mmx644b,I really don’t find websockets to be that complex or difficult to use.,207,2025-04-13 16:50:10,shogun77777777
programming,1jy78sa,mmx42tr,"I completely agree that websockets are overused & introduce unneeded complexity throughout the entire stack. And yet I disagree with most of these points.

Websocket messages are indeed not transactional. Neither are messages over an http stream. Syncing state & operations between clients in real time is an extremely hard problem, and the transport is largely irrelevant. The example api in this article is naive, and like the article points out, for the api to support multiple clients, there needs to be some kind of guaranteed delivery mechanism, handling or avoiding conflicts, handing stale clients, etc. Using http streams does not change this problem.

That's not to say that http steams aren't awesome. I use them regularly & unless I truly need a bidirectional stream, they are indeed much easier to maintain & reason with. I'd recommend using server-side events with fetch (not EventSource), as they are well defined & more friendly with load balancers, proxies & other infrastructure, as some things will buffer the streams in chunks.",84,2025-04-13 16:39:24,markus_obsidian
programming,1jy78sa,mmxys1g,Or use a higher level abstraction like SignalR and let it decide the optimal transport.,27,2025-04-13 19:18:35,shadowndacorner
programming,1jy78sa,mmzjj35,Just post to an iframe already.,10,2025-04-14 00:44:33,dhlowrents
programming,1jy78sa,mmwilke,"Http streams are great but as far as I know you cannot use them if you plan to stream data from the client.

So unless you’re ready to ditch http web sockets are fine. Of course you need to know the details, but that applies for everything.",30,2025-04-13 14:46:55,KeyIsNull
programming,1jy78sa,mn0mem6,"> WebSocket messages aren’t transactional

Correct me if I'm wrong, but isn't this problem solved, if not manageable using event acknowledgements. I'm thinking of the [socket.io implementation](https://socket.io/docs/v4/tutorial/api-overview#acknowledgements) specifically",5,2025-04-14 05:30:43,eazieLife
programming,1jy78sa,mn0y8yq,"I’m curious why the author didn’t even mention [SSE](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events). (The answer is probably because they wanted to advertise their own library, but it’s still strange to not even mention as a contender.)

Also kind of an odd choice to reinvent the wheel instead of building on something like RxJS which has well-defined patterns and a decent ecosystem. In fact, I’m reading through [the docs](https://hntrl.github.io/eventkit/guide/concepts/transforming-data) and this looks like almost a 1:1 copy of RxJS lol",4,2025-04-14 07:29:08,tj-horner
programming,1jy78sa,mmyn3ay,"Use WebSockets, but with another layer on top of it. Personally I like JSON-RPC. And find a library that can manage it for you, so it'd handle things like closing/opening/pinging.",2,2025-04-13 21:30:08,somebodddy
programming,1jy78sa,mn11ad9,"If you want browsers to talk to each other, you need to relay the messages. This is why I created WebSocket Relay, which dramatically simplifies the process:

[https://github.com/nick-hill-dev/wsrelay-server](https://github.com/nick-hill-dev/wsrelay-server)

[https://github.com/nick-hill-dev/wsrelay-client](https://github.com/nick-hill-dev/wsrelay-client)",2,2025-04-14 08:02:14,nahill
programming,1jy78sa,mn0udls,i actually love websockets so i think i need them :(,3,2025-04-14 06:48:58,FederalRace5393
programming,1joczc6,mkxh3y7,"The 68000 detected illegal instructions and call a Trap interrupt.

The 6502 did have ""Quasi Opcodes"" which were not reliable 100%, though some games used them to save clock cycles.",5,2025-04-01 22:10:24,UVRaveFairy
programming,1joczc6,mkr5seu,Article is from 2023. Good read.,8,2025-03-31 21:21:06,Initial_Low_5027
programming,1k0lt3s,mnezv9q,"Did I understand it correctly, that kotlin notebooks are now available in the community edition? That would be so amazing",49,2025-04-16 14:40:19,some3uddy
programming,1k0lt3s,mnkdq43,"Couldn't help but notice they're ditching an extremely useful modal commit dialog in favor of VSCode-like approach, having unprecedented backlash because of it and not giving a damn about negative feedback at https://youtrack.jetbrains.com/issue/IJPL-177161

This is quite spectacular to watch JB going downhill, especially for a long-time [UPD] paid user like me.",17,2025-04-17 11:17:12,develop7
programming,1k0lt3s,mnf3red,I just wish WSL wasn't broken for basically the last 1.5 years. But looks like it'll be broken for a bit longer.,44,2025-04-16 14:59:29,Actual-Many3
programming,1k0lt3s,mnfnbhz,">The ability to download drivers from Maven or other custom repositories

>Version 2025.1 allows you to add custom repositories for downloading drivers. To do so, add the repositories you need to the mirrors attribute of the HOME\_PATH/.m2/settings.xml file.

Fucking finally. [Only took them 7 years... ](https://youtrack.jetbrains.com/issue/DBE-6690/Data-Sources-driver-download-should-use-configured-Maven)",21,2025-04-16 16:36:17,MrNighty
programming,1k0lt3s,mnycgi6,This version is painful to work with. Compilation errors take forever to show-up. I have to literally restart this piece to crap to work with - and I have the ultimate version.,2,2025-04-19 17:01:40,hope11223
programming,1k0lt3s,mnhu9qv,"Can no longer open any Jetbrains IDEs on Arch...

Edit: nvm got it working again  
Edit 2: This was huge, can't believe I didn't know: [https://blog.jetbrains.com/platform/2024/07/wayland-support-preview-in-2024-2/](https://blog.jetbrains.com/platform/2024/07/wayland-support-preview-in-2024-2/)",4,2025-04-16 23:19:17,superman1113n
programming,1k0lt3s,mnfny3u,Have they added multiple projects in the same window yet?,2,2025-04-16 16:39:24,BlueGoliath
programming,1k0lt3s,mnl4zno,Is their free AI assistant any good?,1,2025-04-17 14:05:01,HypnoToad0
programming,1k0lt3s,mnli8l2,Dev Containers _still_ broken (docker compose),1,2025-04-17 15:10:32,kevleyski
programming,1k0lt3s,mnj01gj,ai chat and junie are too unstable and too slow. It's like the situation with google bard when chatgpt was first released. It is important to properly create quality services.,1,2025-04-17 03:37:29,hogu-any
programming,1k4iwkq,modox9r,When do we get the g-strings?,134,2025-04-22 04:31:25,NinjaBreaker
programming,1k4iwkq,mobprz5,"f-strings
t-strings

Python likes fancy strings.

    name = ""World""
    template: Template = t""Hello {name}!""

I can't yet decide whether this is good or bad. First impression is that it is quite verbose.

> If you’ve worked with JavaScript, t-strings may feel familiar. They are the pythonic parallel to JavaScript’s tagged templates.

I didn't even know JavaScript had tagged templates. Need to update my JavaScript knowledge urgently ...

I read the rest of the article, but I am still not certain where or when t-strings are necessary. Are they simply or primarily just more efficient Strings? What is the primary use case, like if someone wrote some small library in python with a few functions, how do t-strings fit in there?",46,2025-04-21 21:28:14,shevy-java
programming,1k4iwkq,mohz6vy,"I was there when f strings were introduced and I thought it was a fad. But later on I found it useful. 

Now we have t strings. I see what it could be used for but when I use Django everywhere I need to do html templating I don't find it useful. Though it looks like it might be useful in other ways.",1,2025-04-22 21:07:02,lamp-town-guy
programming,1k4iwkq,modthee,"I guess it doesn't fix the need to rewrite { and } as {{ and }} everywhere, which is my biggest annoyance.",-5,2025-04-22 05:07:35,zhivago
programming,1k4iwkq,mofkzut,Python doesn't need more batteries :(,-1,2025-04-22 14:04:18,mr-figs
programming,1jsasl3,mlkzkyg,"Don't tell me, another backspace rescue shell bug.",102,2025-04-05 19:02:27,BlueGoliath
programming,1jsasl3,mlmmtq9,"> Integer overflow in ReiserFS

Is not it gone from the Kernel as of the last release? A little late to fix this one, imho",29,2025-04-06 00:57:42,voronaam
programming,1jsasl3,mlohuau,"GRUB2 has been fairly disappointing - way too many bugs. There is something fundamentally wrong with the GRUB2 development process; I don't know why, but many other projects work significantly better and I don't think the bootloader is necessarily more complicated than LLVM, mesa, the linux kernel, gcc or glibc really. Plus, grub-legacy kind of worked better in many ways; I understand that things got more complicated in the last ~15 years, but there is still something wrong with the development process. It also causes secondary problems, such as installers using grub no longer working; I am not claiming the latter is the direct fault of the grub2-developers of course, but people write code for installers for linux-based systems, and the more brittle and unreliable grub2 is, the more often code breaks or does not work. I've run into this problem in regards to GoboLinux a few times, and while I am not saying this is necessarily the direct fault of grub2-developers, any downstream software developer also depends on upstream writing good solid code. And documented code, too.",10,2025-04-06 10:36:20,shevy-java
programming,1jsasl3,mloj5di,"One bug is about overflowing an integer representing the length of a string.
Technically a bug but practically nonsense. 


In what universe will a bootloader read a 4 gigabyte string?",5,2025-04-06 10:49:45,rep_movsd
programming,1jsasl3,mll0k6d,Thanks Microsoft. Who about testing a little known closed source software that is is full of CVEs? I think it's called Windows,8,2025-04-05 19:08:02,Accomplished-Moose50
programming,1jsasl3,mlmuvsp,"I still don’t believe it’s AI that’s doing the work. What is happening that discussion about same bug may have been lying it some small public website which never got any attention. AI is just finding that piece of information and since we never scroll to one million search results after first 100, but AI does it. So we believe it’s thinking.",-28,2025-04-06 01:51:40,akash_kava
programming,1jsasl3,mll6yga,"Good job.  Leveraged co pilot to find vulnerabilities, hackers haven't found in 15 years...  mayvevlookbatvyour own shit...",-61,2025-04-05 19:44:54,painefultruth76
programming,1k0mf09,mnf2yg1,[Previous discussion 6 years ago](https://www.reddit.com/r/programming/comments/8rlr3a/fibonacci_hashing_the_optimization_that_the_world/),27,2025-04-16 14:55:34,ketralnis
programming,1k0mf09,mnfpt48,"> And everyone should be using it.

A year before, at CppCon 2017, Matt Kulundis presented Abseil and its hash-table in particular. During the course of the presentation, he notably argued that bad hashes are bad hashes, a programmer error, and hash-table implementations shouldn't penalize programmers who do their homework for the sake of those who don't. It's against C++ philosophy of ""You Don't Pay For What You Don't Use"".

Just like prime number hashing is one of those ""post-hash"" fixes which attempt to fix-up bad hashes, so is fibonacci hashing.

So in essence it may be that it's not so much the world over forgot Fibonacci Hashing, and more that it's useless whenever hash frameworks are of good quality by default. C++ and Java being, perhaps, the most obvious outliers there...

(I really wish [Type Don't Know #](https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3980.html) had been adopted...)",47,2025-04-16 16:48:25,matthieum
programming,1k0mf09,mng6qj1,"\`& Mask\` and \`>> (BitWidth - Bits)\` are just ways to extract the low or high bits of a value.

So the multiply in FiboHashing is purely for hashing purposes. so comparing it to \`& Mask\` and saying to hashes better is kind of obvious, the fair comparison is with >>

That said multiply does stack entropy in the high bits, and most other hashing tricks can be used to stack entropy in the high bits too. So definitely can get very good results with using >> instead of &.

But as always Hash Maps and Hash function NEED to be co-designed to get good results.",9,2025-04-16 18:08:34,mAtYyu0ZN1Ikyg3R6_j0
programming,1jk7319,mjt290h,If there is a performance gain from this I'm not seeing it. Running the code pen raises cpu usage by 20 points and scrolling another 10. Using content visibility auto doesn't seem to improve it.,89,2025-03-26 09:45:38,Kozmyn
programming,1jk7319,mjt30ew,"Using it for like a year, had a bunch of problems on iOS safari mobile and no perceivable performance gain, removed",48,2025-03-26 09:53:21,cokeplusmentos
programming,1jk7319,mjt3yum,">When to Use It

>This optimization is particularly effective for:

> * Long lists of items (like product catalogs)
> * Complex dashboards with many components
> * Infinite scroll implementations
> * Tables with many rows

>[...]

>**If search functionality is crucial for your use case**, you might want to:

> Disable content-visibility: auto for searchable content

I have to admit, it is more likely that people will use the website's built in search tool to find what they want. But then again, if they did and they got a long list of elements...

I'll shake my fist at the search-function-ception going on here and move along...",30,2025-03-26 10:02:49,not_perfect_yet
programming,1jk7319,mjum3o5,"NEVER use this because I just can't stand when ctrl-f doesn't work, websites keep doing this for no reason (apart from destroying the social media space with infinite scroll). Just stop doing insane single page websites and implement normal pagination, nothing wrong with it.",33,2025-03-26 15:44:21,ficiek
programming,1jk7319,mjvix2n,"My pet peeve: Blog posts that talk about a well documented topic without linking to that documentation.

So for reference:

- [content-visibility - CSS: Cascading Style Sheets | MDN](https://developer.mozilla.org/en-US/docs/Web/CSS/content-visibility)
- [contain-intrinsic-size - CSS: Cascading Style Sheets | MDN](https://developer.mozilla.org/en-US/docs/Web/CSS/contain-intrinsic-size)",8,2025-03-26 18:21:12,OMG_A_CUPCAKE
programming,1jk7319,mjtunnu,"There are also some accessibility caveats, notably with [hidden elements](https://web.dev/articles/content-visibility#a_note_on_accessibility)",7,2025-03-26 13:21:26,i_still_have_a_core2
programming,1jk7319,mjtd51r,"Not sure if the performance gain would be big enough to notice on the example the website gives.

It's not like the browsers are rendering (painting) the entire website, even what you can't see at all times, that would destroy mobile devices. So I doubt adding blur to elements does anything to test.

So probably the property helps by skipping layout calculations and DOM work on invisible elements, but since we are testing just a static list, content visibility auto doesn't do much, and regular performance optimizations kick in instead.

A better test would use css animations or js to dynamically change the size of random elements on the list, even invisible ones.",13,2025-03-26 11:24:22,Cold_Meson_06
programming,1jk7319,mjswwn1,"Excellent! I feel like this should be common knowledge, but I certainly wasn’t familiar with it beforehand.",1,2025-03-26 08:47:44,AwesomeTheorist
programming,1jk7319,mjua9mg,is this theoretically a sub for list virtualization?,0,2025-03-26 14:45:08,lunacraz
programming,1jxuvey,mmu7m7t,Worked at a FAANG did you? I think I can guess which one.,28,2025-04-13 03:09:40,visicalc_is_best
programming,1jxuvey,mmtz2rz,"What does ""active in your workflow"" mean?",6,2025-04-13 02:10:57,teerre
programming,1jxuvey,mmv1u66,"I've been wanting something like this! I use git lens and its history is so busy it's useless. Most of the noise is the branch merged commits, hoping yours hides that",5,2025-04-13 07:31:30,Humprdink
programming,1jxuvey,mmu6meo,"I was just about to comment this looks like Smartlog at work, good job :)",8,2025-04-13 03:02:42,Cidan
programming,1jxuvey,mmwnyku,I use https://git-fork.com,3,2025-04-13 15:15:06,ryo0ka
programming,1jxuvey,mmwnpgu,"This looks great, I do miss ISL sometimes 😅",2,2025-04-13 15:13:46,Rubysz
programming,1jxuvey,mmyjkch,"this looks really intuitive, probably a lot easier to understand for beginners, and looks a lot nicer to use than the usual command line :p",2,2025-04-13 21:10:24,code_mc
programming,1jxuvey,mn1xkg4,I don't like it requires github cli. git itself should be enough.,2,2025-04-14 12:50:03,EsoLDo
programming,1jxuvey,mmu6pd2,"Looks interesting, I'll try it.",1,2025-04-13 03:03:16,somazx
programming,1jxuvey,mmwey6e,This looks really cool! Are you planning to open source it?,1,2025-04-13 14:27:08,CraftMechanics
programming,1jm7b8i,mkbnzcr,"Extreamly good list. I absolutely adore danluu.com his blog post are so insightfull and well written. Notice how many of those sites are small, minimalistic and mostly without any javascript. How sites like these fly on modern hardware is amazing.",25,2025-03-29 07:36:26,reveil
programming,1jm7b8i,mkb58el,nullprogram being #37 is a crime. Should be top 10.,8,2025-03-29 04:32:22,Steampunkery
programming,1jm7b8i,mkamw0j,"This is really interesting! I've been a Hacker News lurker for years and always half wondered which personal blogs consistently rise to the top there.

Looking at the list, it's no surprise Paul Graham tops the charts - his essays are practically required reading in tech circles.

I've found some of my favorite technical writers through HN over the years. It's like a filter for high-quality tech content that cuts through the SEO-optimized fluff that dominates Google results these days (though some takes I disagree with, it's at least interesting insights)

Anyone else notice how many of these top blogs use minimal styling? Simple HTML with good content seems to be the winning formula. I should probably stop messing with my site design and just focus on writing better! Which I'll do after one more redesign...",3,2025-03-29 02:22:51,sevenadrian
programming,1jm7b8i,mkbdwlk,So dumb. What exactly id a “helpful blog”? I’ve read dozens of blogs way better than this garbage,-11,2025-03-29 05:49:09,BigBrainGoddess
programming,1jvxwpu,mmedu1e,"TIL there is still significant usability development on GCC. I love the improvement of template error messages, they are always a pain to read.",56,2025-04-10 15:04:31,MortimerErnest
programming,1jvxwpu,mmgpb2z,"Love the indentation and color changes.

Not sure how I feel about the ASCII art; especially for the given example of an infinite loop, it feels like the important information is spread out and sprinkled into a bunch of unnecessary information and scribbled lines.",5,2025-04-10 21:55:43,DavidJCobb
programming,1jvxwpu,mmevj5a,"Honestly, I hate this... a 29-line warning that includes emoji and 140-column rows? More unreadable dark-blue-on-black text because the GCC developer uses a ""not actually dark blue"" as ""dark blue""?

EDIT: And that 29-line warning is just saying that n is not modified in the loop.",20,2025-04-10 16:31:57,RealDeuce
programming,1jvxwpu,mmhw0co,Nice work on both the improvements and the helpful examples. All the best to you and the release effort.,3,2025-04-11 02:09:25,Manixcomp
programming,1jvxwpu,mmifx36,Thanks!,3,2025-04-11 04:31:02,AReluctantRedditor
programming,1jvxwpu,mmiux3q,"I am already using the latest git clone checkout. I do, however had, also have to say that a few programs fail to compile with gcc, so I keep 14.2.0 in another prefix available too and just symlink the binaries (e. g. the latest gcc, or the 14.2.0 binaries); that approach kind of works.

What the article does not go into much at all (aka none) is how GCC 15 compares to llvm/clang. GCC is fine as it is, but to me it feels as if LLVM has way more momentum than GCC. I could be wrong but usually when other projects have more momentum, they may become more and more used by other folks (see the crystal language running on llvm; nobody seems to want to do this with GCC, as one example of many more).",1,2025-04-11 06:48:09,shevy-java
programming,1jvxwpu,mmpupl3,As someone who has no 20/20 vision I often keep terminal about 90 characters wide to not squeeze at wtf is going on. Some messages look too wide to the point I will not be bothered to read them,1,2025-04-12 11:39:49,Maykey
programming,1k3xz7r,mo6civb,"Nice talk! It's great to see this clear goal of going towards data oriented programming. We have been moving towards it, and it has reduced code complexity by a lot. Way less state management and more streamlined data flow. Oh, and sum types are insanely useful. It's true what he says about them. Once you know them, you cannot stop seeing a place for them everywhere.",37,2025-04-21 00:11:30,Gleethos
programming,1k3xz7r,mo5tazo,TL;DR the same path it's been going for the last 3+ years.,159,2025-04-20 22:14:54,BlueGoliath
programming,1k3xz7r,mo6dbjp,"Some pretty negative comments in here. I don't write Java and I don't pay attention to the language. Is its development scarred with slow execution on JEPs as this thread would lead me to believe?

Every time I read about newer Java versions I typically see good things!",35,2025-04-21 00:16:15,anxxa
programming,1k3xz7r,mo88kf3,Kinda interesting to see ADTs finally going mainstream!,5,2025-04-21 09:09:01,syklemil
programming,1k3xz7r,mo5tlck,Why do languages need to go places? It's been around for decades FFS.,44,2025-04-20 22:16:39,myringotomy
programming,1k3xz7r,moas8jg,"A lot of complaints about Java ITT, but compare how its grown & changed compared to C++ over the same amount of time and you'll see it's actually on a very positive trajectory.",3,2025-04-21 18:41:33,CVisionIsMyJam
programming,1k3xz7r,mo6vapa,"After using Scala and Python, I just can't bring myself to use Java anymore.",6,2025-04-21 02:02:38,Hungry_Importance918
programming,1k3xz7r,mo60t28,"Nowhere, slowly; one could reliably guess.",10,2025-04-20 23:01:07,Quiet-Detail-3939
programming,1k3xz7r,moaqexj,"It's a good question. On the one hand it still evolves slowly; on
the other hand there are changes that were inspired by other
languages, and more changes too. Some ideas I like a lot, such
as GraalVM. I hope ""the powers that be"" really push GraalVM
so that it can also become a ""unified platform"" (whatever that
means; I just want to also easily integrate some ruby code or
other languages too, having a single .exe is so convenient 
for people who are not computer techies).

The one thing I still dislike is how Java insists on project
structure when finding files. I'd love a free-form variant; ruby
spoiled me here. I do have a specific layout for my ruby code,
but I also want to have the ability to simply tell java where 
code is, rather than java insisting I have to lay it out in a 
specific way. Why can I not easily use java code residing
ANYWHERE on my local filesystem? Why does java want
to be different to other programming languages? The world
is not coming to an end if we can easily tell java where code
is.",1,2025-04-21 18:32:34,shevy-java
programming,1k3xz7r,mo6e0rh,"Wherever it’s going, it is traveling light and on a slow boat.",2,2025-04-21 00:20:22,manifoldjava
programming,1jo5r2j,mkpi5dk,"> Here’s the dirty secret: Freelancing isn’t about coding. It’s about becoming a therapist, negotiator, and amateur lawyer who occasionally writes code

I tried freelancing and starting my own business.

I learned the hard way that I am not a business man, and never want to deal with business and sales again. It was exceptionally demotivating.

Not everyone is cut out to be an MBA or a salesperson.",244,2025-03-31 16:24:10,i_ate_god
programming,1jo5r2j,mkqyyct,"I negotiate half up front, no exceptions. If they can't afford half up front or are hesitant about it, you haven't sold your services correctly and you probably don't want to work with them anyway. You can use an escrow service, that's what they are for. You can just be a deliverer of solutions if that's what you want if you learn to say ""no, but.""

I've had great success saying ""no, I don't want to do that. Here's how you could do that better and here's someone who could help you with that."" It requires immense domain knowledge, but you retain clients that respect you, your rates, and ultimately your time.

You build in punitive clauses about scope, time delays and expectations because that's how real businesses work too. Those motivate clients to treat your efforts as time sensitive, instead of the default where your concerns are at the bottom of an actively self immolating totem pole.",39,2025-03-31 20:46:02,knottheone
programming,1jo5r2j,mkqboaf,"I must be the odd one out, because I honestly enjoyed the ""businessy"" part of freelancing. Helping clients, educating them, receiving praise for well done work - that made it so much more worthwhile than just banging out code.",32,2025-03-31 18:50:40,deceased_parrot
programming,1jo5r2j,mkq8nuy,"Why the hell are you 200 hours in without the client paying anything?

Most of this is just a list of perfectly avoidable shit. If you don’t want to be a PM don’t work for tiny clients. If you don’t want to really run a business, use one of the myriad of contracting services.

Freelance can mostly be writing code… if that’s what you want it to be.",46,2025-03-31 18:35:33,soft-wear
programming,1jo5r2j,mksr8nm,"Designers have dealt with this forever. There's a great video on this: ""F*ck you. Pay me."" 
https://www.youtube.com/watch?v=jVkLVRt6c1U&t=63s",6,2025-04-01 03:03:18,bawiddah
programming,1jo5r2j,mktfjlf,"Title makes me think

> 99% of gamblers quit right before they hit the jackpot!!",5,2025-04-01 06:29:27,iris700
programming,1jphmgw,mkzmtbl,"Just fix the problems in the first version:

- Iterate over the set and use Collections.binarySearch on the sorted list to invert the check (since the set is much smaller, and the list is sorted)
- intersection is copied needlessly
- consider using ArrayDeque for fast appends at front to avoid the Collections.reverse (or return a reverse iterator if using a JDK with sequenced collections)
- don't consider using LinkedList (it wraps every element and has poor cache locality)",85,2025-04-02 07:32:36,john16384
programming,1jphmgw,mkziqcg,"The math is not correct on the improvement. Also there many other things you optimise. Maybe use a stack instead of an array, or a linked list to avoid reversing? Or use a sorted TreeSet to check for matches.",17,2025-04-02 06:47:40,kennyshor
programming,1jphmgw,ml0efre,It's always beautiful to see Cunningham's Law at work.,14,2025-04-02 12:09:20,TyDie1212
programming,1jphmgw,mkzv157,Thread.Sleep(1000); //cpu usage fix,18,2025-04-02 09:08:35,DonutConfident7733
programming,1jphmgw,ml05enh,"How about this, with a single helper Set. I'm assuming items (B) is HashSet. As little as possible allocations, resulting array and helper set preallocated.  
  
With 2K B-items there's little need for parallelization, 10K A items is on the edge of being useful to go through in parallel but I doubt that it would be beneficial, especially if there's multiple requests going on at the same time.

    private static List<String> sortItems(List<String> sortedItemList, Set<String> items) {
        if (items == null || items.isEmpty()) {
            return Collections.emptyList();
        }
        if (sortedItemList == null || sortedItemList.isEmpty()) {
            return new ArrayList<>(items);
        }
        // Find the intersection of A and B
        // Create list C containing the intersecting items, ordered as they appear in A
        // preallocate capacity
        List<String> result = new ArrayList<>(items.size());
        // Collect appended items, preallocate capacity
        Set<String> appendedItems = new HashSet<>(items.size());
        for (String item : sortedItemList) {
            if (items.contains(item)) {
                result.add(item);
                appendedItems.add(item);
            }
        }
        // Append all remaining items from B to C
        for(String possiblyNotAppendedItem : items) {
            if(!appendedItems.contains(possiblyNotAppendedItem)) {
                result.add(possiblyNotAppendedItem);
            }
        }
        // Reverse the list to get the final desired order
        Collections.reverse(result);
        return result;
    }",5,2025-04-02 10:57:19,m-apo
programming,1jphmgw,ml1yztd,"If you sometimes return Collections.empyList(), you shouldn't also be returning a raw ArrayList. The differing mutability will end up being a bug at some point. Someone somewhere will be adding to that list until the 1 time you return the empty version, and it blows up. You should return Collections.unmodifiableList(result) at the end.",3,2025-04-02 17:16:21,vips7L
programming,1jphmgw,ml1gma6,"Something like:


`list = new ArrayList(items);`
`list.sort(Comparators.comparingInt(s -> map.getOrDefault(s, Integer.MAX_VALUE)).reversed());`
`return list;`


Looks easier than that list -> array -> list thing. You're sorting stuff anyway, might as well just make sort do its job. Also, spares array allocation, which is nice.",2,2025-04-02 15:46:19,Igigog
programming,1jphmgw,ml0f2jr,"You can just simplify the routine with a LinkedHashSet. Less loops is the name of the game, no need for reversing multiple things, etc. 

```
  private static Collection<String> sortItemsRedo(List<String> sortedItemList, Set<String> items) {
        if (items == null || items.isEmpty()) {
            return Collections.emptyList();
        }
        if (sortedItemList == null || sortedItemList.isEmpty()) {
            return new ArrayList<>(items);
        }
       
        // Clone the full set of items and add them all in reverse order by default
        final LinkedHashSet<String> itemsCloned = new LinkedHashSet<String>();
        for (String item: items) {
            itemsCloned.addFirst(item);
        }

        // Move the items in the sortedItemList to the end, since we're in reverse order
        for (int i = sortedItemList.size() - 1; i >= 0; i--) {
            itemsCloned.addLast(sortedItemList.get(i));
        }

        return itemsCloned;
    }
```

Doodle showing it matches output: https://www.jdoodle.com/ia/1FfZ",3,2025-04-02 12:13:56,Scyth3
programming,1jphmgw,mkzsefi,why not just hashmap the smaller one ?,1,2025-04-02 08:37:46,liprais
programming,1jovme5,mkurwwl,You got me up until “Adopt Schrödinger’s tests” 😂,42,2025-04-01 13:43:46,Took_Berlin
programming,1jovme5,mkwtczx,"Isn't this pretty much how selenium, playwright, etc. browser driven tests work anyway. Most of the time red but sometimes green? That's when you deploy. /s",18,2025-04-01 20:04:52,MaverickGuardian
programming,1jovme5,mkvu06g,You think this is a joke but I've been at this company.,25,2025-04-01 17:04:26,s-mores
programming,1jovme5,mkvpzev,I was angry for awhile.,5,2025-04-01 16:43:56,UK-sHaDoW
programming,1jovme5,mkupue3,"On this _special_ day, I wanted to share with you a new software testing paradigm.",16,2025-04-01 13:31:19,teivah
programming,1jovme5,mkwcuki,"Finally, a sane alternative to fuzzing.",4,2025-04-01 18:39:46,Sabotaber
programming,1jovme5,mkvwelh,"Slight grammar boo-boo: ""assertions that favor optimism by silently ignore mismatches"".",2,2025-04-01 17:16:34,youngbull
programming,1jovme5,mkxc25j,"This is not new, I just put the “eventually” limit to be green before I commit the code.

Yeah, it sounds funny if you extend it beyond that and makes for a good joke.

On the other hand, writing tests before and/or as you write the code has merit. If you get accustomed to it, might save you time even.",2,2025-04-01 21:41:54,azhder
programming,1jovme5,ml2vm3b,"Hah, my company has been doing this for years.",2,2025-04-02 19:53:20,ThatNextAggravation
programming,1jovme5,mkxd7uu,"Congratulations, you've invented [test driven development.](https://wiki.c2.com/?TestDrivenDevelopment)",0,2025-04-01 21:48:19,FlyingRhenquest
programming,1juxmy5,mmahizy,predatory cookie settings on that site,11,2025-04-09 22:19:58,mr_dfuse2
programming,1juxmy5,mm6lcux,Right - do we now need a quantum computer?,-28,2025-04-09 09:18:10,shevy-java
programming,1k2cfpp,mntwpne,"Feature flags are great, but don't forget to delete them after the feature's launched and that configurability is no longer needed. Too many feature flags can complicate development and testing.",106,2025-04-18 21:48:41,virtyx
programming,1k2cfpp,mnt6kv4,Next one will be „Git branches For the Win: decoupling feature developmen“,102,2025-04-18 19:28:57,PositiveUse
programming,1k2cfpp,mnvvgi8,Feature flags are to be used sparingly since they explode exponentially. How do you supposedly test all the combinations?,24,2025-04-19 05:47:18,tecnofauno
programming,1k2cfpp,mnwujoc,"How do you implement them ? In the client, does that mean that you to make a bunch of additional API calls to get the feature flag configuration ? In the server, do they live in environment variables ? Alternatively, separate configuration files that are accessed over the network ?

The article is interesting but I feel like it would be much more valuable if it also considered the potential downsides and examined in more details when to use, when **not** to use, and when to remove feature flags. “Everything in software architecture is a trade-off.”",5,2025-04-19 11:41:43,Equivalent_Bet6932
programming,1k2cfpp,mnx176k,We use it a lot via launchdarkly.,2,2025-04-19 12:32:48,tepfibo
programming,1k2cfpp,mo2euzd,"“How do you test all the permutations?”
I see this one comes up a lot with conversations around feature flags. The short answer is you do and you don’t. 
The way I’ve used feature flags in the most sustainable way is that the switching of said feature flag is still tied into your release process, albeit the artifact that represents it is trivial in complexity. 
I’ve used such things as a yaml file that is in VC and are subject to TBD where main is the desired state. 
I’m much less a fan of a model where your feature flags are configurable in every environment, that welcomes chaos and I see as an applicable in only emergency scenarios. 

As it is now within your release process, it is subject to all the usual QA activity that occurs there and that means that your testing the current state as is, if a change is to switch on a flag then we test that state and move to release. If another is to be removed, we test that state and ship it. 

Each change to the feature flag state is atomic and therefore its own change with all that comes with that.
This is reliant on a robust regression suite but that is achievable. 
At that point you are testing permutations but being pragmatic about what states are possible because that state is centralised, continuously deployed and can’t change under your feet",1,2025-04-20 09:39:37,zuanshibei
programming,1k2cfpp,mo1qckg,"My team uses this extensively and so do I but I've always treated it as a form of vandalism of the codebase - something devs only do to spite the organization for not tackling the real root cause of the issues which are shitty DevOps processes and poor planning.

You end up with if-clauses everywhere in the code and for us because we store the flags in a central database - a database full of thousands of these feature flag entries which have to be retrieved by every running instance on startup and which nobody will ever clean up.

That database then also becomes a single point of failure for all instances and loss of data here from a mistyped query would be akin to losing the entire repository because the code would no longer function as normal unless and until all the entries are restored as they were (this has happened before, just not yet in prod).

In other words, I only do it because it's not my software and so I don't really care.",0,2025-04-20 05:27:15,sphqxe
programming,1jm79nx,mkbfexb,"Also, when using uuids in an index, using something like V7 improves performance a lot. If you use v4 (truly random) uuids, your index will constantly need to rebalance the btree, causing much slower inserts/updates",61,2025-03-29 06:04:09,robbiedobbie
programming,1jm79nx,mkb5o6z,90% of this is not specific to PostgreSQL...,24,2025-03-29 04:35:55,bigdamoz
programming,1jm79nx,mkcagck,">This isn't even Postgres specific, just please name your tables using the singular form of a noun.

This barely makes any sense, really.

But anyway, I want to address the ""soft"" deletion and auditing requirements. A lot of solutions come down to these ""flags"": ""deleted"" or ""revoked\_at"" as in your case. This metadata often just pollutes your business logic. We'll come back to this topic a bit later...

The next topic is ""Represent statuses as a log."". This is just a straight messy solution also introducing some ""flag"" columns such as ""latest"" or ""valid\_at"". The author is creating a new table just to track the adoption status changes, which eventually might lead to heavier joins. So, what to do instead? Enter temporal/history/versioned tables. Instead of having the ""adoption\_approval"" table, you can have ""adoption"" table and ""adoption\_history"" table, which pretty much contains all the same columns as the ""adoption"" table but without pkey or fkey constraints.

How it works:

Initially, you'd create a new record in the ""adoption"" table with status ""submitted"". When you update the status, you update the record in the ""adoption"" table and insert the old record in the ""adoption\_history"" table (can be done via trigger). This way, we can track all the changes for the given record in the history table and have an insight into the current state of the data in the so called ""snapshot"" table (""adoption"" table). The beauty of this approach is that it also comes into play when it comes to the deletion of records. In the same manner, we can delete the record in the original table, and recreate it in the history table.

However, the question arises when we cannot actually delete the record due to the constraints (foreign keys in the context of databases). In that case, it's probably time to reconsider your business logic.

For example:

1. Do I also want to delete the correlated data?
2. Is the ""deletion"" really a deletion or a status change? Marking the domain object as inactive, unused, disabled, etc.

The other advantage of temporal/versioned/history tables is that the historical data can be deleted separately and without affecting the current data.

When it comes to downsides, well, this is definitely a more performance-intensive action.",14,2025-03-29 11:38:39,rom_romeo
programming,1jm79nx,mkcggvx,Database altering postgresql patterns!!,6,2025-03-29 12:27:38,n_lens
programming,1jm79nx,mkcu6a3,This was posted here like 3 weeks ago,4,2025-03-29 14:00:13,bushwald
programming,1jm79nx,mkfcu4e,More discussion on the same article posted 11 days ago: [https://www.reddit.com/r/programming/comments/1je3ph0/life\_altering\_postgresql\_patterns/](https://www.reddit.com/r/programming/comments/1je3ph0/life_altering_postgresql_patterns/),2,2025-03-29 22:18:45,Ordinary_Leader_2971
programming,1jkfpbj,mjv7lvs,That's so cool. What is missing from the FLS to match the expectations for a full official language specification? Is rustc aiming to be fully compliant with the FLS? Would this mean rustc and the ferrocene compiler are in direct competition in the safety critical space?,21,2025-03-26 17:27:30,Linguaphonia
programming,1jo66kx,mkpdmg2,"Why the f are they uploading to NPM to debug this stuff? would be 100x more efficient to just run it locally, see that it doesn't work locally, and debug there ¯\\\_\(ツ\)\_\/¯",17,2025-03-31 16:01:41,Takeoded
programming,1jo66kx,mkrkjx7,what a thrilling story!,2,2025-03-31 22:42:48,somnamboola
programming,1jyvozr,mn1xcxj,">## What makes it secure?

>PrimJS (and by extension QuickJS) are written in C/C++; integrating them as-is in your program means you inherit any security issues that might be lingering inside them.

>Hako compiles down to WebAssembly, a memory-safe, sandboxed execution environment. This means even though Hako is written in C/C++, programs it is embedded in have an extra layer of protection from any potential memory vulnerabilities.

I didn't expect ""compile to wasm instead of native"" to be how C/C++ gets to some memory safe state, but, uh, OK.",51,2025-04-14 12:48:43,syklemil
programming,1jyvozr,mn1t8pt,These are not words i expected to see with js lol,11,2025-04-14 12:21:11,AciD1BuRN
programming,1jyvozr,mn206qx,Atwood's law,2,2025-04-14 13:06:26,abhijitht007
programming,1jyvozr,mn2d3gq,"> Hako being a fork of PrimJS means we inherit many of the improvements it made. In sythentic benchmarks, Hako shows performance gains of 28% over QuickJS. Compiling to WebAssembly has no noticable impact on performance as the amazing JIT compilers of JavaScriptCore/Bun, V8/NodeJS, and Wasmtime allow code to run at near-native speeds. I’ve also implemented a number of optimizations (including SIMD) for a few hot paths.

Wouldn't a rust fork with SIMD be even faster?",2,2025-04-14 14:20:20,badpotato
programming,1jtk7ky,mlvf93b,"If OP own this website, you should check your site on mobile phone.

Anyway, great article, I agree with all of your propositions.",39,2025-04-07 14:57:36,_shulhan
programming,1jtk7ky,mluvvnw,Those are great attributes of programmers. The best software engineers I know are good at questioning the requirements and adapting them to what's easiest to implement and that meets all the hidden requirements like durability and adaptability.,28,2025-04-07 13:09:58,gladfelter
programming,1jtk7ky,mlzq5f2,"""Read the error message"" truly underrated. You wouldn't think it was a skill of its own until you have to help your colleagues figure out which part of ""error: directory does not exist"" tells you that the error is that the directory does not exist :)

Of course, other times the error message is just random words from the brain of the original developer, so you have to apply some time-traveling telepathy to translate it into English.

Or the hard part is finding the error in the first place since either the script kept going for 30 minutes after the failure or it follows the actual error with a hundred run-on errors or repeatedly reporting that something else failed earlier.",9,2025-04-08 06:05:36,olsner
programming,1jtk7ky,mlw82jc,"Brief summary:    
Do well and do not do badly.  
Help everyone if you can make your help visible.  
Learn.

I will add to this article my own:  
Remember that the best engineers and happy engineers are two different groups, and they overlap only a small part.

Most of us strive all our lives to become the best engineers. It is not hard (see article). But what about becoming a happy engineer? That is what is really hard.",21,2025-04-07 17:24:58,YahenP
programming,1jtk7ky,mlzupu4,Thought he was going to give us the names of the best programmers he knows,3,2025-04-08 06:47:55,Apterygiformes
programming,1jtk7ky,mlvspgx,"> To know a tool well, you have to know:
>
> * its history: who created it? Why? To solve which problem?
> * its present: who maintains it? Where do they work? On what?

Respectfully WTF?",15,2025-04-07 16:06:28,somebodddy
programming,1jtk7ky,mm1u8ym,"One thing that is really lacking: Best programmers resist the temptation to use the latest and greatest frameworks, tools, and tech and to change/refactor things that are working.",2,2025-04-08 15:41:17,_z_o
programming,1jtk7ky,mm4d0ur,"This website has been temporarily rate limited

You cannot access this site because the owner has reached their plan limits. Check back later once traffic has gone down.

If you are owner of this website, prevent this from happening again by upgrading your plan on the Cloudflare Workers dashboard.",2,2025-04-08 23:13:33,thefinest
programming,1jtk7ky,mlysnec,how many programmers does he know? 5?,2,2025-04-08 01:53:51,zaphod4th
programming,1jtk7ky,mm1i547,"In addition to your post, I think keeping it simple is up there in importance. 

Also, adding to the working code isn't always the answer. I can't tell you how many times I've seen devs add a feature that was already there, the project just needed the slightest adjustment to the current code or, at times, a deletion if a few lines to get the expected result.

Great devs can fix/improve the code base while not adding craft.",1,2025-04-08 14:41:15,ktoks
programming,1k4c5g5,mo9lvvr,"    SELECT c_count, COUNT(*) AS custdist
      FROM
      (
        SELECT c_custkey, COUNT(o_orderkey) AS c_count
        FROM customer
        LEFT OUTER JOIN orders
          ON c_custkey = o_custkey
          AND o_comment NOT LIKE '%unusual%'
        GROUP BY c_custkey
      ) AS c_orders
    GROUP BY c_count
    ORDER BY custdist DESC;

---

    FROM customer
    |> LEFT OUTER JOIN orders
        ON c_custkey = o_custkey
        AND o_comment NOT LIKE '%unusual%'
    |> AGGREGATE COUNT(o_orderkey) AS c_count
      GROUP BY c_custkey
    |> AGGREGATE COUNT(*) AS custdist
      GROUP BY c_count
    |> ORDER BY custdist DESC;

---

Shameless [edgeql](https://geldata.com/) shill time:

    select (
      group Customer
      using c_orders := count(
        .orders filter .comment not like '%unusual%'
      )
      by c_orders
    ) {
      c_count := .key.c_orders,
      custdist := count(.elements),
    }
    order by .custdist desc;",19,2025-04-21 15:00:00,kaelwd
programming,1k4c5g5,moaody4,Try elixir,8,2025-04-21 18:22:37,hearthebell
programming,1k4c5g5,moapm4z,"I am confused.

Isn't that just method-calls on objects?

e. g. he used this example:

    fizz.get(bar).get(buzz).get(foo)

What is the difference? I don't even understand the word ""pipelining"". I thought about x | y | z piping.

Or this example:

    data.iter()
            .map(|w| w.toWingding())
            .filter(|w| w.alive)
            .map(|w| w.id)
            .collect()

I mean, that's method-chaining right? And the (|w| w.alive) that is almost
identical to e. g. in ruby block syntax, as a contrived example:

     cat.jumps_to(:jimmy_the_mouse) {|mouse| mouse.die! }

""Versus the SQL Syntax she told you not to worry about:""

    FROM customer
    |> LEFT OUTER JOIN orders

And that reminds me of elixir now.

I am super-confused. What is pipelining really?",9,2025-04-21 18:28:39,shevy-java
programming,1k4c5g5,mobu9n0,->>/->,3,2025-04-21 21:51:55,deaddyfreddy
programming,1k4c5g5,mohnj7f,I'm an old shell programmer who thought pipelines were about parallelism.,3,2025-04-22 20:09:47,TheAncientGeek
programming,1k4c5g5,moa8p7m,"> This is not real Rust code. Quick challenge for the curious Rustacean, can you explain why we cannot rewrite the above code like this, even if we import all of the symbols?

[What?](https://youtube.com/clip/UgkxQJJ_wSWdcEAL0SlM3my2FQoeYM2WoxNf?si=vPsfudiE2KZXy99A)... 

_Sure_, It doesn't _exactly_ work without full qualification as these functions are implemented on traits not just free functions in a namespace. You don't even need imports.

[All you need is some turbo fish](https://play.rust-lang.org/?version=stable&mode=debug&edition=2024&gist=c2f56a2cc250ff6fee2b486e52e8abc9).",6,2025-04-21 17:07:18,valarauca14
programming,1k4c5g5,mocvryf,"Are you familiar with [monad comprehensions](https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/monad_comprehensions.html), OP? I think that's the perfect example for pipelines in Haskell (or functional programming in general).",2,2025-04-22 01:25:21,BlazeBigBang
programming,1k4c5g5,mokc6fa,"From reading that, I'm not sure what the Rust code has to offer that is better than LINQ.",1,2025-04-23 05:55:52,jssstttoppss
programming,1k1lu1o,mnnlu6f,You’re going to ask for our password to check if it’s compromised aren’t you.,51,2025-04-17 21:20:10,Subsum44
programming,1k1lu1o,mnoj9zi,"I’ll repeat here what I said on /r/netsec:

> gs-loc.apple.com is an endpoint used by Apple to request user's location information.  It was called during a 3-minute recording of the traffic from a single opened app - Make More game. It didn't turn up ever before [when I was analysing other apps] + this game is on the Gravy list.
> 
> However, I don't want to make false claims saying that this app was responsible for Apple's request – that endpoint is not accessible directly for any app except for iOS itself, so in order to get the information from it an app needs to call a dedicated Apple API method and have corresponding permissions. Or maybe not?

I’m very curious about this.  If location services are turned off, apps should not be able to get this data. Bi want a part 3 if you figure this out.",24,2025-04-18 00:29:16,ScottContini
programming,1k1lu1o,mnpi7ko,"I bought some static IPs. I'm based in one state, those IPs were based in another. In a couple months, Google associated all of those IPs with my location - even ones that weren't enabled. So that's fun.",20,2025-04-18 04:24:37,Somepotato
programming,1k1lu1o,mnn3cnj,That's frickijg creepy!!,10,2025-04-17 19:48:32,TheShadowCraft
programming,1k1lu1o,mnq9x9w,"I'm not really understanding the location sharing implications that the title claims.  I fully acknowledge it might be because I'm ignorant. But what i understand is that apps and ads contact thousands of endpoints with your information they can find and that the requests have keys like Lat and Lon and Loc, etc and.. IP address.  Are the lat and lon somehow accessing your precise location with location services turned off or something?",3,2025-04-18 08:56:52,rav3lcet
programming,1k1lu1o,mnn3g5z,"Nice try, Tim, but you won't get me with the same trick twice!",5,2025-04-17 19:49:01,11fdriver
programming,1k1dylg,mnlhh34,"Good description of what seems to be certainly a bug in Apple's symbol loader. A bug that was not in iOS 18.3. It relates to dlsym (a function for fetching and resolving imports from a dynamic library).

Well written too, not overly wordy or AI slop. Recommended.

I gotta say though, I'm well over the ""considered harmful"" stuff. It's trite and adds no information. With a title like ""our efforts finding a new pointer signing bug in iOS 18.4 - and why Apple's code doesn't suffer from it"" would be nicer.

One of the two security bug fixes in iOS 18.4.1 relates to pointer signing. I wonder if it relates to this bug?",66,2025-04-17 15:06:50,happyscrappy
programming,1jmq53i,mkdonty,Best development environments are the ones that keep things as simple as possible.,122,2025-03-29 16:49:59,Isogash
programming,1jmq53i,mkdrrfp,"If it's a multi day project just for someone new to your code to get it running; that's entirely on your shitty code.

Containers shouldn't be a crutch to solve bad dev practices.",72,2025-03-29 17:06:21,Ok-Kaleidoscope5627
programming,1jmq53i,mkgghps,"Devcontainers support per-dev customisation in two ways I use all the time (I use vscode, not the devcontainers CLI, so I can't speak to how it works with that, but I'd hope these are supported, and if not they're possible):

* Per-user default features
* dotfiles home dir repos

The `dev.containers.defaultFeatures`user config option allows users to define a list of extra features that get installed into each devcontainer they open, in addition to the features configured on the devcontainer itself. You can use this to add tools you always use, or even write your own custom features to enable some custom workflow specific to you.

You can automatically install a dotfiles repo into the devcontainer, to set up your shell with the configuration you like, and install user-specific programs. You can use any dotfiles manager you like, e.g [https://yadm.io/](https://yadm.io/)

OP seems to dislike the idea that you'd invoke a package manager inside a container, and I feel like that's a bad take. Immutable environments are one use case for containers, not what every container should aspire to be. A container is just a loose concept for one or more processes that's isolated from the host OS to some degree. It's basically just a way of automating using a bunch of linux features like cgroups. This non-strict definition makes containers very practical as dev environments, as you can always poke more holes into them if you need to reduce the isolation to get something done.

I've been using devcontainers for years, and find them to be really practical and flexible for the most part. They are also great for increasing your level of familiarity with containerisation in general, as when you do bump into issues you generally need to know something about how containers work to understand/fix an issue. 

I do wish the vscode devcontainers extension was not proprietary though, as it's got a lot of room for improvement:

* The experience when a devcontainer image fails to build is terrible. VSCode makes you open a ""recovery container"" to try to edit the Dockerfile/devcontainer.json to fix whatever is broken. The recovery environment sucks, and afterwards you get a recovery devcontainer left sitting in your devcontainer history list for no reason.
* Managing/viewing your devcontainers is terrible, there's no sensible way to see them all and work out if you still need one, without opening it by searching by name/most recently used and then manually assessing if it's useful.
* It's not uncommon that it randomly breaks in some way, requiring a VSCode window reload, or restart of the container itself",10,2025-03-30 02:16:13,h4l
programming,1jmq53i,mkdsqis,"docker + nix does seem like pretty good idea on paper but I've never been able to get nix to work well for myself at least; how does it handle building for different linux variants?

a lot of people dont like or want to use nix so wrapping it up in a devcontainer, or some custom version of dev containers, seems nice to me.",8,2025-03-29 17:11:29,No_Technician7058
programming,1jmq53i,mkhkpkd,"I at least, encountered a problem, I never thought I would never have to think of. 


I wanted to develop an foundry but module. Thought docker ( for windows) would be a good idea. 


You have a module directory, and the rest is basically static, yes I could build the container every time I want to test the code


Or access the module directory directly in windows with my editor. 


But you don't have access to the directory within Windows in docker for windows...


So I installed the windows version of foundry lol",1,2025-03-30 08:05:46,Bitter-Good-2540
programming,1jmq53i,mkfm4f7,Nix nix we like nix,1,2025-03-29 23:12:58,Apterygiformes
programming,1jmq53i,mkflw3i,"Initially read that as ""Crack in containerized development"" and I thought we were talking about something else.",1,2025-03-29 23:11:39,Ambitious_Tax_
programming,1jz0ena,mn2mbak,"FWIW, while the Microchip XC32 compiler is officially paid, it's also a fork of GCC four point something. So you should be able to obtain a copy relatively easily. Not sure if any Linux platforms actually use it, but it's used with their MIPS microcontrollers.",36,2025-04-14 15:08:11,jaskij
programming,1jz0ena,mn9lffd,How do you debug a rust program that compiles to C? Just print statements? Or maybe a way to associate debug info with the Rust source?,1,2025-04-15 17:24:45,mungaihaha
programming,1jpn7oo,ml0n3fw,"LLMs are the killer of stack overflow, but like hunter and prey, when SO is dead, the LLMs will have nowhere to get their software question/answer training data from.

They can only exist together, so if by then AI can’t completely replace software engineers, the AI companies will need to set up something like SO.",190,2025-04-02 13:07:58,m-sasha
programming,1jpn7oo,ml0mkw2,This Reddit post has been marked as a duplicate.,47,2025-04-02 13:04:37,solve-for-x
programming,1jpn7oo,ml0ih6y,"Stack Overflow has been like a toxic friend that is helpful but a pain to be around. When there was no alternative place to get help, everyone used it despite the obnoxious tone maintained by the moderators and several of the participants on the platform. 

Now that there are alternatives, everyone is distancing themselves from the toxic friend. For me, the Stack Overflow culture is much more of a reason and an interesting story than another “AI killed it” piece…",31,2025-04-02 12:37:46,LoopVariant
programming,1jpn7oo,ml0x878,"i personally find so many questions on SO are actually duplicates. 

i bet almost 98% of the questions this week have a HINT OF AN ANSWER somewhere on SO. not an exact answer, but enough that the question should be a duplicate.  seriously, it is very rare that a real programming question (excluding problems that should be on github issue)  has no HINT OF AN ANSWER on SO. very fucking rare. 

unfortunately tho, people want EXACT ANSWERS to their very specific questions and don't want to read anything else, hence all the complaints about their question being a dupe.",23,2025-04-02 14:08:22,Few-Understanding264
programming,1jpn7oo,ml2axhz,"> However, with the rise of AI-driven coding assistants, the platform’s relevance has taken a hit. 

Perhaps AI took a further hit on SO, but the problems of SO have more to do with the design.

I remember several years ago, I was asking a question about mixing licences in a software project. It was a honest question, not a troll question.

Within 5 minutes, I was downvoted to something like -7 or so, in other words a few people simply downvoted it. Ok. Of all who downvoted, how many do you think explained their vote?

Zero. Nada. Nobody even responded to the question.

I checked the next few days and nobody wrote anything either; and the few who may want to write, were
discouraged by the negative votes already as-is. So, I am sorry, but the SO platform simply sucks for asking questions. I still find SO has value in older questions and answers, but this is just one problem of many. I asked a question, expecting people to say something useful, and got zero results. So basically I was wasting my time with SO here.

I am sure others can find related problems and anecdotes, but this is an example of the underlying design of SO simply not being good. They should have changed their voting and participation system a long time already really. They failed to do so, for whatever the reason. Since then it went further downhill.

AI may put the final nail in the coffin, but SO died prior to that already.",8,2025-04-02 18:12:17,shevy-java
programming,1jpn7oo,ml8g7rk,"1. Stack overflow was doomed before AI. ai just acelerated it

2. Llms dont need SO",3,2025-04-03 17:31:35,R3PTILIA
programming,1jpn7oo,ml10cxr,"I told the LLM to create a “stackoverflow” site and it did a pretty good job, then I told it to populate the site with questions and answers and again, it did a pretty good job. Now it can learn from itself, forever.",3,2025-04-02 14:24:31,rwrife
programming,1jpn7oo,ml0mx3l,"I don't get the hate around SO, being critical about your code isn't cool anymore or what?",3,2025-04-02 13:06:49,walkingcontradict1
programming,1jpn7oo,ml0yitf,"The only questions that will be most affected by AI at the ones where: 

- you want an answer
- and not an insult

If you're ok with one (or none) of those things, then Stack Overflow is the perfect choice.",-6,2025-04-02 14:15:07,Top_Meaning6195
programming,1jk6q79,mjv1no1,"I think the most important piece of information is missing. How well does it work?

It needs some kind of benchmarking.",14,2025-03-26 16:59:33,almost_useless
programming,1jk6q79,mjww04j,Inspired by [this](https://youtu.be/a0CVCcb0RJM)?,8,2025-03-26 22:17:56,sargeanthost
programming,1jk6q79,mjtj4pl,But does it use a middle out algorithm?,19,2025-03-26 12:08:43,3Eyes
programming,1jk6q79,mkbskko,"cool! i'll get a look at the repo. i'm learning Rust and the ""Audio"" world is so interesting",1,2025-03-29 08:28:47,uscnep
programming,1jk6q79,mjv0yf5,"Neat, can you expand on the fast audio recognition aspect? how does it identify the song? call to API somewhere?",0,2025-03-26 16:56:16,Successful-Peach-764
programming,1k4j6us,mobeyec,"A classic. I love this part:

*We could, for instance, begin with cleaning up our language by no longer calling a bug a bug but by calling it an error. It is much more honest because it squarely puts the blame where it belongs, viz. with the programmer who made the error. The animistic metaphor of the bug that maliciously sneaked in while the programmer was not looking is intellectually dishonest as it disguises that the error is the programmer's own creation. The nice thing of this simple change of vocabulary is that it has such a profound effect: while, before, a program with only one bug used to be ""almost correct"", afterwards a program with an error is just ""wrong"" (because in error).*",106,2025-04-21 20:33:58,NakamotoScheme
programming,1k4j6us,mob1uhz,"This is from 1988!? This is incredibly (and frustratingly) just as relevant today, if not more.",16,2025-04-21 19:29:02,larikang
programming,1k4j6us,mod0cwu,"If he genuinely accepts the premise that a mammalian brain evolved in a natural environment and therefore is better suited to certain kinds of concepts and conceptual relations then there's little reason to reject the use of these kinds of relations as teaching tools. In fact, there's every reason to suspect that without these thinking crutches most of us -- or perhaps none of us -- could master the advanced and abstract concepts which are the cornerstone of what he calls 'abstract science'.",13,2025-04-22 01:51:58,DragonSlave49
programming,1k4j6us,mof5tka,">The usual way in which we plan today for tomorrow is in yesterday's vocabulary. 

Yeah!

>It is the most common way of trying to cope with novelty: by means of metaphors and analogies we try to link the new to the old, the novel to the familiar. 

Yeah!

>our past experience is no longer relevant, the analogies become too shallow, and the metaphors become more misleading than illuminating. This is the situation that is characteristic for the ""radical"" novelty.

Yeah!

>The other thing I can not stress enough is that the fraction of the population for which gradual change seems to be all but the only paradigm of history is very large, probably much larger than you would expect. 

Yeah!

>[...]

>Finally, in order to drive home the message that this introductory programming course is primarily a course in formal mathematics...

What. The. Fuck.

>(Formal math? The thing I know and enjoy teaching?
>>""Teaching to unsuspecting youngsters the effective use of formal methods is one of the joys of life because it is so extremely rewarding.""

>Surely this is the answer.)

------

Good piece of writing, but the conclusion is so absurdly the exact same trap he described initially *AND* not solving it at all, is hilarious.",4,2025-04-22 12:35:57,not_perfect_yet
programming,1k4j6us,modqe0r,"Dijkstra was one of those hardliner mathematician who thought programming is mathematics. You may prove certain properties of a program here and there but some properties cannot even be proved.

How will you prove a Chrome browser or a video game? Thank god nobody listened to him, and rightly so otherwise we would never have any games ever because you cannot prove them. Programming is not mathematics nor is it science. 

Program proving is a very niche but very important field and there is every reason to be excited but seriously Dijkstra was kinda nuts. I once wanted to read him and in a preface he says something about I couldn't care less about bibliography, lmao. That turned me off. 

Also, Computer Science is a terrible word for this field. It is neither about computers nor is it a science.   I like the word Informatics that they use elsewhere.",1,2025-04-22 04:42:18,Symmetries_Research
programming,1k4j6us,mocxsto,It’s a bug dammit,1,2025-04-22 01:37:10,Nice_Set_6326
programming,1k4j6us,mog2w8e,">(2) the subculture of the compulsive programmer, whose ethics prescribe that one silly idea and a month of frantic coding should suffice to make him a life-long millionaire

spotted vibe coding 40 years ago",1,2025-04-22 15:34:15,NotMNDM
programming,1k4j6us,mobccin,This could have been written in less than a quarter of the copy. I also disagree with most of it.,-7,2025-04-21 20:21:15,Icy_Foundation3534
programming,1k3mjlz,mo38bd0,"> This part will focus on why I think it is an important improvement over the git's status-quo and why I use it daily.

It feels like the article never really went into explanation on why it's an improvement over git.",110,2025-04-20 13:43:47,jhartikainen
programming,1k3mjlz,mo55pa5,"
I think saying changes are branches is pedagogically confusing. Bookmarks should be understood as branches. Then you can just say that the unit of work is not a branch, but a commit, which is in fact the biggest jj strength

Personally I'm not a big fan of ""here's git but jj"" kinda of articles. They usually don't really highlight jj's best features. This one does go over the, very good, feature of always having everything committed, but that's kind it. The real power of jj is how you can manipulate the version history easily and safely

I think if you gonna talk about jj, it should highlight how `new/rebase/squash` gives you full power over your history and `jj op log` makes it impossible to screw it up. It should be contrasted with how much, much more difficult and dangerous the same actions are in git. This article makes it seems jj is harder than git and it definitely isn't, on the opposite, jj is vastly easier than git

edit: hijacking my comment to recommend the absolutely wonderful https://github.com/idursun/jjui. If you liked magit (and its clones), lazygit or even just vim, just will be right up your alley. In no exaggeration, I do all kinds of complex manipulations on my git history without even thinking with this plugin. Just incredible UX",26,2025-04-20 20:00:15,teerre
programming,1k3mjlz,mo5ibqo,"Does it support pre-commit hooks yet? Many workplaces seem to be using those as a way to prevent accidentally committing and pushing secrets into their repos. Without that, Jujutsu won't be a viable replacement there.

EDIT: even if the process looks slightly different with Jujutsu, if it can provide some way to fail out before 'recording' any data, it should still be viable.",10,2025-04-20 21:10:42,yawaramin
programming,1k3mjlz,mo3hd9m,That's a lot of words and no concise explanation of what's different/better. Does it just automatically throw every change into a commit?,17,2025-04-20 14:36:21,wineblood
programming,1k3mjlz,mo3a084,I can't think of of a use case where I would want to track every key press. Which seems to be the only feature that's not just a renamed and over complicated git feature.,26,2025-04-20 13:54:00,Few-Satisfaction6221
programming,1k3mjlz,mo41xqd,"I think it’s important to note

> Jujutsu is an experimental version control system. While Git compatibility is stable, and most developers use it daily for all their needs, there may still be work-in-progress features, suboptimal UX, and workflow gaps that make it unusable for your particular use.

Also it still uses Git on the backend so right now it’s more of a front-end tool for Git than a full fledged VCS.

It’s got some interesting features, mostly taken from other VCS, but rn it’s just something that might be worth a revisit once it’s more mature.",9,2025-04-20 16:27:31,arpan3t
programming,1k3mjlz,mo81ly1,"Fancy, send like it's basically a frontend for git. Including, from the article I could not gather exactly what issues from git it solves. The keeping track of all writes seems neat but would do nothing for me, personally.",2,2025-04-21 07:55:28,Efficient_Role_7772
programming,1k3mjlz,mo3zqrl,"If changes are linked by IDs that are not content-addressed, how can they be shared by multiple people?",2,2025-04-20 16:15:54,lifeeraser
programming,1k3mjlz,mo87ioj,"> In Jujutsu, one doesn't make a merge of branches. Instead, one makes a change with several parents: jj new rev1 rev2 rev3, where rev1, etc. are either change-ids or branch-names (or some other interesting things we did not talk about yet).

That is LITERALLY what merge commit is.

Git's commits are snapshots of state of the tree that just happen to have parent added. Merge isn't special here at all",2,2025-04-21 08:57:59,CrunchyTortilla1234
programming,1k3mjlz,mo6wa4s,"I used to use CSV, but now I manage all my projects with Git. I'm so deep into the code every day that I don’t have time to keep up with version control updates.",1,2025-04-21 02:08:33,Hungry_Importance918
programming,1k3m2fd,mo3brlk,"    fn main() {
        println!(""Max Verstappen"");
    }",254,2025-04-20 14:04:26,Bumblebeta
programming,1k3m2fd,mo34wxj,Cool project. How did you come up with the driver stats? Eg difficult to quantify yukis skill in wet in a car he's only driven once so far.,30,2025-04-20 13:22:39,s32
programming,1k3m2fd,mo4ia8i,"WAT

================================================================================
2025 FORMULA 1 GRAND PRIX - JEDDAH CORNICHE CIRCUIT
Location: Jeddah, Saudi Arabia
Track Length: 6.174km - 50 laps (308km)
Weather: Dry - 29.2°C, Rain: 12%
================================================================================


QUALIFYING RESULTS
------------------------------------------------------------
|   Pos | Driver            | Team            |   No. |
|------:|:------------------|:----------------|------:|
|     1 | Kimi Antonelli    | Mercedes        |    87 |
|     2 | Lewis Hamilton    | Ferrari         |    44 |
|     3 | Lando Norris      | McLaren         |     4 |
|     4 | Max Verstappen    | Red Bull Racing |     1 |


RACE RESULTS
--------------------------------------------------------------------------------
|   Pos | Driver            | Team            |   Start | Change   | Time/Status   | Pts   |
|------:|:------------------|:----------------|--------:|:---------|:--------------|:------|
|     1 | Lando Norris      | McLaren         |       3 | ↑2       | 74:02.033     | 25    |
|     2 | Nico Hulkenberg   | Kick Sauber     |      13 | ↑11      | 74:16.514     | 18    |
|     3 | Max Verstappen    | Red Bull Racing |       4 | ↑1       | 76:20.735 FL  | 16    |
|     4 | Esteban Ocon      | Haas            |      11 | ↑7       | 78:13.426     | 12    |
|     5 | Carlos Sainz      | Williams        |       9 | ↑4       | 80:34.012     | 10    |
|     6 | Fernando Alonso   | Aston Martin    |       7 | ↑1       | 80:38.745     | 8     |",20,2025-04-20 17:53:05,afranke
programming,1k3m2fd,mo3muin,Let's just say I did not read the F1 bit at first,12,2025-04-20 15:06:17,robidaan
programming,1k3m2fd,mo5zl2r,AI slop spotted,7,2025-04-20 22:53:35,bruhmanegosh
programming,1k3m2fd,mo4pydf,So how good was it to predict the first few weeks of the season so far ?,3,2025-04-20 18:33:35,Ythio
programming,1k217n0,mnrleo7,Couldn't you also include a vertical reflection of the board and then not  have to account for whether the white king was above or below the black piece?,11,2025-04-18 14:41:19,goodnewscrew
programming,1k217n0,mnqywbi,"Well this checks if the king could be in check, but I don’t see how you’re checking that there isn’t a piece in between, say, the king and a queen.

What I’m saying is that there are two pieces on the board, then you’ll get the right answer, but if there are three, then how do you know an attack is not blocked?

Interesting technique tho!",9,2025-04-18 12:33:00,DXTRBeta
programming,1k217n0,mnxar5r,Love this. Would be interested to see his approach to testing false positives though. Obviously he can't test every board configuration..,1,2025-04-19 13:36:02,Ok-Regular-8009
programming,1jyue2l,mn1blkg,so Smalltalk-y,15,2025-04-14 09:53:47,phil_gal
programming,1jyue2l,mn279rx,Interface Builder still ships with Xcode and you can use it when building with AppKit or UIKit,15,2025-04-14 13:48:38,__deinit__
programming,1jyue2l,mn1g4vx,"Tools like OpenStep Interface Builder, VB, or MS Access are dated, but they nailed rapid GUI building. There’s still a gap today for something that lets you quickly sketch and wire up a UI with minimal effort.",54,2025-04-14 10:37:56,Evening_Total7882
programming,1jyue2l,mn286ok,"The example text typed into the text field: ""sfsadfsdfa sdf"". There's something very satisfying about the utility of that rather than a probably-focus-grouped-example like ""OpenStep's Interface Builder will change programming""",11,2025-04-14 13:53:42,buckenmuck
programming,1jyue2l,mn1wblz,"What year is it?

This is a video from 1991 where Bill Gates shows VB, which was mind boggling and ground-breaking at the time: https://www.youtube.com/watch?v=Fh_UDQnboRw",10,2025-04-14 12:41:58,baal80
programming,1jyue2l,mn38ept,Love your username.,4,2025-04-14 16:58:56,happyscrappy
programming,1jyue2l,mn3ki5b,Steve Job's young years when he rebelled by having as little collar as possible.,2,2025-04-14 17:57:24,gomsim
programming,1jyue2l,mn5ef40,"Here's an [older video](https://youtu.be/rf5o5liZxnA?t=1387), from 1992 or so.",2,2025-04-14 23:46:50,self
programming,1jyue2l,mn72drz,Relevant: https://paulhammant.com/2013/03/28/interface-builders-alternative-lisp-timeline/,2,2025-04-15 07:05:13,paul_h
programming,1jyue2l,mn7rq1y,Stating the obvious for those without context: it all fell apart the moment you have to collaborate on such files with version control tools such as git.,2,2025-04-15 11:23:10,macchiato_kubideh
programming,1k4sur2,modd9nu,"Sad. Seems like the main reason for withdrawing it is concerns over performance for deep value comparisons. The alternative proposal is for a library-type that uses interning so that equality comparisons will always just be a pointer check -- I wonder why that optimization couldn't be left as an implementation detail for JavaScript engines?


Deep value comparisons don't even seem that concerning to me tbh -- in Rust-land deep comparisons are everywhere and they're almost never problematic. ",60,2025-04-22 03:09:03,JoJoJet-
programming,1jn099y,mkh6cpl,I found found the atop title bug everyone is going crazy about: duplicate word!,102,2025-03-30 05:34:36,Paddy3118
programming,1jn099y,mkfzlkh,"If Bismuth found this ""in minutes"" with AI, I wonder how many exploits have been found by the NSA and other countries using similar tools.",75,2025-03-30 00:32:13,prescod
programming,1jn099y,mkh24s0,"Fun ad, but if you're looking to pay for a service coverity has been finding this kind of bug for decades.",26,2025-03-30 04:56:36,happyscrappy
programming,1jn099y,mkhwn2z,"What does this tool even do? I'm struggling to find a terse description.
It's project/task manager right? Kanban/agile?",1,2025-03-30 10:16:44,MartynAndJasper
programming,1jn099y,mle8iqn,"Who expects a service to run on _an ephemeral port_?

Forget the protocol bug, expecting to find a specific service on _an ephemeral port_ means someone missed Linux 101. Ephemeral ports are for the OS to allocate, one should NEVER bind to one.

So, quick rundown, in Linux:

 - Port 0 is NOT a real port. Asking for port 0 actually means Linux will pick up an ephemeral port for you.
 - Port 1-1023 require root access, that's where 22 (SSH), 80 (HTTP) and 443 (HTTPS) run, for example.
 - _Typically_ Ports 1024-32767 are for the user to manage.
 - _Typically_ Ports 36768-65535 are ephemeral ports, for the OS to manage.

But really, each Linux host can be configured differently, so the actual ephemeral range should be queried, for example by reading `/proc/sys/net/ipv4/ip_local_port_range`.

Now, of course, I know. Not everybody knows about ephemeral ports. Sure. But for the authors of a sysadmin tool... this certainly raises questions. I wouldn't be comfortable using `atop` when they miss such ""trivial"" sysadmin knowledge, who knows what else they miss.",1,2025-04-04 16:09:07,matthieum
programming,1jn099y,mkiyp9j,"Another day, another critical security issue in a fundamental ecosystem tool relied upon by millions.

I know it’s dangerous to mention the R-word on r/programming, but this problem would not have existed if the program was written in that certain other language. How many more millions are we willing to sacrifice by stubbornly sticking to our dangerous and outdated guns?",-5,2025-03-30 14:57:16,simonask_
programming,1jukuv3,mm48gof,Nice writeup!,7,2025-04-08 22:47:57,organman91
programming,1jukuv3,mm5vda8,"Hey OP, cool article.

One minor note: you may want to mention that `where` is a zsh-only built-in. I just checked and no other shell has it. I thought you'd mistyped `which` at first.",6,2025-04-09 04:56:31,pihkal
programming,1jukuv3,mm4qcch,"> We know that ELF is the traditional binary format that Linux uses 

I couldn’t help but recall the [trauma of the migration to ELF](https://web.archive.org/web/20040713171954/http://www.ibiblio.org/pub/historic-linux/distributions/slackware/3.9/docs/ELF-HOWTO) from a.out when I read “traditional binary format.”

Hardly traditional, a.out as the Linux binary format is a historical footnote, rightfully omitted.",9,2025-04-09 00:30:12,Admqui
programming,1jukuv3,mmd4pjh,I had a prof who always pronounced it hash-bang,2,2025-04-10 10:21:28,StarkAndRobotic
programming,1jukuv3,mmor8xs,"Nice one!

Another related series: https://cpu.land/",2,2025-04-12 05:08:54,Still-Knowledge-5302
programming,1jlsyzq,mk8b2tp,"Would be nice if they'd release actual features too, instead of just ways to specify features. The development of WASM has been nothing short of glacial.",55,2025-03-28 18:46:08,pip25hu
programming,1jlsyzq,mkac0cz,I'm a huge supporter of the need for formal semantics and provable properties of code bases. This is an immense step forward in complex language management and sustainability. Congratulations to everyone who contributed to this! Well done.,8,2025-03-29 01:17:09,rajandatta
programming,1jlsyzq,mk6dev4,"Stop slacking and make fucking DOM access instead instead of wanky ""features""",16,2025-03-28 12:55:50,CrunchyTortilla1234
programming,1jlsyzq,mkap94f,ASCII will be much easier to parse than trying to grab the grammar from the RST files.,1,2025-03-29 02:38:09,SCI4THIS
programming,1jlsyzq,mkd7yhd,"Ok but ... what does this enable us to do? I am a bit confused as to what this is useful for, in practice.",1,2025-03-29 15:18:35,shevy-java
programming,1jos4s2,mkubcku,"I spent over an hour trying to get copilot to do something and then 5 minutes on stack overflow finding the right answer. I’m sure for some things it works well, but if you have something a bit more complicated in a lesser used language then it struggles.",149,2025-04-01 11:55:55,RandomisedZombie
programming,1jos4s2,mkuab9x,"I usually don't read these kinds of articles but I feel like you did a great job articulating the problem with too much AI interaction: you're no longer in the drivers seat which means you start losing important skillsets that make you good at your craft.  
  
I still use AI for really basic autocomplete via codeium extension, so its much less obtrusive as others.  
  
For rubber ducking I do talk to AI about topics, but I make sure lead the conversation, not the other way around. So for instance, I explain the algorithm I have in mind and we discuss if that would work well in a specific context to get another perspective rather than ""I have this problem what should I do"".",60,2025-04-01 11:48:13,Craiggles-
programming,1jos4s2,mku50o1,"I never really tried co-pilot. I always thought having AI auto complete block of your code is just too much/intrusive. But as modern rubber ducking tools, it's nice.",42,2025-04-01 11:05:22,aaulia
programming,1jos4s2,mkx2kma,"AI code editors ruin the joy of programming, period.",22,2025-04-01 20:51:02,LinearArray
programming,1jos4s2,mkwe17i,I am learning C after learning Python before as a hobby and I find Copilot in Neovim way too disruptive. I enjoy the chat as I can ask it to explain the code or concepts but the code completion mostly works against me as I need to type it myself to learn. Had to disable it.,6,2025-04-01 18:45:52,Mnaukovitsch
programming,1jos4s2,mkzy9ng,"I replied to a [similar post here](https://www.reddit.com/r/programming/comments/1joeiaj/programming_with_an_ai_copilot_my_perspective_as/mktvhux/) and think the comment is relevant to yours.

I've heard many senior devs make similar observations--and this is not meant to be a criticism--but I wonder if this is the same sort of elitist attitude craftsmen in the past would have had to new industrial machinery. 

Essentially, I think you are broadly correct but it became clear to me very early on that 'prompting' is basically programming in human language. Non-deterministic yes, but programming nonetheless. It's just as non-deterministic as human programmers implementing the specifications from software architects and project managers. We're just at another level of abstraction and human language will become a form of programming language.

Current programming languages are different in that they are more precise and specifically designed to communicate with computers. That doesn't necessarily mean they're intrinsically better at building systems though. Programming languages are definitely better _right now_ because that's the tool we've learned to use.

We haven't learned to use human languages to build software but people have been building things with human language long before software came along. Maybe we just haven't yet learned to use human language in place of computer language. There's no reason you can't constrain human language to be more precise. There's also no reason that building systems necessarily needs to be very precise. Perhaps the lack of precision can be made up by very quick iteration.

Think about how Agile came along when 'the professionals' were using Waterfall. People thought that the 'chaotic' nature of Agile wouldn't work, yet Agile proponents made it work, and arguably it's the most popular methodology he have right now. There is still a need for Waterfall, and there'll always be a need to have very precise language to specify what a computer should do. Nevertheless, most projects don't need Waterfall, and maybe most people won't need the precision of dedicated programming languages.

Our profession is still in the very early stages of this thing and I suspect that prompting will be the coding of the future. There will still be the need for low-level coders to some extent, but most people won't program in the way we do now.

When I was at school, we first learnt to program using logic gates, diodes, transistors, ICs and other electronic components. Afterwards it was BASIC, Pascal, C, and so on. Fast forward into the future and I no longer need to solder components onto a circuit board, nor do I need to compile a program because I mostly use Python and a bunch of web technologies to make things happen.

I don't need to be concerned about all the lower level stuff. I don't even need to remember to allocate or deallocate memory, keep track of my pointers, or clean up garbage collection. It's all done for me.

I think it will eventually be the same with AI coding. We'll tell the AI what we want and it'll figure out the details, then produce the application. This isn't some baseless hypothesising either. My workflow now has the basics of this being put in place.

I have a requirements assistant that helps me translate a client's informal discussions into a BDD document. I'll then feed that into a software architect assistant that will recommend the basic components for the solution. Then I can use something like Replit or other AI coding assistant to give me a quick prototype. From there I can start building out the components 'for real'.

Yes, all of this still requires a hands-on approach and 25+ years of programming experience. But I do wonder if future programmers will need everything I've learned, or if we'll need as many techs as we do now.",4,2025-04-02 09:45:36,anothercoffee
programming,1jos4s2,ml5ylaj,"Very good article, and summarizes my thoughts completely.

Putting aside the fact that AI is not always generating useful code, the biggest problem I see with AI is the fact that it removes you from the equation. I believe that in the end, if everyone can prompt AI the same way you can, you are no different and very disposable. Learning and expertise come from the journey, not the destination, and it seems like AI is here to eliminate the journey altogether.

P.S. Nice blog, and lovely design.",2,2025-04-03 07:45:03,skwee357
programming,1jos4s2,mkutucu,"I""m an intermediate and I simply can't keep up with senior engineer velocity without leveraging cursor. They themselves will use AI for all but domain modelling. The speed at which you can add unit/integration tests, frontend storybooks, and reimplement existing patterns in your codebase is hard to beat. For context, it's a full stack role in a startup working on new features (ie we're not a product company in maintenance mode). 


The top comments talking about dabbling in GitHub copilot 2 years ago aren't relevant to the discussion. A coworker from my last job just sent me a screenshot of his eng slack this morning - they've moved from vsc to cursor as their default IDE.",6,2025-04-01 13:55:08,Lersei_Cannister
programming,1jos4s2,mky24uw,"Lots of crazy talk in here.  I started using cursor about a month ago and the experience has been nothing short of amazing.

Gone are the days of grunt work unit tests and coding out each crud page by hand - it’s now a 5 minute task.  

Learn how to use it or be left behind.",1,2025-04-02 00:14:15,dtown123
programming,1jos4s2,mkugbg0,"I'm not saying you should use these tools on every task, in every project or with every tech stack, but generalizing to ""if you use this too much, you will lose your skills"" is nonsense.  Eschew these tools if you want, but I think you're doing so at a great risk to yourself. 

The comparison to self-driving made me think: OP was always a bad driver, self-driving just made them realize it.",-8,2025-04-01 12:31:03,elh0mbre
programming,1jqk43q,ml7j4yz,"That’s honestly extremely impressive.

Is CSS turing complete these days? It never would have occurred to me to wrap so much custom logic all within CSS.",20,2025-04-03 14:49:32,MakesUsMighty
programming,1jqk43q,ml8a3oe,Too bad the performance sucks on mobile. Really sluggish scrolling. ,6,2025-04-03 17:01:55,blamethebrain
programming,1jqk43q,ml9u5ow,"ah, of course it doesn't work on safari macOS, but Firefox nice!",2,2025-04-03 21:39:54,bonnydoe
programming,1jq7o3e,ml79hor,"Without going too much into singing praises, it's remarkable to see a:

- new graphic editor 
- FOSS
- written in Rust
- using nodes (i.e. non-destructive editing) 
- supporting both vector or raster.

Kudos! I'll get to donation page ASAP.",10,2025-04-03 14:00:34,-Y0-
programming,1jq7o3e,ml51xgi,"As we finish off Q1 of this year, here's a look back at last year's Q4 progress. Stay tuned for updates on this quarter's developments, which includes shiny features like **animation!**

Graphite is a data-driven creative design engine that combines an artist-friendly image editing environment with a procedural graphics renderer built with Graphene, a custom Rust-based compiled functional programming language for portable, scriptable graphics pipelines.

Also: this is the last week to apply for a summer internship building Graphite with us, in Rust! Info here: [https://graphite.rs/blog/internships-for-a-rust-graphics-engine-gsoc-2025/](https://graphite.rs/blog/internships-for-a-rust-graphics-engine-gsoc-2025/?utm_source=reddit&utm_campaign=programming)",9,2025-04-03 03:03:12,Keavon
programming,1jtp3z2,mlxmjdo,is openrsync compatible with rsync?,14,2025-04-07 21:45:34,wapskalyon
programming,1jtp3z2,mlyg4dn,Can't be worse than make 3.81.,3,2025-04-08 00:37:41,happyscrappy
programming,1jtp3z2,mmr1oaq,"I'm so grateful for this article, because when the behavior changed, I couldn't figure out why, particularly when they both claim to be the same 2.6.9 version (or at least ""compatible"" with it). Long story short, if you're finding that directory-based include/exclude rules are not working, try adding a trailing slash to the source path. old rsync didn't need it (and could apply the same set of rules to multiple input directories), new one totally does (you have to hide the parent directory for it to make sense of generic layout rules).",2,2025-04-12 15:59:52,kehawk2
programming,1jtp3z2,mmdjxrf,"The next replacement will have to be called `openestsync` since this one is already `openr`. 

... I'll show myself out",1,2025-04-10 12:19:21,Carighan
programming,1jtp3z2,mmlleg1,If you care about what happens when you type rsync then you should probably not be relying on the system rsync. Just install the one you want.,1,2025-04-11 17:45:37,bananahead
programming,1jtjzl5,mlux24x,"Something about this rubs me the wrong way.  I don't necessarily disagree with it from a broad standpoint but I think it adopts a black and white view where it shouldn't.  I think I've got 2 main problems:    
  
1) It seems to advocate for either unit testing or integration testing rather than a combination of both.  Integration tests are fantastic at tell you something is wrong but unit tests are a much better resource for identifying exactly what is wrong.  I think the hardest part of testing is identifying the right line.  People frequently go too fine grained on their unit tests to the point where they become impossible to maintain which leads them to doing integration only testing.       
  
2) It seems like it advocates process and convention to compensate for bad design.  I 100% agree that you shouldn't mock useState but that's not because it's a framework dependency, it's because it's a mutable value you don't control.  Once you've introduced useState, your function input is no longer predictable and your unit tests are brittle.  It's no different than having a test dependency on a class property when testing something in OOP.",43,2025-04-07 13:17:28,darkpaladin
programming,1jtjzl5,mlvsxnj,"I'd argue that something as fundimental as useState being mocked is a code smell in your design. You're supposed to test the whole unit, and the unit presumably takes in some props, and maybe fires events. What are you doing mocking the state when you can control the input data to directly drive the test in the dom.",20,2025-04-07 16:07:40,blind_ninja_guy
programming,1jtjzl5,mlw6clm,">Create Thin Adapters Around Libraries

Don't mock your framework - create thin layers  
It is like saying I flood my house to protect it from fire hazards",13,2025-04-07 17:16:19,gjosifov
programming,1jtjzl5,mm2lsip,"I used to hate unit tests. They were nightmare to maintain, they broke a lot and never found anything.

It all changed with Ian Cooper's video:  
**TDD, Where Did It All Go Wrong (Ian Cooper)**  
[https://www.youtube.com/watch?v=EZ05e7EMOLM](https://www.youtube.com/watch?v=EZ05e7EMOLM)

I switched to Chicago School of tests and later the whole team switched. Now the unit tests are fun, they give us fast feedback if the feature is working. Event TDD started to make sense. And what's more important, the test don't break when refactoring happens.

How? We tests the behaviors of **modules,** not classes/methods in isolation. And since all classes collaborate, we don't need mocks. Inputs and outputs of the module are covered by Fake objects (plain builders, easy to control and reuse). Of course to make it work you have to isolate your business logic from your infrastructure code. But you all know that from Hex Architecture.",5,2025-04-08 17:54:12,steve-7890
programming,1jtjzl5,mlw027x,"Unit tests have a lot of obvious value on static code, and are easy to write for static code.

But for anything other than static code I have to say I have lost any sense of value of anything that isn't a true end to end integration test.

IMO if something is important, it should be either static logic (and thus easily testable) or capturable by examining user interactions via an integration test. Otherwise - why / how is it important, exactly? All a system is, is its behaviour in response to user interactions and time. That's all any system is - there is literally no other variable. The tests act as regression checks on code mutation.

There's no point testing that the right separation of first+last name gets inserted into the DB, if that is never surfaced to the user in a meaningful way. What difference could it possibly make to anyone if that behaviour changed but the user interactions did not change? It's a waste of a test.

I honestly think anything else is just misdirection, or made necessary because your system is not up to scratch (EG, people mutating DB directly causes need for excessive service tests).

Once you have a comprehensive suite of integration tests I think it's the best possible place to be. They are good at describing what is wrong, and it may take a little more effort to find out what went wrong, but any error is linked to a changeset so it's hardly onerous.

And, as a bonus, an integration focused way of testing lets you capture business requirements and failure cases extremely easily in tests. Much more easily than translating user interactions into what _you think_ the DB structure should be, so you can do a service level test on it.",11,2025-04-07 16:44:26,Inevitable-Plan-7604
programming,1jtjzl5,mlxw8ct,">Google's Testing Blog later gave this concept a URL in a 2020 ""Testing on the Toilet"" article titled [Don't Mock Types You Don't Own](https://testing.googleblog.com/2020/07/testing-on-toilet-dont-mock-types-you.html?ref=laconicwit.com) which warned:

> > The assumptions built into mocks may get out of date as changes are made to the library, resulting in tests that pass even when the code under test has a bug.

More Google testing advice ([see previous](https://abseil.io/resources/swe-book/html/ch13.html#:~:text=A%20real%20implementation%20is%20preferred,a%20list%20or%20a%20map.)) which says that the problem with unit tests is that they aren't integration tests 😒.

I swear, all the hate that stubbed fakes get stems from (1) issues caused by *functional* fakes (which people conflate with stubbed fakes) (2) arguments that they don't catch issues caused by interactions between components (when that's not the goal of a unit tests).",5,2025-04-07 22:40:57,you-get-an-upvote
programming,1jtjzl5,mlwj6k6,"The first two points as to why you shouldn't mock frameworks are reasons to mock frameworks. If your tests make assumptions about how third party libraries work and the libraries change, your tests should fail. That is true whether they use mocks or integrations. That being said, it is a problem that your code is too coupled to framework APIs, but that has nothing to do with mocks. It is just good system design. Create clear integration points with third-party libraries, that way if the library changes, you just update the single integration point.

In my opinion, integration with third party libraries is a clear use case for mocks, but, as the article says, you shouldn't mock the third party library directly, but instead create a thin abstraction that you mock so you can control the interface. Integration tests are \*not\* sufficient to unit test code that integrates with third-party libraries as you are unlikely to be able to test error states (on top of other issues, like apis that have quota limits, violate SPAM laws, or create payments).",4,2025-04-07 18:20:15,itijara
programming,1jtjzl5,mlv67hw,Here is a better idea: Mock only as a last case resort.,3,2025-04-07 14:10:55,-Y0-
programming,1jtjzl5,mlysesf,"When it comes to testing web services specifically, the best approach I've found is to use something like Playwright and focus most of your efforts on writing integration tests that only query/interact with elements using markup-agnostic selectors (e.g aria-label).  I'll write unit tests for complicated bits of code I know I'm going to screw up.

The advantage to this approach is you can test the functionality on both the client and the server while avoiding the implementation details.  This is especially nice if, for example, you decide one day to switch your communication mechanism from JSON to Protobufs.  Because your tests don't care about those implementation details, you got the closest thing to ""fearless refactoring"".

The downside is if you're not familiar with the codebase, you're going to have a hard time figuring out what the problem is if a test breaks.  Another is writing the unit tests are a pain in the butt since you need to manually create data for your service to interact with, and then on top of that, you need to write the selectors to interact with the web page.  And while the markup-agnostic selectors do help, you're still at risk of breaking your tests if you decide to shuffle some components around.

Is anyone else doing something similar?  This approach is far from perfect, but I think it gets you the most bang for your buck.",1,2025-04-08 01:52:25,Aggressive-Pen-9755
programming,1k1fmd1,mnlwuwy,"It’s not really diskless. It just puts the responsibility of the disk in someone else’s hands by replicating to object storage.

Kafka officially coming to eat WarpStream’s lunch.",44,2025-04-17 16:21:14,sleeping-in-crypto
programming,1k1fmd1,mnlo2h7,100% less durable,0,2025-04-17 15:38:42,visicalc_is_best
programming,1k1fmd1,mnqf1ab,...or just use https://buf.build/product/bufstream and save money while you're at it.,0,2025-04-18 09:50:32,brutal_seizure
programming,1jsr4ue,mlsk6w2,TL;DR: epoll,12,2025-04-07 01:17:34,commandersaki
programming,1joanyp,mkrp4i6,[removed],28,2025-03-31 23:08:44,N/A
programming,1joanyp,mkrypuo,"Turbo Pascal 3.0 was where things peaked. It’s all been downhill since then. 

Source: Am an ancient programmer",19,2025-04-01 00:04:30,grout_hater
programming,1joanyp,mkqk3pe,"VS2005 was peak IDE.

I worked with a team making an OG Xbox game back in the day. Their daily routine consisted of

1. Get the latest code from Visual SourceSafe
2. Turn on Xbox.
3. Hit F5.
4. Edit and Continue all day without ever restarting anything.
5. Hit Shift-F5.
6. Turn off Xbox and go home.

Software development has been all downhill from there.",30,2025-03-31 19:32:45,corysama
programming,1joanyp,mksnwse,1976-2025: vi,10,2025-04-01 02:41:12,Cube00
programming,1joanyp,mku7dff,"> Not a single developer today could stand a week in Turbo C 1.0, which didn’t even have syntax highlighting. 

Challenge accepted![1]

I have here, next to me, my Borland  TASM manual and Turbo C++ 3.0.

I will happily (i.e. ""for money"") write the application of your choice, over a week using nothing but those two applications, running on dosbox.

Just tell me what type of 1-week application you need for MSDOS, and I'll give it to you.


[1] Some of my fondest memories were writing C in TC++3.0, *with no syntax highlighter*.",7,2025-04-01 11:25:07,lelanthran
programming,1joanyp,mkulvhb,"Eclipse is one of the best non-web windows-era IDEs. People complaining it was slow because they installed a ton of plugins on top of the already bloated JavaEE version was unfair. The Barebones Java version is one of the fastest and most complete Java IDEs out there, it runs in circles around the IntelliJ cruft. It has versions for Python, C and many other languages. 

I remember I carried the Python version in a pendrive to college back in the day (it is portable). I had a full black-themed IDE where I could create Python unit tests literally with a right click. Meanwhile the others were wrestling with emacs because that's what the professor insisted on using. Overall most of the class spent 2 full days getting accustomed to emacs.",5,2025-04-01 13:06:58,st4rdr0id
programming,1joanyp,mkyk7wl,"I bought Turbo C the day it came out. I had pre-ordered or reserved a copy at my local Egghead (remember that store) and drove in the pouring rain to get my copy - skipping class, I’m sure. I was so excited as I installed it via 5.25” floppy disk on my Compaq Luggable. Such fun. 

Up to that point I’d been using Epsilon (Emacs clone) and Aztec(?) C and later MS C compiler.",3,2025-04-02 02:07:26,lisnter
programming,1joanyp,ml06x3p,Influencer AI Medium spam makes me long nostalgically for the days of corporate blog spam.,3,2025-04-02 11:10:33,not_a_novel_account
programming,1joanyp,mkt8q7n,"1983-2025: emacs (and clones mince*, jove, and loosely X-Code).

*Edit: Mark of the Unicorn ""Mince"". An Emacs clone with low memory requirements ran on CP/M and early MS-DOS. I originally used in on the CP/M 86 OS. After it was ported to early MS-DOS systems, the publisher released full source code. I enhanced it to support macros (not Lisp) and expansed memory systems up 1mb.",3,2025-04-01 05:21:38,brettmjohnson
programming,1joanyp,mkr410m,"I'd like all editors and IDEs to be modular to no ends.

I am using an ancient editor that has been abandoned decades ago already, so a bit like Linus with his microemacs. I'd like to change to a better editor too, but I would also lose some key functionality (I tried many editors). I really wish it would be easier to combine features and functionality as well as different programming languages. 

This isolationist approach in editors and IDEs should really be a thing of the past. Like the emacs versus vim debate, should be pick-what-you-like-in-emacs and pick-what-you-like-in-vim - and then it should work without having to write C code like a dinosaur.",3,2025-03-31 21:11:52,shevy-java
programming,1jjluxe,mjqjmgi,"This is one of those things that sound crazy at first, but I'll just say *""don't knock it until you've tried it""*.

Being able to recompile a large codebase almost immediately and debug at near-release speeds is amazing.",28,2025-03-25 22:32:45,SuperV1234
programming,1jjluxe,mjr0hsd,"I wrote my own standard library from scratch (not a C++ reimplementation, used asm for syscalls). I used it in my [compiler](https://bolinlang.com/) so I wouldn't need glibc and wouldn't need to worry about C/C++ quirks (especially locale). I miss working on my compiler

It's fun to write your own lib. But I imagine a person would only like it if they like optimizing code and writing their own data structures",5,2025-03-26 00:01:46,levodelellis
programming,1jjluxe,mjps49r,"“C++ standard library (also known as STL)”

Uh, STL is not C++ standard library",18,2025-03-25 20:14:48,Ziprx
programming,1jjluxe,mjuuqag,">middle damagers

I'm using this!",2,2025-03-26 16:26:19,Kok_Nikol
programming,1jjluxe,mjt4bf2,"This blog post got more attention (front page hacker news) then deserved in my view. ‘There’s a couple thousand lines of code in the repo total. It’s not a remotely serious attempt at even redoing even 1998 standard library, or even the STL for that matter (STL came from HP and there was an SGI implementation (STL port ) that people used for years - that never contained things like iostreams which is part of std and not STL).

Further, the repo has this at the top of the readme:

  - provide functionality that is in the Python standard library

And it’s named pystd. At this point I’m confused about goals.

I’ll spare this channel an in depth review of the code that’s there, because it’s not a productive use of time. Let’s just say the PR would need a lot of rework. Also, no tests, no docs, no benchmark or ‘std lib version’ to attempt to replicate results. 

To be clear, none of this is a criticism of the author - I’m all for personal experiments to improve your knowledge, etc.  I just think the title is blown out of proportion and the experiment actually demonstrates little about the supposed weaknesses of std like ‘atrocious compilation times’ ( his std version experiment compiled in less than 5 seconds using a single core which is fast - and again not confirmable).",4,2025-03-26 10:06:14,azswcowboy
programming,1jjluxe,mjqdch7,I really like that namespacing trick. It's simple and versatile.,1,2025-03-25 21:59:49,Norphesius
programming,1jjluxe,mk37kpi,"That's a lot of fun. I also like to make my own STL classes and then use them in a project. I made a smart pointer that also acts as a dynamic array. Then I made accounting software that exclusively uses my smart pointer dynamic array. It looks like you only made a unique pointer, but a shared pointer is much more fun!",1,2025-03-27 22:46:30,Sea-Advertising3118
programming,1jwxxbn,mmmq85m,Looks cool. I see it only supports linux host and guest. What's its value over containers?,18,2025-04-11 21:13:35,Dayzerty
programming,1jwxxbn,mms59ix,what changed for CoW? how was it working before? I didn't really understand what you started doing differently.,2,2025-04-12 19:28:24,No_Technician7058
programming,1jwxxbn,mmmdxa2,Thanks that was interesting!,3,2025-04-11 20:09:58,HolyPommeDeTerre
programming,1jlbmzj,mk42wkd,"> Here, I’ll build on that by showing how this technique can be used outside of niche academic languages

We have done nothing to deserve this slander 😢

But otherwise, a good article. I knew it was doable in C, but this article showed a way simpler approach then what I was thinking of.",18,2025-03-28 01:36:22,davidalayachew
programming,1jlbmzj,mk31ibf,"Some good tips here!

> With Parse, Don’t Validate, you will never run into the situation of accidentally swapping parameters around in a function call

Unfortunately this is not true - if a function takes two email_ts (e.g. from and to), they can still be swapped.",23,2025-03-27 22:16:02,theuniquestname
programming,1jlbmzj,mk5qdnp,"Very good article, much better than what I expected. It’s a good “how-to”, and not a “hight level description of some ideals”.

---

However it does highlight a big flaw in C. The easiest way to express that something is optional is to use a pointer. Which means that that the easiest way to express that a function is faillible is to either return NULL or a dynamically allocated objet, which tanks performances (mostly because it’s much harder for the optimizer to do its job, not because malloc is that slow).

If I had to write this code, instead of `email_t *email_parse (const char *untrusted)`, I would probably write `bool email_parse(const char* untrusted, email_t out)` to remove the unnecessary dynamic allocation.

This digression doesn’t remove anything from the article.",10,2025-03-28 09:56:41,robin-m
programming,1jlbmzj,mk288lc,Good article but your link to opaque types is broken.,3,2025-03-27 19:20:49,BlueGoliath
programming,1jlbmzj,mk6x9wi,"Loved this one. The distinction between parsing and validating is subtle but *so* important, especially when dealing with low-level languages like C. It’s the kind of mindset shift that prevents entire classes of bugs. More devs need to read this.",3,2025-03-28 14:44:26,tomasartuso
programming,1jlbmzj,mk9dwe7,"Great Article! I want to follow your Blog, but you dont offer an RSS feed x/",2,2025-03-28 22:03:23,Wolfspaw
programming,1jlbmzj,mkaj2ma,Just read this and other posts in your blog. Very enjoyable. Great writing. I’ll use these concepts.,2,2025-03-29 01:59:09,Manixcomp
programming,1jlbmzj,mk5qcga,"> You parse them once into the correct data type, and then code deep in the belly of the system cannot be compromised with malicious input, because the only data that the rest of the system will see is data that has been parsed into specific types.

Now that is just plain wrong and the kind of overpromise that puts people in danger. Which is a shame because I otherwise agree with the approach.

What is true is that using a type system you can establish a boundary between validated and unvalidated inputs. This is great and should be used more often, even within the code base (for example distinguishing different types of cryptographic keys with different types is a basic but effective strategy to limit the risk of mixing them up). It is also true that enforcing validation greatly limits the amount of bugs that can be exploited.

However parsing is generally really hard and many bugs happen in parsers. In the same way validating inputs is really hard and in many cases it's the wrong approach altogether (which is why to fight injections for example it's best to escape rather than sanitize, or in the case of emails actually where validation will almost always be either uneffective or too restrictive and simply sending a validation link is almost always the better approach). Granted ""validation"" can mean a great many things in practice, but that's just the point: to say that no bug can be exploited because your data was validated supposes that your validation is absolutely perfect and encompasses all risks present and future.

I'd feel a lot more enclined to recommend this article to people it it wasn't promising things it can't deliver on.",-1,2025-03-28 09:56:20,cym13
programming,1jlbmzj,mk4q69x,"Finally, some good advices instead of yet another RiiR written by people who clearly lack qualification to write a secure software

I'd make a step even further and say, wherever possible, don't parse at all. Instead, get the necessary data from where it's already present. And if software holding your data lacks necessary API, then make a PR to that software. If some data format or protocol makes it hard to parse, then come up with better data format or protocol. Like, store different kinds of data in different files, use CLI args, etc etc etc.",-8,2025-03-28 04:01:09,void4
programming,1k45lwh,mo8qy70,"I'm so glad this brings up the ""RDBMS is because disks"" bit because I was bewildered when I first saw it and am always surprised it gets so little attention.

It's probably what first taught me that Bob will literally make shit up to make a point.

Network and hierarchical DBMSs existed _before_ the relational model and are much closer to the models Bob cheers on. 
 Codd introduced the relational model in a response to their shortcomings, which are all to do with consistency, flexibility, abstracting query patterns from storage layout etc.  All semantic things.  Performance considerations are barely talked about as a throwaway in [the OG paper](https://dl.acm.org/doi/10.1145/362384.362685).

To steal a [quote from Wikipedia](https://en.wikipedia.org/wiki/Hierarchical_database_model#cite_ref-1) (my bold)
> When the relational database model emerged, one criticism of hierarchical database models was their close dependence on application-specific implementation. This limitation, along with the relational model's ease of use, contributed to the popularity of relational databases, **despite their initially lower performance** in comparison with the existing network and hierarchical models.[1]",15,2025-04-21 11:56:55,therealgaxbo
programming,1k45lwh,mo8066d,">In my opinion, anecdotes can be a very powerful persuasion technique. Nothing like a good anecdote to prove I am right and you are wrong, although it is still a logical fallacy.

I like this quote about anecdotes

I have to add something also, IT anecdotes are really bad, because if you are following anecdote as a rule and the anecdote is from 80s or 90s, then you are following advice that was useful in 80s and 90s

Like the Java knock, knock joke from late 90s  
It was true at the time, however a guy name Cliff Click fix the problem and the joke isn't true from the past 20 years

Take IT anecdotes with big grain of salt, especially if they are too old and learn how they came to be, because 9 out of 10 time, most of those anecdotes aren't true anymore",12,2025-04-21 07:40:11,gjosifov
programming,1k45lwh,moejq3f,"> THE DATABASE IS A DETAIL

that's all you need to know that it's shit. the DB often long outlives the app code",2,2025-04-22 09:36:43,randompoaster97
programming,1k45lwh,mo8vj7z,Fantastic post! Hopefully this closes the book on the issue: your database is _not_ an ignorable detail. The semantics of your chosen DB affect your user in every way. Not accounting for this is sheer insanity.,4,2025-04-21 12:29:06,editor_of_the_beast
programming,1k45lwh,mo9458i,"On point 2 you're strawmanning a bit. While I dislike Bob on many points, he's saying you should not use frameworks that allow you to directly manipulate/pass around rows and tables in your database because this causes too much coupling. He's not saying not to use your data. He's saying you shouldn't be coupling your application to the row/table schema of your database, which I think is correct. 

Changing your denormalization scheme should not need changes everywhere in your code.",3,2025-04-21 13:24:07,Proper-Ape
programming,1k45lwh,mo7tcu9,"I was about to comment angrily on ""THE DATABASE IS A DETAIL"", but I'm happy I looked at your blog post before.

Please be careful about your title, as it conveys Martin's opinion and not yours.",4,2025-04-21 06:27:49,nfrankel
programming,1k45lwh,mo9wcs4,"What a strange rant of an article. It tries to argue that database choice is a significant architecture element, but does so by listing reasons why it's not...


What if I told you it can be both?


From one point of view it is important for all the various reasons. From another it is an implementation detail, because treating it as such is beneficial.


Treating DB as a detail lets you decouple from from this decision and as a consequence pospone this decision. To a point where you know more about the system in question. Possibly replacing it when needs change. Or even using multiple if conflicting needs arise.",2,2025-04-21 16:05:22,Januson
programming,1k45lwh,mobvt5f,"Nice article, found reading it was easier than reading the actual books. On a touching note: does anybody else had a problem with reading technical books like Clean Code/Clean Architecture? I can't find a way to pick on where I left with it and usually I leave the book for more than 3 days if I leave it. I don't read that often, but when I want to I start where my bookmark is and then can't catch up on what the hell author is talking about cause nothing makes sense. Feels like I have to start reading from the start. Clean code at least has a ""Code smells"" section for quick lookup.. maybe it's just abscense of a good reading habit but can't tell really with my inexperience",0,2025-04-21 22:00:18,Strict-Criticism7677
programming,1k45lwh,moe32xc,"I agree with most of the article. A good phrase I heard once was ""Architecture is anything you can't change in a week"", which I use as a good guideline for how much you think about up front rather than as you go along.


The maths of the AI content did amuse me...


> Explicit Adoption: Approximately 20–30%...
>
> Implicit/Partial Adoption: Around 70–80% o...
>
> Non-Adoption: The remaining 20–30% 


So 110-140% then.",0,2025-04-22 06:37:32,Old_Pomegranate_822
programming,1k45lwh,mo8ujwt,"And somehow Martin manages to br overall correct for like 99% of projects. And most of the code in the remaining 1%.

Data storage is an implementation detail. Abstract it away and forget about it.",-10,2025-04-21 12:22:27,Blecki
programming,1jj3iwn,mjnc421,"It's an interesting read and asks hard questions.  

Some choice quotes:

>  ""In 2025, basically every language in the RedMonk top 20 has lambdas, pattern matching, lightweight concurrency, and type systems! So why would any project pick Scala?""
> 
> ""Scala cannot compete with mainstream languages on stability and polish alone, so if we halt feature development today, Scala would end up as a language with worse features, worse polish and stability, and no reason to exist""
> 
> ""The third biggest issue we see in the Scala language is the learnability of the ecosystem. [I]t has lacked a platform for less-sophisticated users. Documentation in the Scala ecosystem has also traditionally been a problem.""

That's a lot of introspection.  I feel like their dismissal of *""One common request from the community is to go “all in” on some framework or toolchain in the Scala community.""* is a mistake.  

If they go all in on a framework, they can set the foundation for solving many of the issues:

1. By actually going through the exercise of building something complex with the language
2. Have a tight feedback loop to discover points of friction with the DX and tooling
3. Set an example of best practices for the community (e.g. documentation)

C#, for example, certainly benefits from Microsoft internally building ASP.NET and still leaves enough room for community projects like FastEndpoints.  Microsoft's documentation around .NET and C# are fanstastic and make it approachable.

I think one thing that has been fascinating is watching Evan You and how his approach with the Vue/Vite ecosystem has been really masterful.  *He's almost standardized modern JS development on Vite*.  He produced VitePress to make community documentation easier.  He created Vitest to move JS unit testing forward (faster, easier).  He's been instrumetal in integrating a lot of community efforts like Oxc.  The Vue project runs integration tests against popular community projects like Nuxt.js to ensure that they catch breaking changes allowing the core Vue to evolve the internals of the Vue framework with full considerations for the downstream impacts.

I think it is a mistake for the Scala team to have this mindset: 

> ""The core Scala developers are not framework experts""

True as it may be, my sense is that they *need* to become framework experts to dogfood Scala and understand the limits and friction themselves; they cannot just put the onus on the community and sit in their garden sipping tea.  I can't help but think that if they recruited some folks to build a ""flagship"" Scala framework, that would yield a lot of positives for the language and the community as well.  Having that flagship would then also make it more approachable for newcomers who really just need to build things and ship software, not debate the theoreticals of language superiority.",18,2025-03-25 13:06:17,c-digs
programming,1jj3iwn,mjn6ui8,"So, Scala was number 14 in the ranking of programming languages in 2014, and remains so in 2025. That's indeed a fairly successful indicator. Even without being backed by giants (like Go, Dart and to an extent, Rust - which is not just backed by Mozzilla but also Amazon and MSFT now) it managed to ""remain just outside mainstream"" for a decade, when the most common fate of languages that do not become mainstream after their ""peak"" is to fade into obscurity.

I was an early enthusiast of Scala in the early 2010's but never really got to use it professionally and had the impression that it was going too far off into FP purity, like Haskell, to be used by mere mortals like me and my colleagues. When I wanted that sort of thing I would just go and use Haskell already (though I quickly learned I couldn't understand most Haskell code, even the one I'd written 6 months before, that used all those advanced category theory stuff - which is all of it as people don't use Haskell just to throw away most of its features - they want to try it all even when it does not improve their lives from a maintainability perspective)...

Anyway, looking at Scala 3, it does seem really interesting and cool to me, but my impression that it's not very approachable has, if anything, grown even more. Did they really need to add Python whitespace while still keeping curly braces as well?? That's the kind of thing that makes Scala look like ""anything goes"".",14,2025-03-25 12:32:55,renatoathaydes
programming,1jj3iwn,mjnov08,"I imagine that the typical younger developer barely knows that Scala exists. So in the here and now, their most pressing problem would simply be lack of mindshare.",4,2025-03-25 14:17:50,frou
programming,1jj3iwn,mjnrcxu,"Scala has always neglected their tooling experience and binary compatibility. To their own detriment.


Kotlin is a different language but it got the sweet spot right and surged ahead of scala. Despite scala having the head start.


Now scala has to add features and make up for what ultimately was bad steering/stewardship.


Maybe they can chase some AI trends to ""too little too late"" to compensate - but we all know how that ends up looking from the outside.",9,2025-03-25 14:30:52,RDOmega
programming,1jj3iwn,mjnkhvt,"Oh, this brings back some memories... :D

I was using Play Framework with Scala on several projects, it was about 8 years ago and I remember I had to wait \~45 seconds to recompile after any change. That was a real productivity killer.

I was convinced the strong type safety is the best for sever code, so I didn't want to use JavaScript.

But then I've learned TypeScript, and I knew this is the way to go. So after watching a long course of NestJS I've rewrote the whole backend with it (and TypeScript), and I'm extremely happy! Performance is basically the same, and now I can even share the code with frontend. And recompiling time is so short, it's not even worth mentioning :D.",3,2025-03-25 13:54:49,juraj_m
programming,1jwxvtn,mmzjci3,This needs crossposts :),1,2025-04-14 00:43:22,przemo_li
programming,1jwxz74,mmq7qcs,I had no idea the default size of h1 was depending on nesting level.,13,2025-04-12 13:13:24,thomas_m_k
programming,1jv9wi3,mm96b5e,"Niche fitting is a very interesting feature of Rust to us low-level meganerds. Even in the most basic instance, the fact that `size_of::<Option<Box<T>>>() == size_of::<Box<T>>()` is really nice, because it means there is literally no cost to take extra type safety (or “null safety” if you like).

The fact that enum discriminants are chosen from available niches in the general case is just extra awesome.",39,2025-04-09 18:23:25,simonask_
programming,1jv9wi3,mm99ffe,"Enums are always a fun sandbox to play in. Largely because they can yield some hilariously unexpected performance optimizations without you changing a line of code. All during compile time too.

To give an example, Java has enums too (though you guys have a different interpretation than we do -- Sum types vs Constrained Value Domain), and one super clever optimization is how we handle them in Sets.

A Set in Java follows [the mathematical definition](https://simple.wikipedia.org/wiki/Set) -- a collection of elements where there are no duplicates.

Well, since enums are just plain old classes in Java, with fields and methods and constructors, one would think that you would need to hold at least a hash of the instance when storing in memory, but that is not so.

Since all the instances are known of ahead of time (it's an enum!), Java has a specialized [Set](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/Set.html) called an [EnumSet](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/EnumSet.html). Instead of using hashes or object inlining to denote inclusion/exclusion for the Set, the EnumSet literally uses a `long` (or a `long[]`, if there are more than 64 values in the enum), and just uses ***index (ordinal)*** to denote set inclusion ***by flipping the bits of the `long`***.

That is terrifyingly fast. It makes it the fastest Set implementation in the JDK because checking if an instance is in the Set is literally just a [Logical AND](https://en.wikipedia.org/wiki/Logical_conjunction). You basically CAN'T get faster than that without dipping into things like SIMD or the equivalent.

Compared to [HashSet](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/HashSet.html) (from my informal performance tests), I saw 300% speed improvements, and it used a fraction of the memory. And to make matters worse, HashSet is unordered, but EnumSet is ordered! That actually makes this an unfair comparison for EnumSet! To give a true apples to apples comparison, we would need a Set implementation that includes ordering, which is [TreeSet](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/TreeSet.html), and the speed difference was almost 500%.

The only real competition EnumSet has in the JDK is another specialized Set -- the [unmodifiable internal Sets returned by Set.of()](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/Set.html#of\(E...\)), and those are backed by objects like [Set12](https://github.com/openjdk/jdk/blob/a2a7703370caf07afd88b5cfe44e1a78eed699e9/src/java.base/share/classes/java/util/Set.java#L470), which is literally [just an object with 2 fields lol](https://github.com/openjdk/jdk/blob/a2a7703370caf07afd88b5cfe44e1a78eed699e9/src/java.base/share/classes/java/util/ImmutableCollections.java#L775). Those are so specialized that you literally get a different implementation, depending on how many values are in your factory method lol. Set.of(1, 2) will return a different implementation than Set.of(1, 2, 3) lol. And the second you go for [the array version](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/Set.html#of\(E...\)), which can hold any number of params, then you are right back to EnumSet being the fastest implementation. In fact, in Java 24, once you get past [3 parameters](https://github.com/openjdk/jdk/blob/a2a7703370caf07afd88b5cfe44e1a78eed699e9/src/java.base/share/classes/java/util/Set.java#L695), EnumSet becomes the fastest, though I think that might change soon.

That shows the type of crazy stuff that enums can do. And I haven't talked about other fun ones, like [EnumMap](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/EnumMap.html) or how they interact with Switch cases/expressions or pattern-matching.

Enums are my favorite feature in any programming language, let alone Java. Such a simple, yet powerful concept. And it's great in any language that it's in, even though Java's Enums are better than all other languages' versions.",33,2025-04-09 18:38:36,davidalayachew
programming,1jv9wi3,mmcy092,"> What’s going on? The Rust compiler knows that while char takes up 4 bytes of memory, not every value of those 4 bytes is a valid value of char. Char only has about 2^21 valid values (one for each Unicode code point), whereas 4 bytes support 2^32 different values. The compiler choses one of these invalid bit patterns as a niche. It then represents the enum value without using tags. It represents the Some variant identically to char. It represents the None variant using the niche.


Is this hardcoded in the compiler? Or can this be expressed as a Rust type declaration? 

Could I write a type `MyChar`  where the compiler would know that it doesn't use all bit patterns and does the same optimization?",3,2025-04-10 09:13:18,Skaarj
programming,1jv9wi3,mmcyhjk,"> The representation of the value Outer::D(inner) is identical to the representation of inner!

Does this have influence on binary compatibility (ABI compatibility)? 

When I would accept or return a enum value through a public funtion of my library `whatever.so`, does the enum use the same format? That means that the use of this optimization must be predictable and can't be changed in the future, right?",1,2025-04-10 09:18:26,Skaarj
programming,1jtjp2c,mluo5uj,nailed it!! concise and to the point.,3,2025-04-07 12:18:13,ashemark2
programming,1jtjp2c,mlwaw3a,IBM MQ?,1,2025-04-07 17:38:51,Valendr0s
programming,1jtjp2c,mm04tfv,btw your header gets shortened to “System Design but SIMP” on my phone,1,2025-04-08 08:36:51,hellishcharm
programming,1jkvfcd,mjyjhol,"> Can’t you simply open a ticket at your IT department? Certain situations may make a deeper architectural solution impossible on the timescale that a project needs delivering, happenings need to happen and things need to thing

Yeah, should add to this disclaimer that doing this will get you fired on the spot for circumventing security controls. I’m at some dozen, maybe 15 developers I’ve personally gotten fired *this year* for circumventing security controls. And I’m one of an entire team of incident responders. ",82,2025-03-27 04:08:53,usernamedottxt
programming,1jkvfcd,mjz6jwc,"I have to say it’s very well written and a thorough explanation! It’s also good to see Nix and Windows support side by side in one article, giving it a more comprehensive feel. 

+1 to “this could well get you fired for IT Policy breaches” of course. If you’re doing this in an actual corporate network on a daily basis, you’re probably doing the wrong thing for the wrong reasons. 

However it’s a great way to learn!",11,2025-03-27 07:52:01,Agreeable_Assist_978
programming,1jkvfcd,mk2eblh,"Way to go to get yourself fired or criminally prosecuted. Not to mention that SSH tunnelling is like several decades' old and every self-aware company has means in place to detect it, because every self-aware IT-monkey in the world has tried it at some point since the 90s.",-3,2025-03-27 20:22:29,zam0th
programming,1jkvfcd,mk5sra6,"I feel like all the suggestions are over-engineered. If you have control over both the server and client, just use `socat` to redirect ssh traffic through a dead simple xor-based encrypter/decrypter using a pre-shared key. Obviously it's fairly easy to decode if you want to, but there's no way an automated system is going to do that and identify it as ssh traffic. From the firewall's perspective, it just looks like random bytes going to a random port. If you want to further obfuscate it, wrap it in some http headers.",0,2025-03-28 10:20:02,MooseBoys
programming,1k2b1v4,mnuv2ow,"I really liked putting the parameters in the middle of the function name. Are there any other languages that do that? I always thought ObjC was very readable, but the lines to get long quickly. I know a lot of people don't like the syntax, but I never had an issue with it.

I don't know why the C++ standard library authors think there are a shortage of letters, so every function name needs to be as short as possible.",29,2025-04-19 01:17:25,turniphat
programming,1k2b1v4,mnu5wk1,I wish there was a reason to use objective-C outside of maintaining old iOS/Mac applications. I always thought the brackets were a fun departure from other languages. Too bad that isn’t a good enough reason to use it.,12,2025-04-18 22:42:53,Stroggi
programming,1k2b1v4,mnvc8bh,"> These were not curt, Hemingwayesque sentences, but long, floral, Proustian ones

I think this broke my pretentiousness meter.",11,2025-04-19 03:10:14,Monsieur_Moneybags
programming,1k2b1v4,mnz3mzr,One of the best languages. ObjC with https://objfw.nil.im/home objfw is an awesome choice for development,2,2025-04-19 19:25:56,Limp_Day_6012
programming,1k2b1v4,mnwhdzt,"Such a powerful language. Progressive type system, static and dynamic dispatch, message passing, method swizzling, optional protocol functions, plus bidirectional interoperability with C.

AFNetworking’s API is a modern take on NSUrlSession (wish more modern wrappers existed). Function names don’t magically change when using Swift. You still have to pass in the `includingPropertiesForKeys` named parameter to `FileManager.enumerate` 🤷‍♂️",3,2025-04-19 09:33:40,amirrajan
programming,1k2b1v4,mnysczp,Paywalled,1,2025-04-19 18:23:50,nekokattt
programming,1k2b1v4,mnwq1rn,"Personally, ObjC is second lowest, right above Closure.",0,2025-04-19 11:02:12,andricathere
programming,1jl3gi0,mk0fd17,"This is a terrible article. The first half is technically correct but the writing is bad. The second half maintains the bad writing but goes off the rails on facts and terminology. 

> The iPhone sends an authorization request to the payment network. It contains the request cryptogram and transaction details. Put simply, DAN never leaves the iPhone for security.

The DAN, which is a 15- or 16-digit card number provisioned for the individual device, is not a secret. When you tap to pay, the card number is always transmitted to the terminal in clear text. That’s just how EMV Contactless works. If the DAN didn’t leave the device, the merchant wouldn’t have a card number to charge. Moreover, it’s the payment terminal sending the request. The iPhone’s duties are handled offline.

Edit: I try to avoid too much self-promotion but I actually wrote [a detailed explanation of how Apple Pay works](https://kirklennon.com/a/applepay.html) back when it launched. I haven’t updated it to reflect online Apple Pay purchases, but it’s otherwise current. My website has no ads, no third-party tracking, nor any other sort of revenue generation.",276,2025-03-27 13:53:37,kirklennon
programming,1jl3gi0,mk0gp6s,Im still a little confused as to how digital wallets are able to process transactions without internet access. I understand that NFC is being used but how does the payment service get notified/verify a transaction. Is it because the card reader is connected to the internet so it sends all the needed data to the payment service? Or is the transaction just logged on the phone and the next time the user get internet access all transactions get sent to the service?,62,2025-03-27 14:00:43,JohnFish2734
programming,1jl3gi0,mk2d7jf,"This is not how ApplePay works. ""Payment network"" term is wrong, since that is not what processes transactions when you try to pay with ApplePay. ""Credit card"" doesn't make sense since ApplePay works with any plastic. ApplePay won't work **at all** unless the issuing bank implements corresponding transactional gateways.

>The card reader creates a transaction record, which contains details such as the payment amount and date.

This is outright false as it's not how a POS-terminal functions. OP has not the slightest idea about transaction processing and card payments.",28,2025-03-27 20:16:34,zam0th
programming,1jl3gi0,mk2jh5d,This article is factually incorrect. Probably AI-generated.,8,2025-03-27 20:48:32,st4rdr0id
programming,1jl3gi0,mk08r9p,"I know I’m gonna get hate from Apple dislikers, but Apple Pay is for me the sole reason to buy an iPhone instead of the competition. It’s the key feature for me.

Google and Samsung wallets are a joke compared to this.",73,2025-03-27 13:16:28,Calm-Success-5942
programming,1jl3gi0,mkbscf0,"That's interesting, thank you. I'll send it to my mom—she doesn't want to *put* her credit card on the phone xD",1,2025-03-29 08:26:09,uscnep
programming,1jl3gi0,mk20c1p,Like all other Apple products. It just works. /s,-7,2025-03-27 18:28:57,Ironamsfeld
programming,1jl3gi0,mk23q6d,In my experience the way it works is that it often doesn't.,-7,2025-03-27 18:45:33,IAmASolipsist
programming,1jl3gi0,mk1160j,Ireland 1%corp tax,-13,2025-03-27 15:42:33,NoleMercy05
programming,1jw39fl,mmf8xdp,I think recognizing that leaf applications (non libraries) have different needs than libraries is great.,81,2025-04-10 17:36:56,mpinnegar
programming,1jw39fl,mmgxcxv,"I get the appeal as a library developer, but I absolutely hate it as an application developer.

If I haven't updated an old app for two years, I don't want to have to crawl through dozens of release notes to figure out where the breaking changes happened and what they were. With SemVer, there is a clear demarcation, so I know exactly where to look.


If I want to know when a version was released, I just look at the date of the release notes.",59,2025-04-10 22:40:52,jessepence
programming,1jw39fl,mmhp7pi,"Calver is great for apps and services, for libraries, it may be a bad idea.",10,2025-04-11 01:27:03,pfc-anon
programming,1jw39fl,mmg62q7,"How do you handle patches? Say you introduced a bug or security issue in 2025.4, how would you add patches in the same month? 2025.4.10?",3,2025-04-10 20:18:15,Jolly-Warthog-1427
programming,1jw39fl,mmh90lk,"What about using a combination of the two?

MAJOR.YYYY.x?",2,2025-04-10 23:48:15,KrazyKirby99999
programming,1jw39fl,mmn711k,"Calendar versioning is fine, but please never for APIs…",1,2025-04-11 22:49:28,PositiveUse
programming,1jw39fl,mnj2qnm,"I’ve tried to blend the best of both worlds: [/r/golang/comments/1jzucpw/scalable\_calendar\_versioning\_calver\_semver/](https://www.reddit.com/r/golang/comments/1jzucpw/scalable_calendar_versioning_calver_semver/)

Versions may look a bit long at first, but the idea is to use only as much detail as your release cadence needs. You can start, say `1.2025` for a yearly release. As the project grows and releases speed up, the format “stretches” to stay ordered: after `1.2025.72` you can cleanly jump to `1.202509.0` and keep perfect numeric sorting.

* `1.2025.0` < `1.2025.1` < `1.2025.2`
* `1.202503.0` < `1.202503.1` < `1.202503.2`
* `1.2025.0` < 1.202503.0 < 1.20250301.0
* `1.20250410.0` < `2.2026.1` < `3.20260310.0`

Format: `MAJOR.YYYY[MM[DD]].PATCH`

Progressions: `MAJOR.YYYY.PATCH` → `MAJOR.YYYYMM.PATCH` → `MAJOR.YYYYMMDD.PATCH`

Bottom line: it stays **SemVer‑compatible** while adding CalVer clarity and can be ""stretched"". Examples and details here [veiloq/scalver](https://github.com/veiloq/scalver)",2,2025-04-17 03:57:15,NecessaryVictory9087
programming,1jw39fl,mmfxrea,"Unless you have a specific reason to use SemVer, calendar versioning is far superior.

In other words, calendar versioning should be the default.",-20,2025-04-10 19:38:27,Rodwell_Returns
programming,1jrluud,mli8oi5,"From one perspective it's an extremely technical subject and from another, like the hacker News example, it's an extremely obvious technique. It's nice to have the procedure explained because it's something I've done already without having a name for it",10,2025-04-05 07:10:31,dakotapearl
programming,1jrluud,mlq68c8,Not refactoring if functionality changes.,2,2025-04-06 17:09:53,TrumpIsAFascistFuck
programming,1js8w4w,mlo2wdt,"Writing Go in Java is like writing Java in Go and both are like giving yourself a vodka enema to get really drunk without chundering. 

It works, but you really shouldn't.",36,2025-04-06 07:55:05,BroBroMate
programming,1js8w4w,mlr30sy,"So that code to save the file lets you potentially overwrite server files 

I haven't tried it but it potentially also lets me read server files as well by putting .. in the path.",3,2025-04-06 20:03:58,nekokattt
programming,1js8w4w,mlonfms,"Kotlin as an alternative language with extension methods, and finally Native Image for compilation could make this pretty useful for extremely small projects.

The big problem is that Java and Go are separate mindsets, even though they are incredibly close thanks to colorless functions, and a clear orientation on where they come into place.
Much like a JavaScript developer might not fathom on writing 3 lines of code yourself instead of importing a framework, Go comes from the anti-C++ mindset, while Java is... complicated. Java's Enterprise-y-ness is both a joke and reality.

Of course a Java dev will instead use something like Spring Boot for big projects, and something smaller but still 3rd party for smaller projects. It comese from the Java ecosystem being pretty stable and pretty high quality.

Using 3rd party stuff in Go meanwhile is rare, because the std lib might be one of the best ones possible. And on the other ends of the spectrum we have JS development. Or - an ecosystem somehow perfectly combining all the worst parts - C++. The tools and language design influence the mindset of the language's users.


Still a pretty nice article for showing of a new feature.

One recommendation: going with JStachio as a templating engine instead might increase type safety of the templates more, and comes even closer to the beauty that is Templ in Go.",6,2025-04-06 11:31:22,n3phtys
programming,1js8w4w,mlpw03u,"Brought to you by the authors of ""You can write Java in every language"".",2,2025-04-06 16:14:52,txdv
programming,1js8w4w,mllniru,You can rip JAX-RS from my cold dead hands. ,-1,2025-04-05 21:18:32,vips7L
programming,1jrvnx9,mlhuwe7,"In this post, the author essentially redefines ""open source"" as ""the source code is available"". This is not necessarily a widely accepted view point.


In the Open Source community, software is considered Open Source if it provides Software Freedom, when it has a license that allows anyone to inspect, modify, and share the software for any purpose.


Software where the source code is public but which doesn't have Open Source licensing is more clearly called ""Source Available"".


Of course, the author makes some good point that hold for both Open Source and Source Available software:


* users are not owed support
* the project might not accept outside contributions
* access to the software might not be gratis",177,2025-04-05 05:01:31,latkde
programming,1jrvnx9,mljcp87,"I do have to agree with one of their points at least.  
Developers of opensource software owe you absolutely nothing (assuming they've not done anything malicious).",11,2025-04-05 13:29:23,cfehunter
programming,1jrvnx9,mli60a4,"My guy should have just stuck to his strongest points. Trying to conflate source-available with open source really sours the otherwise good argument. The core point of ""open source is just open source"" is kinda undermined when your starting point is begging the question of what open source even is.",26,2025-04-05 06:43:59,zixaphir
programming,1jrvnx9,mlhwlhq,"Open source was a term and concept invented to provide a more corporate friendly alternative to the GPL and the FSF. At the time Microsoft was waging an all out war on open source calling it communism, funding the SCO lawsuit (that one was a doozy if you ever want to read some history), and paying online pundits to post blog posts saying crazy things.

Now it seems like the leopards are eating the faces of the open source developers as the likes of Amazon just prey on the successful projects and everybody scrambles trying to figure out how they are going to make a living picking leftover crumbs in the footprints of the giants.",19,2025-04-05 05:16:47,myringotomy
programming,1jrvnx9,mli12wr,"The distinction between free as in beer and free as in speech is not made. I don’t know if the author understands the GNU. Definitely does not respect the 30+ years of custom. 

I don’t think the author understands he does not get the right to determine the definition of open source. That’s [aleady been done](https://www.theopensourceway.org/the_open_source_way-guidebook-2.0.html). He can create his own scheme, more power to him.

License matters and explains the rules. He only gets to determine license for software he wrote and owns the copyright for. Anything that he includes, its license must be respected. When was the last time you saw anything that was 100% Unlicense licensed? When he uses copyleft work, his work is copyleft as well. Some permissive licensing also requires attribution.",25,2025-04-05 05:59:08,zaskar
programming,1jrvnx9,mlk3l6p,Unrelated but I love this layout,2,2025-04-05 16:05:47,Rude-Researcher-2407
programming,1jrvnx9,mliqzu8,"Open Source means free scrapping of your code by ""AI"" companies inorder of replacing you and make you redundant",1,2025-04-05 10:31:05,SoftEngin33r
programming,1jrvnx9,mlifdl8,">When software is open-source, it means it is open-source – that the source is open – nothing more. This simple fact is frequently misunderstood, so let me be crystal clear about what open-source does *not* automatically mean by default:

>It does not mean open to contributions;

>It does not mean support is offered;

>It does not mean you’re entitled to feature requests;

>It does not mean the developer owes you their time;

>It does not mean you’re entitled to anything;

>It does not mean it is *free* and open-source (FOSS).

Some may say this doesn't mean open source, but source available isn't open source and open source isn't a free beer, but free speech  
That is just philosophical difference

In practical terms the author is 100% correct  
Because software has two costs - initial cost to build the software in some usable state and maintaining cost

Closed source has both costs  
Open source has maintaining cost, that in most cases nobody wants to pay it

When you define open source from cost perspective, things are more clear for the users of open source and the maintainers of open source

Things like source available, licencing, true open source licences, none restrictive open source and other details are irrelevant to those that want to participate in open source  
and we all see now after so many people burn out in the past decade

These details are only good for those that want to exploit open source",-4,2025-04-05 08:21:36,gjosifov
programming,1jrvnx9,mliquay,">It does not mean open to contributions;

>It does not mean support is offered;

>It does not mean you’re entitled to feature requests;

>It does not mean the developer owes you their time;

>It does not mean you’re entitled to anything;

>It does not mean it is free and open-source (FOSS).

If it isn't free, then it **does** automatically mean that i'm absolutely entitled to any and all of the things listed above. If you make customers pay for your product and not offer SLAs/OLAs then you're just an asshole.

If it's free **and** open-source indeed then, well, it's a grey area. Do you want people to see you as a total jerk? In that case feel free to ignore your customers and/or tell them to fuck off. The only thing this achieves is that someone else will fork your software and offer users everything that you don't, and/or make your software better on their own but, oh wait, that's not *your* software anymore and they will never merge upstream because you actively resist that! **That** is open-source.",-8,2025-04-05 10:29:30,zam0th
programming,1jmzkug,mkftgw5,"I don’t think I would use this before I used a more established package manager like brew, chocolatey, or apt/yum.  Some people also like Ninite on Windows.

If I wanted to have repeatable dev environments I’d like use something like Ansible, Puppet, or Chef which can handle various arch/OS permutation: in conjunction with a package manager.  Nix is also good once you pay the learning curve.  I’ve also gone the dev VM approach for portability to any system.

For simple binary distribution I’ve used Dropbox, a home file server, or S3.

I don’t want to yuck your yum.  If this works for you and is a useful project that’s great, but I don’t think the problem it’s trying to solve is a problem I have.",46,2025-03-29 23:55:35,Ancillas
programming,1jmzkug,mkgy5oa,Have you seen Nix/NixOs?,11,2025-03-30 04:23:24,Ashamed-Gap450
programming,1jmzkug,mkhssz9,"This is very similar to dotslash from facebook, no? Are you aware of this project? If so in what it differs? https://github.com/facebook/dotslash",3,2025-03-30 09:35:41,blaizardlelezard
programming,1jmzkug,mki86ik,"Either this is no more complicated than a git repo with `bin-arch/$ARCH/` and a `PATH=$PATH:$REPO/bin-arch/$(arch)`, and I don't see the point of having a thirdparty script do it.

Or this is more complicated and i don't understand what features it offers and why.",3,2025-03-30 12:05:10,throwaway490215
programming,1jmzkug,mkhruee,This is amazing - thanks for creating this!!!,1,2025-03-30 09:25:03,ZachVorhies
programming,1jmzkug,mkhw2e7,"I think mise handles handles this case well, and more actually.",1,2025-03-30 10:10:39,zarrro
programming,1jmzkug,mkjl4l7,"Homebrew used to work this way (roughly), and still does for 3rd party tool repos. But they moved core away from git because it is really slow and has throttling/availability issues at scale (both # of users scale and # of tools/revisions scale). It makes sense for small use cases, but be wary of using this approach for anything substantial.",1,2025-03-30 16:54:54,dccorona
programming,1jmzkug,mknfttx,I use asdf for this purpose.,1,2025-03-31 07:37:40,elixir-spider
programming,1jmzkug,mko755z,"Please excuse my ignorance, but isn't that the same  feature as already provided by Ansibel? Sure, it's meant for servers, but I think it can be utilized for PCs as well",1,2025-03-31 12:03:14,cainhurstcat
programming,1jmzkug,mkfufcb,Very cool. Thanks for sharing,1,2025-03-30 00:01:13,pickledplumber
programming,1k2b3ns,mntodas,"For C/C++ it would be better to use the standard atomic stuff instead:

https://en.cppreference.com/w/c/atomic

Obviously that's C, C++ is similar and even a little bit better. Use the C++ stuff if you are using C++ (the C stuff will work, but why do that?).

It would be better to actually identify the variables which are being operated on with the order dependencies. That allows the compiler more freedom to reorder other stuff. But if you are just going to do it like MS does it here with explicit standalone barriers then the equivalences are this:

    #define MemoryBarrier() atomic_thread_fence(memory_order_acquire)

    #define __lwsync atomic_thread_fence(memory_order_acquire)

    #define __sync atomic_thread_fence(memory_order_acq_rel)

I never found a suitable replacement for what they call _ReadWriteBarrier() in here. Maybe someone else knows. You can use the stronger barrier __sync above. Or you can hack it like this:

    #define _ReadWriteBarrier() asm volatile ("""" ::: ""memory"");

If you need _ReadBarrier() and _WriteBarrier() too then you can define them to the same as _ReadWriteBarrier(). This is not strictly the same thing, it's a little stronger than necessary. It will work.

Generally I would suggest not using lockless programming.

This article from MS likely came about because PowerPC has a much more relaxed memory order than x86 does. And so code which seemed otherwise fine (and would be fine without an optimizing compiler) would fail on multi processor PowerPCs. And Xbox 360 was a multiprocessor PowerPC.",12,2025-04-18 21:02:52,happyscrappy
programming,1k2b3ns,mnuallo,XBox360 article in 2020? Intresting,11,2025-04-18 23:10:57,Limp_Day_6012
programming,1jyo8tl,mn0c8r2,"Im sorry and not trying to attack OP, but do we need another blog post explaining how javascript works? This information has been regurgitated so many times. Seems like every time a new developer learns how JS works we get a blog about it.",34,2025-04-14 04:02:52,theboston
programming,1jyo8tl,mn06unt,Very important information for programmers.,-8,2025-04-14 03:21:27,BlueGoliath
programming,1jpq3sy,ml15w7x,"""For every 25% increase in problem complexity, there is a 100% increase in solution complexity.""  Woodfield, 1979. *Almost 50 years ago.*^1

Also, intrinsic / inherent / domain complexity vs. extrinsic / accidental complexity.  
Yes, all of them have slightly different context associations, btu that's a good thing, I think. That's how language is.

But I vibe with the question, my go-to answer is: we, as a business, have ignored and belittled science as ""ivory tower"" for much too long, it's not a search for words as much as a better shared understanding, which leads to formalization, which leads to the words requested. 

Which would also, and I belive is the *actual* crux, maybe one day give us an idea how to teach programming. Something we utterly suck at. We are masters at identifying why a solution sucks, apprentices at recognizing a good solution, and drunk bumblebees when looking for a predictable, teachable path from problem to solution. 

---

^1 ^(Now, I'd need to read Woodfield to see if that factor of 4 is an observed typical value, i.e., accidental complexity, or if it's a minimum, i.e., an unavoidable ""tax"")",36,2025-04-02 14:52:29,elperroborrachotoo
programming,1jpq3sy,ml1u3si,"The practice of software engineering is applied fuzzy logic. It is inherently resistant to parsimonious, prescriptive frameworks, that's why they all suck if followed religiously.",14,2025-04-02 16:53:08,ub3rh4x0rz
programming,1jpq3sy,ml16p97,"I tried coming up with solutions without having to invent words, but I just ended up repeating the same generic ""too complex"" with different grammars. So, I have to agree.

Makes you wonder: how are words invented?",7,2025-04-02 14:56:30,Lisoph
programming,1jpq3sy,ml13zv6,"This article is going nowhere, ask me how i know it was done by manager with AI access",31,2025-04-02 14:42:57,semmaz
programming,1jpq3sy,ml5peb3,"Brooks, in ""No silver bullet"" introduces us to essential complexity (inherent to the problem) and accidental complexity (introduced by the approach to solving):
https://web.archive.org/web/20160910002130/http://worrydream.com/refs/Brooks-NoSilverBullet.pdf",5,2025-04-03 06:10:53,No_Perception5351
programming,1jpq3sy,ml603r5,"We do have words:
  - the complexity inherent to a problem: intrisic or existential complexity
  - remental, unnecessary complexity introduced by the design of the solution: accidental complexity
  - the complexity in a logical model versus the complexity in its implementation: not sure. I don’t
  really understand the difference with existential and accidental complexity
  - unidentified implicit interdependency: unnecessary unexpected coupling
  - individual software module’s software dependencies: internal dependency
  - dependencies in the environment: system dependency",3,2025-04-03 08:01:01,robin-m
programming,1jpq3sy,ml2il94,There is a dialect of English specifically spoken in Antarctica and most of their “unique” words are just multiple ways to describe snow.,4,2025-04-02 18:49:48,Artistic-Jello3986
programming,1jpq3sy,ml86s8j,"This is something I run into with USD (the 3d file format, not the currency).

USD can be intimidating, as it's a framework for composing time-sampled hierarchies that feels more like a data language than a data format. Explaining the finer details of USD can feel like explaining what a monad is — by the time you have a firm grasp on it yourself, you've used it enough that it's infected your vocabulary. If you say something like ""Loft parameters to the interface layer of component models so they're visible above the payload"" to someone who doesn't use USD, it won't even register as actionable advice for artists. 

After all, surely that advice is just for implementation details that can be hidden from the art department. It doesn't *sound* like creative advice, so do we really need to present these concepts directly to artists?

Yeah, we kinda do.

You can build a USD pipeline without making your artists learn USD vocabulary, but you don't really benefit from USD as a format if your creative team doesn't have a firm grasp on how USD works. Art isn't made in a vacuum; the affordances offered by your tools shapes both the idea and the implementation. Understanding USD's composition arcs and hierarchies gives you a set of tools that you can actively design with. Expressive tools, creative tools. Hiding those tools behind the automated machinery of your pipeline might make the transition to USD easier, but it also slows the rate at which folks learn USD and that makes hiring and training and standardization significantly harder than it needs to be.

We're seeing USD everywhere — folks are using it in film, gaming, BIM, robotics,  machine learning, and even augmented reality. All the major DCCs support USD I/O, but artists can't really *use* USD when their DCC doesn't have an equivalent layer stack and composition system. The gap between art students and junior artists keeps getting wider, because those art students don't even have the *opportunity* to learn concepts that are quickly becoming ubiquitous in production. They can't even learn the vocabulary. They're just left unprepared. 

And yet we wonder why costs keep going up.",2,2025-04-03 16:45:49,TheOtherZech
programming,1jpq3sy,ml2ita2,"aww, here i was hoping someone was working on hydrometeor classification algorithms.",2,2025-04-02 18:50:54,asphias
programming,1jpq3sy,ml6ion1,">Any ideas?

Hmmm, people have built graphs and ""ontologies"" e.g. this one https://graphologi.com/ ( I just searched for ""ontology management software"" and that was a top result ).

But the ones i have seen have not really convinced me that they are ""solving"" this issue.

There is something that can be done with nested assumption- / namespaces. ... ish?

Generally, we are not encountering this problem often enough that an automated solution is *really* necessary. We YAGNI and ""inline"" it and just use a verbose description of what we mean in our context, when we need it.

It doesn't feel satisfying to me either and I don't think it's a good solution for e.g. academia to do this all the time, and even if we ""unwrap"" a citation graph into one big text document, we would have an automated context of paper and subsection, but not necessarily a good mapping for a specific word.

So there **is** a need and use case and if / when the global academic community finally leaves the 1850's style of paper writing and publishing in print media, we have a good shot of getting a few attempts at a good solution.

My preferred organization scheme is that of decimal classification (not the library / dewey one, the general kind), which should look familiar because it's basically how IPs / URLs and in programming languages variables access are formed. The idea is simple, you invent words or index numbers and separate with a separator and the final identification of what you're talking about is formed that way.

E.g.

programming.concepts.class

vs.

biology.taxonomy.class

But there is no global dictionary that actually does this well (yet). 

With some amount of work, this kind of thing could be built in https://www.wikidata.org/  but that's superficial, since it's more about the contained graph than the infrastructure, and nobody has built a good, global graph yet, to my knowledge. There is no particular reason to pick any infrastructure or programming language or protocol over another, as long as they support some sort of graph / linked list structure.

tl;dr: yes there are other attempts, but mostly it's just hard and a lot of work.",1,2025-04-03 11:06:43,not_perfect_yet
programming,1jv9u41,mm8pzxz,"By going to school.

(Ba dum tssssss)",57,2025-04-09 17:06:45,Positive-Quiet4548
programming,1jv9u41,mma3chl,A compiler,17,2025-04-09 21:04:02,jonny_boy27
programming,1jv9u41,mm900xh,I wonder how assembly is being compiled… is on the top of my tongue 🤔,15,2025-04-09 17:53:31,OmicronFan22
programming,1jv9u41,mm9uhvc,If you are interested in the subject you should read “The Dragon Book” (I honestly can’t remember the actual title it’s Compilers: something…) or “Engineering a Compiler”,9,2025-04-09 20:20:53,ThePonderousBear
programming,1jv9u41,mmcp7jl,"Then from assembly it becomes machine code, what’s the question? Should you go to school to learn things? Yes.

You havn’t lived until you crunch operations through the kernel",1,2025-04-10 07:37:01,TheApprentice19
programming,1jv9u41,mm8gw12,it generally turns it into **byte code** not **assembly**,-43,2025-04-09 16:22:20,krista
programming,1jmwzpg,mkf7qw5,"This is amazing, i like this.  
Althought i wish there was a full screen editor and also the validate json button seams to be broken.",7,2025-03-29 21:49:15,Psychoscattman
programming,1jmwzpg,mkk3sf6,"Amazing ! I would have needed that a week ago...


Maybe having a way to create defs items would be really nice to avoid repetition


Also interface on mobile can get junky",2,2025-03-30 18:28:48,Anosema
programming,1jj16rl,mjn72v8,"Lol, title sounds like it's about furries first",7,2025-03-25 12:34:29,Reasonable_Ticket_84
programming,1jj16rl,mjn1me3,"It annoys me to no end that the most modern authorization methods are ""pass this magic token around and maybe automatically refresh it"" rather than proper priv/pubkey auth that solves near all of the problems",5,2025-03-25 11:56:29,CrunchyTortilla1234
programming,1k3hz8g,mo5hmm3,"how do GitOps strategies factor in, e.g. using Flux or Argo? Do they only affect the process of deploying?",5,2025-04-20 21:06:43,CheeseNuke
programming,1k3hz8g,mo867am,"Obvious gpt article, but still interesting as a kubernetes newbie.",0,2025-04-21 08:44:10,Vetinari_
programming,1k2uycx,mnx452i,"How do you cache this? There is a reason REST is designed the way it is. One reason is being able to leverage HTTP caching. When you no longer follow the convention of 'one resource, one url' you make caching very difficult. 

True REST is tricky, not well-understood, not well-supported. It's why I don't use it much, but what you are blaming REST for is actually because you haven't implemented it well. You complain about multiple calls, but if that is an issue you should be caching calls on the client side and designing your resources to be cacheable.",53,2025-04-19 12:53:10,TheWix
programming,1k2uycx,mnx1sna,"Pretty soon it's going to be JSX in the database.  Finally, those FE guys will be able to work full stack!",101,2025-04-19 12:37:02,c-digs
programming,1k2uycx,mnxg6dt,Thanks I hate it.,47,2025-04-19 14:08:35,D20sAreMyKink
programming,1k2uycx,mnxeg3g,This is great until you want to use your API for something other than rendering this exact React page at this exact version,43,2025-04-19 13:58:26,rooktakesqueen
programming,1k2uycx,mnxclp4,"JS devs never really stop and ask themselves ""is this a good idea?""",59,2025-04-19 13:47:24,MandalorianBear
programming,1k2uycx,mnxm14x,The example problem is exactly why Facebook created GraphQL which I think solves it better ,14,2025-04-19 14:41:13,New_York_Rhymes
programming,1k2uycx,mnxyfay,This is just htmx with extra steps,14,2025-04-19 15:47:22,Difficult_Loss657
programming,1k2uycx,mnxvbs7,"JSX is a pretty good templating language, it would be great if we can rip the templating language of other frameworks and replace it with jsx.",10,2025-04-19 15:31:18,d0pe-asaurus
programming,1k2uycx,mnxqfxw,Just go back to Rails/Django style design. Simpler. You are already almost there.,7,2025-04-19 15:05:13,pinpinbo
programming,1k2uycx,mnxpqow,"Terrifying. This guy probably discovered React yesterday.

(Intense /s)",9,2025-04-19 15:01:26,sickcodebruh420
programming,1ju8qbn,mm0dxnb,"This strategy doesn't always alleviate delivery pressure. The idea of ""we'll fix it in the firebreak"" could pressure the developers to introduce technical debt because there's a clear time to address it. If that technical debt is introduced shortly after a firebreak, then work will be built on top of it between then and the next firebreak, leading to even more technical debt. If the team can't fully address technical debt during the firebreak, they'll continuously grow technical debt in the system.

Now, this idea does have merit. You even see similar ideas in other frameworks. Shape Up has a ""cool-down"" after the 6-week delivery cycle, where, for 2 weeks, the team has the opportunity not to schedule work. This can be used for planning, but it can also be used for fixing bugs, paying down technical debt, or even learning (which can help prevent reckless technical debt in the future). Even SAFe has an IP iteration that can and should be used for similar purposes.

A combination of strategies will need to be used. This includes being deliberate and prudent about what technical debt is introduced, actively managing technical debt (including planning high-impact resolution as a dependency to building other work), and considering techniques to regularly invest in tech debt paydown as larger efforts.",30,2025-04-08 10:14:30,TomOwens
programming,1ju8qbn,mm0w2lh,"You can do this but as a dev, it usually feels artificial and unmotivated - I have to sort through all of the tech debt that I've waded through in the past 3 months and somehow identify a project that is both (by some measure) important and one that can be tackled in a weeks' time.  Good luck with that.

""Fix it as you go"" will always be a better strategy.  If nothing else, you are consistently modeling the \_real\_ cost of software development to your management, keeping in check their unrealistic ""velocity"" expectations.  You can be sure the tech debt is topical and you have an accurate sense of how expensive it is to deal (or not deal) with.  You are still required to make good practical engineering decisions but that's true no matter how you address tech debt.

Tech debt has a real product and/or development cost -- otherwise it isn't really tech debt (it's just work not done).  That cost is how you justify your effort to your management.  If they don't understand/believe it, then you're doomed anyway.",13,2025-04-08 12:36:23,mcmcc
programming,1ju8qbn,mm0cowd,"I think it sets the wrong expectation with business. If you are not prioritising stability and productivity as part of your regular sprint, business will always pushback if it's not in their radar and features will always trump tech debt. If you always prioritise features, you deprioritise tech debt.


Being able to justify why you need to slow down features to address XFRs is a big part of a good tech leads arsenal.",22,2025-04-08 10:01:59,pkspks
programming,1ju8qbn,mm3n10k,"At Octopus Deploy we do ""Sharpening"" (the term is a nod to ""sharpening the saw""). This has a roughly similar shape to the Firebreak sprints the article describes, but is even less constrained, and we do it about 8x per year.
Developers can do whatever they want, with the general framing that you should try to improve, learn or experiment with something. One of our VP's once put it as ""a bet on Autonomy""; Sometimes the best ideas come from one developer who wanted to do something for fun.

Some people choose to use the time to do training courses or exercises. Some will use it to experiment with new platforms or tooling such as Kubernetes or AI. Some people use it to pay down technical debt, or scratch other itches that have been bothering them. Personally I've used it to fix a bunch of tech debt, improve the performance of our product, and do some learning; I wrote a proof-of-concept Docker Registry recently to learn more about how those work. Stuff like that.

I think the fact that we _don't_ just focus on tech-debt style things actually helps here. If we had something like a firebreak sprint, as other commenters rightly point out, it sets up the incentive to create more tech debt because we can always clean it up in the firebreak. But with sharpening, there's no expectation or guarantee that anyone will choose to use their time on tech debt. It removes that incentive to take shortcuts while still allowing developers to solve their own problems freely if they choose.

Other than that though, I agree with the article. Our codebase, company, developer skills and morale are all much better than if we didn't take the time for sharpening, and overall we are able to deliver product _faster_ than if we didn't do it.",4,2025-04-08 20:53:57,borland
programming,1ju8qbn,mm394sc,">Dedicated refactoring sprints often turn into death marches with arbitrary deadlines and management-dictated targets

This **is** a “dedicated refactoring sprint”. Non-engineers will either question the usefulness, or they will expect this week to yield quality benefits.

>“20% time” policies typically evaporate under delivery pressure

This **is** 20% time. Except it’s only 10% time. You say 3-4 times a year. Let’s say four. Given ~200 days a year (sick leave and vacation subtracted), or 50 a quarter, that’s 5 days a quarter, or 10%.

>“Just fix things as they go” is magical thinking when product roadmaps are already overstuffed

“They’ll fix it in their allotted one week a quarter” is the exact same magical thinking.",2,2025-04-08 19:48:32,chucker23n
programming,1ju8qbn,mm1re94,"1 week per quarter is not enough time to fix critical design flaws, I don't care what you call it",1,2025-04-08 15:27:08,angrynoah
programming,1ju8qbn,mm3totm,"Anything that causes an impromptu death march , even with the good intention of minimizing tech debt will cause burnouts. 

Hard to come back to normal when a large portion of the team, wishes they were anywhere else but on the job",1,2025-04-08 21:27:09,wapskalyon
programming,1k2jv1l,mnwdnxz,"Just learn SQL and the relational model ffs, your degree course probably covered it well enough hell the UK's A level courses for 17 to 18 year olds cover it well enough.

Do people really just want to learn one programming language and then call it quits?

The amount of effort people go to to not have to use SQL is astounding.",42,2025-04-19 08:53:06,Plank_With_A_Nail_In
programming,1k2jv1l,mnutx29,"lol, this was good

one of the ultimate examples of this is the configuration complexity clock [https://mikehadlow.blogspot.com/2012/05/configuration-complexity-clock.html](https://mikehadlow.blogspot.com/2012/05/configuration-complexity-clock.html) ...you increase in complexity going round the clock and then collapse right back to the platform itself",32,2025-04-19 01:10:04,bzbub2
programming,1k2jv1l,mnwskki,"My first thought when describing the SQL inner platform was: ORM.

It's debatable, but I don't like them for the core reason explain in this video. They make hard things harder and easy things easier. Prefer a query tool instead (kisely is one example)",11,2025-04-19 11:24:53,HolyPommeDeTerre
programming,1k2jv1l,molaszg,"u/cube-drone Thanks! 

Nice, short, explanation of a common pitfall.  Really well done!",1,2025-04-23 11:35:18,static_br
programming,1k2jv1l,mnwfi7o,"I'm astonished people don't realize SQL was an inner platform because auditors wanted to be able to scrutinize code for database access. It's untyped, prone to injection attacks, non modular, non source controlled and generally generated by another programming language anyway to keep in sync with the actual program code. People say ""use it"" because there is no alternative.",-6,2025-04-19 09:13:08,SnoWayKnown
programming,1k1kn02,mnmspea,"(Note that this is a re-post with the mod's permission after it was accidentally taken down yesterday)

Hey folks - just wanted to share this news about the future of Earthly, the open-source CI/CD framework, in case you’re a user. We’re incredibly grateful to everyone who tried Earthly, contributed, gave feedback, or just cheered us on. Thanks for being part of the ride ❤️

If you have any questions, I'll do my best to respond here.",14,2025-04-17 18:55:10,ketchupANmustard
programming,1k1kn02,mnn7bsr,"Really sad. In my mind, Earthly is ""the way"" to do monorepo with mixed language dependencies for the masses. There's no other solution that ""just works"" nearly as well. Sucks that there wasn't a business to be made there. The big companies have their tools, but good luck putting them to work with a team size between 1 to 100.

I'm not particularly interested in Earthly Lunar, but I realize I am not the target audience for that product; its something that will be sold to CTOs' looking to enforce software compliance with best practices across their armies of developers. Top-down sales is simpler and easier than the open source path; build the thing, hire a few tech sales people, land a few big contracts and the rest takes care of itself. I hope they are able to land a few big customers soon.",6,2025-04-17 20:08:17,CVisionIsMyJam
programming,1k19ocm,mnk9f2b,"Hello, author here.

I'm using this technique to develop a Go project that supports only x86_64. In short, its a way to set up Linux VM with Go installed

It can help somebody.",9,2025-04-17 10:42:43,askoma
programming,1jzt6n9,mn9trsa,"> LLVM’s target triple list is the one that should be regarded as “most official”, for a few reasons

This is not quite true, if for no other reason than LLVM only supporting a relatively small subset of the *many* targets that binutils and GCC support. If you want a more complete picture of reality, you have to reference *all* of these projects.

It's also worth noting that LLVM will defer to other projects on target triples when it makes sense; LLVM rarely invents its own thing that's arbitrarily different.

> A major compiler (so, clang or rustc) uses it. Rust does a way better job than LLVM of documenting their targets, so I prefer to give it deference. You can find Rust’s official triples here.

Should probably have pointed out that Rust triples do not necessarily map 1:1 to LLVM triples. For example, `riscv64gc-linux-gnu` will not be recognized by LLVM/Clang. In Zig we similarly have target triples that (for sanity and regularity) differ from LLVM but are lowered to what LLVM expects.

> Of course, LLVM’s ARM support also sports some naughty subarchitectures not part of this system, with naughty made up names.

Should have included `aarch64_32`/`arm64_32` in this list. It's an absolutely bonkers Apple invention that for some inexplicable reason, as the only example of this, crams the ABI into the architecture component of the triple. So you get `arm64_32-apple-ios` instead of something more sane like `aarch64-apple-ios-ilp32`, like on other architectures (think `x86_64-linux-gnux32`, `mips64-linux-gnuabin32`, etc). `aarch64-linux-gnu_ilp32` was also introduced at some point, and sanity prevailed on that one, thankfully.

> When we say “x86” unqualified, in 2025, we almost always mean x86_64, because 32-bit x86 is dead. If you need to talk about 32-bit x86, you should either say “32-bit x86”, “protected mode”11, or “i386” (the first Intel microarchitecture that implemented protected mode)12. You should not call it x86_32 or just x86.

I disagree; given that almost nobody considers the actual i386 to be the baseline for 32-bit x86 anymore, and considering that `i386`/`i486`/`i586`/`i686` are all valid in a triple yet mean different things, it's misleading to use `i386` to refer to 32-bit x86 as a whole.

This is why Zig switched from `i386` to `x86` for this case in target triples (and simultaneously bumped the baseline to `pentium4`). We have not found this confusing in practice; it's understood well enough what is meant by `x86` and `x86_64` respectively.

(And, unfortunately, 32-bit x86 is not as dead as I'd like.)

> 32-bit x86 is extremely not called “x32”; this is what Linux used to call its x86 ILP324 variant before it was removed (which, following the ARM names, would have been called x86_6432).

It hasn't actually been removed (yet!).

> The vendor is intended to identify who is responsible for the ABI definition for that target. Although provides little to no value to the compiler itself, but it does help to sort related targets together. Sort of.

Fun fact: The vendor component does actually affect logic throughout LLVM/Clang [in some cases](https://github.com/ziglang/zig/blob/933beb4cbd82ce8026a7bd4e887d8096dd3784a9/src/codegen/llvm.zig#L164-L187).

> A lot of jankier targets use the ABI portion to specify the object file, such as the aforementioned riscv32imc-unknown-none-elf.

LLVM parses the ABI (""environment"") component of the triple in such a way that checks for the ABI do a ""starts with"" check, while checks for the object format do an ""ends with"" check. So it's still pretty odd that there isn't an extra, formal component for the object format, but there is actually a method to the madness here.

> And no, a “target quadruple” is not a thing and if I catch you saying that I’m gonna bonk you with an Intel optimization manual. 

[Come at me!](https://github.com/ziglang/zig/issues/20690)

> No idea what this is, and Google won’t help me.  

It's NEC's Vector Engine: https://en.wikipedia.org/wiki/NEC_SX-Aurora_TSUBASA

I have an architecture manual stashed [here](https://github.com/vezel-dev/hoard/releases/tag/ve) if you're curious.",30,2025-04-15 18:05:19,TheFakeZor
programming,1jzt6n9,mn9b35o,"I have always wondered what these compiler targets actually meant. After reading this article, I feel like I know even less than I did before. I actually appreciate how Go handles it, despite the fact that they basically made their own standard. It's apparent nobody else was following a real standard anyway.",8,2025-04-15 16:34:37,itijara
programming,1jzt6n9,mndtcq8,">After all, you don’t want to be building your iPhone app on literal iPhone hardware.

What an unfortunate mindset. It is a shame that a dominant computing platform is so hostile to creation, and that this is seen as normal.",2,2025-04-16 10:01:50,voidstarcpp
programming,1jzt6n9,mnduqx4,"> If you need to talk about 32-bit x86, you should either say “32-bit x86”, “protected mode”, or “i386” (the first Intel microarchitecture that implemented protected mode).

While it's historical information that's not relevant outside of the retrocomputing subculture (which does seem to be gaining popularity). This and the accompanying footnote:

> Very kernel-hacker-brained name. It references the three processor modes of an x86 machine: real mode, protected mode, long mode, which correspond to 16-, 32-, and 64-bit modes. 

Is incorrect. There are _four_ ""canonical"" modes of x86 CPUs, not three (plus two compatibility sub-modes).

""Real mode"" is the original 16-bit 8086/8088 ""mode"" (there were no other modes at the time) that supports up to 1MB\* address space divided into fixed 64KB ""segments"" that overlap at 16-byte intervals.

""Protected mode"" was introduced with the (still 16-bit) 80286 and supports up to 16MB address space, but divided into variable-sized (up to 64KB) segments with arbitrary, configurable locations in memory.

""32-bit (protected) mode"" was introduced with the 80386 and extends protected mode to support segments of up to 4GB over an address space of the same size. It also introduced ""paging"" (although the original 80386 allowed paging to be active in any mode, including real mode, this was never supported by Intel and was removed in later CPUs) which has replaced segmentation as the preferred way to manage memory on 32-bit OSs. The architecture also extended the CPU registers to 32-bits, but this is also usable (with some caveats) by 80386-specific code running in the old 16-bit ""modes"". There is also a sub-mode of 32-bit protected mode known as ""V86 mode"" that is designed to allow 16-bit real-mode code to work with a protected mode OS (the OS needs to contain a little 32-bit code for this mode to be used, but can be ""mostly"" 16-bit, like Windows 3.x).

""Long mode"" (i.e. 64-bit mode) was introduced with the original AMD Athlon 64 CPUs in 2003 (the only mode not invented by Intel) and extends the capabilities of the 32-bit mode to 64-bit, but removes some of the flexibility from the ""segmentation"" system available in the protected modes (as use of this was never particularly common on 32-bit systems). Analogous to V86 mode, there is also ""compatibility mode"" that allows 32-bit code to work with a 64-bit OS.

Saying ""protected mode"" when you mean 32-bit mode will cause confusion, since that originally meant the _16-bit_ protected mode of the 80286. Saying ""i386"" is generally better (and is used by the ""target triples""), but can also refer to code that uses 386-or-later opcodes in any mode. Basically, just stick to x86_32 if you want to be completely clear.

Using ""real mode"" to refer to all x86 16-bit code is just plain incorrect.

\* Since the silly MB/MiB distinction didn't exist until the late 1990s and didn't gain traction until the 2010s, I will be using the units as they existed at the time. 1KB=1024 bytes, 1MB = 1024\*1KB, 1GB=1024\*1MB.",2,2025-04-16 10:15:23,mallardtheduck
programming,1jzt6n9,mn9gt4p,[deleted],-1,2025-04-15 17:02:39,N/A
programming,1jzt6n9,mndbwy2,"Where is ISO or some other Standards body?

Great opportunity to make a committee cash in here, and improve the life for all of us. :)",-2,2025-04-16 06:55:59,McUsrII
programming,1jzt6n9,mn98muf,Surprised I read that whole thing.,-5,2025-04-15 16:22:37,Timothy303
programming,1jqbm3m,ml61cf0,"As a CPTO, I've been observing how AI tools like Copilot are highlighting a critical issue in modern development: the knowledge preservation crisis. While AI can help generate code, it often misses crucial organizational context and architectural decisions.

We've found that AI tools actually amplify the documentation gap - they can write code, but can't capture the ""why"" behind architectural decisions. This creates a dangerous cycle where teams rely more on AI while losing critical institutional knowledge.

I recently wrote about this challenge and how we're addressing it by treating knowledge preservation as a first-class citizen in our development process, focusing on capturing not just what we build, but why we build it that way.

What has been your experience with maintaining architectural knowledge while using AI tools?",65,2025-04-03 08:14:22,traderprof
programming,1jqbm3m,ml6alxm,"""\[...\] because AI is so incredibly cool and hip and for many people the only intelligence they know"" haha",28,2025-04-03 09:53:31,steos
programming,1jqbm3m,mld9su0,This article was posted here two days ago https://www.reddit.com/r/programming/s/IDyBc6GDGS,2,2025-04-04 13:08:02,OsmiumYummy
programming,1jqbm3m,ml727p7,"Lol, don't.",1,2025-04-03 13:19:49,voteyesatonefive
programming,1jqbm3m,mlnwvqz,"Exactly. What you're describing with Cursor rules is an excellent approach to the context problem. You're manually creating a structured knowledge system.

The challenge I've found is that this method requires considerable effort:

* Creating and maintaining these rules
* Ensuring they're updated when architecture changes
* Requiring someone with deep knowledge to explicitly document everything

I've been working on [PAELLADOC](http://github.com/jlcases/paelladoc)  a professional framework for managing architectural and technical knowledge. Rather than just automating, it establishes a structured methodology for capturing, organizing, and utilizing organizational knowledge in software development.

The concept is to provide a sustainable structure where knowledge is not only captured but evolves naturally with the code and can be integrated with LLMs to improve context accuracy.

Have you encountered challenges maintaining consistency in these rules when multiple developers work on the same codebase?",1,2025-04-06 06:54:01,traderprof
programming,1jqbm3m,mmg5y95,That's a perfect summary of my own thoughts and feelings too. It's tragic that some people who make decisions don't even want to hear feedback from those who are actually supposed to use these tools. Thank you for the link.,1,2025-04-10 20:17:40,neithere
programming,1jqbm3m,ml7o6gg,[deleted],-10,2025-04-03 15:14:15,N/A
programming,1jp2n0t,mkx6785,As a Haskell-brained individual I support all efforts to extend the warm blanket of type-level logic across the unwashed masses,33,2025-04-01 21:10:01,anzu_embroidery
programming,1jp2n0t,ml2htim,"Didn't finish reading, but you mentioned that Java had sealed types to represent Sum Types.

Well, Java now has `record` to represent Product Types. Your `Transaction` example melts down to this.

    record Transaction(long timestamp, double amount)
    {/* your stuff here */}",2,2025-04-02 18:46:00,davidalayachew
programming,1jvlx0w,mmcdnrp,"It's annoying that the article didn't start with what e-graphs are and _why_ they're important, as it would've helped motivate the reader to read the article.",11,2025-04-10 05:41:22,fungussa
programming,1jkefwx,mjzgkog,Great... though my (personal) experience is that even 100ms for remote controls feels very laggy. And I'm an old man!,5,2025-03-27 09:42:26,klaasvanschelven
programming,1jz0a2f,mn6jstb,"A nice bit of history, thanks.",3,2025-04-15 04:11:58,Gibgezr
programming,1jz0a2f,mn7s091,"Nice digging. It did miss the opportunity to explore what sort of fonts the Greek used for delta back in the day.

I have to say I also like sites from graphics oriented people since they tend to include useful yet rare widgets, like a widget to play around with the pixels of a delta symbol.",1,2025-04-15 11:25:22,double-you
programming,1jz0be6,mn2grnt,"Nice blog, most people really don't know how to use git

That said, it's telling that to understand a git command you have to go read the source code. Classic. Use jj, people",8,2025-04-14 14:39:42,teerre
programming,1jz0be6,mn2x38k,"Nicely explained! That 'revert' example took me a bit. But it was a nice showcase of how versatile something like the generic logic of a ""3-way merge"" can be, by simply changing it's inputs.",2,2025-04-14 16:02:10,ThatWasYourLastToast
programming,1jz0be6,mn8pe8s,"Wait, why would one assume it is just a patch and be surprised that it is a merge like the other merges? The author kind of glossed over that.",1,2025-04-15 14:46:19,emperor000
programming,1jz0be6,mnu5n6j,"In the cherry-pick example, wouldn’t `A` be the base, given it’s the last common commit?",1,2025-04-18 22:41:20,Schmittfried
programming,1jwni7m,mmq7aca,Cool 🙂,2,2025-04-12 13:10:34,teodorfon
programming,1jv830o,mm9acjt,Was here yesterday: https://www.reddit.com/r/programming/comments/1ju1f1g/20_years_of_git/,1,2025-04-09 18:43:01,steveklabnik1
programming,1jwq9c2,mmkux09,"Obligatory: https://github.com/susam/mintotp

Previously posted: https://www.reddit.com/r/Python/comments/138ioae/minimal_totp_generator_in_20_lines_of_python/",3,2025-04-11 15:35:54,p-orbitals
programming,1jwq9c2,mmpv9p6,"This is a rite of passage when having to deal with providers that are adamant against providing service accounts because apparently ""that's insecure"". Cool, enjoy having my account credentials provided via CI and a python script that implements totp (not that it matters to them because I am the one breaking the contract of 1 user per account).",1,2025-04-12 11:44:20,Worth_Trust_3825
programming,1jwq9c2,mmkbokh,"Cool. Try my app

https://github.com/AllanOricil/esp32-mfa-authenticator",1,2025-04-11 14:00:16,Positive_Method3022
programming,1jiu30j,mjilpis,"Just out of curiosity, any reason this has to be hard-coded to RSA? You're sending the public key on every new request which could double or triple the header size. That might seem like a drop in the bucket but most folks' bandwidth is asymmetric, so uplink speed is much lower than downlink. Adding a 0.5K-1K header to every call could start adding up. Is ED25519 an option?

Also, it might be worth noting in the README that you're regenerating the key pair every time the service worker starts. You obviously can't dump it in localstorage or anything like that without exposing it, but this means the server also can't pin/cache the key. There is a replay attack vector here where a request can be duplicated and resent if the original can be intercepted. You included a timestamp I suppose as a sort of nonce? But since you can't rely on the server and client having perfectly in-sync clocks, the server can't just check if the timestamp === now. You might need to include some type of always-incrementing request ID to allow the server to remember the last value and ensure that new requests are always > that. 

Finally, I'm not sure how one would provide session revocation here. With a JWT (which, granted, has its own complications) you can use a JTI and a CRL to do things like ""log me out of other devices - but not this one"" or even ""log me out of my Pixel 4a that I no longer own and don't remember using this past year, but keep my others"" like Facebook and the other big platforms do. Perhaps you might include a handshake mechanism of some sort in which the client, when it sees its keypair is blank/needs to be generated, can call the server and ask for a session ID of some sort to be included in future requests. Sort of a ""device registration"" call of some sort?

Finally finally, don't forget that browser extensions may be able to poke around the guts here. They can for all the other techniques too, so it's not any worse, but it may be worth a warning.",22,2025-03-24 18:01:07,CodeAndBiscuits
programming,1jiu30j,mjj9rx6,"You say there is no need for CSRF checks, but wouldn't the service worker sign any request to the backend automagically? Or is there some sort of limitation I don't know about?


But otherwise you've rediscovered client side certificates and implemented a variation in a service worker without the rigid testing and knowledge usually in place for something like that. As far as I know browsers no longer provides a way of implementing generation and adding it to the cert store (they did 20+ years ago). ",10,2025-03-24 19:57:08,fiskfisk
programming,1jiu30j,mjkrv1q,Read up on OAuth 2.0 DPoP and challenge nonce. That should help with what you’re trying to do.,5,2025-03-25 00:34:40,detroitsongbird
programming,1jiu30j,mjiob5o,Can't I intercept the service worker request to steal the key used to sign the request?,1,2025-03-24 18:13:37,Positive_Method3022
programming,1jiu30j,mjnrm97,Oh boy I can't wait to find the security vulnerabilities with this approach.,1,2025-03-25 14:32:14,engineered_academic
programming,1jiu30j,mjnsucs,"The README states:  
*""In a production environment, use proper secure credential storage and HTTPS.""*

It suggests there are many options for secure credential storage on the client side, but currently, the only viable ones seem to be LocalStorage or maybe IndexedDB. However, both storage mechanisms are susceptible to XSS attacks. Of course, there is the good old cookie with the `httpOnly` attribute, but as far as I understand, this solution does not cater to the cookie-session paradigm.

I also read that it is supposed to help prevent replay attacks, but for that benefit, each request still needs a unique value, such as a timestamp. Meanwhile, our well-established, battle-tested SSL/TLS already provides built-in protection against replay attacks.

I don’t mean to be harsh; I’m just genuinely confused on many more levels than I’m able to articulate currently :)",1,2025-03-25 14:38:37,WindCurrent
programming,1k0okkg,mnh1zd3,"You can taste the hatred of Python in every paragraph, lol.",20,2025-04-16 20:45:19,Business-Decision719
programming,1k0okkg,mnm3cm1,Comparing Rust performance against Python and saying it is an issue on Python makes it clear the author has zero understanding of programming languages,8,2025-04-17 16:52:45,omeguito
programming,1k0okkg,mnflo0s,"Overall a decent article, but the section on ""async"" feels a bit flippant. It relies too much on outdated clichés, and is sometimes either flat-out wrong or just poorly worded.",8,2025-04-16 16:28:03,simon_o
programming,1k0okkg,mnm5lat,"A lot of blog posts mention they almost don’t use debugger. I absolutely hate how debugger sucks in Rust, and I've tried all options. Debugging async is almost impossible or the experience sucks, I hate that I don’t have inline expressions too.",2,2025-04-17 17:03:24,javasuxandiloveit
programming,1k0okkg,mnkn33p,"Yes. My experience with rust ended because of that module system. When ""cargo"" overfilled my ""/home"" partition with files that were not needed for anything. And I just wanted to compile a simple rust program and somehow link /usr/lib/libsqlite3.so together.",2,2025-04-17 12:22:15,LowEquivalent6491
programming,1k0okkg,mnhkyja,"It feels as if all those languages, C, C++, Rust, to some extent Java and Go (but both less, IMO), become increasingly complex and complicated. Now, most languages naturally become more complex when more features are added, but there should be some objective metric we could use; I would wager that, if we'd have that, C++ and Rust are probably among the most complicated programming languages (perhaps Haskell too), and C also follows close behind. (C is probably a bit simpler than both C++ and Rust because it lacks many features compared to these two; and C++ is kind of a ""subset"" in that it is also backwards compatible with C, so C++ is probably the most complex programming language. It's also successful, which is somewhat strange to me; right now #2 on TIOBE. Not that TIOBE means much but still ...)",-6,2025-04-16 22:26:52,shevy-java
programming,1jqwygg,mld8t8c,"> By some counts, there are over 200 languages that use the JVM as compilation target

I would like to know by *whose* counts, and where did they learn to count.",30,2025-04-04 13:01:58,nelmaloc
programming,1jqwygg,mlc5ze2,"> Homogeneous translations are more amenable to abstracting over parametric families of types, such as Java’s wildcards, or C#’s declaration-site variance

O_o

C# uses heterogeneous translation for generics.",27,2025-04-04 07:17:22,decoderwheel
programming,1jqwygg,mlex3l6,"The only reason why erasure is a problem is because Java's type system is half-assed. If it had no type checks but instead tagged unions (like Rust), things would look much better.

Rust structs are also type erased, but you'll never notice. And all that while it also has trait objects in cases where you want to avoid explosive code generation.",6,2025-04-04 18:11:47,flying-sheep
programming,1jqwygg,mlfir58,"Reification issues aside, Java generics are a disaster. Use-site variance--what Java calls “wildcards""--is one of the language’s worst missteps. It takes a straightforward concept (variance) and inverts it, forcing you to express it *at the point of use* instead of the point of definition. It’s backwards 99.9% of the time.

And spare me the myth that Java is just “waiting patiently” while other languages make mistakes so it can deliver the perfect version later. That’s revisionist nonsense, a post-hoc excuse for Java’s chronic feature lag. If anything, Java’s track record is littered with half-baked or completely missing features. Pick your poison: generics, lambdas, null safety, traits, delegation, member literals, properties, optional parameters, operator overloading, serialization, lazy values… the list goes on.",4,2025-04-04 20:03:19,manifoldjava
programming,1jqwygg,mlubhur,"> Existing generic code will occasionally resort to unchecked casts when it knows something about runtime types that the compiler does not, and there is no easy way to express it in the generic type system; many of these techniques would have been impossible with reified generics, meaning that they would have to have been expressed in a different, and often far more expensive, way.

It would be interesting to see examples of techniques that are impossible with reified generics.",1,2025-04-07 10:35:54,Linguistic-mystic
programming,1jqwygg,mlclao0,[deleted],-4,2025-04-04 10:01:52,N/A
programming,1jqwygg,mlbftc0,"People who think erasure is a terrible idea need to read this article from one of the most respected language designers.

Erasure is a great choice for languages that are open to evolution and interfacing with other languages.",-20,2025-04-04 03:34:29,devraj7
programming,1joyi4l,mkxmrul,"does this support  math output? Or is that not supported yet? Boy, if this does support math output and equations, it'd be stupidly nice for building up a quick math presentation. I know tools like Jupiter or colab can do it in markdown directly, but being able to output PDF and HTML document with accessible math formulas in HTML mode would be super nice.
Edit: weird spelling/grammar",3,2025-04-01 22:43:01,blind_ninja_guy
programming,1joyi4l,mkwlatw,This is bloody genius! Thank you for your hard work! Death to LaTex!,5,2025-04-01 19:23:26,randomguy4q5b3ty
programming,1joyi4l,ml2j72k,I'm using Quarto with RStudio and I have run into trouble with LateX export. Could I use Quarkdown for generating PDFs?,1,2025-04-02 18:52:48,hoedownsergeant
programming,1jlrw8j,mk5yy35,"> In modern development, Git handles version history

Correct. You don't need to document version history in comments anymore. However, documenting which version a (breaking) change was introduced in is still useful - e.g., if you're programming against some library, and you want to know which version ranges you can safely depend on, it's important to know when the APIs you are using were introduced and removed, and you want that information available in the (generated) documentation, rather than having to search through the source code in git.

> and many teams rely on self-explanatory code

Many teams *tell* themselves that their code is self-explanatory. It's usually not, at least not entirely. Documentation that just repeats what's already perfectly obvious from the code itself is bad (see the infamous ""increment i by 1"" comment), but anyone who insists that their code is 100% self-explanatory and needs to documentation whatsoever is delusional.

> Swagger (for APIs) i work with swagger in my controllers , but about other fucntions like repositories , services ect...?

Swagger (and similar documentation generators) can only show information that exists in the code; without any additional documentation efforts on your end, Swagger will only document which calls exists, which parameters they take, and what their types are. It will not tell the user anything about what those calls do, how you are supposed to use them, what edge cases there are, why they are structured the way they are, etc. There is no way around adding that information yourself.

> and IDE auto-documentation instead of manual inline documentation.

An IDE does not understand the code any better than a compiler, so just like Swagger, it can only ""auto-document"" things based on the information already present in the code, which is usually redundant. This stuff can be helpful as a *starting point* for your own documentation, providing a skeleton that contains stubs for all your methods, arguments, etc.; but that stub on its own is worthless unless you add useful information to it.

> So, is this style outdated?

This particular style, yes, but most of what it aims to achieve is still relevant.

A more modern style would:

- Omit version history information (we have source control for that)
- Put documentation that refers to specific identifiers (functions, constants, types...) close to where they are defined, rather than listing them at the top (we have documentation generators to extract this information and convert it to something human-readable)
- Omit function names from function documentation - by placing the documentation right before the function definition, this information becomes redundant, the documentation generator will extract it from the code itself
- Use a machine-readable commenting style to enable the use of said documentation generators (in many modern languages, documentation comment syntax is standardized or even part of the language syntax itself; where it's not, you should adopt a documentation generator of your choice and use the comment syntax it expects)

And even back then, stuff like this is redundant and useless:

> * BulletClass::~BulletClass -- Destructor for bullet objects. *

The name `BulletClass` already tells us that it's a bullet object, and `~BulletClass` is literally C++ destructor syntax, which means it's a destructor for bullet objects. This will be second nature for anyone who knows C++, and yet the comment regurgitates this exact information, and adds absolutely nothing else. Redundant documentation is worse than absent documentation, because it can (and thus, at some point, will) go out of sync with the code - e.g., someone might rename the bullet class, but forget to update the documentation, or someone might remove the destructor and instead rely on the default destructor, etc., but the documentation, which is now incorrect, will still be there.",41,2025-03-28 11:14:46,tdammers
programming,1jlrw8j,mk6rj9i,"> many teams rely on self-explanatory code

This is a lie people tell themselves. 

Code is never self-explanatory. Proof? Go back and read code you've written a year or two ago. You will most certainly be asking ""wait, why is this done like this?"". 

There's probably a quirk that was obvious at the time that you had to work around, but now it's lost to you and good luck trying to remember why the implementation quirk was made. 

Comments are extremely important. Updating comments is equally as important as code changes. Comments should provide ***context*** above all. The code describes the ""*how*"", but the comments describe the ""*why*"".",93,2025-03-28 14:15:05,Anodynamix
programming,1jlrw8j,mk6fm0d,"""Still Relevant"", ""old-school"", ""30-year-old [] source code"", ""modern development"", ""self-explanatory code"", ""IDE auto-documentation""

You're getting lost in the sauce.  Learn what's useful to yourself, and to your team.

Do you write javadoc/doxygen comments but they're stale and full of inaccuracies because you never use them or even build the docs to see the things so wrong the tool can detect and throw warnings? Then delete them.

Do you find generated docs so useful for quickly browsing through type definitions and function signatures that you do it even on uncommented code? Then adding some doc comments would probably make that even more powerful to you.

Having things like filenames, dates, change summaries in the file is redundant to the information in version control, but it is used even with version control tools.  Many tools have built-in clean and smudge filters (in git parlance) to edit that information into source files on retrieval.  Maybe it was an optimization before distributed VCS, maybe it's prevalence is tied to built-in support.  All I know is that it's not as popular anymore.

Even beyond just comments, there are in-code conventions that are adopted because they help a dev/team be successful.  For example RAII.  Nothing forces you to do it, it's only ""good practice"" insofar as if a dev/team tends to make errors that RAII prevents then it may be worth adopting.

In general, play it safe by sticking to the conventions of the project you're in, or the modern style for the language you're using.  Once you've done it long enough your experience will develop a sense of taste and knowing where your own common pitfalls are.",5,2025-03-28 13:09:00,old-toad9684
programming,1jlrw8j,mk85ywg,"The updated date and by who is outdated. However, the rest of it that describes what it does and the parameters it takes is absolutely not outdated. You should have something like that on all functions that are part of the API of the code (so in OO programming all public methods).

Most languages have support for this: 

* Java -- JavaDoc
* Python -- Docstrings
* JavaScript -- JSDoc
* Kotlin - KDoc
* Rust - Rustdoc

etc.

When the command and conquer code was released I looked at it and was quite pleased to see those comments in there that explain what it did and the parameters it takes. Makes it so much easier to figure out what is going on.

> self-explanatory code

Bullshit.",3,2025-03-28 18:20:48,wildjokers
programming,1jlrw8j,mk63f4m,"Having documentation available is almost always better than no documentation. (One can reason that incorrect and/or outdated documentation may be worse, and there is an argument for that, but even then I prefer this over no documentation.)

> So, is this style outdated?

So I would not call this documentation to be outdated.

I also think it should not matter whether git/github exists or not - the documentation and intrinsic quality of documentation should always be specific to the project at hand. Conversely, if github exists, and people remove documentation like that, then in my opinion this leads to a worse project (assuming the documentation is correct; if the documentation in itself is a joke, then removing it would actually be beneficial, but most documentation, such as this one here, is correct or mostly correct).

> In modern development, Git handles version history, and many teams rely on self-explanatory code

One of my simple rules is: if a team or a developer claims the code is self-explanatory, then this team or developer needs to be let go. Because code is NEVER self-explanatory, and that includes for instance ruby code. Ruby code can be super-natural, close to the problem domain via some kind of DSL (such as in rails). None of this is an excuse for omitting documentation, so anyone who claims ""my code is self-explanatory"", has to be removed from any important project at once. These people just find excuses for laziness - it is how the mind works. On top of that, code can be wrong, so ""self-explanatory code"" does not apply in this case; and often code can be written in different ways, so people may ask WHY that code was written in a particular manner. These are all reasons as to why documentation has to exist. (Whether this is in the same file, or elsewhere, is secondary; I usually begin to write some specification and documentation up front, at the least if a project becomes large. For small projects it is indeed often just easier to begin to write code and adjust as you go, then write the documentation. I am lazy too but I don't reason that omitting documentation is ever a good thing - documentation is almost as important as code, in my opinion. The style of documentation is also important, but as a secondary consideration. Personally I do like in-source-file documentation too, but I understand people who may decide to document things elsewhere; but often, there is simply no documentation at all and people abandon projects without ever writing any documentation.)

Case in point, by the way: I am currently revisiting opal (in ruby), because JavaScript annoys me to no ends. Opal's website can be found here:

https://opalrb.com/

I read it first in the past, years ago; I am now re-reading it. And I have to say ... if ruby projects continue to have such horrible substandard quality, I am no longer surprised that ruby is no longer among TIOBE top 20, sorry. Ruby is a great language, but the lack of documentation in various projects, is really just telling people to use python instead and be done with it. I don't understand why the ruby core team does not acknowledge this as one primary problem in the larger ruby ecosystem (I am aware it is not their fault, since these are of course external projects, nor am I implying that every single ruby project has such poor documentation, but this is not the only example here, just look at sinatra - I don't understand why so many ruby projects have a total joke of a documentation. There are of course exceptions too; rails has high quality documentation really, or Jeremy's projects, such as sequel, also have excellent documentation or at the least very good documentation. This should become a strict requirement in ruby really, aka ""if you lack documentation, you can no longer invoke the ruby parser"" - that would get people to commit towards better documentation really. Not that it would lead to a resurgence in popularity though ... but seriously, if ruby wants to be more relevant, then it HAS TO IMPROVE THE DOCUMENTATION SITUATION IN GENERAL, everywhere.)",9,2025-03-28 11:49:33,shevy-java
programming,1jlrw8j,mk8i54i,"This post set me off with the title.    Git fist and foremost is a Source Code Management system, it IS NOT a documentation system!!!!!!!   Sure Git provides a way to document commits but that has little to do with documentation of code.   Beyond all of that and possibly more important; commit comments are not contemporaneous with your code.  That is you can not read a comment inline with the code that comment impacts.

The concept of self documenting code is fine, in fact it is a great idea, in my day your where taught to write idomatic code which similarly refers to lucid easy to read code.   However code can do a perfectly good job of documenting itself but punt on the WHY?    Often it is the why that is important and forgotten.   

The ""why"" may or may not need to go into the SCM systems commit note but if it isn't in the code text you may never know that a why exists or be forced to take a long detore into the SCM system to try to find the why.   Frankly I can't understand why anybody would want to spread important information about how a piece of code works all over the place.",3,2025-03-28 19:21:12,spinwizard69
programming,1jlrw8j,mk9tx07,"Even if it's possible to dig the information out of the git history, anyone reading the file still needs to know that information *exists* before they'll even try searching, and the more a file's actively changed, the more that history will be cluttered with unrelated commits.

Mentioning the most important items inline? A form of caching, and adds additional metadata about the importance of specific issues. If you've ever heard an anecdote about a database query that used to take hours, cut down to minutes just by adding one carefully-thought-through index, how much more valuable would something that saves hours of *programmer time* be?",1,2025-03-28 23:31:53,Uristqwerty
programming,1jlrw8j,mkao4kc,"It's still appropriate for a module header comment to state the module's reason for being, plus copyright and perhaps first author.


All those per-method comments belong with the methods, and should generally be either longer, or excised if they only state the obvious (like the ""delete"" method.)


What's more interesting is how a team links its modules with the relevant design information and with the bug tracking system. Git doesn't just contain the date and author of each change, it also has to tie commits to the REASON for each change. This is true regardless of what source code control system you use.",1,2025-03-29 02:30:49,Leverkaas2516
programming,1jlrw8j,mkavld1,"Comments in code give much needed context that was understood at the time it was written but often long forgotten months or years later.

I write comments in code when I think it’s useful to understand WHY a piece of code is there.

“Self documenting code” is a misnomer. What people are saying is that you generally don’t need to write down WHAT the code is doing because people can read the code.

It doesn’t explain WHY it’s there",1,2025-03-29 03:20:40,NiteShdw
programming,1jlrw8j,mkbdbo1,"The Files are all caps and under 16 characters long, DOS.",1,2025-03-29 05:43:26,fryerandice
programming,1jy57q7,mmxk4jy,Amen to that! The number of systems and programs I see where people decouple for the sake of decoupling until the codebase becomes cryptic and unnatural to follow.,19,2025-04-13 18:01:06,alim0ra
programming,1jy57q7,mmxyxdl,"I would argue that, to a certain degree, loose coupling is just a natural consequence of getting cohesion right.",8,2025-04-13 19:19:22,pdpi
programming,1jvxk5r,mmkhd6n,Anyone actually using this in production ?,4,2025-04-11 14:29:02,running101
programming,1jr3xz7,mlbthng,Kudos for the great content and animations! Keep doing more of those,4,2025-04-04 05:23:00,DevGrohl
programming,1jr3xz7,mlbrriw,This is exactly the hard hitting programming content I come to /r/programming for.,7,2025-04-04 05:07:54,BlueGoliath
programming,1jr3xz7,mldpq14,"I’ll be honest, I’m not sure I understand the premise of the article - the behavior of the example at the start and in the conclusion is indistinguishable from one another. What am I missing?",1,2025-04-04 14:35:38,Chisignal
programming,1jzt762,mna9pn7,Can't wait for someone to get origami to run Doom.,19,2025-04-15 19:25:40,BennyLee
programming,1jzt762,mn8u20g,"> While it is likely that rigid origami is also Turing complete as a computational device, to our knowledge
no one has proven this. The crease patterns and gadgets in the present work are not rigidly foldable and
therefore could not be used as-is in such a proof.

Might as well give it a go if you need an academic publication under your name.",14,2025-04-15 15:09:37,Skaarj
programming,1jxo0gz,mmsolod,"The Blackboard pattern is underutilized in modern system design, especially for high-performance, low-latency applications. This implementation is particularly interesting because it addresses several common challenges with IPC:

1. The zero-copy approach eliminates a major performance bottleneck in traditional message passing
2. The shared memory design avoids serialization/deserialization overhead
3. The architecture supports both one-to-many and many-to-many communication patterns

I've seen similar patterns implemented in high-frequency trading systems where nanoseconds matter. The key insight is treating memory as a communication mechanism rather than just storage.

One challenge with this approach is handling process crashes - when a process dies while holding a lock or mid-write, recovery can be complex. Some production implementations add fault tolerance through watchdog processes or transaction-like semantics.

For those interested in this area, it's worth also looking into lock-free data structures and memory-mapped files as complementary techniques. The LMAX Disruptor pattern also solves similar problems with a slightly different approach.",12,2025-04-12 21:16:09,traderprof
programming,1jxo0gz,mmvl5ue,"More examples and more code than actual description of the pattern ...

It'd be helpful to start with a description of the pattern (e.g. the data structure and its api), then discuss how it applies to the examples provided. All I got was that two very different scenarios require a shared global state and that the blackboard pattern somehow addresses that.

So it's a shared in-memory key-value store with subscriptions at the key level? What are the downsides? How are concurrent writes handled? What's the consistency model?",4,2025-04-13 10:56:58,GeorgeS6969
programming,1jjmqmj,mjowjhs,"I was surprised by the [Finding a good order to visit the graph is difficult](https://v8.dev/blog/leaving-the-sea-of-nodes#finding-a-good-order-to-visit-the-graph-is-difficult). Namely the following:

> With Sea of Nodes, it’s not possible to process pure instructions from start to end, since they aren’t on any control or effect chain, and thus there is no pointer to pure roots or anything like that. 

I've had the complete opposite experience. With some (granted) annoyingly laborious upfront work to designate some ""_holy_"" Node/Edge types and ensure you constructors respect their invariant you have have a say, `AdditionPrototype` whose outgoing edges are `AdditionOp`, which link to every Addition within the SoN. 

You repeat this enough and checking if a peephole optimization can/cannot be applied amortizes to `O(1)` as you're only indexing into nodes which at a bare minimum have the operation that qualifies for the transformation.",7,2025-03-25 17:41:18,valarauca14
programming,1jjmqmj,mjo8ny8,"At the end:

> So, after ten years of dealing with Turbofan and battling Sea of Nodes, we’ve finally decided to get rid of it, and instead go back to a more traditional CFG IR. Our experience with our new IR has been extremely positive so far, and we are very happy to have gone back to a CFG: compile time got divided by 2 compared to SoN, the code of the compiler is a lot simpler and shorter, investigating bugs is usually much easier, etc.",7,2025-03-25 15:57:16,self
programming,1jjmqmj,mjo8v6v,"blah, flubbed the title.",4,2025-03-25 15:58:15,self
programming,1jjjurj,mjp01at,"The question of hardware is interesting to me. It's unlikely that you're going to be able to create a CPU or a stick of RAM from scratch. So a 100 year computer would need to be made of software that can run on hardware you can find. While I agree that ""x86 has probably run its course"", if you start the 100 year clock today, you're more likely to have regular access to x86 CPUs. I guess ARM SoCs in smart phones might be even more ubiquitous, but they would be much harder to leverage for a general purpose device, I think. 


As much as I love RISC-V as an open standard, I don't think supply is there. 


Another interesting angle is the interoperability of hardware. A CPU is no good if you can't find a motherboard for it. From my experience restoring some old computers, tracking down a motherboard can be the hardest part. I don't know enough here to make an educated guess, but it makes me wish there was a way to make a motherboard that was designed to be jerry-rigged to whatever parts you can find.",12,2025-03-25 17:57:58,MrRufsvold
programming,1jjjurj,mjo2n5n,This is an amazing piece - and just in time since I am just starting cyberdeck project and this is basically a full fledged PRD (product requirements document) for a post apocalyptic computer!,6,2025-03-25 15:27:58,wrong-dog
programming,1jjjurj,mjrr6bq,I like this guys style of writing/postulating. It reminds me a lot of solar sands on YouTube. Really fun thought experiment,1,2025-03-26 02:35:07,amestrianphilosopher
programming,1jjjurj,mjpu2dv,If society collapses it would be precisely because of some orwellian terminator endgame. So please don't recreate computing ever again.,2,2025-03-25 20:24:04,st4rdr0id
programming,1jil5uw,mjg3paz,Tl/dr: not much,19,2025-03-24 08:20:22,bert8128
programming,1jil5uw,mjh2imj,That second diagram in the article makes absolutely no sense and the first clearly explains how the application components interact. So maybe you should stick to Archimate after all.,5,2025-03-24 13:22:38,no-ai-no-cry
programming,1jil5uw,mjho6gp,"UML needs to come back as standard way of documenting software  
and this is a good start

I like the idea - UML standard boxes are bad looking, but the way to solve this is  
customizing and stereotyping the boxes with default icon sets or custom icon sets

It isn't Archimate bad, but it there isn't customization which is valid concert given the fact diagrams have to be presented to someone with little or no IT knowledge",0,2025-03-24 15:18:54,gjosifov
programming,1jy78vm,mmwv6zb,"Well some people are just better than I am at this programing lark. ""I'm going to define my own executable format that allows zero-length files to return a value based on the ASCII of their filename. And I'm going to use a crown emoji as the extension. Why? Why not?"".

So making a file with an asterisk as the filename (ASCII 42, and also just a fundamentally evil concept anyway) does the following

    $ touch '*.♚'
    $ chmod +x '*.♚'
    $ './*.♚'
    $ echo $?
    42

diabolical. Wish I had thought of it",9,2025-04-13 15:52:56,Advanced-Essay6417
programming,1jvi6sd,mmaj99w,"Doesn't HTTP3, (ie QUIC) , solve this already?",5,2025-04-09 22:29:58,Lachee
programming,1ju880g,mm039ho,"People like Shannon and Conway are brilliant moments of hitting a ""singularity"".",3,2025-04-08 08:19:04,bluefourier
programming,1ju880g,mm3t8il,"Huh, wild smullyan reference.",1,2025-04-08 21:24:47,Blecki
programming,1jsx4ef,mlq6e28,"This discussion reminds me of assurance levels from when I worked in aerospace. Based on the criticality of how a system was intended to be used, it would be assigned an assurance level, which would dictate the rigor needed in the development process, covering things like what activities were necessary, what activities needed to be done with independence, and what artifacts needed to be available to demonstrate that the activities were done. The assurance level would need to be met or exceeded by everything in the system, from operating systems up to custom software. If you didn't know the assurance level or an element was at a lower assurance level, there were ways to ""backfill"" the missing steps through various verification and validation activities.

This is also where the concept of software of unknown pedigree or software of unknown provenance comes in. For a lot of software, especially general-purpose software, you don't know who built it, how it was built, or have any assurances about its quality or fitness for a particular use. This can require a lot of effort, to the point where it could be easier and cheaper to build custom solutions.

It is crucial for software product development organizations to understand their current and possible future customers, especially when making software packages targeting horizontal markets. Awareness and informed decision-making can help open up new markets for tools. Even if the development organization isn't targeting safety-critical applications, understanding how their product could be used in these contexts and thinking about what could be done to ease customers' legal and regulatory burdens can lead to new business.

Going to the specific example, tools like [MATLAB have tool qualification and certification packages](https://www.mathworks.com/help/slcheck/tool-qualification-and-certification.html) that make it easier for the user to get the information they need to use in contexts requiring assurance more easily. But these don't have to be provided by the tool creator. Some companies have done a lot of the legwork to put together the packages for some open-source tools. But other tools haven't had anything done at all, so you'd either have to avoid them or put in the effort.",29,2025-04-06 17:10:44,TomOwens
programming,1jsx4ef,mlprsu5,"I know, let's put 'AI' on the problem.

[Now you have two problems](https://regex.info/blog/2006-09-15/247).

[Reified reference](https://xkcd.com/1171).",3,2025-04-06 15:51:57,church-rosser
programming,1jsx4ef,mlqdymd,"For anyone that wants to study these questions seriously; these are not answers you have to dream up yourselves. There are all sorts of standards that regulate how to use and develop software in a safety-critical context. 

An example is [ISO 13849](https://en.m.wikipedia.org/wiki/ISO_13849). Doesn't tell you much without the surrounding related standards though. 

On a deeper level, there's e.g. MISRA C, which tells you what you have to do to actually code safe software in C. A few other alternatives exist. 

Looking at MATLAB specifically, it has the ability (with the right licenses of course) to generate C code that follows MISRA C, and can be used in a safety-critical product, if all rules and regulations are followed. Plenty of automotive systems are coded in MATLAB.",6,2025-04-06 17:50:03,Etni3s
programming,1jsx4ef,mlpxq3m,"Software by itself is a sequence of 1s and 0s.  It only contributes to hazards when it's surrounded by a system that interacts with the physical world.  It's the system that gets evaluated for safety.

The distance from the software's output to the hazard determines how much effort needs to be employed to verify the software's correctness and robustness.  For example, if people directly take the spreadsheet output as gospel, then it would need to be developed at the highest software assurance level.  If there are independent calculations being done, then the software assurance level may go down.

All code on the computer system that interacts with the physical world is part of its overall software, so it can all potentially contribute to a hazard.  Thus, Excel and MATLAB in the examples would be part of the software that would need to be evaluated.  Since those programs aren't written to any safety assurance level for any standard, they are poor choices for implementing the safety-significant function.

Lots of software can become unintentionally safety-critical such as databases.  Case in point: a medical database that stores the patient's blood type.  Failure to produce the correct result may be fatal during a blood transfusion.",3,2025-04-06 16:24:12,gpcz
programming,1jsx4ef,mlu8jcc,"This raises an interesting point:

> If calculating dosages in a spreadsheet is too dangerous, what would we recommend instead?

Using a pocket calculator, phone or even doing the calculations in your head are probably no less prone to error... Having a ""don't use Excel for safety-critical calculations"" policy could easily lead to _more_ errors.

I do note that the spreadsheet shown does have a ""checked by"" column; presumably the associated procedures would ensure that another competent individual checked the calculations by _a different method_. Additionally, the checker should probably be experienced enough to know instinctively what the right ""ballpark"" dosages are.",1,2025-04-07 10:06:54,mallardtheduck
programming,1jsx4ef,mlundw9,"You don't delegate safety to software and you don't present software in a way that might lead humans to think you have. 

Most people understand how Excel does math. People who work with fentanyl dosing know the risks associated and have been trained to verify these. 

A common error is messing up unit conversions, particularly between milligrams and micrograms, and the difficulty representing the Greek mu character in systems with ASCII character encoding (yes they still exist). 

So the Institute for Safe Medication Practices recommends that micrograms be represented in clinical systems as mcg instead of with the IU standard mu. 

Some systems enforce this, but all trained professionals check this, every time.",1,2025-04-07 12:12:35,spinur1848
programming,1jl8zxk,mk540bk,For anyone curious it is about 75k pages.,3,2025-03-28 05:56:54,nivvis
programming,1jl8zxk,mk54i4c,"Did you figure out who did it?? Hah. Cool stuff though. I was just doing something similar.

You should check out building a knowledge graph, there’s a lot of interesting new ideas and tooling there.

For semantic, is pinecone just abstracting something like rerank search, or? If not you might consider semantic + rerank, though maybe that works better for something like code. How are people liking pinecone btw? Been using qdrant and it’s fine — fast but pretty barebones. Also tried some of the Postgres tooling and it’s pretty decent.

I was just processing 40k pages overnight (the original McClellan Committee / Teamsters archive) and am debating what to do with it. I think I will try some sort of hierarchical summary maybe + RAG.

Cool stuff.",2,2025-03-28 06:01:44,nivvis
programming,1jl8zxk,mk8whke,We need an LLM for this.,-1,2025-03-28 20:32:33,dhlowrents
programming,1k2b2ee,mnufti4,"I'm always surprised no one elaborates on the big gotcha with `set -e` the post mentions where it doesn't work if youre in a conditional. idk I don't have a good example ready but let's pretend we're wanting to create a bunch of files in a specific directory and rely on `set -e` to bail out early and not create files if we can't actually get into the directory we want.

    set -e

    mkdir blah
    cd blah
    touch bunch of files within blah

It's gonna stop if `blah` already exists and is not a directory like we'd want:

    $ bash ~/foo.sh
    mkdir: cannot create directory ‘blah’: File exists
    $ ls
    blah

Now pretend we're trying to be extra tidy about it and put everything into a function, so we can easily check if it succeeded:

        foo() {
                set -e

                mkdir blah
                cd blah
                touch bunch of files within blah
        }

        if ! foo; then
                echo >&2 ""couldn't create a bunch of files within blah""
        fi

Then everything is a mess because it created those files in the current directory:

    $ bash ~/foo.sh
    mkdir: cannot create directory ‘blah’: File exists
    ~/foo.sh: line 5: cd: blah: Not a directory
    $ ls
    blah  bunch  files  of  within

Obviously you don't want `set -e` to cause the script to exit when you do, like, `if thing-that-sometimes-fails; then`, but completely breaking it in any environment that's not even lexically within the conditional is such a big limitation on program structure I'm surprised it's not discussed more.",7,2025-04-18 23:42:08,ben0x539
programming,1k2b2ee,mo2qwii,"Common shell script mistakes:

1. Not using ShellCheck",3,2025-04-20 11:38:26,XNormal
programming,1k2b2ee,mo4b1zk,The biggest mistake is using shell where you need a real language.,1,2025-04-20 17:15:39,gofl-zimbard-37
programming,1k2b2ee,mo2cihh,"I honestly don't write bash scripts anymore, if a problem is too complicated for AI to figure out in a couple of prompts then it probably shouldn't be a bash script.",-1,2025-04-20 09:13:35,bigdamoz
programming,1jsqato,mlpwa94,fun read,8,2025-04-06 16:16:24,press0
programming,1jsqato,mltb292,"Too bad there was no resolution. Not saying the author had to, but without it it feels pretty depressing. But great observation on why the process feels so broken.",5,2025-04-07 04:27:42,reddit_wisd0m
programming,1jsqato,mltxmds,"Interviewing is hard, making a mistake is catastrophic, and there's no clear best practices. It's why referrals are given so much weight - in a sea of strangers, even an average acquaintance stands out.",5,2025-04-07 08:05:51,hbarSquared
programming,1jsqato,mltr6vv,"Interview process is a job

The more interview process looks like the actual job, the less it will fell like a job - because it just 2-3 hours of the usual job you are already doing at your current job

However, the interview process is created by people who don't do the real job and they are just copy pasting from the internet - how big companies are doing their interview process, while giving less money then the big companies

Is interview process broken ?  
Yes

Can we fix it ?

Well, in order to fix it - you need to hire competent people that know what the hell is going on in your company and hire them with your current interview process

  
and there a lot of incompetent people who think they know how to do interview process",4,2025-04-07 06:56:43,gjosifov
programming,1jjqwax,mjqdihb,"    SetProcessMitigationPolicy(ProcessSignaturePolicy, MitigationOptIn);",-4,2025-03-25 22:00:40,Top_Meaning6195
programming,1jplgsq,ml53yt2,"The only thing I didn't get: was it a dedicated native window? Because usually in web world (chrome/cef/electron/etc) popups aren't native windows but just a piece of html with a different z-offset rendered within the main content window. And obviously, you wouldn't see a popup in Spy++.",1,2025-04-03 03:16:51,ioneska
programming,1jplgsq,mla4yri,Does it prevent changing Teams status? Asking for a friend.,1,2025-04-03 22:41:14,randomlogin6061
programming,1jplgsq,mla8wj1,"One of the ones I've seen over & over again, just using powercfg is the steam application. Not always, I think it has something to do with the embedded web view on the store page marking the process with ""thou shalt not sleep"" and crashing or unloading before it can undo",1,2025-04-03 23:03:45,tswaters
programming,1jplgsq,ml53gbb,"TLDR:

* playing a video prevents sleep (an obvious feature of all video players) 
* closing a window in CEF doesn't release its resources (well, it's electron - what else would you expect)",-1,2025-04-03 03:13:23,ioneska
programming,1k2b02n,mnwsyzf,"> The net result of this is that with only a **tiny amount of extra thought** you get garbage collection **for free**. Extend this to other concepts in your program with the **appropriate use of Pool allocators, Bucket allocators, and the likes**, and suddenly you get impressive performance improvements and a **fair amount of memory safety** for very little effort. 

this isn't garbage collection or memory safety, this is using memory allocators lol",50,2025-04-19 11:28:21,floodyberry
programming,1k2b02n,mnub8ck,"Some weird takes in this. The interface example is precisely not an interface since it copying the data layout of a type and interfaces are precisely useful because they decouple the data from the transformation 

The author seems to indicate that raii is a downside when it's one of the few things that C++ actually did really well? `defer` not only is something you can forget, but also makes code harder to read if you use it as you're supposed to (that is, far away from actual construction since presumably that's advantage of decoupling it from construction) 

On a more subjective note it seems jai doesn't support sum types? That's a huge downside. Also, `foo :: (x: [$N]$T)`  is hella ugly",34,2025-04-18 23:14:42,teerre
programming,1k2b02n,mnzbbat,"If you tried Zig and thought, “I like this but it needs to be closed-source and have an insufferable, condescending creator & no community,” then Jai is for you!",40,2025-04-19 20:08:48,Capable_Chair_8192
programming,1k2b02n,mo2smcu,"> no RAII in 2025

🤦‍♂️",9,2025-04-20 11:52:45,SuperV1234
programming,1k2b02n,mo5nd8w,"> It’s a serious language being made by adults, for adults. For serious programmers, by serious programmers.

Lol, lmao. We've already got Common Lisp, the ideal language for ""recursion and condescension"".

We don't need another. I'm surprised the author didn't mention Blub languages.",3,2025-04-20 21:39:44,BroBroMate
programming,1jz0and,mn4nvhu,"C vs. Pascal was a major component of the Windows vs. Mac developer community conflict up through the 90s.

Pascal did evolve over time, and plenty of serious applications were developed with it. Early versions of Mac OS (up through, if I remember right, System 7.5) featured a lot of Pascal, especially in the extensive developer documentation.

Pascal developers loathed C's messy syntax and there were quite a few die-hards who tried to keep the language vibrant. I was one of them!

I still remember going to a local Mac Users Group meeting in the early 90s, and learning about object-oriented programming for the first time. Pascal quickly made the jump (""Object-Oriented Pascal"", of course). I thought it was all terribly dumb, but that was in part because early advocates for OOP insisted that objects could only interact by passing ""messages"" to each other. Early OOP was slooooow.

In those early days of computing, Pascal's length-prefixed strings were pretty nice, up until you had to come up with clever ways around the 255-byte limitation. Still, C's null-terminated strings seemed like a terrible idea (and still do).

It was a nice language for simple console-based programs. There was minimal fuss needed to just accept some input, do something with the input, and print some output.",24,2025-04-14 21:16:13,gottago_gottago
programming,1jz0and,mn30ezy,I only programmed in later version of Pascal/Delphi. There the issues with `string` were not relevant as you treat it as an opaque type. I'm remember sorting just working. So the `The size of an array is part of its type` issues were solved as well (I assume at the language level).,6,2025-04-14 16:19:02,Skaarj
programming,1jz0and,mn7f5g6,"You can have complaints about Pascal, but this largely reads like a C user whining that Pascal is not C.",5,2025-04-15 09:25:04,simon_o
programming,1jz0and,mn9r1w6,"Standard Pascal was a rubbish language.  Standard C would have been rejected as equally rubbish if the definition of ""conforming C program"" didn't allow programmers to exploit all of the ways in which practical C implementations behaved more usefully than the Standard required.",2,2025-04-15 17:51:52,flatfinger
programming,1jz0and,mn7qq40,"What a shitty paper, honestly.

Extremely shallow.

More of a c programmer’s rant of not adapting to a different language.",-1,2025-04-15 11:15:20,therealdivs1210
programming,1jz0and,mn7rrky,"Is it true that pascal doesn’t have array routines?

This sounds like a really bad design decision, and one that would show it’s ugly consequences soon enough to be corrected.

I have a feeling the author of the paper didn’t find the pascal way of doing things?",0,2025-04-15 11:23:30,therealdivs1210
programming,1jz06gy,mn2ipv7,"Pretty cool! Who is the target audience?

When I think lua, I think scriptable clients like game devs might use to control a critter. I don't think artists and non-technical collaborators would have an easier time with fennel, but this is my first time looking at the project.

I'm excited to take a closer look. This is a fun project",21,2025-04-14 14:49:47,pbNANDjelly
programming,1jz06gy,mn4zvcp,There can never be enough lisps out there,2,2025-04-14 22:22:43,AcanthisittaScary706
programming,1jz06gy,mn74wek,I’m afraid I find [Moonscript](https://moonscript.org/#overview) more bitchin’,2,2025-04-15 07:32:23,Linguistic-mystic
programming,1jz06gy,mnb14jr,"As a gamedev programmer, I see the benefit. Lua is usable anywhere and lisp is great at making dsls, which is very useful.

For example, I believe Naughty Dog uses their own flavor of lisp and they use it for a wide array of things AI, Animation, Scripting etc",2,2025-04-15 21:43:39,totallytroy
programming,1jz06gy,mn2icbb,"Looks like a fun project, but honestly I cannot take seriously anyone who wants to write lisp for anything serious. I have tried doing this myself and it was miserable.",5,2025-04-14 14:47:52,Awesan
programming,1jz06gy,mn6fow8,"Everytime I look at a Lisp language, I think giving it a chance. But then, it's like, you gotta switch to Emacs, or use a complicated plugin that messes all your keybindings, and setup the REPL, and it's just a pain to deal with.


I guess it's just beyond my grasp. 


Like the idea of the project though.",1,2025-04-15 03:40:29,nelmaven
programming,1jz06gy,mn3byj7,This subreddit is just bots commenting to bots arguing about AI,-11,2025-04-14 17:16:27,NoleMercy05
programming,1jz06gy,mn2eob1,Tldr or no one is clicking that,-47,2025-04-14 14:28:42,NoleMercy05
programming,1jvssmp,mmcuvwm,"That was a good read. Really interesting!

> While many frameworks push for totally decentralized designs, iroh strategically incorporates limited centralization

How does that work?",7,2025-04-10 08:39:36,imported_username_
programming,1jvssmp,mmhulfa,Love that it’s likely named after uncle iroh ( maybe ),1,2025-04-11 02:00:32,flarthestripper
programming,1jvssmp,mmcud0f,Great post!,0,2025-04-10 08:33:38,ThenTumbleweed4474
programming,1jvssmp,mmfwlps,Impressive technology,0,2025-04-10 19:32:33,faustoc5
programming,1k4ixn9,moekhef,"The implicit subtext here is that somehow Zig has a tasteful subset of comptime.

However, Zig’s comptime is remains fairly opaque to IDEs. In particular because types are created at compile time, an IDE will struggle to do simple refactorings.

Secondly, Zig’s ”only check what is traced to be used” (so that a function which isn’t detected to be called will not be semantically, checked - it’s like a macro that’s never called: it can look like almost anything) is both novel and bad. This latter thing is acknowledged in blog post but not highlighted.

This essentially means that Zig drops to a dynamic scripting language in terms of what one can infer by something compiling (as most people knows, uninvoked code in scripting languages aren’t even guaranteed to compile)

This is by design, as this is Zig’s way to implement conditional compilation.

Zig *could* have chosen to do conditional compilation in a more clear and conventional way, but this too is ”things that Zig comptime won’t do”: being clear about what code is actually type checked.

The conflation of runtime and compiletime code in if statements, and this ”branches/functions not taken are not checked” makes Zig comptime unnecessarily difficult to read.

(Disclaimer: I did in the past submit feedback on Zig issues to improve the readability of Zig ”comptime”. When I later started working on C3 I made sure that it would be extremely clear as to what was runtime and what was compile time code)",13,2025-04-22 09:44:39,Nuoji
programming,1k4ixn9,moav8pr,"Just a small detail, in the ""No #eval "" section it starts mentioning D's mixins, then says:

> Zig has a completely different feature, partial evaluation/specialization, which, none the less, is enough to cover most of use-cases for dynamic code generation.

Then proceeds to describe how to use `comptime` as a keywork in parameters. So it seems like he assumes that in D you would use `mixin` in order to get that variable evaluated at compile time?

But nobody would do that, in D you just use `static if` (evaluate the condition at compile time). Once you do `static if` (or static foreach, or static assert) on a variable, it will be evaluated at compile time.",5,2025-04-21 18:56:18,EnUnLugarDeLaMancha
programming,1k2ayyz,mnwv5gd,Love this. Any other relevant repos which are equivalents for this for other languages?,0,2025-04-19 11:46:40,RamboCambo15
programming,1joh0xq,mkszyd4,"Looks like a very cool language.
The docs are very straightforward and include crucial things like

- interop with racket
- building standalone executable
- how to unit tests, etc

Just one question to OP, are there any performance benchmarks?",7,2025-04-01 04:07:00,getaway-3007
programming,1joh0xq,mkt5ryr,Didn’t find the “error handling” chapter in the reference. Does Rhombus prevent all errors?,5,2025-04-01 04:54:50,Linguistic-mystic
programming,1joh0xq,mkze5pn,"Seems to provide the syntaxic simplicity of javascript and python with the guidance of typescript, all while maintaining scheme semantics. Pretty cool",3,2025-04-02 06:00:16,funkie
programming,1joh0xq,mkrp430,"Rhombus is ready for early adopters.  
Learn more and get it now at [https://rhombus-lang.org/](https://rhombus-lang.org/)",3,2025-03-31 23:08:41,sdegabrielle
programming,1joh0xq,mktbaef,Year of the Rhombus esolang.,0,2025-04-01 05:46:05,BlueGoliath
